question_text,company,difficulty,question_type,topics,source,answer_text,created_at
"More Data: Generally reduces variance, but can also help a high-bias model better capture underlying patterns.",,medium,stats,,Devinterview-io/data-scientist-interview-questions,,2025-11-17T10:49:35.639618
Feature Selection/Engineering: Aims to reduce overfitting by focusing on the most relevant features.,,medium,coding,feature_engineering,Devinterview-io/data-scientist-interview-questions,,2025-11-17T10:49:35.639658
Simpler Models: Helps alleviate overfitting; reduces variance but might increase bias.,,medium,stats,,Devinterview-io/data-scientist-interview-questions,,2025-11-17T10:49:35.639684
"Regularization: A technique that adds a penalty term for model complexity, which can help decrease overfitting.",,medium,ml,,Devinterview-io/data-scientist-interview-questions,,2025-11-17T10:49:35.639712
"Ensemble Methods: Combine multiple models to reduce variance and, in some cases, improve bias.",,medium,stats,ensemble,Devinterview-io/data-scientist-interview-questions,,2025-11-17T10:49:35.639737
"Cross-Validation: Helps estimate the performance of a model on an independent dataset, providing insights into both bias and variance. <br> ## 6. Explain the concept of _Cross-Validation_ and its importance in ML. Cross-Validation (CV) is a robust technique for assessing the performance of a machine learning model, especially when it involves hyperparameter tuning or comparing multiple models. It addresses issues such as overfitting and ensures a more reliable performance estimate on unseen data. ### Kinds of Cross-Validation",,medium,stats,,Devinterview-io/data-scientist-interview-questions,,2025-11-17T10:49:35.639810
Holdout Method: Data is simply split into training and test sets.,,medium,ml,,Devinterview-io/data-scientist-interview-questions,,2025-11-17T10:49:35.639831
"K-Fold CV: Data is divided into K folds; each fold is used as a test set, and the rest are used for training.",,medium,ml,,Devinterview-io/data-scientist-interview-questions,,2025-11-17T10:49:35.639857
"Stratified K-Fold CV: Like K-Fold, but preserves the class distribution in each fold, useful for balanced datasets.",,medium,stats,probability,Devinterview-io/data-scientist-interview-questions,,2025-11-17T10:49:35.639882
Leave-One-Out (LOO) CV: A special case of K-Fold where K equals the number of instances; each observation is used as a test set once.,,medium,mixed,,Devinterview-io/data-scientist-interview-questions,,2025-11-17T10:49:35.639919
"Time Series CV: Specifically designed for temporal data, where the training set always precedes the test set. ### Benefits of K-Fold Cross-Validation - Data Utilization: Every data point is used for both training and testing, providing a more comprehensive model evaluation. - Performance Stability: Averaging results from multiple folds can help reduce variability. - Hyperparameter Tuning: Helps in tuning model parameters more effectively, especially when combined with techniques like grid search. ### Code Example: K-Fold Cross-Validation Here is the Python code: `python import numpy as np from sklearn.model_selection import KFold # Create sample data X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]) y = np.array([1, 2, 3, 4, 5]) # Initialize K-Fold splitter kf = KFold(n_splits=3) # Demonstrate how data is split fold_index = 1 for train_index, test_index in kf.split(X): print(f""Fold {fold_index} - Train set indices: {train_index}, Test set indices: {test_index}"") fold_index += 1 ` <br> ## 7. What is _Regularization_ and how does it help prevent _overfitting_? Regularization in machine learning is a technique used to prevent overfitting, which occurs when a model is too closely fit to a limited set of data points and may perform poorly on new data. Regularization discourages overly complex models by adding a penalty term to the loss function used to train the model. ### Types of Regularization #### L1 Regularization (Lasso Regression) $$ \text{Cost} + \lambda \sum_{i=1}^{n} |w_i| $$ L1 regularization, also known as Lasso (Least Absolute Shrinkage and Selection Operator), adds the absolute values of the coefficients to the cost function. This encourages a sparse solution, effectively performing feature selection by potentially reducing some coefficients to zero. #### L2 Regularization (Ridge Regression) $$ \text{Cost} + \lambda \sum_{i=1}^{n} w_i^2 $$ L2 regularization, or Ridge regression, adds the squared values of the coefficients to the cost function. This generally helps to reduce the model complexity by constraining the coefficients, especially effective when many features have small or moderate effects. #### Elastic Net Regularization $$ \text{Cost} + \lambda_1 \sum_{i=1}^{n} |w_i| + \lambda_2 \sum_{i=1}^{n} w_i^2 $$ Elastic Net is a hybrid of L1 and L2 regularization. It combines both penalties in the cost function and is useful for handling situations when there are correlations amongst the features or when you need to incorporate both attributes of L1 and L2 regularization. #### Max Norm Regularization Max Norm Regularization constrains the L2 norm of the weights for each neuron and is typically used in neural networks. It limits the size of the parameter weights, ensuring that they do not grow too large: `python from keras.constraints import max_norm ` This can be particularly beneficial in preventing overfitting in deep learning models. ### Code Examples #### L1 and L2 Regularization Example: For Lasso and Ridge regression, you can use the respective classes from Scikit-learn‚Äôs linear_model module: `python from sklearn.linear_model import Lasso, Ridge # Example of Lasso Regression lasso_reg = Lasso(alpha=0.1) lasso_reg.fit(X_train, y_train) # Example of Ridge Regression ridge_reg = Ridge(alpha=1.0) ridge_reg.fit(X_train, y_train) ` #### Elastic Net Regularization Example: You can apply Elastic Net regularization using its specific class from Scikit-learn: `python from sklearn.linear_model import ElasticNet # Elastic Net combines L1 and L2 regularization elastic_net = ElasticNet(alpha=1.0, l1_ratio=0.5) elastic_net.fit(X_train, y_train) ` #### Max Norm Regularization Example: Max Norm regularization can be specified for layers in a Keras model as follows: `python from keras.layers import Dense from keras.models import Sequential from keras.constraints import max_norm model = Sequential() model.add(Dense(64, input_dim=8, kernel_constraint=max_norm(3))) ` Here, the max_norm(3) constraint ensures that the max norm of the weights does not exceed 3. <br> ## 8. Describe the difference between _Parametric_ and _Non-Parametric_ models. Parametric and non-parametric models represent distinct approaches in statistical modeling, each with unique characteristics in terms of assumptions, computational complexity, and suitability for various types of data. ### Key Distinctions - Parametric Models: - Make explicit and often strong assumptions about data distribution. - Are defined by a fixed number of parameters, regardless of sample size. - Typically require less data for accurate estimation. - Common examples include linear regression, logistic regression, and Gaussian Naive Bayes. - Non-parametric Models: - Make minimal or no assumptions about data distribution. - The number of parameters can grow with sample size, offering more flexibility. - Generally require more data for accurate estimation. - Examples encompass k-nearest neighbors, decision trees, and random forests. ### Advantages and Disadvantages of Each Approach - Parametric Models - Advantages: - Inferential speed: Once trained, making predictions or conducting inference is often computationally fast. - Parameter interpretability: The meaning of parameters can be directly linked to the model and the data. - Efficiency with small, well-behaved datasets: Parametric models can yield highly accurate results with relatively small, clean datasets that adhere to the model's distributional assumptions. - Disadvantages: - Strong distributional assumptions: Data must closely match the specified distribution for the model to produce reliable results. - Limited flexibility: These models might not adapt well to non-standard data distributions. - Non-Parametric Models - Advantages: - Distribution-free: They do not impose strict distributional assumptions, making them more robust across a wider range of datasets. - Flexibility: Can capture complex, nonlinear relationships in the data. - Larger sample adaptability: Particularly suitable for big data or data from unknown distributions. - Disadvantages: - Computational overhead: Can be slower for making predictions, especially with large datasets. - Interpretability: Often, the predictive results are harder to interpret in terms of the original features. ### Code Example: Gaussian Naive Bayes vs. Decision Tree (Scikit-learn) Here is the Python code: `python # Gaussian Naive Bayes (parametric) from sklearn.naive_bayes import GaussianNB model = GaussianNB() # Decision Tree (non-parametric) from sklearn.tree import DecisionTreeClassifier model_dt = DecisionTreeClassifier() ` <br> ## 9. What is the _curse of dimensionality_ and how does it impact ML models? The curse of dimensionality describes the issues that arise when working with high-dimensional data, affecting the performance of machine learning models. ### Key Challenges",,hard,coding,regression|classification|probability|python|deep_learning|ensemble|feature_engineering,Devinterview-io/data-scientist-interview-questions,,2025-11-17T10:49:35.640936
"Sparse Data: As the number of dimensions increases, the data points become more spread out, and the density of data points decreases.",,medium,mixed,,Devinterview-io/data-scientist-interview-questions,,2025-11-17T10:49:35.640980
"Increased Volume of Data: With each additional dimension, the volume of the sample space grows exponentially, necessitating a larger dataset to maintain coverage.",,medium,mixed,,Devinterview-io/data-scientist-interview-questions,,2025-11-17T10:49:35.641018
Overfitting: High-dimensional spaces make it easier for models to fit to noise rather than the underlying pattern in the data.,,medium,ml,,Devinterview-io/data-scientist-interview-questions,,2025-11-17T10:49:35.641046
"Computational Complexity: Many machine learning algorithms exhibit slower performance and require more resources as the number of dimensions increases. ### Visual Example Consider a hypercube (n-dimensional cube) inscribed in a hypersphere (n-dimensional sphere) with a large number of dimensions, say 100. If you were to place a ""grid"" or uniformly spaced points within the hypercube, you'd find that the majority of these points actually fall outside the hypersphere. This disparity grows more pronounced as the number of dimensions increases, leading to a ""density gulf"" between the data contained within the hypercube and that within the hypersphere. !curse-of-dimensionality.png?alt=media&token=24d3cde6-89ae-4eb3-8d05-1d6358bb5ac9) ### Recommendations to Mitigate the Curse of Dimensionality",Google,medium,coding,,Devinterview-io/data-scientist-interview-questions,,2025-11-17T10:49:35.641133
"Feature Selection and Dimensionality Reduction: Prioritize quality over quantity of features. Techniques like PCA, t-SNE, and LDA can help reduce dimensions.",,medium,coding,feature_engineering,Devinterview-io/data-scientist-interview-questions,,2025-11-17T10:49:35.641161
"Simpler Models: Consider using algorithms with less sensitivity to high dimensions, even if it means sacrificing a bit of performance.",,medium,coding,,Devinterview-io/data-scientist-interview-questions,,2025-11-17T10:49:35.641187
"Sparse Models: For high-dimensional, sparse datasets, models that can handle sparsity, like LASSO or ElasticNet, might be beneficial.",,medium,ml,,Devinterview-io/data-scientist-interview-questions,,2025-11-17T10:49:35.641215
Feature Engineering: Craft domain-specific features that can capture relevant information more efficiently.,,medium,mixed,feature_engineering,Devinterview-io/data-scientist-interview-questions,,2025-11-17T10:49:35.641243
"Data Quality: Strive for a high-quality dataset, as more data doesn't necessarily counteract the curse of dimensionality.",,medium,mixed,,Devinterview-io/data-scientist-interview-questions,,2025-11-17T10:49:35.641273
"Data Stratification and Sampling: When possible, stratify and sample data to ensure coverage across the high-dimensional space.",,medium,mixed,,Devinterview-io/data-scientist-interview-questions,,2025-11-17T10:49:35.641303
"Computational Resources: Leverage cloud computing or powerful hardware to handle the increased computational demands. <br> ## 10. Explain the concept of _Feature Engineering_ and its significance in ML. Feature engineering is a vital component of the machine-learning pipeline. It entails creating meaningful and robust representations of the data upon which the model will be built. ### Significance of Feature Engineering - Improved Model Performance: High-quality features can make even simple models more effective, while poor features can hamper the performance of the most advanced models. - Dimensionality Reduction: Carefully engineered features can distill relevant information from high-dimensional data, leading to more efficient and accurate models. - Model Interpretability: Certain feature engineering techniques, such as binning or one-hot encoding, make it easier to understand and interpret the model's decisions. - Computational Efficiency: Engineered features can often streamline computational processes, making predictions faster and cheaper. ### Common Feature Engineering Techniques",,hard,stats,hypothesis_testing|metrics|feature_engineering,Devinterview-io/data-scientist-interview-questions,,2025-11-17T10:49:35.641434
"Handling Missing Data - Removing or imputing missing values. - Creating a separate ""missing"" category.",,medium,mixed,,Devinterview-io/data-scientist-interview-questions,,2025-11-17T10:49:35.641465
"Handling Categorical Data - Converting categories into ordinal values. - Using one-hot encoding to create binary ""dummy"" variables. - Grouping rare categories into an ""other"" category.",,medium,mixed,,Devinterview-io/data-scientist-interview-questions,,2025-11-17T10:49:35.641504
"Handling Temporal Data - Extracting specific time-related features from timestamps, such as hour or month. - Converting timestamps into different representations, like age or duration since a specific event.",,medium,mixed,feature_engineering,Devinterview-io/data-scientist-interview-questions,,2025-11-17T10:49:35.641544
Variable Transformation - Using mathematical transformations such as logarithms. - Normalizing or scaling data to a specific range.,,medium,mixed,,Devinterview-io/data-scientist-interview-questions,,2025-11-17T10:49:35.641576
"Discretization - Converting continuous variables into discrete bins, e.g., converting age to age groups.",,medium,mixed,,Devinterview-io/data-scientist-interview-questions,,2025-11-17T10:49:35.641609
Feature Extraction - Reducing dimensionality through techniques like PCA or LDA.,,medium,mixed,feature_engineering,Devinterview-io/data-scientist-interview-questions,,2025-11-17T10:49:35.641634
"Feature Creation - Engineering domain-specific metrics. - Generating polynomial or interaction features. <br> ## 11. What is _Data Preprocessing_ and why is it important in ML? Data Preprocessing is a vital early-stage task in any machine learning project. It involves cleaning, transforming, and standardizing data to make it more suitable for predictive modeling. ### Key Steps in Data Preprocessing",,medium,ml,metrics|feature_engineering,Devinterview-io/data-scientist-interview-questions,,2025-11-17T10:49:35.641691
Data Cleaning: - Address missing values: Implement strategies like imputation or removal. - Outlier detection and handling: Identify and deal with data points that deviate significantly from the rest.,,medium,mixed,,Devinterview-io/data-scientist-interview-questions,,2025-11-17T10:49:35.641732
Feature Selection and Engineering: - Choose the most relevant features that contribute to the model's predictive accuracy. - Create new features that might improve the model's performance.,,medium,coding,feature_engineering,Devinterview-io/data-scientist-interview-questions,,2025-11-17T10:49:35.641762
"Data Transformation: - Normalize or standardize numerical data to ensure all features contribute equally. - Convert categorical data into a format understandable by the model, often using techniques like one-hot encoding. - Discretize continuous data when required.",,medium,ml,feature_engineering,Devinterview-io/data-scientist-interview-questions,,2025-11-17T10:49:35.641805
"Data Integration: - Combine data from multiple sources, ensuring compatibility and consistency.",,medium,mixed,,Devinterview-io/data-scientist-interview-questions,,2025-11-17T10:49:35.641847
"Data Reduction: - Reduce the dimensionality of the feature space, often to eliminate noise or improve computational efficiency. ### Code Example: Handling Missing Data Here is the Python code: `python # Drop rows with missing values cleaned_data = raw_data.dropna() # Fill missing values using the mean mean_value = raw_data['column_name'].mean() raw_data['column_name'].fillna(mean_value, inplace=True) ` ### Code Example: Feature Scaling Here is the Python code: `python from sklearn.preprocessing import StandardScaler scaler = StandardScaler() X_train = scaler.fit_transform(X_train) X_test = scaler.transform(X_test) ` ### Code Example: Dimensionality Reduction Using PCA Here is the Python code: `python from sklearn.decomposition import PCA pca = PCA(n_components=2) X_pca = pca.fit_transform(X) ` <br> ## 12. Explain the difference between _Feature Scaling_ and _Normalization_. Both Feature Scaling and Normalization are data preprocessing techniques that aim to make machine learning models more robust and accurate. While they share similarities in standardizing data, they serve slightly different purposes. ### Key Distinctions - Feature Scaling adjusts the range of independent variables or features so that they are on a similar scale. Common methods include Min-Max Scaling and Standardization. - Normalization, in the machine learning context, typically refers to scaling the magnitude of a vector to make its Euclidean length 1. It's also known as Unit Vector transformation. In some contexts, it may be used more generally to refer to scaling quantities to be in a range (like Min-Max), but this is a less common usage in the ML community. ### Methods in Feature Scaling and Normalization - Min-Max Scaling: Transforms the data to a specific range (usually 0 to 1 or -1 to 1). - Standardization: Rescales the data to have a mean of 0 and a standard deviation of 1. - Unit Vector Transformation: Scales data to have a Euclidean length of 1. ### Use Cases - Feature Scaling: Beneficial for algorithms that compute distances or use linear methods, such as K-Nearest Neighbors (KNN) or Support Vector Machines (SVM). - Normalization: More useful for algorithms that work with vector dot products, like the K-Means clustering algorithm and Neural Networks. <br> ## 13. What is the purpose of _One-Hot Encoding_ and when is it used? One-Hot Encoding is a technique frequently used to prepare categorical data for machine learning algorithms. ### Purpose of One-Hot Encoding It is employed when: - Categorical Data: The data on hand is categorical, and the algorithm or model being used does not support categorical input. - Nominal Data Order: The categorical data is nominal, i.e., not ordinal, which means there is no inherent order or ranking. - Non-Scalar Representation: The model can only process numerical (scalar) data. The model may be represented as the set $x = \{x_1, x_2, \ldots, x_k\}$ each $x_i$ corresponding to a category. A scalar transformation $f(x_i)$ or comparison $f(x_i) > f(x_j)$ is not defined for the categories directly. - Category Dimension: The categorical variable has many distinct categories. For instance, using one-hot encoding consistently reduces the computational and statistical burden in algorithms. ### Code Example: One-Hot Encoding Here is the Python code: `python import pandas as pd # Sample data data = pd.DataFrame({'color': ['red', 'green', 'blue', 'green', 'red']}) # One-hot encode one_hot_encoded = pd.get_dummies(data, columns=['color']) print(one_hot_encoded) ` ### Output: One-Hot Encoding | | color_blue | color_green | color_red | |---:|-----------:|------------:|----------:| | 0 | 0 | 0 | 1 | | 1 | 0 | 1 | 0 | | 2 | 1 | 0 | 0 | | 3 | 0 | 1 | 0 | | 4 | 0 | 0 | 1 | ### Output: Binary representation (alternatively) | Color | Binary Red | Binary Green | Binary Blue | |-------|------------|--------------|-------------| | Red | 1 | 0 | 0 | | Green | 0 | 1 | 0 | | Blue | 0 | 0 | 1 | <br> ## 14. Describe the concept of _Handling Missing Values_ in datasets. Handling Missing Values is a crucial step in the data preprocessing pipeline for any machine learning or statistical analysis. It involves identifying and dealing with data points that are not available, ensuring the robustness and reliability of the subsequent analysis or model. ### Common Techniques for Handling Missing Values #### Deletion - Listwise Deletion: Eliminate entire rows with any missing value. This method is straightforward but can lead to significant information loss, especially if the dataset has a large number of missing values. - Pairwise Deletion: Ignore specific pairs of missing values across variables. While this method preserves more data than listwise deletion, it can introduce bias in the analysis. #### Single-Imputation Methods - Mean/ Median/ Mode: Replace missing values with the mean, median, or mode of the variable. This method is quick and easy to implement but can affect the distribution and introduce bias. - Forward or Backward Fill (Last Observation Carried Forward - LOCF / Last Observation Carried Backward - LOCB): Substitute missing values with the most recent (forward) or next (backward) non-missing value. These methods are useful for time-series data. - Linear Interpolation: Estimate missing values by fitting a linear model to the two closest non-missing data points. This method is particularly useful for ordered data, but it assumes a linear relationship. #### Multiple-Imputation Methods - k-Nearest Neighbors (KNN): Impute missing values based on the values of the k most similar instances or neighbors. This method can preserve the original data structure and is more robust than single imputation. - Expectation-Maximization (EM) Algorithm: Model the data with an initial estimate, then iteratively refine the imputations. It's effective for data with complex missing patterns. #### Prediction Models - Use predictive models, typically regression or decision tree-based models, to estimate missing values. This approach can be more accurate than simpler methods but also more computationally intensive. ### Best Practices - Understanding the Mechanism of Missing Data: Investigating why the data is missing can provide insights into the problem. For instance, is the data missing completely at random, at random, or not at random? - Combining Techniques: Employing multiple imputation methods or a combination of imputation and deletion strategies can help achieve better results. - Evaluating Impact on Model: Compare the performance of the model with and without the imputation method to understand its effect. <br> ## 15. What is _Feature Selection_ and its techniques? Feature Selection is a critical step in the machine learning pipeline. It aims to identify the most relevant features from a dataset, leading to improved model performance, reduced overfitting, and faster training times. ### Feature Selection Techniques #### 1. Filter Methods - Description: Filter methods rank features based on certain criteria, such as their correlation with the target variable or their variance. - Advantages: They are computationally efficient and can be used in both regression and classification tasks. - Limitations: They do not take feature dependencies into account. #### 2. Wrapper Methods - Description: Wrapper methods select features based on their performance with a specific machine learning algorithm. Common techniques include Recursive Feature Elimination (RFE) and Forward-Backward Selection. - Advantages: They take feature dependencies into account and can improve model accuracy. - Limitations: They can be computationally expensive and prone to overfitting. #### 3. Embedded Methods - Description: Embedded methods integrate feature selection with the model building process. Techniques like LASSO (Least Absolute Shrinkage and Selection Operator) and decision tree feature importances are examples of this approach. - Advantages: They are computationally efficient and provide feature rankings. - Limitations: They may not be transferable to other models. ### Code Example: Filter Methods Here is the Python code: `python import pandas as pd from sklearn.feature_selection import VarianceThreshold # Generate example data data = {'feature1': [1, 2, 3, 4, 5], 'feature2': [0, 0, 0, 0, 0], 'feature3': [1, 0, 1, 0, 1], 'target': [0, 1, 0, 1, 0]} df = pd.DataFrame(data) # Remove features with low variance X = df.drop('target', axis=1) y = df['target'] selector = VarianceThreshold(threshold=0.2) X_selected = selector.fit_transform(X) print(X_selected) ` #### Code Example: Wrapper Methods Here is the Python code: `python from sklearn.feature_selection import RFE from sklearn.linear_model import LogisticRegression # Create the RFE object and rank features model = LogisticRegression(solver='lbfgs') rfe = RFE(model, 3) fit = rfe.fit(X, y) print(""Selected Features:"") print(fit.support_) ` <br> #### Explore all 100 answers here üëâ Devinterview.io - Data Scientist <br> <a href=""https://devinterview.io/questions/machine-learning-and-data-science/""> <img src=""https://firebasestorage.googleapis.com/v0/b/dev-stack-app.appspot.com/o/github-blog-img%2Fmachine-learning-and-data-science-github-img.jpg?alt=media&token=c511359d-cb91-4157-9465-a8e75a0242fe"" alt=""machine-learning-and-data-science"" width=""100%""> </a> </p>",Google,easy,coding,regression|classification|clustering|probability|python|deep_learning|metrics|feature_engineering,Devinterview-io/data-scientist-interview-questions,,2025-11-17T10:49:35.642628
TN / True Negative: case was negative and predicted negative,,medium,mixed,,iamtodor/data-science-interview-questions-and-answers,,2025-11-17T10:49:36.279389
TP / True Positive: case was positive and predicted positive,,medium,mixed,,iamtodor/data-science-interview-questions-and-answers,,2025-11-17T10:49:36.279432
FN / False Negative: case was positive but predicted negative,,medium,mixed,,iamtodor/data-science-interview-questions-and-answers,,2025-11-17T10:49:36.279466
"FP / False Positive: case was negative but predicted positive !alt text Now, your boss asks you three questions: * What percent of your predictions were correct? You answer: the ""accuracy"" was (9,760+60) out of 10,000 = 98.2% * What percent of the positive cases did you catch? You answer: the ""recall"" was 60 out of 100 = 60% * What percent of positive predictions were correct? You answer: the ""precision"" was 60 out of 200 = 30% See also a very good explanation of Precision and recall in Wikipedia. !alt text ROC curve represents a relation between sensitivity (RECALL) and specificity(NOT PRECISION) and is commonly used to measure the performance of binary classifiers. However, when dealing with highly skewed datasets, Precision-Recall (PR) curves give a more representative picture of performance. Remember, a ROC curve represents a relation between sensitivity (RECALL) and specificity(NOT PRECISION). Sensitivity is the other name for recall but specificity is not PRECISION. Recall/Sensitivity is the measure of the probability that your estimate is 1 given all the samples whose true class label is 1. It is a measure of how many of the positive samples have been identified as being positive. Specificity is the measure of the probability that your estimate is 0 given all the samples whose true class label is 0. It is a measure of how many of the negative samples have been identified as being negative. PRECISION on the other hand is different. It is a measure of the probability that a sample is a true positive class given that your classifier said it is positive. It is a measure of how many of the samples predicted by the classifier as positive is indeed positive. Note here that this changes when the base probability or prior probability of the positive class changes. Which means PRECISION depends on how rare is the positive class. In other words, it is used when positive class is more interesting than the negative class. * Sensitivity also known as the True Positive rate or Recall is calculated as, Sensitivity = TP / (TP + FN). Since the formula doesn‚Äôt contain FP and TN, Sensitivity may give you a biased result, especially for imbalanced classes. In the example of Fraud detection, it gives you the percentage of Correctly Predicted Frauds from the pool of Actual Frauds pool of Actual Non-Frauds. * Specificity, also known as True Negative Rate is calculated as, Specificity = TN / (TN + FP). Since the formula does not contain FN and TP, Specificity may give you a biased result, especially for imbalanced classes. In the example of Fraud detection, it gives you the percentage of Correctly Predicted Non-Frauds from the pool of Actual Frauds pool of Actual Non-Frauds Assessing and Comparing Classifier Performance with ROC Curves ## 6. Is it better to have too many false positives, or too many false negatives? It depends on the question as well as on the domain for which we are trying to solve the question. In medical testing, false negatives may provide a falsely reassuring message to patients and physicians that disease is absent, when it is actually present. This sometimes leads to inappropriate or inadequate treatment of both the patient and their disease. So, it is desired to have too many false positive. For spam filtering, a false positive occurs when spam filtering or spam blocking techniques wrongly classify a legitimate email message as spam and, as a result, interferes with its delivery. While most anti-spam tactics can block or filter a high percentage of unwanted emails, doing so without creating significant false-positive results is a much more demanding task. So, we prefer too many false negatives over many false positives. ## 7. How do you deal with unbalanced binary classification? Imbalanced data typically refers to a problem with classification problems where the classes are not represented equally. For example, you may have a 2-class (binary) classification problem with 100 instances (rows). A total of 80 instances are labeled with Class-1 and the remaining 20 instances are labeled with Class-2. This is an imbalanced dataset and the ratio of Class-1 to Class-2 instances is 80:20 or more concisely 4:1. You can have a class imbalance problem on two-class classification problems as well as multi-class classification problems. Most techniques can be used on either. The remaining discussions will assume a two-class classification problem because it is easier to think about and describe.",,medium,stats,classification|probability|metrics,iamtodor/data-science-interview-questions-and-answers,,2025-11-17T10:49:36.280457
Can You Collect More Data?</br> A larger dataset might expose a different and perhaps more balanced perspective on the classes. More examples of minor classes may be useful later when we look at resampling your dataset.,,medium,mixed,,iamtodor/data-science-interview-questions-and-answers,,2025-11-17T10:49:36.280524
"Try Changing Your Performance Metric</br> Accuracy is not the metric to use when working with an imbalanced dataset. We have seen that it is misleading. From that post, I recommend looking at the following performance measures that can give more insight into the accuracy of the model than traditional classification accuracy: - Confusion Matrix: A breakdown of predictions into a table showing correct predictions (the diagonal) and the types of incorrect predictions made (what classes incorrect predictions were assigned). - Precision: A measure of a classifiers exactness. Precision is the number of True Positives divided by the number of True Positives and False Positives. Put another way, it is the number of positive predictions divided by the total number of positive class values predicted. It is also called the Positive Predictive Value (PPV). Precision can be thought of as a measure of a classifiers exactness. A low precision can also indicate a large number of False Positives. - Recall: A measure of a classifiers completeness. Recall is the number of True Positives divided by the number of True Positives and the number of False Negatives. Put another way it is the number of positive predictions divided by the number of positive class values in the test data. It is also called Sensitivity or the True Positive Rate. Recall can be thought of as a measure of a classifiers completeness. A low recall indicates many False Negatives. - F1 Score (or F-score): A weighted average of precision and recall. I would also advise you to take a look at the following: - Kappa (or Cohen‚Äôs kappa): Classification accuracy normalized by the imbalance of the classes in the data. ROC Curves: Like precision and recall, accuracy is divided into sensitivity and specificity and models can be chosen based on the balance thresholds of these values.",,medium,ml,classification|metrics,iamtodor/data-science-interview-questions-and-answers,,2025-11-17T10:49:36.281008
"Try Resampling Your Dataset * You can add copies of instances from the under-represented class called over-sampling (or more formally sampling with replacement) * You can delete instances from the over-represented class, called under-sampling.",,medium,mixed,,iamtodor/data-science-interview-questions-and-answers,,2025-11-17T10:49:36.281081
Try Different Algorithms,,medium,coding,,iamtodor/data-science-interview-questions-and-answers,,2025-11-17T10:49:36.281106
Try Penalized Models</br> You can use the same algorithms but give them a different perspective on the problem. Penalized classification imposes an additional cost on the model for making classification mistakes on the minority class during training. These penalties can bias the model to pay more attention to the minority class. Often the handling of class penalties or weights are specialized to the learning algorithm. There are penalized versions of algorithms such as penalized-SVM and penalized-LDA. Using penalization is desirable if you are locked into a specific algorithm and are unable to resample or you‚Äôre getting poor results. It provides yet another way to ‚Äúbalance‚Äù the classes. Setting up the penalty matrix can be complex. You will very likely have to try a variety of penalty schemes and see what works best for your problem.,,medium,coding,classification,iamtodor/data-science-interview-questions-and-answers,,2025-11-17T10:49:36.281321
"Try a Different Perspective</br> Taking a look and thinking about your problem from these perspectives can sometimes shame loose some ideas. Two you might like to consider are anomaly detection and change detection. ## 8. What is statistical power? Statistical power or sensitivity of a binary hypothesis test is the probability that the test correctly rejects the null hypothesis (H0) when the alternative hypothesis (H1) is true. It can be equivalently thought of as the probability of accepting the alternative hypothesis (H1) when it is true‚Äîthat is, the ability of a test to detect an effect, if the effect actually exists. To put in another way, Statistical power is the likelihood that a study will detect an effect when the effect is present. The higher the statistical power, the less likely you are to make a Type II error (concluding there is no effect when, in fact, there is). A type I error (or error of the first kind) is the incorrect rejection of a true null hypothesis. Usually a type I error leads one to conclude that a supposed effect or relationship exists when in fact it doesn't. Examples of type I errors include a test that shows a patient to have a disease when in fact the patient does not have the disease, a fire alarm going on indicating a fire when in fact there is no fire, or an experiment indicating that a medical treatment should cure a disease when in fact it does not. A type II error (or error of the second kind) is the failure to reject a false null hypothesis. Examples of type II errors would be a blood test failing to detect the disease it was designed to detect, in a patient who really has the disease; a fire breaking out and the fire alarm does not ring; or a clinical trial of a medical treatment failing to show that the treatment works when really it does. !alt text ## 9. What are bias and variance, and what are their relation to modeling data? Bias is how far removed a model's predictions are from correctness, while variance is the degree to which these predictions vary between model iterations. Bias is generally the distance between the model that you build on the training data (the best model that your model space can provide) and the ‚Äúreal model‚Äù (which generates data). Error due to Bias: Due to randomness in the underlying data sets, the resulting models will have a range of predictions. Bias measures how far off in general these models' predictions are from the correct value. The bias is error from erroneous assumptions in the learning algorithm. High bias can cause an algorithm to miss the relevant relations between features and target outputs (underfitting). Error due to Variance: The error due to variance is taken as the variability of a model prediction for a given data point. Again, imagine you can repeat the entire model building process multiple times. The variance is how much the predictions for a given point vary between different realizations of the model. The variance is error from sensitivity to small fluctuations in the training set. High variance can cause an algorithm to model the random noise) in the training data, rather than the intended outputs (overfitting). Big dataset -> low variance <br/> Low dataset -> high variance <br/> Few features -> high bias, low variance <br/> Many features -> low bias, high variance <br/> Complicated model -> low bias <br/> Simplified model -> high bias <br/> Decreasing Œª -> low bias <br/> Increasing Œª -> low variance <br/> We can create a graphical visualization of bias and variance using a bulls-eye diagram. Imagine that the center of the target is a model that perfectly predicts the correct values. As we move away from the bulls-eye, our predictions get worse and worse. Imagine we can repeat our entire model building process to get a number of separate hits on the target. Each hit represents an individual realization of our model, given the chance variability in the training data we gather. Sometimes we will get a good distribution of training data so we predict very well and we are close to the bulls-eye, while sometimes our training data might be full of outliers or non-standard values resulting in poorer predictions. These different realizations result in a scatter of hits on the target. !alt text As an example, using a simple flawed Presidential election survey as an example, errors in the survey are then explained through the twin lenses of bias and variance: selecting survey participants from a phonebook is a source of bias; a small sample size is a source of variance. Minimizing total model error relies on the balancing of bias and variance errors. Ideally, models are the result of a collection of unbiased data of low variance. Unfortunately, however, the more complex a model becomes, its tendency is toward less bias but greater variance; therefore an optimal model would need to consider a balance between these 2 properties. The statistical evaluation method of cross-validation is useful in both demonstrating the importance of this balance, as well as actually searching it out. The number of data folds to use -- the value of k in k-fold cross-validation -- is an important decision; the lower the value, the higher the bias in the error estimates and the less variance. !alt text The most important takeaways are that bias and variance are two sides of an important trade-off when building models, and that even the most routine of statistical evaluation methods are directly reliant upon such a trade-off. We may estimate a model fÃÇ (X) of f(X) using linear regressions or another modeling technique. In this case, the expected squared prediction error at a point x is: Err(x)=E[(Y‚àífÃÇ (x))^2] This error may then be decomposed into bias and variance components: Err(x)=(E[fÃÇ (x)]‚àíf(x))^2+E[(fÃÇ (x)‚àíE[fÃÇ (x)])^2]+œÉ^2e Err(x)=Bias^2+Variance+Irreducible That third term, irreducible error, is the noise term in the true relationship that cannot fundamentally be reduced by any model. Given the true model and infinite data to calibrate it, we should be able to reduce both the bias and variance terms to 0. However, in a world with imperfect models and finite data, there is a tradeoff between minimizing the bias and minimizing the variance. That third term, irreducible error, is the noise term in the true relationship that cannot fundamentally be reduced by any model. Given the true model and infinite data to calibrate it, we should be able to reduce both the bias and variance terms to 0. However, in a world with imperfect models and finite data, there is a tradeoff between minimizing the bias and minimizing the variance. If a model is suffering from high bias, it means that model is less complex, to make the model more robust, we can add more features in feature space. Adding data points will reduce the variance. The bias‚Äìvariance tradeoff is a central problem in supervised learning. Ideally, one wants to choose a model that both accurately captures the regularities in its training data, but also generalizes well to unseen data. Unfortunately, it is typically impossible to do both simultaneously. High-variance learning methods may be able to represent their training set well, but are at risk of overfitting to noisy or unrepresentative training data. In contrast, algorithms with high bias typically produce simpler models that don't tend to overfit, but may underfit their training data, failing to capture important regularities. Models with low bias are usually more complex (e.g. higher-order regression polynomials), enabling them to represent the training set more accurately. In the process, however, they may also represent a large noise component in the training set, making their predictions less accurate - despite their added complexity. In contrast, models with higher bias tend to be relatively simple (low-order or even linear regression polynomials), but may produce lower variance predictions when applied beyond the training set. #### Approaches Dimensionality reduction and feature selection can decrease variance by simplifying models. Similarly, a larger training set tends to decrease variance. Adding features (predictors) tends to decrease bias, at the expense of introducing additional variance. Learning algorithms typically have some tunable parameters that control bias and variance, e.g.: * (Generalized) linear models can be regularized to decrease their variance at the cost of increasing their bias. * In artificial neural networks, the variance increases and the bias decreases with the number of hidden units. Like in GLMs, regularization is typically applied. * In k-nearest neighbor models, a high value of k leads to high bias and low variance (see below). * In Instance-based learning, regularization can be achieved varying the mixture of prototypes and exemplars.[ * In decision trees, the depth of the tree determines the variance. Decision trees are commonly pruned to control variance. One way of resolving the trade-off is to use mixture models and ensemble learning. For example, boosting) combines many ""weak"" (high bias) models in an ensemble that has lower bias than the individual models, while bagging combines ""strong"" learners in a way that reduces their variance. Understanding the Bias-Variance Tradeoff ## 10. What if the classes are imbalanced? What if there are more than 2 groups? Binary classification involves classifying the data into two groups, e.g. whether or not a customer buys a particular product or not (Yes/No), based on independent variables such as gender, age, location etc. As the target variable is not continuous, binary classification model predicts the probability of a target variable to be Yes/No. To evaluate such a model, a metric called the confusion matrix is used, also called the classification or co-incidence matrix. With the help of a confusion matrix, we can calculate important performance measures: * True Positive Rate (TPR) or Recall or Sensitivity = TP / (TP + FN) * Precision = TP / (TP + FP) * False Positive Rate(FPR) or False Alarm Rate = 1 - Specificity = 1 - (TN / (TN + FP)) * Accuracy = (TP + TN) / (TP + TN + FP + FN) * Error Rate = 1 ‚Äì Accuracy F-measure = 2 / ((1 / Precision) + (1 / Recall)) = 2 (precision * recall) / (precision + recall) * ROC (Receiver Operating Characteristics) = plot of FPR vs TPR * AUC (Area Under the [ROC] Curve) Performance measure across all classification thresholds. Treated as the probability that a model ranks a randomly chosen positive sample higher than negative ## 11. What are some ways I can make my model more robust to outliers? There are several ways to make a model more robust to outliers, from different points of view (data preparation or model building). An outlier in the question and answer is assumed being unwanted, unexpected, or a must-be-wrong value to the human‚Äôs knowledge so far (e.g. no one is 200 years old) rather than a rare event which is possible but rare. Outliers are usually defined in relation to the distribution. Thus outliers could be removed in the pre-processing step (before any learning step), by using standard deviations (Mean +/- 2*SD), it can be used for normality. Or interquartile ranges Q1 - Q3, Q1 - is the ""middle"" value in the first half of the rank-ordered data set, Q3 - is the ""middle"" value in the second half of the rank-ordered data set. It can be used for not normal/unknown as threshold levels. Moreover, data transformation (e.g. log transformation) may help if data have a noticeable tail. When outliers related to the sensitivity of the collecting instrument which may not precisely record small values, Winsorization may be useful. This type of transformation (named after Charles P. Winsor (1895‚Äì1951)) has the same effect as clipping signals (i.e. replaces extreme data values with less extreme values). Another option to reduce the influence of outliers is using mean absolute difference rather mean squared error. For model building, some models are resistant to outliers (e.g. tree-based approaches) or non-parametric tests. Similar to the median effect, tree models divide each node into two in each split. Thus, at each split, all data points in a bucket could be equally treated regardless of extreme values they may have. ## 12. In unsupervised learning, if a ground truth about a dataset is unknown, how can we determine the most useful number of clusters to be? The elbow method is often the best place to start, and is especially useful due to its ease of explanation and verification via visualization. The elbow method is interested in explaining variance as a function of cluster numbers (the k in k-means). By plotting the percentage of variance explained against k, the first N clusters should add significant information, explaining variance; yet, some eventual value of k will result in a much less significant gain in information, and it is at this point that the graph will provide a noticeable angle. This angle will be the optimal number of clusters, from the perspective of the elbow method, It should be self-evident that, in order to plot this variance against varying numbers of clusters, varying numbers of clusters must be tested. Successive complete iterations of the clustering method must be undertaken, after which the results can be plotted and compared. DBSCAN - Density-Based Spatial Clustering of Applications with Noise. Finds core samples of high density and expands clusters from them. Good for data which contains clusters of similar density. ## 13. Define variance Variance is the expectation of the squared deviation of a random variable from its mean. Informally, it measures how far a set of (random) numbers are spread out from their average value. The variance is the square of the standard deviation, the second central moment of a distribution, and the covariance of the random variable with itself. Var(X) = E[(X - m)^2], m=E[X] Variance is, thus, a measure of the scatter of the values of a random variable relative to its mathematical expectation. ## 14. Expected value Expected value ‚Äî Expected Value (Probability Distribution In a probability distribution, expected value is the value that a random variable takes with greatest likelihood. Based on the law of distribution of a random variable x, we know that a random variable x can take values x1, x2, ..., xk with probabilities p1, p2, ..., pk. The mathematical expectation M(x) of a random variable x is equal. The mathematical expectation of a random variable X (denoted by M (X) or less often E (X)) characterizes the average value of a random variable (discrete or continuous). Mathematical expectation is the first initial moment of a given CB. Mathematical expectation is attributed to the so-called characteristics of the distribution position (to which the mode and median also belong). This characteristic describes a certain average position of a random variable on the numerical axis. Say, if the expectation of a random variable - the lamp life is 100 hours, then it is considered that the values of the service life are concentrated (on both sides) from this value (with dispersion on each side, indicated by the variance). The mathematical expectation of a discrete random variable X is calculated as the sum of the products of the values xi that the CB takes X by the corresponding probabilities pi: `python import numpy as np X = [3,4,5,6,7] P = [0.1,0.2,0.3,0.4,0.5] np.sum(np.dot(X, P)) ` ## 15. Describe the differences between and use cases for box plots and histograms A histogram is a type of bar chart that graphically displays the frequencies of a data set. Similar to a bar chart, a histogram plots the frequency, or raw count, on the Y-axis (vertical) and the variable being measured on the X-axis (horizontal). The only difference between a histogram and a bar chart is that a histogram displays frequencies for a group of data, rather than an individual data point; therefore, no spaces are present between the bars. Typically, a histogram groups data into small chunks (four to eight values per bar on the horizontal axis), unless the range of data is so great that it easier to identify general distribution trends with larger groupings. A box plot, also called a box-and-whisker plot, is a chart that graphically represents the five most important descriptive values for a data set. These values include the minimum value, the first quartile, the median, the third quartile, and the maximum value. When graphing this five-number summary, only the horizontal axis displays values. Within the quadrant, a vertical line is placed above each of the summary numbers. A box is drawn around the middle three lines (first quartile, median, and third quartile) and two lines are drawn from the box‚Äôs edges to the two endpoints (minimum and maximum). Boxplots are better for comparing distributions than histograms! !alt text ## 16. How would you find an anomaly in a distribution? Before getting started, it is important to establish some boundaries on the definition of an anomaly. Anomalies can be broadly categorized as:",,medium,coding,regression|classification|clustering|hypothesis_testing|probability|python|deep_learning|ensemble|metrics|feature_engineering,iamtodor/data-science-interview-questions-and-answers,,2025-11-17T10:49:36.284737
"Point anomalies: A single instance of data is anomalous if it's too far off from the rest. Business use case: Detecting credit card fraud based on ""amount spent.""",,medium,mixed,,iamtodor/data-science-interview-questions-and-answers,,2025-11-17T10:49:36.284796
"Contextual anomalies: The abnormality is context specific. This type of anomaly is common in time-series data. Business use case: Spending $100 on food every day during the holiday season is normal, but may be odd otherwise.",,medium,mixed,,iamtodor/data-science-interview-questions-and-answers,,2025-11-17T10:49:36.284852
"Collective anomalies: A set of data instances collectively helps in detecting anomalies. Business use case: Someone is trying to copy data form a remote machine to a local host unexpectedly, an anomaly that would be flagged as a potential cyber attack. Best steps to prevent anomalies is to implement policies or checks that can catch them during the data collection stage. Unfortunately, you do not often get to collect your own data, and often the data you're mining was collected for another purpose. About 68% of all the data points are within one standard deviation from the mean. About 95% of the data points are within two standard deviations from the mean. Finally, over 99% of the data is within three standard deviations from the mean. When the value deviate too much from the mean, let‚Äôs say by ¬± 4œÉ, then we can considerate this almost impossible value as anomaly. (This limit can also be calculated using the percentile). #### Statistical methods Statistically based anomaly detection uses this knowledge to discover outliers. A dataset can be standardized by taking the z-score of each point. A z-score is a measure of how many standard deviations a data point is away from the mean of the data. Any data-point that has a z-score higher than 3 is an outlier, and likely to be an anomaly. As the z-score increases above 3, points become more obviously anomalous. A z-score is calculated using the following equation. A box-plot is perfect for this application. #### Metric method Judging by the number of publications, metric methods are the most popular methods among researchers. They postulate the existence of a certain metric in the space of objects, which helps to find anomalies. Intuitively, the anomaly has few neighbors in the instannce space, and a typical point has many. Therefore, a good measure of anomalies can be, for example, the ¬´distance to the k-th neighbor¬ª. (See method: Local Outlier Factor). Specific metrics are used here, for example Mahalonobis distance. Mahalonobis distance is a measure of distance between vectors of random variables, generalizing the concept of Euclidean distance. Using Mahalonobis distance, it is possible to determine the similarity of unknown and known samples. It differs from Euclidean distance in that it takes into account correlations between variables and is scale invariant. !alt text The most common form of clustering-based anomaly detection is done with prototype-based clustering. Using this approach to anomaly detection, a point is classified as an anomaly if its omission from the group significantly improves the prototype, then the point is classified as an anomaly. This logically makes sense. K-means is a clustering algorithm that clusters similar points. The points in any cluster are similar to the centroid of that cluster, hence why they are members of that cluster. If one point in the cluster is so far from the centroid that it pulls the centroid away from it's natural center, than that point is literally an outlier, since it lies outside the natural bounds for the cluster. Hence, its omission is a logical step to improve the accuracy of the rest of the cluster. Using this approach, the outlier score is defined as the degree to which a point doesn't belong to any cluster, or the distance it is from the centroid of the cluster. In K-means, the degree to which the removal of a point would increase the accuracy of the centroid is the difference in the SSE, or standard squared error, or the cluster with and without the point. If there is a substantial improvement in SSE after the removal of the point, that correlates to a high outlier score for that point. More specifically, when using a k-means clustering approach towards anomaly detection, the outlier score is calculated in one of two ways. The simplest is the point's distance from its closest centroid. However, this approach is not as useful when there are clusters of differing densities. To tackle that problem, the point's relative distance to it's closest centroid is used, where relative distance is defined as the ratio of the point's distance from the centroid to the median distance of all points in the cluster from the centroid. This approach to anomaly detection is sensitive to the value of k. Also, if the data is highly noisy, then that will throw off the accuracy of the initial clusters, which will decrease the accuracy of this type of anomaly detection. The time complexity of this approach is obviously dependent on the choice of clustering algorithm, but since most clustering algorithms have linear or close to linear time and space complexity, this type of anomaly detection can be highly efficient. ## 17. How do you deal with outliers in your data? For the most part, if your data is affected by these extreme cases, you can bound the input to a historical representative of your data that excludes outliers. So that could be a number of items (>3) or a lower or upper bounds on your order value. If the outliers are from a data set that is relatively unique then analyze them for your specific situation. Analyze both with and without them, and perhaps with a replacement alternative, if you have a reason for one, and report your results of this assessment. One option is to try a transformation. Square root and log transformations both pull in high numbers. This can make assumptions work better if the outlier is a dependent. ## 18. How do you deal with sparse data? We could take a look at L1 regularization since it best fits to the sparse data and do feature selection. If linear relationship - linear regression either - svm. Also it would be nice to use one-hot-encoding or bag-of-words. A one hot encoding is a representation of categorical variables as binary vectors. This first requires that the categorical values be mapped to integer values. Then, each integer value is represented as a binary vector that is all zero values except the index of the integer, which is marked with a 1. ## 19. Big Data Engineer Can you explain what REST is? REST stands for Representational State Transfer. (It is sometimes spelled ""ReST"".) It relies on a stateless, client-server, cacheable communications protocol -- and in virtually all cases, the HTTP protocol is used. REST is an architecture style for designing networked applications. The idea is simple HTTP is used to make calls between machines. * In many ways, the World Wide Web itself, based on HTTP, can be viewed as a REST-based architecture. RESTful applications use HTTP requests to post data (create and/or update), read data (e.g., make queries), and delete data. Thus, REST uses HTTP for all four CRUD (Create/Read/Update/Delete) operations. REST is a lightweight alternative to mechanisms like RPC (Remote Procedure Calls) and Web Services (SOAP, WSDL, et al.). Later, we will see how much more simple REST is. * Despite being simple, REST is fully-featured; there's basically nothing you can do in Web Services that can't be done with a RESTful architecture. REST is not a ""standard"". There will never be a W3C recommendation for REST, for example. And while there are REST programming frameworks, working with REST is so simple that you can often ""roll your own"" with standard library features in languages like Perl, Java, or C#. ## 20. Logistic regression Log odds - raw output from the model; odds - exponent from the output of the model. Probability of the output - odds / (1+odds). ## 21. What is the effect on the coefficients of logistic regression if two predictors are highly correlated? What are the confidence intervals of the coefficients? When predictor variables are correlated, the estimated regression coefficient of any one variable depends on which other predictor variables are included in the model. When predictor variables are correlated, the precision of the estimated regression coefficients decreases as more predictor variables are added to the model. In statistics, multicollinearity (also collinearity) is a phenomenon in which two or more predictor variables in a multiple regression model are highly correlated, meaning that one can be linearly predicted from the others with a substantial degree of accuracy. In this situation the coefficient estimates of the multiple regression may change erratically in response to small changes in the model or the data. Multicollinearity does not reduce the predictive power or reliability of the model as a whole, at least within the sample data set; it only affects calculations regarding individual predictors. That is, a multiple regression model with correlated predictors can indicate how well the entire bundle of predictors predicts the outcome variable, but it may not give valid results about any individual predictor, or about which predictors are redundant with respect to others. The consequences of multicollinearity: * Ratings estimates remain unbiased. * Standard coefficient errors increase. * The calculated t-statistics are underestimated. * Estimates become very sensitive to changes in specifications and changes in individual observations. * The overall quality of the equation, as well as estimates of variables not related to multicollinearity, remain unaffected. * The closer multicollinearity to perfect (strict), the more serious its consequences. Indicators of multicollinearity:",,medium,coding,regression|clustering|probability|metrics|feature_engineering,iamtodor/data-science-interview-questions-and-answers,,2025-11-17T10:49:36.286401
High R2 and negligible odds.,,medium,mixed,,iamtodor/data-science-interview-questions-and-answers,,2025-11-17T10:49:36.286427
Strong pair correlation of predictors.,,medium,mixed,,iamtodor/data-science-interview-questions-and-answers,,2025-11-17T10:49:36.286450
"High VIF - variance inflation factor. Confidence interval (CI) is a type of interval estimate (of a population parameter) that is computed from the observed data. The confidence level is the frequency (i.e., the proportion) of possible confidence intervals that contain the true value of their corresponding parameter. In other words, if confidence intervals are constructed using a given confidence level in an infinite number of independent experiments, the proportion of those intervals that contain the true value of the parameter will match the confidence level. Confidence intervals consist of a range of values (interval) that act as good estimates of the unknown population parameter. However, the interval computed from a particular sample does not necessarily include the true value of the parameter. Since the observed data are random samples from the true population, the confidence interval obtained from the data is also random. If a corresponding hypothesis test is performed, the confidence level is the complement of the level of significance, i.e. a 95% confidence interval reflects a significance level of 0.05. If it is hypothesized that a true parameter value is 0 but the 95% confidence interval does not contain 0, then the estimate is significantly different from zero at the 5% significance level. The desired level of confidence is set by the researcher (not determined by data). Most commonly, the 95% confidence level is used. However, other confidence levels can be used, for example, 90% and 99%. Factors affecting the width of the confidence interval include the size of the sample, the confidence level, and the variability in the sample. A larger sample size normally will lead to a better estimate of the population parameter. A Confidence Interval is a range of values we are fairly sure our true value lies in. X ¬± Z*s/‚àö(n), X is the mean, Z is the chosen Z-value from the table, s is the standard deviation, n is the number of samples. The value after the ¬± is called the margin of error. ## 22. What‚Äôs the difference between Gaussian Mixture Model and K-Means? Let's says we are aiming to break them into three clusters. K-means will start with the assumption that a given data point belongs to one cluster. Choose a data point. At a given point in the algorithm, we are certain that a point belongs to a red cluster. In the next iteration, we might revise that belief, and be certain that it belongs to the green cluster. However, remember, in each iteration, we are absolutely certain as to which cluster the point belongs to. This is the ""hard assignment"". What if we are uncertain? What if we think, well, I can't be sure, but there is 70% chance it belongs to the red cluster, but also 10% chance its in green, 20% chance it might be blue. That's a soft assignment. The Mixture of Gaussian model helps us to express this uncertainty. It starts with some prior belief about how certain we are about each point's cluster assignments. As it goes on, it revises those beliefs. But it incorporates the degree of uncertainty we have about our assignment. Kmeans: find kk to minimize (x‚àíŒºk)^2 Gaussian Mixture (EM clustering) : find kk to minimize (x‚àíŒºk)^2/œÉ^2 The difference (mathematically) is the denominator ‚ÄúœÉ^2‚Äù, which means GM takes variance into consideration when it calculates the measurement. Kmeans only calculates conventional Euclidean distance. In other words, Kmeans calculate distance, while GM calculates ‚Äúweighted‚Äù distance. K means: * Hard assign a data point to one particular cluster on convergence. * It makes use of the L2 norm when optimizing (Min {Theta} L2 norm point and its centroid coordinates). EM: * Soft assigns a point to clusters (so it give a probability of any point belonging to any centroid). * It doesn't depend on the L2 norm, but is based on the Expectation, i.e., the probability of the point belonging to a particular cluster. This makes K-means biased towards spherical clusters. ## 23. Describe how Gradient Boosting works. The idea of boosting came out of the idea of whether a weak learner can be modified to become better. Gradient boosting relies on regression trees (even when solving a classification problem) which minimize MSE. Selecting a prediction for a leaf region is simple: to minimize MSE we should select an average target value over samples in the leaf. The tree is built greedily starting from the root: for each leaf a split is selected to minimize MSE for this step. To begin with, gradient boosting is an ensembling technique, which means that prediction is done by an ensemble of simpler estimators. While this theoretical framework makes it possible to create an ensemble of various estimators, in practice we almost always use GBDT ‚Äî gradient boosting over decision trees. The aim of gradient boosting is to create (or ""train"") an ensemble of trees, given that we know how to train a single decision tree. This technique is called boosting because we expect an ensemble to work much better than a single estimator. Here comes the most interesting part. Gradient boosting builds an ensemble of trees one-by-one, then the predictions of the individual trees are summed: D(x)=d‚Äãtree 1‚Äã‚Äã(x)+d‚Äãtree 2‚Äã‚Äã(x)+... The next decision tree tries to cover the discrepancy between the target function f(x) and the current ensemble prediction by reconstructing the residual. For example, if an ensemble has 3 trees the prediction of that ensemble is: D(x)=d‚Äãtree 1‚Äã‚Äã(x)+d‚Äãtree 2‚Äã‚Äã(x)+d‚Äãtree 3‚Äã‚Äã(x). The next tree (tree 4) in the ensemble should complement well the existing trees and minimize the training error of the ensemble. In the ideal case we'd be happy to have: D(x)+d‚Äãtree 4‚Äã‚Äã(x)=f(x). To get a bit closer to the destination, we train a tree to reconstruct the difference between the target function and the current predictions of an ensemble, which is called the residual: R(x)=f(x)‚àíD(x). Did you notice? If decision tree completely reconstructs R(x), the whole ensemble gives predictions without errors (after adding the newly-trained tree to the ensemble)! That said, in practice this never happens, so we instead continue the iterative process of ensemble building. ### AdaBoost the First Boosting Algorithm The weak learners in AdaBoost are decision trees with a single split, called decision stumps for their shortness. AdaBoost works by weighting the observations, putting more weight on difficult to classify instances and less on those already handled well. New weak learners are added sequentially that focus their training on the more difficult patterns. Gradient boosting involves three elements:",,hard,coding,regression|classification|clustering|hypothesis_testing|probability|ensemble|metrics,iamtodor/data-science-interview-questions-and-answers,,2025-11-17T10:49:36.287568
A loss function to be optimized.,,medium,mixed,,iamtodor/data-science-interview-questions-and-answers,,2025-11-17T10:49:36.287593
A weak learner to make predictions.,,medium,mixed,,iamtodor/data-science-interview-questions-and-answers,,2025-11-17T10:49:36.287616
"An additive model to add weak learners to minimize the loss function. #### Loss Function The loss function used depends on the type of problem being solved. It must be differentiable, but many standard loss functions are supported and you can define your own. For example, regression may use a squared error and classification may use logarithmic loss. A benefit of the gradient boosting framework is that a new boosting algorithm does not have to be derived for each loss function that may want to be used, instead, it is a generic enough framework that any differentiable loss function can be used. #### Weak Learner Decision trees are used as the weak learner in gradient boosting. Specifically regression trees are used that output real values for splits and whose output can be added together, allowing subsequent models outputs to be added and ‚Äúcorrect‚Äù the residuals in the predictions. Trees are constructed in a greedy manner, choosing the best split points based on purity scores like Gini or to minimize the loss. Initially, such as in the case of AdaBoost, very short decision trees were used that only had a single split, called a decision stump. Larger trees can be used generally with 4-to-8 levels. It is common to constrain the weak learners in specific ways, such as a maximum number of layers, nodes, splits or leaf nodes. This is to ensure that the learners remain weak, but can still be constructed in a greedy manner. #### Additive Model Trees are added one at a time, and existing trees in the model are not changed. A gradient descent procedure is used to minimize the loss when adding trees. Traditionally, gradient descent is used to minimize a set of parameters, such as the coefficients in a regression equation or weights in a neural network. After calculating error or loss, the weights are updated to minimize that error. Instead of parameters, we have weak learner sub-models or more specifically decision trees. After calculating the loss, to perform the gradient descent procedure, we must add a tree to the model that reduces the loss (i.e. follow the gradient). We do this by parameterizing the tree, then modify the parameters of the tree and move in the right direction by reducing the residual loss. Generally this approach is called functional gradient descent or gradient descent with functions. The output for the new tree is then added to the output of the existing sequence of trees in an effort to correct or improve the final output of the model. A fixed number of trees are added or training stops once loss reaches an acceptable level or no longer improves on an external validation dataset. ### Improvements to Basic Gradient Boosting Gradient boosting is a greedy algorithm and can overfit a training dataset quickly. It can benefit from regularization methods that penalize various parts of the algorithm and generally improve the performance of the algorithm by reducing overfitting. In this section we will look at 4 enhancements to basic gradient boosting: * Tree Constraints * Shrinkage * Random sampling * Penalized Learning #### Tree Constraints It is important that the weak learners have skill but remain weak. There are a number of ways that the trees can be constrained. A good general heuristic is that the more constrained tree creation is, the more trees you will need in the model, and the reverse, where less constrained individual trees, the fewer trees that will be required. Below are some constraints that can be imposed on the construction of decision trees: * Number of trees, generally adding more trees to the model can be very slow to overfit. The advice is to keep adding trees until no further improvement is observed. * Tree depth, deeper trees are more complex trees and shorter trees are preferred. Generally, better results are seen with 4-8 levels. * Number of nodes or number of leaves, like depth, this can constrain the size of the tree, but is not constrained to a symmetrical structure if other constraints are used. * Number of observations per split imposes a minimum constraint on the amount of training data at a training node before a split can be considered * Minimum improvement to loss is a constraint on the improvement of any split added to a tree. #### Weighted Updates The predictions of each tree are added together sequentially. The contribution of each tree to this sum can be weighted to slow down the learning by the algorithm. This weighting is called a shrinkage or a learning rate. Each update is simply scaled by the value of the ‚Äúlearning rate parameter‚Äù v The effect is that learning is slowed down, in turn require more trees to be added to the model, in turn taking longer to train, providing a configuration trade-off between the number of trees and learning rate. Decreasing the value of v [the learning rate] increases the best value for M [the number of trees]. It is common to have small values in the range of 0.1 to 0.3, as well as values less than 0.1. Similar to a learning rate in stochastic optimization, shrinkage reduces the influence of each individual tree and leaves space for future trees to improve the model. #### Stochastic Gradient Boosting A big insight into bagging ensembles and random forest was allowing trees to be greedily created from subsamples of the training dataset. This same benefit can be used to reduce the correlation between the trees in the sequence in gradient boosting models. This variation of boosting is called stochastic gradient boosting. At each iteration a subsample of the training data is drawn at random (without replacement) from the full training dataset. The randomly selected subsample is then used, instead of the full sample, to fit the base learner. A few variants of stochastic boosting that can be used: * Subsample rows before creating each tree. * Subsample columns before creating each tree * Subsample columns before considering each split. Generally, aggressive sub-sampling such as selecting only 50% of the data has shown to be beneficial. According to user feedback, using column sub-sampling prevents over-fitting even more so than the traditional row sub-sampling. #### Penalized Gradient Boosting Additional constraints can be imposed on the parameterized trees in addition to their structure. Classical decision trees like CART are not used as weak learners, instead a modified form called a regression tree is used that has numeric values in the leaf nodes (also called terminal nodes). The values in the leaves of the trees can be called weights in some literature. As such, the leaf weight values of the trees can be regularized using popular regularization functions, such as: * L1 regularization of weights. * L2 regularization of weights. The additional regularization term helps to smooth the final learnt weights to avoid over-fitting. Intuitively, the regularized objective will tend to select a model employing simple and predictive functions. More details in 2 posts (russian): * https://habr.com/company/ods/blog/327250/ * https://alexanderdyakonov.files.wordpress.com/2017/06/book_boosting_pdf.pdf ## 24. Difference between AdaBoost and XGBoost. Both methods combine weak learners into one strong learner. For example, one decision tree is a weak learner, and an emsemble of them would be a random forest model, which is a strong learner. Both methods in the learning process will increase the ensemble of weak-trainers, adding new weak learners to the ensemble at each training iteration, i.e. in the case of the forest, the forest will grow with new trees. The only difference between AdaBoost and XGBoost is how the ensemble is replenished. AdaBoost works by weighting the observations, putting more weight on difficult to classify instances and less on those already handled well. New weak learners are added sequentially that focus their training on the more difficult patterns. AdaBoost at each iteration changes the sample weights in the sample. It raises the weight of the samples in which more mistakes were made. The sample weights vary in proportion to the ensemble error. We thereby change the probabilistic distribution of samples - those that have more weight will be selected more often in the future. It is as if we had accumulated samples on which more mistakes were made and would use them instead of the original sample. In addition, in AdaBoost, each weak learner has its own weight in the ensemble (alpha weight) - this weight is higher, the ‚Äúsmarter‚Äù this weak learner is, i.e. than the learner least likely to make mistakes. XGBoost does not change the selection or the distribution of observations at all. XGBoost builds the first tree (weak learner), which will fit the observations with some prediction error. A second tree (weak learner) is then added to correct the errors made by the existing model. Errors are minimized using a gradient descent algorithm. Regularization can also be used to penalize more complex models through both Lasso and Ridge regularization. In short, AdaBoost- reweighting examples. Gradient boosting - predicting the loss function of trees. Xgboost - the regularization term was added to the loss function (depth + values ‚Äã‚Äãin leaves). ## 25. Data Mining Describe the decision tree model A decision tree is a structure that includes a root node, branches, and leaf nodes. Each internal node denotes a test on an attribute, each branch denotes the outcome of a test, and each leaf node holds a class label. The topmost node in the tree is the root node. Each internal node represents a test on an attribute. Each leaf node represents a class. The benefits of having a decision tree are as follows: * It does not require any domain knowledge. * It is easy to comprehend. * The learning and classification steps of a decision tree are simple and fast. Tree Pruning Tree pruning is performed in order to remove anomalies in the training data due to noise or outliers. The pruned trees are smaller and less complex. Tree Pruning Approaches Here is the Tree Pruning Approaches listed below: * Pre-pruning ‚àí The tree is pruned by halting its construction early. * Post-pruning - This approach removes a sub-tree from a fully grown tree. Cost Complexity The cost complexity is measured by the following two parameters ‚àí Number of leaves in the tree, and Error rate of the tree. ## 26. Notes from Coursera Deep Learning courses by Andrew Ng Notes from Coursera Deep Learning courses by Andrew Ng ## 27. What is a neural network? Neural networks are typically organized in layers. Layers are made up of a number of interconnected 'nodes' which contain an 'activation function'. Patterns are presented to the network via the 'input layer', which communicates to one or more 'hidden layers' where the actual processing is done via a system of weighted 'connections'. The hidden layers then link to an 'output layer' where the answer is output as shown in the graphic below. Although there are many different kinds of learning rules used by neural networks, this demonstration is concerned only with one: the delta rule. The delta rule is often utilized by the most common class of ANNs called 'backpropagation neural networks' (BPNNs). Backpropagation is an abbreviation for the backwards propagation of error. With the delta rule, as with other types of back propagation, 'learning' is a supervised process that occurs with each cycle or 'epoch' (i.e. each time the network is presented with a new input pattern) through a forward activation flow of outputs, and the backwards error propagation of weight adjustments. More simply, when a neural network is initially presented with a pattern it makes a random 'guess' as to what it might be. It then sees how far its answer was from the actual one and makes an appropriate adjustment to its connection weights. More graphically, the process looks something like this: !alt text Backpropagation performs a gradient descent within the solution's vector space towards a 'global minimum' along the steepest vector of the error surface. The global minimum is that theoretical solution with the lowest possible error. The error surface itself is a hyperparaboloid but is seldom 'smooth'. Indeed, in most problems, the solution space is quite irregular with numerous 'pits' and 'hills' which may cause the network to settle down in a 'local minimum' which is not the best overall solution. Since the nature of the error space can not be known a priori, neural network analysis often requires a large number of individual runs to determine the best solution. Most learning rules have built-in mathematical terms to assist in this process which control the 'speed' (Beta-coefficient) and the 'momentum' of the learning. The speed of learning is actually the rate of convergence between the current solution and the global minimum. Momentum helps the network to overcome obstacles (local minima) in the error surface and settle down at or near the global minimum. Once a neural network is 'trained' to a satisfactory level it may be used as an analytical tool on other data. To do this, the user no longer specifies any training runs and instead allows the network to work in forward propagation mode only. New inputs are presented to the input pattern where they filter into and are processed by the middle layers as though training were taking place, however, at this point the output is retained and no backpropagation occurs. The output of a forward propagation run is the predicted model for the data which can then be used for further analysis and interpretation. ## 28. How do you deal with sparse data? We could take a look at L1 regularization since it best fits the sparse data and does feature selection. If linear relationship - linear regression either - svm. Also it would be nice to use one-hot-encoding or bag-of-words. A one hot encoding is a representation of categorical variables as binary vectors. This first requires that the categorical values be mapped to integer values. Then, each integer value is represented as a binary vector that is all zero values except the index of the integer, which is marked with a 1. ## 29. RNN and LSTM Here are a few of my favorites: * Understanding LSTM Networks, Chris Olah's LSTM post * Exploring LSTMs, Edwin Chen's LSTM post * The Unreasonable Effectiveness of Recurrent Neural Networks, Andrej Karpathy's blog post * CS231n Lecture 10 - Recurrent Neural Networks, Image Captioning, LSTM, Andrej Karpathy's lecture * Jay Alammar's The Illustrated Transformer the guy generally focuses on visualizing different ML concepts ## 30. Pseudo Labeling Pseudo-labeling is a technique that allows you to use predicted with confidence test data in your training process. This effectivey works by allowing your model to look at more samples, possibly varying in distributions. I have found this Kaggle kernel to be useful in understanding how one can use pseudo-labeling in light of having too few train data points. ## 31. Knowledge Distillation It is the process by which a considerably larger model is able to transfer its knowledge to a smaller one. Applications include NLP and object detection allowing for less powerful hardware to make good inferences without significant loss of accuracy. Example: model compression which is used to compress the knowledge of multiple models into a single neural network. Explanation ## 32. What is an inductive bias? A model's inductive bias is referred to as assumptions made within that model to learn your target function from independent variables, your features. Without these assumptions, there is a whole space of solutions to our problem and finding the one that works best becomes a problem. Found this StackOverflow question useful to look at and explore. Consider an example of an inducion bias when choosing a learning algorithm with the minimum cross-validation (CV) error. Here, we rely on the hypothesis of the minimum CV error and hope it is able to generalize well on the data yet to be seen. Effectively, this choice is what helps us (in this case) make a choice in favor of the learning algorithm (or model) being tried. ## 33. What is a confidence interval in layman's terms? Confidence interval as the name suggests is the amount of confidence associated with an interval of values to get the desired outcome. For example : if 100 - 200 range is a 95% confidence interval , it implies that someone can have 95% assurance that the data point or any desired value is present in that range.",,easy,coding,regression|classification|probability|deep_learning|ensemble|metrics|feature_engineering,iamtodor/data-science-interview-questions-and-answers,,2025-11-17T10:49:36.290245
Explain Difference between joins,,hard,mixed,,jayinai/data-science-question-answer,"* **(INNER) JOIN**: Returns records that have matching values in both tables
* **LEFT (OUTER) JOIN**: Return all records from the left table, and the matched records from the right table
* **RIGHT (OUTER) JOIN**: Return all records from the right table, and the matched records from the left table
* **FULL (OUTER) JOIN**: Return all records when there is a match in either left or right table



(#data-science-question-answer)


## Tools and Framework

The resources here are only meant to help you",2025-11-17T11:42:20.246097
Explain Spark,,hard,mixed,,jayinai/data-science-question-answer,"Using PySpark API.

* The best resource is of course [Spark's documentation](https://spark.apache.org/docs/latest/). Take a thorough review of the topics
* If you are really time constrained, scan the Spark's documentation and check [PySpark cheat sheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PySpark_Cheat_Sheet_Python.pdf) for the basics


(#data-science-question-answer)


## Statistics and ML In General

* [Project Workflow](#project-workflow)
* [Cross Validation](#cross-vali",2025-11-17T11:42:20.246124
Explain Project Workflow,,hard,mixed,,jayinai/data-science-question-answer,"Given a data science / machine learning project, what steps should we follow? Here's
how I would tackle it:

* **Specify business objective.** Are we trying to win more customers, achieve higher satisfaction, or gain more revenues?
* **Define problem.** What is the specific gap in your ideal world and the real one that requires machine learning to fill? Ask questions that can be addressed using your data and predictive modeling (ML algorithms).
* **Create a common sense baseline.** But before yo",2025-11-17T11:42:20.246149
Explain Cross Validation,,medium,mixed,,jayinai/data-science-question-answer,"Cross-validation is a technique to evaluate predictive models by partitioning the original sample into a training set to train the model, and a validation set to evaluate it. For example, a k-fold cross validation divides the data into k folds (or partitions), trains on each k-1 fold, and evaluate on the remaining 1 fold. This results to k models/evaluations, which can be averaged to get a overall model performance.



(#data-science-question-answer)",2025-11-17T11:42:20.246161
Explain Feature Importance,,medium,mixed,,jayinai/data-science-question-answer,"* In linear models, feature importance can be calculated by the scale of the coefficients
* In tree-based methods (such as random forest), important features are likely to appear closer to the root of the tree.  We can get a feature's importance for random forest by computing the averaging depth at which it appears across all trees in the forest.

(#data-science-question-answer)",2025-11-17T11:42:20.246169
Explain Mean Squared Error vs. Mean Absolute Error,,medium,mixed,,jayinai/data-science-question-answer,"* **Similarity**: both measure the average model prediction error; range from 0 to infinity; the lower the better
* Mean Squared Error (MSE) gives higher weights to large error (e.g., being off by 10 just MORE THAN TWICE as bad as being off by 5), whereas Mean Absolute Error (MAE) assign equal weights (being off by 10 is just twice as bad as being off by 5)
* MSE is continuously differentiable, MAE is not (where y_pred == y_true)

(#data-science-question-answer)",2025-11-17T11:42:20.246178
Explain L1 vs L2 regularization,,hard,mixed,,jayinai/data-science-question-answer,"* **Similarity**: both L1 and L2 regularization **prevent overfitting** by shrinking (imposing a penalty) on the coefficients
* **Difference**: L2 (Ridge) shrinks all the coefficient by the same proportions but eliminates none, while L1 (Lasso) can shrink some coefficients to zero, performing variable selection.
* **Which to choose**: If all the features are correlated with the label, ridge outperforms lasso, as the coefficients are never zero in ridge. If only a subset of features are correlate",2025-11-17T11:42:20.246187
Explain Correlation vs Covariance,,hard,mixed,,jayinai/data-science-question-answer,"* Both determine the relationship and measure the dependency between two random variables
* Correlation is when the change in one item may result in the change in the another item, while covariance is when two items vary together (joint variability)
* Covariance is nothing but a measure of correlation. On the contrary, correlation refers to the scaled form of covariance
* Range: correlation is between -1 and +1, while covariance lies between negative infinity and infinity.


(#data-science-quest",2025-11-17T11:42:20.246195
Explain Would adding more data address underfitting,,medium,mixed,,jayinai/data-science-question-answer,"Underfitting happens when a model is not complex enough to learn well from the data. It is the problem of model rather than data size. So a potential way to address underfitting is to increase the model complexity (e.g., to add higher order coefficients for linear model, increase depth for tree-based methods, add more layers / number of neurons for neural networks etc.)

(#data-science-question-answer)",2025-11-17T11:42:20.246203
Explain Activation Function,,medium,mixed,,jayinai/data-science-question-answer,"For neural networks

* Non-linearity: ReLU is often used. Use Leaky ReLU (a small positive gradient for negative input, say, `y = 0.01x` when x < 0) to address dead ReLU issue
* Multi-class: softmax
* Binary: sigmoid
* Regression: linear

(#data-science-question-answer)",2025-11-17T11:42:20.246210
Explain Bagging,,hard,mixed,,jayinai/data-science-question-answer,"To address overfitting, we can use an ensemble method called bagging (bootstrap aggregating),
which reduces the variance of the meta learning algorithm. Bagging can be applied
to decision tree or other algorithms.

Here is a [great illustration](http://scikit-learn.org/stable/auto_examples/ensemble/plot_bias_variance.html#sphx-glr-auto-examples-ensemble-plot-bias-variance-py) of a single estimator vs. bagging.



* Bagging is when samlping is performed *with* replacement. When sampling is perfor",2025-11-17T11:42:20.246219
Explain Stacking,,hard,mixed,,jayinai/data-science-question-answer,"* Instead of using trivial functions (such as hard voting) to aggregate the predictions from individual learners, train a model to perform this aggregation
* First split the training set into two subsets: the first subset is used to train the learners in the first layer
* Next the first layer learners are used to make predictions (meta features) on the second subset, and those predictions are used to train another models (to obtain the weigts of different learners) in the second layer
* We can t",2025-11-17T11:42:20.246227
Explain Generative vs discriminative,,hard,mixed,,jayinai/data-science-question-answer,"* Discriminative algorithms model *p(y|x; w)*, that is, given the dataset and learned
parameter, what is the probability of y belonging to a specific class. A discriminative algorithm
doesn't care about how the data was generated, it simply categorizes a given example
* Generative algorithms try to model *p(x|y)*, that is, the distribution of features given
that it belongs to a certain class. A generative algorithm models how the data was
generated.

> Given a training set, an algorithm like log",2025-11-17T11:42:20.246240
Explain Parametric vs Nonparametric,,medium,mixed,,jayinai/data-science-question-answer,"* A learning model that summarizes data with a set of parameters of fixed size (independent of the number of training examples) is called a parametric model.
* A model where the number of parameters is not determined prior to training. Nonparametric does not mean that they have no parameters. On the contrary, nonparametric models (can) become more and more complex with an increasing amount of data.

(#data-science-question-answer)",2025-11-17T11:42:20.246247
Explain Recommender System,,hard,mixed,,jayinai/data-science-question-answer,"* I put recommend system here since technically it falls neither under supervised nor unsupervised learning
* A recommender system seeks to predict the 'rating' or 'preference' a user would give to items and then recommend items accordingly
* Content based recommender systems recommends items similar to those a given user has liked in the past, based on either explicit (ratings, like/dislike button) or implicit (viewed/finished an article) feedbacks. Content based recommenders work solely with t",2025-11-17T11:42:20.246259
Explain Linear regression,,hard,mixed,,jayinai/data-science-question-answer,"* How to learn the parameter: minimize the cost function
* How to minimize cost function: gradient descent
* Regularization:
    - L1 (Lasso): can shrink certain coef to zero, thus performing feature selection
    - L2 (Ridge): shrink all coef with the same proportion; almost always outperforms L1
    - Elastic Net: combined L1 and L2 priors as regularizer
* Assumes linear relationship between features and the label
* Can add polynomial and interaction features to add non-linearity



(#data-sci",2025-11-17T11:42:20.246268
Explain Logistic regression,,medium,mixed,,jayinai/data-science-question-answer,"* Generalized linear model (GLM) for binary classification problems
* Apply the sigmoid function to the output of linear models, squeezing the target
to range [0, 1]
* Threshold to make prediction: usually if the output > .5, prediction 1; otherwise prediction 0
* A special case of softmax function, which deals with multi-class problems

(#data-science-question-answer)",2025-11-17T11:42:20.246275
Explain Naive Bayes,,hard,mixed,,jayinai/data-science-question-answer,"* Naive Bayes (NB) is a supervised learning algorithm based on applying [Bayes' theorem](https://en.wikipedia.org/wiki/Bayes%27_theorem)
* It is called naive because it builds the naive assumption that each feature
are independent of each other
* NB can make different assumptions (i.e., data distributions, such as Gaussian,
Multinomial, Bernoulli)
* Despite the over-simplified assumptions, NB classifier works quite well in real-world
applications, especially for text classification (e.g., spam f",2025-11-17T11:42:20.246284
Explain Decision tree,,hard,mixed,,jayinai/data-science-question-answer,"* Non-parametric, supervised learning algorithms
* Given the training data, a decision tree algorithm divides the feature space into
regions. For inference, we first see which
region does the test data point fall in, and take the mean label values (regression)
or the majority label value (classification).
* **Construction**: top-down, chooses a variable to split the data such that the
target variables within each region are as homogeneous as possible. Two common
metrics: gini impurity or informa",2025-11-17T11:42:20.246301
Explain Random forest,,hard,mixed,,jayinai/data-science-question-answer,"Random forest improves bagging further by adding some randomness. In random forest,
only a subset of features are selected at random to construct a tree (while often not subsample instances).
The benefit is that random forest **decorrelates** the trees.

For example, suppose we have a dataset. There is one very predicative feature, and a couple
of moderately predicative features. In bagging trees, most of the trees
will use this very predicative feature in the top split, and therefore making mos",2025-11-17T11:42:20.246309
Explain Boosting Tree,,hard,mixed,,jayinai/data-science-question-answer,"**How it works**

Boosting builds on weak learners, and in an iterative fashion. In each iteration,
a new learner is added, while all existing learners are kept unchanged. All learners
are weighted based on their performance (e.g., accuracy), and after a weak learner
is added, the data are re-weighted: examples that are misclassified gain more weights,
while examples that are correctly classified lose weights. Thus, future weak learners
focus more on examples that previous weak learners misclass",2025-11-17T11:42:20.246318
Explain RNN and LSTM,,hard,mixed,,jayinai/data-science-question-answer,"RNN is another paradigm of neural network where we have difference layers of cells,
and each cell not only takes as input the cell from the previous layer, but also the previous
cell within the same layer. This gives RNN the power to model sequence.



This seems great, but in practice RNN barely works due to exploding/vanishing gradient, which
is cause by a series of multiplication of the same matrix. To solve this, we can use
a variation of RNN, called long short-term memory (LSTM), which is c",2025-11-17T11:42:20.246333
Explain Clustering,,hard,mixed,,jayinai/data-science-question-answer,"* Clustering is a unsupervised learning algorithm that groups data in such
a way that data points in the same group are more similar to each other than to
those from other groups
* Similarity is usually defined using a distance measure (e.g, Euclidean, Cosine, Jaccard, etc.)
* The goal is usually to discover the underlying structure within the data (usually high dimensional)
* The most common clustering algorithm is K-means, where we define K (the number of clusters)
and the algorithm iterativel",2025-11-17T11:42:20.246342
Explain Principal Component Analysis,,hard,mixed,,jayinai/data-science-question-answer,"* Principal Component Analysis (PCA) is a dimension reduction technique that projects
the data into a lower dimensional space
* PCA uses Singular Value Decomposition (SVD), which is a matrix factorization method
that decomposes a matrix into three smaller matrices (more details of SVD [here](https://en.wikipedia.org/wiki/Singular-value_decomposition))
* PCA finds top N principal components, which are dimensions along which the data vary
(spread out) the most. Intuitively, the more spread out the",2025-11-17T11:42:20.246351
Explain Autoencoder,,medium,mixed,,jayinai/data-science-question-answer,"* The aim of an autoencoder is to learn a representation (encoding) for a set of data
* An autoencoder always consists of two parts, the encoder and the decoder. The encoder would find a lower dimension representation (latent variable) of the original input, while the decoder is used to reconstruct from the lower-dimension vector such that the distance between the original and reconstruction is minimized
* Can be used for data denoising and dimensionality reduction",2025-11-17T11:42:20.246359
Explain Generative Adversarial Network,,hard,mixed,,jayinai/data-science-question-answer,"* Generative Adversarial Network (GAN) is an unsupervised learning algorithm that also has supervised flavor: using supervised loss as part of training
* GAN typically has two major components: the **generator** and the **discriminator**. The generator tries to generate ""fake"" data (e.g, images or sentences) that fool the discriminator into thinking that they're real, while the discriminator tries to distinguish between real and generated data. It's a fight between the two players thus the name ",2025-11-17T11:42:20.246371
Explain Tokenization,,hard,mixed,,jayinai/data-science-question-answer,"* Tokenization is the process of converting a sequence of characters into a sequence of tokens
* Consider this example: `The quick brown fox jumped over the lazy dog`. In this case each word (separated by space) would be a token
* Sometimes tokenization doesn't have a definitive answer. For instance, `O'Neill` can be tokenized to `o` and `neill`, `oneill`, or `o'neill`.
* In some cases tokenization requires language-specific knowledge. For example, it doesn't make sense to tokenize `aren't` into",2025-11-17T11:42:20.246379
Explain Stemming and lemmatization,,hard,mixed,,jayinai/data-science-question-answer,"* The goal of both stemming and lemmatization is to reduce inflectional forms and sometimes derivationally related forms of a word to a common base form
* Stemming usually refers to a crude heuristic process that chops off the ends of words
* Lemmatization usually refers to doing things properly with the use of a vocabulary and morphological analysis of words
* If confronted with the token `saw`, stemming might return just `s`, whereas lemmatization would attempt to return either `see` or `saw` ",2025-11-17T11:42:20.246387
Explain N gram,,hard,mixed,,jayinai/data-science-question-answer,"* n-gram is a contiguous sequence of n items from a given sample of text or speech
* An n-gram of size 1 is referred to as a ""unigram""; size 2 is a ""bigram"" size 3 is a ""trigram"". Larger sizes are sometimes referred to by the value of n in modern language, e.g., ""four-gram"", ""five-gram"", and so on.
* Consider this example: `The quick brown fox jumped over the lazy dog.`
  - bigram would be `the quick`, `quick brown`, `brown fox`, ..., i.e, every two consecutive words (or tokens)
  - trigram woul",2025-11-17T11:42:20.246394
Explain Bag of Words,,hard,mixed,,jayinai/data-science-question-answer,"* Why? Machine learning models cannot work with raw text directly; rather, they take numerical values as input.
* Bag of words (BoW) builds a **vocabulary** of all the unique words in our dataset, and associate a unique index to each word in the vocabulary
* It is called a ""bag"" of words, because it is a representation that completely ignores the order of words
* Consider this example of two sentences: (1) `John likes to watch movies, especially horor movies.`, (2) `Mary likes movies too.` We wo",2025-11-17T11:42:20.246402
Explain word2vec,,hard,mixed,,jayinai/data-science-question-answer,"* Shallow, two-layer neural networks that are trained to construct linguistic context of words
* Takes as input a large corpus, and produce a vector space, typically of several hundred
dimension, and each word in the corpus is assigned a vector in the space
* The key idea is **context**: words that occur often in the same context should have same/opposite
meanings.
* Two flavors
    - continuous bag of words (CBOW): the model predicts the current word given a window of surrounding context words
",2025-11-17T11:42:20.246413
Explain Cron job,,hard,mixed,,jayinai/data-science-question-answer,"The software utility **cron** is a **time-based job scheduler** in Unix-like computer operating systems. People who set up and maintain software environments use cron to schedule jobs (commands or shell scripts) to run periodically at fixed times, dates, or intervals. It typically automates system maintenance or administration -- though its general-purpose nature makes it useful for things like downloading files from the Internet and downloading email at regular intervals.



Tools:
* [Apache Ai",2025-11-17T11:42:20.246423
Explain Linux,,medium,mixed,,jayinai/data-science-question-answer,"Using **Ubuntu** as an example.

* Become root: `sudo su`
* Install package: `sudo apt-get install <package>`

(#data-science-question-answer)


Confession: some images are adopted from the internet without proper credit. If you are the author and this would be an issue for you, please let me know.",2025-11-17T11:42:20.246431
Explain to me a technical concept related to the role that you‚Äôre interviewing for.,,medium,behavioral,communication,kojino/120-DS-Questions,,2025-11-18T16:04:43.447330
Introduce me to something you‚Äôre passionate about.,,medium,behavioral,communication,kojino/120-DS-Questions,,2025-11-18T16:04:43.447342
How would you explain an A/B test to an engineer with no statistics background? A linear regression?,,medium,behavioral,communication,kojino/120-DS-Questions,"- A/B testing, or more broadly, multivariate testing, is the testing of different elements of a user's experience to determine which variation helps the business achieve its goal more effectively (i.e. increasing conversions, etc..)¬† This can be copy on a web site, button colors, different user interfaces, different email subject lines, calls to action, offers, etc.",2025-11-18T16:04:43.447381
How would you explain a confidence interval to an engineer with no statistics background? What does 95% confidence mean?,,medium,behavioral,communication,kojino/120-DS-Questions,- [link](https://www.quora.com/What-is-a-confidence-interval-in-laymans-terms),2025-11-18T16:04:43.447402
How would you explain to a group of senior executives why data is important?,,medium,behavioral,communication,kojino/120-DS-Questions,,2025-11-18T16:04:43.447408
(Given a Dataset) Analyze this dataset and tell me what you can learn from it.,,medium,case,data_analysis,kojino/120-DS-Questions,,2025-11-18T16:04:43.447458
What is R2? What are some other metrics that could be better than R2 and why?,,medium,case,data_analysis,kojino/120-DS-Questions,"- goodness of fit measure. variance explained by the regression / total variance
  - the more predictors you add the higher R^2 becomes.
    - hence use adjusted R^2 which adjusts for the degrees of freedom¬†
    - or train error metrics",2025-11-18T16:04:43.447469
What is the curse of dimensionality?,,hard,case,data_analysis,kojino/120-DS-Questions,"- High dimensionality makes clustering hard, because having lots of dimensions means that everything is ""far away"" from each other.
  - For example, to cover a fraction of the volume of the data we need to capture a very wide range for each variable as the number of variables increases
  - All samples are close to the edge of the sample.¬†And this is a bad news because prediction is much more difficult near the edges of the training sample.
  - The sampling density decreases exponentially as p in",2025-11-18T16:04:43.447483
Is more data always better?,,hard,case,data_analysis,kojino/120-DS-Questions,"- Statistically,
    - It depends on the quality of your data, for example, if your data is biased, just getting more data won‚Äôt help.
    - It depends on your model. If your model suffers from high bias, getting more data won‚Äôt improve your test results beyond a point. You‚Äôd need to add more features, etc.
  - Practically,
    - Also there‚Äôs a tradeoff between having more data and the additional storage, computational power, memory it requires. Hence, always think about the cost of having more ",2025-11-18T16:04:43.447495
What are advantages of plotting your data before per- forming analysis?,,hard,case,data_analysis,kojino/120-DS-Questions,"- 1) Data sets have errors.¬† You won't find them all but you might find some. That 212 year old man. That 9 foot tall woman.  
2) Variables can have skewness, outliers etc.¬† Then the arithmetic mean might not be useful. Which means the standard deviation isn't useful.  
3) Variables can be multimodal!¬† If a variable is multimodal then anything based on its mean or median is going to be suspect.",2025-11-18T16:04:43.447506
How can you make sure that you don‚Äôt analyze something that ends up meaningless?,,hard,case,data_analysis,kojino/120-DS-Questions,"- Proper exploratory data analysis.  
In every data analysis task, there's the¬†exploratory¬†phase where you're just graphing things, testing things on small sets of the data, summarizing simple statistics, and getting rough ideas of what hypotheses you might want to pursue further.  
Then there's the¬†exploitatory¬†phase, where you look deeply into a set of hypotheses.¬†  
The exploratory phase will generate lots of possible hypotheses, and the exploitatory phase will let you really understand a few",2025-11-18T16:04:43.447523
What is the role of trial and error in data analysis? What is the the role of making a hypothesis before diving in?,,hard,case,data_analysis,kojino/120-DS-Questions,"- data analysis is a repetition of setting up a new hypothesis and trying to refute the null hypothesis.
  - The scientific method is eminently¬†inductive: we elaborate a hypothesis, test it and refute it or not. As a result, we come up with new hypotheses which are in turn tested and so on. This is an iterative process, as science always is.",2025-11-18T16:04:43.447536
How can you determine which features are the most im- portant in your model?,,medium,case,data_analysis,kojino/120-DS-Questions,"- run the features though a Gradient Boosting Machine or Random Forest to generate plots of relative importance and information gain for each feature in the ensembles.
  - Look at the variables added in forward variable selection",2025-11-18T16:04:43.447545
How do you deal with some of your predictors being missing?,,hard,case,data_analysis,kojino/120-DS-Questions,"- Remove rows with missing values -¬†This works well if 1) the values are missing randomly (see¬†[Vinay Prabhu's answer](https://www.quora.com/How-can-I-deal-with-missing-values-in-a-predictive-model/answer/Vinay-Prabhu-7)¬†for more details on this) 2) if you don't lose too much of the dataset after doing so.
  - Build another predictive model to predict the missing values -¬†This could be a whole project in itself, so simple techniques are usually used here.
  - Use a model that can incorporate mis",2025-11-18T16:04:43.447558
"You have several variables that are positively correlated with your response, and you think combining all of the variables could give you a good prediction of your response. However, you see that in the multiple linear regression, one of the weights on the predictors is negative. What could be the issue?",,hard,case,data_analysis,kojino/120-DS-Questions,"- Multicollinearity¬†refers to a situation in which two or more explanatory variables in a¬†[multiple regression](https://en.wikipedia.org/wiki/Multiple_regression ""Multiple regression"")¬†model are highly linearly related.¬†
  - Leave the model as is, despite multicollinearity. The presence of multicollinearity doesn't affect the efficiency of extrapolating the fitted model to new data provided that the predictor variables follow the same pattern of multicollinearity in the new data as in the data o",2025-11-18T16:04:43.447579
Let‚Äôs say you‚Äôre given an unfeasible amount of predictors in a predictive modeling task. What are some ways to make the prediction more feasible?,,medium,case,data_analysis,kojino/120-DS-Questions,- PCA,2025-11-18T16:04:43.447587
"Now you have a feasible amount of predictors, but you‚Äôre fairly sure that you don‚Äôt need all of them. How would you perform feature selection on the dataset?",,hard,case,data_analysis,kojino/120-DS-Questions,"- ridge / lasso / elastic net regression
  - Univariate Feature Selection where a statistical test is applied to each feature individually. You retain only the best features according to the test outcome scores
  - ""Recursive Feature Elimination"":  
    - First, train a model with all the feature and evaluate its performance on held out data.
    - Then drop let say the 10% weakest features (e.g. the feature with least absolute coefficients in a linear model) and retrain on the remaining feature",2025-11-18T16:04:43.447604
Your linear regression didn‚Äôt run and communicates that there are an infinite number of best estimates for the regression coefficients. What could be wrong?,,medium,case,data_analysis,kojino/120-DS-Questions,"- p > n.
  - If some of the explanatory variables are perfectly correlated (positively or negatively) then the coefficients would not be unique.",2025-11-18T16:04:43.447614
"You run your regression on different subsets of your data, and find that in each subset, the beta value for a certain variable varies wildly. What could be the issue here?",,medium,case,data_analysis,kojino/120-DS-Questions,"- The dataset might be¬†heterogeneous. In which case, it is recommended to cluster datasets into different subsets wisely, and then draw different models for different subsets. Or, use models like non parametric models (trees) which can deal with¬†heterogeneity quite nicely.",2025-11-18T16:04:43.447627
"What is the main idea behind ensemble learning? If I had many different models that predicted the same response variable, what might I want to do to incorporate all of the models? Would you expect this to perform better than an individual model or worse?",,hard,case,data_analysis,kojino/120-DS-Questions,"- The assumption is that a group of weak learners can be combined to form a strong learner.
  - Hence the combined model is expected to perform better than an individual model.
  - Assumptions:
    - average out biases
    - reduce variance
  - Bagging works because some underlying learning algorithms are unstable: slightly different inputs leads to very different outputs. If you can take advantage of this instability by running multiple instances, it can be shown that the reduced instability le",2025-11-18T16:04:43.447660
"Given that you have wi data in your o ce, how would you determine which rooms and areas are underutilized and overutilized?",,medium,case,data_analysis,kojino/120-DS-Questions,"- If the data is more used in one room, then that one is¬†over utilized! Maybe account for the room capacity and normalize the data.",2025-11-18T16:04:43.447669
How could you use GPS data from a car to determine the quality of a driver?,,medium,case,data_analysis,kojino/120-DS-Questions,,2025-11-18T16:04:43.447673
"Given accelerometer, altitude, and fuel usage data from a car, how would you determine the optimum acceleration pattern to drive over hills?",,medium,case,data_analysis,kojino/120-DS-Questions,,2025-11-18T16:04:43.447680
"Given position data of NBA players in a season‚Äôs games, how would you evaluate a basketball player‚Äôs defensive ability?",,medium,case,data_analysis,kojino/120-DS-Questions,,2025-11-18T16:04:43.447685
How would you quantify the influence of a Twitter user?,,medium,case,data_analysis,kojino/120-DS-Questions,- like page rank with each user corresponding to the webpages and linking to the page equivalent to following.,2025-11-18T16:04:43.447691
"Given location data of golf balls in games, how would construct a model that can advise golfers where to aim?",,medium,case,data_analysis,kojino/120-DS-Questions,,2025-11-18T16:04:43.447697
"You have 100 mathletes and 100 math problems. Each mathlete gets to choose 10 problems to solve. Given data on who got what problem correct, how would you rank the problems in terms of di culty?",,hard,case,data_analysis,kojino/120-DS-Questions,"- One way you could do this is by storing a ""skill level"" for each user and a ""difficulty level"" for each problem.¬† We assume that the probability that a user solves a problem only depends on the skill of the user and the difficulty of the problem.*¬† Then we maximize the likelihood of the data to find the hidden skill and difficulty levels.
  - The Rasch model for dichotomous data takes the form:  
{\displaystyle \Pr\\{X_{ni}=1\\}={\frac {\exp({\beta _{n}}-{\delta _{i}})}{1+\exp({\beta _{n}}-{\d",2025-11-18T16:04:43.447714
You have 5000 people that rank 10 sushis in terms of saltiness. How would you aggregate this data to estimate the true saltiness rank in each sushi?,,medium,case,data_analysis,kojino/120-DS-Questions,"- Some people would take the mean rank of each sushi.¬† If I wanted something simple, I would use the median, since ranks are (strictly speaking) ordinal and not interval, so adding them is a bit risque (but people do it all the time and you probably won't be far wrong).",2025-11-18T16:04:43.447726
"Given data on congressional bills and which congressional representatives co-sponsored the bills, how would you determine which other representatives are most similar to yours in voting behavior? How would you evaluate who is the most liberal? Most republican? Most bipartisan?",,medium,case,data_analysis,kojino/120-DS-Questions,"- collaborative filtering. you have your votes and we can calculate the similarity for each representatives and select the most similar representative
  - for liberal and republican parties, find the mean vector and find the representative closest to the center point",2025-11-18T16:04:43.447740
How would you come up with an algorithm to detect plagiarism in online content?,,medium,case,data_analysis,kojino/120-DS-Questions,"- reduce the text to a more compact form (e.g. fingerprinting, bag of words) then compare those with other texts by calculating the similarity",2025-11-18T16:04:43.447747
You have data on all purchases of customers at a grocery store. Describe to me how you would program an algorithm that would cluster the customers into groups. How would you determine the appropriate number of clusters to include?,,medium,case,data_analysis,kojino/120-DS-Questions,"- KMeans
  - choose a small value of¬†k¬†that still has a low SSE (elbow method)
  - <https://bl.ocks.org/rpgove/0060ff3b656618e9136b>",2025-11-18T16:04:43.447759
Let's say you're building the recommended music engine at Spotify to recommend people music based on past listening history. How would you approach this problem?,,medium,case,data_analysis,kojino/120-DS-Questions,- [collaborative filtering](https://en.wikipedia.org/wiki/Collaborative_filtering),2025-11-18T16:04:43.447768
(Given a Dataset) Analyze this dataset and give me a model that can predict this response variable.,,hard,ml,predictive_modeling,kojino/120-DS-Questions,"- Start by fitting a simple model (multivariate regression, logistic regression), do some feature engineering accordingly, and then try some complicated models. Always split the dataset into train, validation, test dataset and use cross validation to check their performance.
- Determine if the problem is classification or regression
- Favor simple models that run quickly and you can easily explain.
- Mention cross validation as a means to evaluate the model.
- Plot and visualize the data.",2025-11-18T16:04:43.447814
What could be some issues if the distribution of the test data is significantly different than the distribution of the training data?,,hard,ml,predictive_modeling,kojino/120-DS-Questions,"- The model that has high training accuracy might have low test accuracy. Without further knowledge, it is hard to know which dataset represents the population data and thus the generalizability of the algorithm is hard to measure. This should be mitigated by repeated splitting of train vs test dataset (as in cross validation).
- When there is a change in data distribution, this is called the dataset shift. If the train and test data has a different distribution, then the classifier would likely",2025-11-18T16:04:43.447836
What are some ways I can make my model more robust to outliers?,,hard,ml,predictive_modeling,kojino/120-DS-Questions,"- We can have regularization such as L1 or L2 to reduce variance (increase bias).
- Changes to the algorithm:
  - Use tree-based methods instead of regression methods as they are more resistant to outliers. For statistical tests, use non parametric tests instead of parametric ones.
  - Use robust error metrics such as MAE or Huber Loss instead of MSE.
- Changes to the data:
  - Winsorizing the data
  - Transforming the data (e.g. log)
  - Remove them only if you‚Äôre certain they‚Äôre anomalies not ",2025-11-18T16:04:43.447849
"What are some differences you would expect in a model that minimizes squared error, versus a model that minimizes absolute error? In which cases would each error metric be appropriate?",,hard,ml,predictive_modeling,kojino/120-DS-Questions,"- MSE is more strict to having outliers. MAE is more robust in that sense, but is harder to fit the model for because it cannot be numerically optimized. So when there are less variability in the model and the model is computationally easy to fit, we should use MAE, and if that‚Äôs not the case, we should use MSE.
- MSE: easier to compute the gradient, MAE: linear programming needed to compute the gradient
- MAE more robust to outliers. If the consequences of large errors are great, use MSE
- MSE ",2025-11-18T16:04:43.447866
What error metric would you use to evaluate how good a binary classifier is? What if the classes are imbalanced? What if there are more than 2 groups?,,hard,ml,predictive_modeling,kojino/120-DS-Questions,"- Accuracy: proportion of instances you predict correctly. Pros: intuitive, easy to explain, Cons: works poorly when the class labels are imbalanced and the signal from the data is weak
- AUROC: plot fpr on the x axis and tpr on the y axis for different threshold. Given a random positive instance and a random negative instance, the AUC is the probability that you can identify who's who. Pros: Works well when testing the ability of distinguishing the two classes, Cons: can‚Äôt interpret predictions",2025-11-18T16:04:43.447887
"What are various ways to predict a binary response variable? Can you compare two of them and tell me when one would be more appropriate? What‚Äôs the difference between these? (SVM, Logistic Regression, Naive Bayes, Decision Tree, etc.)",,hard,ml,predictive_modeling,kojino/120-DS-Questions,"- Things to look at: N, P, linearly seperable?, features independent?, likely to overfit?, speed, performance, memory usage
- Logistic Regression
  - features roughly linear, problem roughly linearly separable
  - robust to noise, use l1,l2 regularization for model selection, avoid overfitting
  - the output come as probabilities
  - efficient and the computation can be distributed
  - can be used as a baseline for other algorithms
  - (-) can hardly handle categorical features
- SVM
  - with a ",2025-11-18T16:04:43.447919
What is regularization and where might it be helpful? What is an example of using regularization in a model?,,medium,ml,predictive_modeling,kojino/120-DS-Questions,"- Regularization is useful for reducing variance in the model, meaning avoiding overfitting . For example, we can use L1 regularization in Lasso regression to penalize large coefficients.",2025-11-18T16:04:43.447928
Why might it be preferable to include fewer predictors over many?,,hard,ml,predictive_modeling,kojino/120-DS-Questions,"- When we add irrelevant features, it increases model's tendency to overfit because those features introduce more noise. When two variables are correlated, they might be harder to interpret in case of regression, etc.
- curse of dimensionality
- adding random noise makes the model more complicated but useless
- computational cost
- Ask someone for more details.",2025-11-18T16:04:43.447938
"Given training data on tweets and their retweets, how would you predict the number of retweets of a given tweet after 7 days after only observing 2 days worth of data?",,hard,ml,predictive_modeling,kojino/120-DS-Questions,"- Build a time series model with the training data with a seven day cycle and then use that for a new data with only 2 days data.
- Ask someone for more details.
- Build a regression function to estimate the number of retweets as a function of time t
- to determine if one regression function can be built, see if there are clusters in terms of the trends in the number of retweets
- if not, we have to add features to the regression function
- features + # of retweets on the first and the second da",2025-11-18T16:04:43.447956
How could you collect and analyze data to use social media to predict the weather?,,hard,ml,predictive_modeling,kojino/120-DS-Questions,"- We can collect social media data using twitter, Facebook, instagram API‚Äôs. Then, for example, for twitter, we can construct features from each tweet, e.g. the tweeted date, number of favorites, retweets, and of course, the features created from the tweeted content itself. Then use a multi variate time series model to predict the weather.
- Ask someone for more details.",2025-11-18T16:04:43.447967
How would you construct a feed to show relevant content for a site that involves user interactions with items?,,hard,ml,predictive_modeling,kojino/120-DS-Questions,"- We can do so using building a recommendation engine. The easiest we can do is to show contents that are popular other users, which is still a valid strategy if for example the contents are news articles. To be more accurate, we can build a content based filtering or collaborative filtering. If there‚Äôs enough user usage data, we can try collaborative filtering and recommend contents other similar users have consumed. If there isn‚Äôt, we can recommend similar items based on vectorization of items",2025-11-18T16:04:43.447980
How would you design the people you may know feature on LinkedIn or Facebook?,,hard,ml,predictive_modeling,kojino/120-DS-Questions,"- Find strong unconnected people in weighted connection graph
  - Define similarity as how strong the two people are connected
  - Given a certain feature, we can calculate the similarity based on
    - friend connections (neighbors)
    - Check-in‚Äôs people being at the same location all the time.
    - same college, workplace
    - Have randomly dropped graphs test the performance of the algorithm
- ref. News Feed Optimization
  - Affinity score: how close the content creator and the users are
",2025-11-18T16:04:43.447995
How would you predict who someone may want to send a Snapchat or Gmail to?,,hard,ml,predictive_modeling,kojino/120-DS-Questions,"- for each user, assign a score of how likely someone would send an email to
- the rest is feature engineering:
  - number of past emails, how many responses, the last time they exchanged an email, whether the last email ends with a question mark, features about the other users, etc.
- Ask someone for more details.
- People who someone sent emails the most in the past, conditioning on time decay.",2025-11-18T16:04:43.448006
How would you suggest to a franchise where to open a new store?,,hard,ml,predictive_modeling,kojino/120-DS-Questions,"- build a master dataset with local demographic information available for each location.
  - local income levels, proximity to traffic, weather, population density, proximity to other businesses
  - a reference dataset on local, regional, and national macroeconomic conditions (e.g. unemployment, inflation, prime interest rate, etc.)
  - any data on the local franchise owner-operators, to the degree the manager
- identify a set of KPIs acceptable to the management that had requested the analysis ",2025-11-18T16:04:43.448022
"In a search engine, given partial data on what the user has typed, how would you predict the user‚Äôs eventual search query?",,hard,ml,predictive_modeling,kojino/120-DS-Questions,"- Based on the past frequencies of words shown up given a sequence of words, we can construct conditional probabilities of the set of next sequences of words that can show up (n-gram). The sequences with highest conditional probabilities can show up as top candidates.
- To further improve this algorithm,
  - we can put more weight on past sequences which showed up more recently and near your location to account for trends
  - show your recent searches given partial data",2025-11-18T16:04:43.448036
"Given a database of all previous alumni donations to your university, how would you predict which recent alumni are most likely to donate?",,medium,ml,predictive_modeling,kojino/120-DS-Questions,"- Based on frequency and amount of donations, graduation year, major, etc, construct a supervised regression (or binary classification) algorithm.",2025-11-18T16:04:43.448045
You‚Äôre Uber and you want to design a heatmap to recommend to drivers where to wait for a passenger. How would you approach this?,,hard,ml,predictive_modeling,kojino/120-DS-Questions,"- Based on the past pickup location of passengers around the same time of the day, day of the week (month, year), construct
- Ask someone for more details.
- Based on the number of past pickups
  - account for periodicity (seasonal, monthly, weekly, daily, hourly)
  - special events (concerts, festivals, etc.) from tweets",2025-11-18T16:04:43.448056
How would you build a model to predict a March Madness bracket?,,hard,ml,predictive_modeling,kojino/120-DS-Questions,"- One vector each for team A and B. Take the difference of the two vectors and use that as an input to predict the probability that team A would win by training the model. Train the models using past tournament data and make a prediction for the new tournament by running the trained model for each round of the tournament
- Some extensions:
  - Experiment with different ways of consolidating the 2 team vectors into one (e.g concantenating, averaging, etc)
  - Consider using a RNN type model that ",2025-11-18T16:04:43.448069
"You want to run a regression to predict the probability of a flight delay, but there are flights with delays of up to 12 hours that are really messing up your model. How can you address this?",,medium,ml,predictive_modeling,kojino/120-DS-Questions,"- This is equivalent to making the model more robust to outliers.
- See Q3.",2025-11-18T16:04:43.448079
"Bobo the amoeba has a 25%, 25%, and 50% chance of producing 0, 1, or 2 offspring, respectively. Each of Bobo‚Äôs descendants also have the same probabilities. What is the probability that Bobo‚Äôs lineage dies out?",,hard,stats,probability,kojino/120-DS-Questions,- p=1/4+1/4*p+1/2*p^2 => p=1/2,2025-11-18T16:04:43.448114
"In any 15-minute interval, there is a 20% probability that you will see at least one shooting star. What is the proba- bility that you see at least one shooting star in the period of an hour?",,hard,stats,probability,kojino/120-DS-Questions,"- 1-(0.8)^4. Or, we can use Poisson processes",2025-11-18T16:04:43.448124
How can you generate a random number between 1 - 7 with only a die?,,hard,stats,probability,kojino/120-DS-Questions,"* Launch it 3 times: each throw sets the nth bit of the result. 
* For each launch, if the value is 1-3, record a 0, else 1.
The result is between 0 (000) and 7 (111), evenly spread (3 independent throw). Repeat the throws if 0 was obtained: the process stops on evenly spread values.",2025-11-18T16:04:43.448133
How can you get a fair coin toss if someone hands you a coin that is weighted to come up heads more often than tails?,,hard,stats,probability,kojino/120-DS-Questions,"- Flip twice and if HT then H, TH then T.",2025-11-18T16:04:43.448139
You have an 50-50 mixture of two normal distributions with the same standard deviation. How far apart do the means need to be in order for this distribution to be bimodal?,,hard,stats,probability,kojino/120-DS-Questions,- more than two standard deviations,2025-11-18T16:04:43.448147
"Given draws from a normal distribution with known parameters, how can you simulate draws from a uniform distribution?",,hard,stats,probability,kojino/120-DS-Questions,- plug in the value to the CDF of the same random variable,2025-11-18T16:04:43.448154
"A certain couple tells you that they have two children, at least one of which is a girl. What is the probability that they have two girls?",,hard,stats,probability,kojino/120-DS-Questions,- 1/3,2025-11-18T16:04:43.448161
"You have a group of couples that decide to have children until they have their first girl, after which they stop having children. What is the expected gender ratio of the children that are born? What is the expected number of children each couple will have?",,hard,stats,probability,kojino/120-DS-Questions,- gender ratio is 1:1. Expected number of children is 2. let X be the number of children until getting a female (happens with prob 1/2). this follows a geometric distribution with probability 1/2,2025-11-18T16:04:43.448174
How many ways can you split 12 people into 3 teams of 4?,,hard,stats,probability,kojino/120-DS-Questions,- the outcome follows a multinomial distribution with n=12 and k=3. but the classes are indistinguishable,2025-11-18T16:04:43.448179
"Your hash function assigns each object to a number between 1:10, each with equal probability. With 10 objects, what is the probability of a hash collision? What is the expected number of hash collisions? What is the expected number of hashes that are unused.",,hard,stats,probability,kojino/120-DS-Questions,"- the probability of a hash collision:¬†1-(10!/10^10)
  - the expected number of hash collisions: 1-10*(9/10)^10
  - the expected number of hashes that are unused:¬†10*(9/10)^10",2025-11-18T16:04:43.448192
"You call 2 UberX‚Äôs and 3 Lyfts. If the time that each takes to reach you is IID, what is the probability that all the Lyfts arrive first? What is the probability that all the UberX‚Äôs arrive first?",,hard,stats,probability,kojino/120-DS-Questions,"- All Lyft's first
    * probability that the first car is Lyft = 3/5
    * probability that the second car is Lyft = 2/4
    * probability that the third car is Lyft = 1/3
    Therefore, probability that all the Lyfts arrive first = (3/5) * (2/4) * (1/3) = 1/10
  - All Uber's first
    * probability that the first car is Uber = 2/5
    * probability that the second car is Uber = 1/4
    Therefore, probability that all the Ubers arrive first = (2/5) * (1/4) = 1/10",2025-11-18T16:04:43.448209
"I write a program should print out all the numbers from 1 to 300, but prints out Fizz instead if the number is divisible by 3, Buzz instead if the number is divisible by 5, and FizzBuzz if the number is divisible by 3 and 5. What is the total number of numbers that is either Fizzed, Buzzed, or FizzBuzzed?",,hard,stats,probability,kojino/120-DS-Questions,- 100+60-20=140,2025-11-18T16:04:43.448222
"On a dating site, users can select 5 out of 24 adjectives to describe themselves. A match is declared between two users if they match on at least 4 adjectives. If Alice and Bob randomly pick adjectives, what is the probability that they form a match?",,hard,stats,probability,kojino/120-DS-Questions,- 24C5*(1+5(24-5))/24C5*24C5 = 4/1771,2025-11-18T16:04:43.448232
"A lazy high school senior types up application and envelopes to n different colleges, but puts the applications randomly into the envelopes. What is the expected number of applications that went to the right college?",,hard,stats,probability,kojino/120-DS-Questions,- 1,2025-11-18T16:04:43.448241
"Let‚Äôs say you have a very tall father. On average, what would you expect the height of his son to be? Taller, equal, or shorter? What if you had a very short father?",,hard,stats,probability,kojino/120-DS-Questions,- Shorter. Regression to the mean,2025-11-18T16:04:43.448250
What‚Äôs the expected number of coin flips until you get two heads in a row? What‚Äôs the expected number of coin flips until you get two tails in a row?,,hard,stats,probability,kojino/120-DS-Questions,"- After the first two flips, you can see this problem as a Markov chain, with states HH, HT, TH, TT. 
  - HH is the final state. You can than define the expected number of steps N before reaching HH: E(N) = 2 + 0.25nHH, 0.25nHT, 0.25nTH, 0.25nTT. nXX represents the expected number of steps before reaching HH starting from state XX.
  - Solve linear equation:
  * nHH = 0
  * nHT = 1 + 0.5nTT + 0.5nTH
  * nTH = 1 + 0.5nHH + 0.5nHT
  * nTT = 1 + 0.5nTH + 0.5nTT
  - Result gives E(N) = 6.",2025-11-18T16:04:43.448265
"Let‚Äôs say we play a game where I keep flipping a coin until I get heads. If the first time I get heads is on the nth coin, then I pay you 2n-1 dollars. How much would you pay me to play this game?",,hard,stats,probability,kojino/120-DS-Questions,- less than $3,2025-11-18T16:04:43.448274
"You have two coins, one of which is fair and comes up heads with a probability 1/2, and the other which is biased and comes up heads with probability 3/4. You randomly pick coin and flip it twice, and get heads both times. What is the probability that you picked the fair coin?",,hard,stats,probability,kojino/120-DS-Questions,- 4/13,2025-11-18T16:04:43.448285
"You have a 0.1% chance of picking up a coin with both heads, and a 99.9% chance that you pick up a fair coin. You flip your coin and it comes up heads 10 times. What‚Äôs the chance that you picked up the fair coin, given the information that you observed?",,hard,stats,probability,kojino/120-DS-Questions,"* Events: F = ""picked a fair coin"", T = ""10 heads in a row""
  * (1) P(F|T) = P(T|F)P(F)/P(T) (Bayes formula)
  * (2) P(T) = P(T|F)P(F) + P(T|¬¨F)P(¬¨F) (total probabilities formula)
  * Injecting (2) in (1): P(F|T) = P(T|F)P(F)/(P(T|F)P(F) + P(T|¬¨F)P(¬¨F)) = 1 / (1 + P(T|¬¨F)P(¬¨F)/(P(T|F)P(F)))
  * Numerically: 1/(1 + 0.001 * 2^10 /0.999).
  * With 2^10 ‚âà 1000 and 0.999 ‚âà 1 this simplifies to 1/2",2025-11-18T16:04:43.448303
What is a P-Value ?,,hard,stats,probability,kojino/120-DS-Questions,"* The probability to obtain a similar or more extreme result than observed when the null hypothesis is assumed.
  * ‚áí If the p-value is small, the null hypothesis is unlikely",2025-11-18T16:04:43.448308
"What would be good metrics of success for an advertising-driven consumer product? (Buzzfeed, YouTube, Google Search, etc.) A service-driven consumer product? (Uber, Flickr, Venmo, etc.)",,medium,case,product_metrics,kojino/120-DS-Questions,"* advertising-driven: Pageviews and daily actives, CTR, CPC (cost per click)
    * click-ads  
    * display-ads  
  * service-driven: number of purchases, conversion rate",2025-11-18T16:04:43.448343
"What would be good metrics of success for a productiv- ity tool? (Evernote, Asana, Google Docs, etc.) A MOOC? (edX, Coursera, Udacity, etc.)",,medium,case,product_metrics,kojino/120-DS-Questions,"* productivity tool: same as premium subscriptions
  * MOOC:¬†same as premium subscriptions, completion rate",2025-11-18T16:04:43.448351
"What would be good metrics of success for an e-commerce product? (Etsy, Groupon, Birchbox, etc.) A subscrip- tion product? (Net ix, Birchbox, Hulu, etc.) Premium subscriptions? (OKCupid, LinkedIn, Spotify, etc.)",,hard,case,product_metrics,kojino/120-DS-Questions,"* e-commerce:¬†number of purchases, conversion rate,¬†Hourly, daily, weekly, monthly, quarterly, and annual sales, Cost of goods sold,¬†Inventory levels,¬†Site traffic,¬†Unique visitors versus returning visitors,¬†Customer service phone call count,¬†Average resolution time
  * subscription
    * churn, CoCA, ARPU, MRR, LTV
  * premium subscriptions:",2025-11-18T16:04:43.448365
"What would be good metrics of success for a consumer product that relies heavily on engagement and interac- tion? (Snapchat, Pinterest, Facebook, etc.) A messaging product? (GroupMe, Hangouts, Snapchat, etc.)",,medium,case,product_metrics,kojino/120-DS-Questions,"* heavily on engagement and interaction:¬†uses AU ratios, email summary by type, and push notification summary by type, resurrection ratio
  * messaging product:",2025-11-18T16:04:43.448377
"What would be good metrics of success for a product that o ered in-app purchases? (Zynga, Angry Birds, other gaming apps)",,medium,case,product_metrics,kojino/120-DS-Questions,"* Average Revenue Per Paid User
  * Average Revenue Per User",2025-11-18T16:04:43.448383
A certain metric is violating your expectations by going down or up more than you expect. How would you try to identify the cause of the change?,,medium,case,product_metrics,kojino/120-DS-Questions,"* breakdown the KPI‚Äôs into what consists them and find where the change is
  * then further breakdown that basic KPI by channel, user cluster, etc. and relate them with any campaigns, changes in user behaviors in that segment",2025-11-18T16:04:43.448394
Growth for total number of tweets sent has been slow this month. What data would you look at to determine the cause of the problem?,,medium,case,product_metrics,kojino/120-DS-Questions,"* look at competitors' tweet growth
  * look at your social media engagement on other platforms
  * look at your sales data",2025-11-18T16:04:43.448402
You‚Äôre a restaurant and are approached by Groupon to run a deal. What data would you ask from them in order to determine whether or not to do the deal?,,medium,case,product_metrics,kojino/120-DS-Questions,"* for similar restaurants (they should define similarity), average increase in revenue gain per coupon, average increase in customers per coupon, number of meals sold",2025-11-18T16:04:43.448412
You are tasked with improving the e ciency of a subway system. Where would you start?,,medium,case,product_metrics,kojino/120-DS-Questions,* define efficiency,2025-11-18T16:04:43.448417
Say you are working on Facebook News Feed. What would be some metrics that you think are important? How would you make the news each person gets more relevant?,,hard,case,product_metrics,kojino/120-DS-Questions,"* rate for each action, duration users stay, CTR for sponsor feed posts
  * ref. News Feed Optimization
    * Affinity score: how close the content creator and the users are
    * Weight: weight for the edge type (comment, like, tag, etc.). Emphasis on features the company wants to promote
    * Time decay: the older the less important",2025-11-18T16:04:43.448429
How would you measure the impact that sponsored stories on Facebook News Feed have on user engagement? How would you determine the optimum balance between sponsored stories and organic content on a user‚Äôs News Feed?,,medium,case,product_metrics,kojino/120-DS-Questions,* AB test on¬†different balance ratio and see,2025-11-18T16:04:43.448440
You are on the data science team at Uber and you are asked to start thinking about surge pricing. What would be the objectives of such a product and how would you start looking into this?,,hard,case,product_metrics,kojino/120-DS-Questions,"* ¬†there is a gradual step-function type scaling mechanism until that imbalance of requests-to-drivers is alleviated and then vice versa as too many drivers come online enticed by the surge pricing structure.¬†
  * I would bet the algorithm is custom tailored and calibrated to each location as price elasticities almost certainly vary across different cities depending on a huge multitude of variables: income, distance/sprawl, traffic patterns, car ownership, etc. With the massive troves of user da",2025-11-18T16:04:43.448460
Say that you are Netflix. How would you determine what original series you should invest in and create?,,medium,case,product_metrics,kojino/120-DS-Questions,* Netflix uses data to estimate the potential market size for an original series before giving it the go-ahead.,2025-11-18T16:04:43.448467
What kind of services would nd churn (metric that tracks how many customers leave the service) helpful? How would you calculate churn?,,medium,case,product_metrics,kojino/120-DS-Questions,* subscription based services,2025-11-18T16:04:43.448474
Let‚Äôs say that you‚Äôre are scheduling content for a content provider on television. How would you determine the best times to schedule content?,,medium,case,product_metrics,kojino/120-DS-Questions,,2025-11-18T16:04:43.448481
"Write a function to calculate all possible assignment vectors of 2n users, where n users are assigned to group 0 (control), and n users are assigned to group 1 (treatment).",,medium,coding,programming,kojino/120-DS-Questions,- Recursive programming (sol in code),2025-11-18T16:04:43.448517
"Given a list of tweets, determine the top 10 most used hashtags.",,medium,coding,programming,kojino/120-DS-Questions,- Store all the hashtags in a dictionary and get the top 10 values,2025-11-18T16:04:43.448523
Program an algorithm to find the best approximate solution to the knapsack problem1 in a given time.,,medium,coding,programming,kojino/120-DS-Questions,- Greedy solution (add the best v/w as much as possible and move on to the next),2025-11-18T16:04:43.448529
"You have a stream of data coming in of size n, but you don‚Äôt know what n is ahead of time. Write an algorithm that will take a random sample of k elements. Can you write one that takes O(k) space?",,medium,coding,programming,kojino/120-DS-Questions,- https://en.wikipedia.org/wiki/Reservoir_sampling,2025-11-18T16:04:43.448545
Write an algorithm that can calculate the square root of a number.,,medium,coding,programming,kojino/120-DS-Questions,"- <https://www.quora.com/What-is-the-method-to-calculate-a-square-root-by-hand?redirected_qid=664405>
  - https://en.wikipedia.org/wiki/Newton's_method#Square_root_of_a_number",2025-11-18T16:04:43.448552
"Given a list of numbers, can you return the outliers?",,medium,coding,programming,kojino/120-DS-Questions,- sort then select the highest and the lowest 2.5%,2025-11-18T16:04:43.448556
When can parallelism make your algorithms run faster?,,medium,coding,programming,kojino/120-DS-Questions,"When could it make your algorithms run slower?
  - Ask someone for more details.
  - compute in parallel when communication cost < computation cost
    - ensemble trees
    - minibatch
    - cross validation
    - forward propagation
    - minibatch
    - not suitable for online learning",2025-11-18T16:04:43.448565
What are the different types of joins? What are the differences between them?,,medium,coding,programming,kojino/120-DS-Questions,"- (INNER) JOIN: Returns records that have matching values in both tables
    LEFT (OUTER) JOIN: Return all records from the left table, and the matched records from the right table
    RIGHT (OUTER) JOIN: Return all records from the right table, and the matched records from the left table
    FULL (OUTER) JOIN: Return all records when there is a match in either left or right table",2025-11-18T16:04:43.448575
Why might a join on a subquery be slow? How might you speed it up?,,medium,coding,programming,kojino/120-DS-Questions,- Change the subquery to a join.,2025-11-18T16:04:43.448580
Describe the difference between primary keys and foreign keys in a SQL database.,,medium,coding,programming,kojino/120-DS-Questions,- Primary keys are columns whose value combinations must be unique in a specific table so that each row can be referenced uniquely. Foreign keys are columns that references columns (often primary keys) in other tables.,2025-11-18T16:04:43.448587
"Given a COURSES table with columns course_id and course_name, a FACULTY table with columns faculty_id and faculty_name, and a COURSE_FACULTY table with columns faculty_id and course_id, how would you return a list of faculty who teach a course given the name of a course?",,medium,coding,programming,kojino/120-DS-Questions,- select faculty_name from faculty_id c join (select faculty_id from (select course_id from COURSES where course_name=xxx) as a join COURSE_FACULTY b on a.course_id = b.course_id) d on c.faculty_id = d.faculty_id,2025-11-18T16:04:43.448601
"Given a IMPRESSIONS table with ad_id, click (an indicator that the ad was clicked), and date, write a SQL query that will tell me the click-through-rate of each ad by month.",,medium,coding,programming,kojino/120-DS-Questions,"- select id, average(click) from (select count(click) as click from IMPRESSIONS group by id,month(date)) group by id",2025-11-18T16:04:43.448610
Write a query that returns the name of each department and a count of the number of employees in each:,,medium,coding,programming,kojino/120-DS-Questions,"EMPLOYEES containing: Emp_ID (Primary key) and Emp_Name  
EMPLOYEE_DEPT containing: Emp_ID (Foreign key) and Dept_ID (Foreign key)  
DEPTS containing: Dept_ID (Primary key) and Dept_Name
  - select Dept_Name, count(1) from DEPTS a right join EMPLOYEE_DEPT b on a.Dept_id = b.Dept_id group by Dept_Name",2025-11-18T16:04:43.448620
"In an A/B test, how can you check if assignment to the various buckets was truly random?",,hard,stats,statistical_inference,kojino/120-DS-Questions,"- Plot the distributions of multiple features for both A and B and make sure that they have the same shape. More rigorously, we can conduct a permutation test to see if the distributions are the same.
  - MANOVA to compare different means",2025-11-18T16:04:43.448663
"What might be the benefits of running an A/A test, where you have two buckets who are exposed to the exact same product?",,hard,stats,statistical_inference,kojino/120-DS-Questions,- Verify the sampling algorithm is random.,2025-11-18T16:04:43.448670
What would be the hazards of letting users sneak a peek at the other bucket in an A/B test?,,hard,stats,statistical_inference,kojino/120-DS-Questions,"- The user might not act the same suppose had they not seen the other bucket. You are essentially adding additional variables of whether the user peeked the other bucket, which are not random across groups.",2025-11-18T16:04:43.448678
What would be some issues if blogs decide to cover one of your experimental groups?,,hard,stats,statistical_inference,kojino/120-DS-Questions,- Same as the previous question. The above problem can happen in larger¬†scale.,2025-11-18T16:04:43.448684
How would you conduct an A/B test on an opt-in feature?,,hard,stats,statistical_inference,kojino/120-DS-Questions,- Ask someone for more details.,2025-11-18T16:04:43.448690
"How would you run an A/B test for many variants, say 20 or more?",,hard,stats,statistical_inference,kojino/120-DS-Questions,"- one control, 20 treatment, if the sample size for each group is big enough.
  - Ways to attempt to correct for this include changing your confidence level (e.g. Bonferroni Correction) or doing family-wide tests before you dive in to the individual metrics (e.g. Fisher's Protected LSD).",2025-11-18T16:04:43.448698
How would you run an A/B test if the observations are extremely right-skewed?,,hard,stats,statistical_inference,kojino/120-DS-Questions,"- lower the variability by modifying the KPI
  - cap values
  - percentile metrics
  - log transform
  - <https://www.quora.com/How-would-you-run-an-A-B-test-if-the-observations-are-extremely-right-skewed>",2025-11-18T16:04:43.448706
I have two different experiments that both change the sign-up button to my website. I want to test them at the same time. What kinds of things should I keep in mind?,,hard,stats,statistical_inference,kojino/120-DS-Questions,- exclusive -> ok,2025-11-18T16:04:43.448713
What is a p-value? What is the difference between type-1 and type-2 error?,,hard,stats,statistical_inference,kojino/120-DS-Questions,"- A p-value is defined such that under the null hypothesis less than the fraction p of events have parameter values more extreme than the observed parameter. It is not the probability that the null hypothesis is wrong. 
  - type-1 error: rejecting Ho when Ho is true
  - type-2 error: not rejecting Ho when Ha is true",2025-11-18T16:04:43.448722
You are AirBnB and you want to test the hypothesis that a greater number of photographs increases the chances that a buyer selects the listing. How would you test this hypothesis?,,hard,stats,statistical_inference,kojino/120-DS-Questions,"- For randomly selected listings with more than 1 pictures, hide 1 random picture for group A, and show all for group B. Compare the booking rate for the two groups.
  - Ask someone for more details.",2025-11-18T16:04:43.448733
How would you design an experiment to determine the impact of latency on user engagement?,,hard,stats,statistical_inference,kojino/120-DS-Questions,"- The best way I know to quantify the impact of performance is to isolate just that factor using a slowdown experiment, i.e., add a delay in an A/B test.",2025-11-18T16:04:43.448740
What is maximum likelihood estimation? Could there be any case where it doesn‚Äôt exist?,,hard,stats,statistical_inference,kojino/120-DS-Questions,"- A method for parameter optimization (fitting a model). We choose parameters so as to maximize the likelihood function (how likely the outcome would happen given the current data and our model).
  - maximum likelihood estimation¬†(MLE) is a method of¬†[estimating](https://en.wikipedia.org/wiki/Estimator ""Estimator"")¬†the¬†[parameters](https://en.wikipedia.org/wiki/Statistical_parameter ""Statistical parameter"")¬†of a¬†[statistical model](https://en.wikipedia.org/wiki/Statistical_model ""Statistical mod",2025-11-18T16:04:43.448765
"What‚Äôs the difference between a MAP, MOM, MLE estima\- tor? In which cases would you want to use each?",,hard,stats,statistical_inference,kojino/120-DS-Questions,"- MAP estimates the posterior distribution given the prior distribution and data which maximizes the likelihood function. MLE is a special case of MAP where the prior is uninformative uniform distribution.
  - MOM sets moment values and solves for the parameters. MOM is not used much anymore because¬†maximum likelihood estimators have higher probability of being close to the quantities to be estimated and are more often unbiased.",2025-11-18T16:04:43.448777
What is a confidence interval and how do you interpret it?,,hard,stats,statistical_inference,kojino/120-DS-Questions,"- For example, 95% confidence interval is an interval that when constructed for a set of samples each sampled in the same way, the constructed intervals include the true mean 95% of the time.
  - if confidence intervals are constructed using a given confidence level in an infinite number of independent experiments, the proportion of those intervals that contain the true value of the parameter will match the confidence level.
  - [confidence intervals refresher from khanacademy](https://www.khana",2025-11-18T16:04:43.448794
What is unbiasedness as a property of an estimator? Is this always a desirable property when performing inference? What about in data analysis or predictive modeling?,,hard,stats,statistical_inference,kojino/120-DS-Questions,"- Unbiasedness means that the expectation of the estimator is equal to the population value we are estimating. This is desirable in inference because the goal is to explain the dataset as accurately as possible. However, this is not always desirable for data analysis or predictive modeling as there is the bias variance tradeoff. We sometimes want to prioritize the generalizability and avoid overfitting by reducing variance and thus increasing bias.",2025-11-18T16:04:43.448808
What is Selection Bias?,,hard,stats,statistical_inference,kojino/120-DS-Questions,"- Selection bias is a kind of error that occurs when the researcher decides who is going to be studied. It is usually associated with research where the selection of participants isn‚Äôt random. It is sometimes referred to as the selection effect. It is the distortion of statistical analysis, resulting from the method of collecting samples. If the selection bias is not taken into account, then some conclusions of the study may not be accurate.
  - The types of selection bias include:
  - Sampling ",2025-11-18T16:04:43.448829
What is Machine learning?,,medium,ml,machine_learning,165_ML_Interview_QA,"Machine learning is a branch of computer science which deals with system programming to automatically learn and improve with experience. For example, Robots are programmed so that they can perform the task based on data they gather from sensors. It automatically learns programs from data.",2025-11-18T17:20:54.000373
Mention the difference between Data Mining and Machine learning?,,hard,ml,machine_learning,165_ML_Interview_QA,"Machine learning relates to the study, design, and development of the algorithms that give computers the capability to learn without being explicitly programmed. While data mining can be defined as the process in which the unstructured data tries to extract knowledge or unknown interesting patterns. During this processing machine, learning algorithms are used.",2025-11-18T17:20:54.000398
What is ‚ÄòOverfitting‚Äô in Machine learning?,,hard,ml,machine_learning,165_ML_Interview_QA,"In machine learning, when a statistical model describes random error or noise instead of underlying relationship ‚Äòoverfitting‚Äô occurs. When a model is excessively complex, overfitting is normally observed, because of having too many parameters concerning the number of training data types. The model exhibits poor performance which has been overfitted.",2025-11-18T17:20:54.000416
Why does overfitting happen?,,medium,ml,machine_learning,165_ML_Interview_QA,The possibility of overfitting exists as the criteria used for training the model is not the same as the criteria used to judge the efficacy of a model.,2025-11-18T17:20:54.000424
How can you avoid overfitting ?,,hard,ml,machine_learning,165_ML_Interview_QA,"By using a lot of data overfitting can be avoided, overfitting happens relatively as you have a small dataset, and you try to learn from it. But if you have a small database and you are forced to come with a model based on that. In such a situation, you can use a technique known as cross-validation. We can use data augmentation techniques or regularization. We can also try to reduce the futures or we can try to simplify our model structure.",2025-11-18T17:20:54.000443
What is inductive machine learning?,,medium,ml,machine_learning,165_ML_Interview_QA,"The inductive machine learning involves the process of learning by examples, where a system, from a set of observed instances, tries to induce a general rule.",2025-11-18T17:20:54.000451
What are the five popular algorithms of Machine Learning?,,easy,ml,machine_learning,165_ML_Interview_QA,Decision Trees Neural Networks (backpropagation) Probabilistic networks Nearest Neighbor Support vector machines,2025-11-18T17:20:54.000458
What are the different Algorithm techniques in Machine Learning?,,medium,ml,machine_learning,165_ML_Interview_QA,The different types of techniques in Machine Learning are Supervised Learning Unsupervised Learning Semi-supervised Learning Reinforcement Learning Transduction Learning to Learn,2025-11-18T17:20:54.000467
What are the three stages to build the hypotheses or model in machine learning?,,easy,ml,machine_learning,165_ML_Interview_QA,Model building Model testing Applying the model,2025-11-18T17:20:54.000472
What is the standard approach to supervised learning?,,easy,ml,machine_learning,165_ML_Interview_QA,The standard approach to supervised learning is to split the set of examples into the training set and the test.,2025-11-18T17:20:54.000479
What is ‚ÄòTraining set‚Äô and ‚ÄòTest set‚Äô?,,hard,ml,machine_learning,165_ML_Interview_QA,"In various areas of information science like machine learning, a set of data is used to discover the potentially predictive relationship known as ‚ÄòTraining Set‚Äô. The training set is an example given to the learner, while the Test set is used to test the accuracy of the hypotheses generated by the learner, and it is the set of examples held back from the learner. The training set is distinct from the Test set.",2025-11-18T17:20:54.000496
List down various approaches for machine learning?,,medium,ml,machine_learning,165_ML_Interview_QA,The different approaches in Machine Learning are Concept Vs Classification Learning Symbolic Vs Statistical Learning Inductive Vs Analytical Learning ** 13) What is not Machine Learning?** => Artificial Intelligence Rule-based inference,2025-11-18T17:20:54.000507
Explain what is the function of ‚ÄòUnsupervised Learning‚Äô?,,medium,ml,machine_learning,165_ML_Interview_QA,Find clusters of the data Find low-dimensional representations of the data Find interesting directions in data Interesting coordinates and correlations Find novel observations/ database cleaning,2025-11-18T17:20:54.000516
What is algorithm independent machine learning?,,medium,ml,machine_learning,165_ML_Interview_QA,Machine learning in where mathematical foundations are independent of any particular classifier or learning algorithm is referred to as algorithm independent machine learning?,2025-11-18T17:20:54.000531
What is the difference between artificial learning and machine learning?,,medium,ml,machine_learning,165_ML_Interview_QA,"Designing and developing algorithms according to the behaviors based on empirical data are known as Machine Learning. While artificial intelligence in addition to machine learning, also covers other aspects like knowledge representation, natural language processing, planning, robotics, etc.",2025-11-18T17:20:54.000543
What is a classifier in machine learning?,,medium,ml,machine_learning,165_ML_Interview_QA,"A classifier in Machine Learning is a system that inputs a vector of discrete or continuous feature values and outputs a single discrete value, the class.",2025-11-18T17:20:54.000551
What are the advantages of Naive Bayes?,,medium,ml,machine_learning,165_ML_Interview_QA,"In Na√Øve Bayes classifier will converge quicker than discriminative models like logistic regression, so you need less training data. The main advantage is that it can‚Äôt learn the interactions between features.",2025-11-18T17:20:54.000561
In what areas Pattern Recognition is used?,,easy,ml,machine_learning,165_ML_Interview_QA,Pattern Recognition can be used in Computer Vision Speech Recognition Data Mining Statistics Informal Retrieval Bio-Informatics,2025-11-18T17:20:54.000568
What is Genetic Programming?,,medium,ml,machine_learning,165_ML_Interview_QA,Genetic programming is one of the two techniques used in machine learning. The model is based on testing and selecting the best choice among a set of results.,2025-11-18T17:20:54.000575
What is Inductive Logic Programming in Machine Learning?,,easy,ml,machine_learning,165_ML_Interview_QA,Inductive Logic Programming (ILP) is a subfield of machine learning which uses logic programming representing background knowledge and examples.,2025-11-18T17:20:54.000582
What is Model Selection in Machine Learning?,,medium,ml,machine_learning,165_ML_Interview_QA,"The process of selecting models among different mathematical models, which are used to describe the same data set is known as Model Selection. Model selection is applied to the fields of statistics, machine learning, and data mining.",2025-11-18T17:20:54.000593
What are the two methods used for the calibration in Supervised Learning?,,medium,ml,machine_learning,165_ML_Interview_QA,"The two methods used for predicting good probabilities in Supervised Learning are Platt Calibration Isotonic Regression These methods are designed for binary classification, and it is not trivial.",2025-11-18T17:20:54.000602
Which method is frequently used to prevent overfitting?,,easy,ml,machine_learning,165_ML_Interview_QA,When there is sufficient data ‚ÄòIsotonic Regression‚Äô is used to prevent an overfitting issue.,2025-11-18T17:20:54.000609
What is the difference between heuristic for rule learning and heuristics for decision trees?,,medium,ml,machine_learning,165_ML_Interview_QA,The difference is that the heuristics for decision trees evaluate the average quality of many disjointed sets while rule learners only evaluate the quality of the set of instances that are covered with the candidate rule.,2025-11-18T17:20:54.000620
What is Perceptron in Machine Learning?,,easy,ml,machine_learning,165_ML_Interview_QA,"In Machine Learning, Perceptron is an algorithm for supervised classification of the input into one of several possible non-binary outputs.",2025-11-18T17:20:54.000627
Explain the two components of the Bayesian logic program?,,medium,ml,machine_learning,165_ML_Interview_QA,"Bayesian logic program consists of two components. The first component is a logical one; it consists of a set of Bayesian Clauses, which captures the qualitative structure of the domain. The second component is a quantitative one, it encodes the quantitative information about the domain.",2025-11-18T17:20:54.000639
What are Bayesian Networks (BN) ?,,easy,ml,machine_learning,165_ML_Interview_QA,Bayesian Network is used to represent the graphical model for the probability relationship among a set of variables.,2025-11-18T17:20:54.000645
Why instance-based learning algorithm sometimes referred to as a Lazy learning algorithm?,,medium,ml,machine_learning,165_ML_Interview_QA,Instance-based learning algorithm is also referred to as the Lazy learning algorithm as they delay the induction or generalization process until classification is performed.,2025-11-18T17:20:54.000654
What are the two classification methods that SVM ( Support Vector Machine) can handle?,,easy,ml,machine_learning,165_ML_Interview_QA,Combining binary classifiers Modifying binary to incorporate multiclass learning,2025-11-18T17:20:54.000661
What is ensemble learning?,,medium,ml,machine_learning,165_ML_Interview_QA,"To solve a particular computational program, multiple models such as classifiers or experts are strategically generated and combined. This process is known as ensemble learning.",2025-11-18T17:20:54.000668
Why ensemble learning is used?,,easy,ml,machine_learning,165_ML_Interview_QA,"Ensemble learning is used to improve the classification, prediction, function approximation, etc of a model.",2025-11-18T17:20:54.000674
When to use ensemble learning?,,easy,ml,machine_learning,165_ML_Interview_QA,Ensemble learning is used when you build component classifiers that are more accurate and independent from each other.,2025-11-18T17:20:54.000680
What are the two paradigms of ensemble methods?,,easy,ml,machine_learning,165_ML_Interview_QA,The two paradigms of ensemble methods are Sequential ensemble methods Parallel ensemble methods,2025-11-18T17:20:54.000686
What is the general principle of an ensemble method and what is bagging and boosting in the ensemble method?,,hard,ml,machine_learning,165_ML_Interview_QA,The general principle of an ensemble method is to combine the predictions of several models built with a given learning algorithm to improve robustness over a single model. Bagging is a method in an ensemble for improving unstable estimation or classification schemes. While boosting methods are used sequentially to reduce the bias of the combined model. Boosting and Bagging both can reduce errors by reducing the variance term.,2025-11-18T17:20:54.000704
What is a bias-variance decomposition of classification error in the ensemble method?,,hard,ml,machine_learning,165_ML_Interview_QA,The expected error of a learning algorithm can be decomposed into bias and variance. A bias term measures how closely the average classifier produced by the learning algorithm matches the target function. The variance term measures how much the learning algorithm‚Äôs prediction fluctuates for different training sets.,2025-11-18T17:20:54.000719
What is an Incremental Learning algorithm in the ensemble?,,medium,ml,machine_learning,165_ML_Interview_QA,Incremental learning method is the ability of an algorithm to learn from new data that may be available after classifier has already been generated from the already available dataset.,2025-11-18T17:20:54.000728
"What are PCA, KPCA, and ICA used for?",,medium,ml,machine_learning,165_ML_Interview_QA,"PCA (Principal Components Analysis), KPCA ( Kernel-based Principal Component Analysis), and ICA ( Independent Component Analysis) are important feature extraction techniques used for dimensionality reduction.",2025-11-18T17:20:54.000737
What is dimension reduction in Machine Learning?,,medium,ml,machine_learning,165_ML_Interview_QA,"In Machine Learning and statistics, dimension reduction is the process of reducing the number of random variables under consideration and can be divided into feature selection and feature extraction.",2025-11-18T17:20:54.000746
What are support vector machines?,,easy,ml,machine_learning,165_ML_Interview_QA,Support vector machines are supervised learning algorithms used for classification and regression analysis.,2025-11-18T17:20:54.000752
What are the components of relational evaluation techniques?,,medium,ml,machine_learning,165_ML_Interview_QA,The important components of relational evaluation techniques are Data Acquisition Ground Truth Acquisition Cross-Validation Technique Query Type Scoring Metric Significance Test,2025-11-18T17:20:54.000760
What are the different methods for Sequential Supervised Learning?,,medium,ml,machine_learning,165_ML_Interview_QA,The different methods to solve Sequential Supervised Learning problems are Sliding-window methods Recurrent sliding windows Hidden Markow models Maximum entropy Markow models Conditional random fields Graph transformer networks,2025-11-18T17:20:54.000770
What are the areas in robotics and information processing where sequential prediction problem arises?,,medium,ml,machine_learning,165_ML_Interview_QA,The areas in robotics and information processing where sequential prediction problem arises are: Imitation Learning Structured prediction Model-based reinforcement learning,2025-11-18T17:20:54.000779
What is batch statistical learning?,,hard,ml,machine_learning,165_ML_Interview_QA,Statistical learning techniques allow learning a function or predictor from a set of observed data that can make predictions about unseen or future data. These techniques provide guarantees on the performance of the learned predictor on the future unseen data based on a statistical assumption on the data generating process.,2025-11-18T17:20:54.000792
What are the different categories you can categorize the sequence learning process?,,easy,ml,machine_learning,165_ML_Interview_QA,Sequence prediction Sequence generation Sequence recognition Sequential decision,2025-11-18T17:20:54.000805
What is sequence learning?,,easy,ml,machine_learning,165_ML_Interview_QA,Sequence learning is a method of teaching and learning in a logical manner.,2025-11-18T17:20:54.000809
What are two techniques of Machine Learning ?,,hard,ml,machine_learning,165_ML_Interview_QA,The two techniques of Machine Learning are Genetic Programming Inductive Learning Here is one more explanation of Overfitting and Underfitting for you. https://media.geeksforgeeks.org/wp-content/cdn-uploads/20190523171229/overfitting_1.png Overfitting ‚Äì High variance and low bias Techniques to reduce overfitting: Increase the training data. Reduce model complexity. Early stopping during the training phase (have an eye over the loss over the training period as soon as loss begins to increase stop,2025-11-18T17:20:54.000899
What is SQL?,,medium,sql,sql_database,SQL_Interview_QA,SQL is Structured Query Language designed specifically for communicating with databases (for inserting and modifying in a relational database management system). SQL is an ANSI (American National Standards Institute) standard.,2025-11-18T17:20:54.032680
What are the Advantages of SQL?,,medium,sql,sql_database,SQL_Interview_QA,"SQL is not a proprietary language used by specific database vendors. Almost every major DBMS supports SQL, so learning this one language will enable programmers to interact with any database like ORACLE, SQL, MYSQL etc. SQL is easy to learn. The statements are all made up of descriptive English words, and there aren't that many of them. SQL is actually an immensely powerful language and by using its language elements you can perform very complex and sophisticated database operations",2025-11-18T17:20:54.032715
What is a field in a database?,,easy,sql,sql_database,SQL_Interview_QA,"A field is an area within a record reserved for a specific piece of data. Examples: Employee Name, Employee ID etc.",2025-11-18T17:20:54.032738
What is a database transaction?,,hard,sql,sql_database,SQL_Interview_QA,"A database transaction takes the database from one consistent state to another. At the end of the transaction the system must be in the prior state if transaction fails or the status of the system should reflect the successful completion if the transaction goes through. A Database Transaction is a set of database operations that must be treated as whole, meaning either all operations are executed or none of them. An example can be a bank transaction from one account to another account. Either bo",2025-11-18T17:20:54.032793
What are the properties of a transaction?,,hard,sql,sql_database,SQL_Interview_QA,"Properties of the transaction can be summarized as ACID Properties. Atomicity A transaction consists of many steps. When all the steps in a transaction are completed, it will get reflected in DB or if any step fails, all the transactions are rolled back. Consistency The database will move from one consistent state to another, if the transaction succeeds and remain in the original state if the transaction fails. Isolation Every transaction should operate as if it is the only transaction in the sy",2025-11-18T17:20:54.032819
What is SQL Order of Execution?,,medium,sql,sql_database,SQL_Interview_QA,About 90% of data analysts will get the SQL order of execution WRONG The correct order is: FROM ‚Äì Define which tables you‚Äôll source data from WHERE ‚Äì Apply filters to your base data GROUP BY ‚Äì Aggregate your data HAVING ‚Äì Filter the aggregated data SELECT ‚Äì Display the final data ORDER BY ‚Äì Sort data for easy viewing LIMIT ‚Äì Restrict the number of results Why is SELECT not first in the order of execution you ask? Because it is different from the order of writing! Our machines FIRST look for the ,2025-11-18T17:20:54.032848
What is the difference between having and where clause?,,medium,sql,sql_database,SQL_Interview_QA,"Ans: HAVING is used to specify a condition for a group or an aggregate function used in select statement. The WHEREclause selects before grouping. The HAVINGclause selects rows after grouping. Unlike HAVINGclause, the WHEREclause cannot contain aggregate functions.",2025-11-18T17:20:54.032861
What is Join?,,medium,sql,sql_database,SQL_Interview_QA,"Ans: An SQL Join is used to combine data from two or more tables, based on a common field between them. For example, consider the following two tables. Student Table EnrollNo StudentName Address 1000 geek1 geeksquiz1 1001 geek2 geeksquiz2 1002 geek3 geeksquiz3 StudentCourse Table CourseID EnrollNo 1 1000 2 1000 3 1000 1 1002 2 1003 The following is a join query that shows names of students enrolled in different courseIDs. SELECT StudentCourse.CourseID, Student.StudentName FROM StudentCourse INNE",2025-11-18T17:20:54.032903
What is a view in SQL? How to create one,,easy,sql,sql_database,SQL_Interview_QA,Ans: A view is a virtual table based on the result-set of an SQL statement. We can create using create view syntax. CREATE VIEW view_name AS SELECT column_name(s) FROM table_name WHERE condition,2025-11-18T17:20:54.032913
What are the uses of a view? (Level: Intermediate),,medium,sql,sql_database,SQL_Interview_QA,"Views can represent a subset of the data contained in a table; consequently, a view can limit the degree of exposure of the underlying tables to the outer world: a given user may have permission to query the view, while denied access to the rest of the base table. Views can join and simplify multiple tables into a single virtual table. Views can act as aggregated tables, where the database engine aggregates data (sum, average etc.) and presents the calculated results as part of the data Views ca",2025-11-18T17:20:54.032941
What are Primary Keys and Foreign Keys? (Level: Beginner),,medium,sql,sql_database,SQL_Interview_QA,"Ans: Primary keys are the unique identifiers for each row. They must contain unique values and cannot be null. Due to their importance in relational databases, Primary keys are the most fundamental aspect of all keys and constraints. A table can have only one primary key. Foreign keys are a method of ensuring data integrity and manifestation of the relationship between tables.",2025-11-18T17:20:54.032958
What are the different types of SQL or different commands in SQL?,,medium,sql,sql_database,SQL_Interview_QA,"DDL‚Äì Data Definition Language. DDL is used to define the structure that holds the data. DML‚Äì Data Manipulation Language. DML is used for manipulation of the data itself. Typical operations are Insert, Delete, Update and retrieving the data from the table. DCL‚ÄìData Control Language. DCL is used to control the visibility of data like granting database access and set privileges to create tables etc. TCL -Transaction Control Language. TCL commands are basically used for managing and controlling the ",2025-11-18T17:20:54.032986
In SQL interviews you will often be asked what constraint commands are,,medium,sql,sql_database,SQL_Interview_QA,Here's the short answer for you: Constraints are rules that limit the types of data that can go into a table. The most important commands are: NOT NULL - Ensures that a column cannot have a NULL value UNIQUE - Ensures that all values in a column are different PRIMARY KEY - A combination of a NOT NULL and UNIQUE. FOREIGN KEY - Prevents actions that would destroy links between tables CHECK - Ensures that the values in a column satisfies a specific condition DEFAULT - Sets a default value for a col,2025-11-18T17:20:54.033013
"What is a foreign key, and what is it used for?",,medium,sql,sql_database,SQL_Interview_QA,"A foreign key is used to establish relationships among relations (tables) in the relational model. Technically, a foreign key is a column (or columns) appearing in one relation that is (are) the primary key of another table. Although there may be exceptions, the values in the foreign key columns usually must correspond to values existing in the set of primary key values. This correspondence requirement is created in a database using a referential integrity constraint on the foreign key.",2025-11-18T17:20:54.033033
What is Aggregate Functions?,,medium,sql,sql_database,SQL_Interview_QA,"Aggregate functions perform a calculation on a set of values and return a single value. Aggregate functions ignore NULL values except COUNT function. HAVING clause is used, along with GROUP BY, for filtering query using aggregate values. Following functions are aggregate functions. AVG, MIN, CHECKSUM_AGG, SUM, COUNT, STDEV, COUNT_BIG, STDEVP, GROUPING, VAR, MAX. VARP",2025-11-18T17:20:54.033049
What is CTE?,,medium,sql,sql_database,SQL_Interview_QA,CTE is an abbreviation Common Table Expression. A Common Table Expression (CTE) is an expression that can be thought of as a temporary result set which is defined within the execution of a single SQL statement. A CTE is similar to a derived table in that it is not stored as an object and lasts only for the duration of the query.,2025-11-18T17:20:54.033062
What is PRIMARY KEY?,,medium,sql,sql_database,SQL_Interview_QA,A PRIMARY KEY constraint is a unique identifier for a row within a database table. Every table should have a primary key constraint to uniquely identify each row and only one primary key constraint can be created for each table. The primary key constraints are used to enforce entity integrity.,2025-11-18T17:20:54.033093
What is UNIQUE KEY constraint?,,medium,sql,sql_database,SQL_Interview_QA,"A UNIQUE constraint enforces the uniqueness of the values in a set of columns, so no duplicate values are entered. The unique key constraints are used to enforce entity integrity as the primary key constraints.",2025-11-18T17:20:54.033103
What is FOREIGN KEY?,,medium,sql,sql_database,SQL_Interview_QA,A FOREIGN KEY constraint prevents any actions that would destroy links between tables with the corresponding data values. A foreign key in one table points to a primary key in another table. Foreign keys prevent actions that would leave rows with foreign key values when there are no primary keys with that value. The foreign key constraints are used to enforce referential integrity.,2025-11-18T17:20:54.033118
What is CHECK Constraint?,,easy,sql,sql_database,SQL_Interview_QA,A CHECK constraint is used to limit the values that can be placed in a column. The check constraints are used to enforce domain integrity.,2025-11-18T17:20:54.033125
What is NOT NULL Constraint?,,easy,sql,sql_database,SQL_Interview_QA,"A NOT NULL constraint enforces that the column will not accept null values. The not null constraints are used to enforce domain integrity, as the check constraints.",2025-11-18T17:20:54.033134
"Suppose you had bank transaction data, and wanted to separate out likely fraudulent transactions. How would you approach it? Why might accuracy be a bad metric for evaluating success?",,hard,case,data_science,DS_Interview_Notebook,"* In Machine Learning, problems like fraud detection are usually framed as classification problems. In order to solve this problem we may use different features like amount, merchant, location, time etc associated with each transaction. * One of the biggest challenge with fraud transaction detection is- majority of transactions are not fraud, so we have inbalance data! * First step will be to do EDA and understand our data and intesity of class inbalance. * In order to handle inbalance data prob",2025-11-18T17:20:54.033738
Explain inner working on linear regression,,easy,ml,data_science,DS_Interview_Notebook,,2025-11-18T17:20:54.033749
What are the assumptions for linear regression,,hard,ml,data_science,DS_Interview_Notebook,"Linear regression assumptions are as below * Data should have linear relationship between X and Y (actually mean of Y) * Data should be normally distributed * No or little multicollinearity (observations should be independent of each other) * Assumption of additivity: This means that each feature (X) should affect the target (Y) independently. In other words, the influence of one feature on the target does not change because of another feature. * Example: Let's say you're predicting house prices",2025-11-18T17:20:54.033787
How can AI be used in spam email detection?,,hard,mixed,data_science,DS_Interview_Notebook,"AI, particularly through NLP techniques, analyzes the content of emails to determine if they are spam. It does this by identifying patterns, keywords, and stylistic choices that are common in spam messages. Here's a simplified breakdown of the process: **Steps in AI-Based Spam Detection** 1. **Data Collection:** * A large dataset of emails, both spam and legitimate (""ham""), is gathered. 2. **Preprocessing:** * Emails are cleaned and standardized. * This often involves: * Removing punctuation and",2025-11-18T17:20:54.033948
How to build sentiment analysis model from scratch?,,hard,ml,data_science,DS_Interview_Notebook,"**1. Data Gathering:** * Collect a set of text data (e.g., movie reviews, tweets, product feedback) where each piece of text is labeled with its corresponding sentiment (positive, negative, or neutral). **2. Text Preprocessing:** * Clean and standardize the text: * Remove punctuation, special characters, and HTML tags. * Convert all text to lowercase. * Remove stop words (common words like 'the', 'and', etc.) * Tokenize the text into individual words. * Consider stemming or lemmatization to redu",2025-11-18T17:20:54.034003
When to use tokenization and stemming/Lemmatization?,,hard,mixed,data_science,DS_Interview_Notebook,"* **Tokenization:** * **Always** use tokenization as the first step in any NLP task that involves analyzing the text at the word level. * It's fundamental for breaking down sentences into individual words or subwords, which is necessary for further processing and analysis. * **Stemming/Lemmatization:** * Use these when you want to reduce words to their base or root forms. This can be helpful for: * **Reducing dimensionality:** Fewer unique words to deal with. * **Improving generalization:** Mode",2025-11-18T17:20:54.034056
What are the advantages and disadvantages of neural networks?,,hard,ml,data_science,DS_Interview_Notebook,"**Here are some advantages of Neural Networks** * Storing information on the entire network: Information such as in traditional programming is stored on the entire network, not on a database. The disappearance of a few pieces of information in one place does not restrict the network from functioning. * The ability to work with inadequate knowledge: After ANN training, the data may produce output even with incomplete information. The lack of performance here depends on the importance of the missi",2025-11-18T17:20:54.034124
What is the difference between bias and variance?,,hard,mixed,data_science,DS_Interview_Notebook,"* Bias comes from model underfitting some set of data, whereas variance is the result of model overfitting some set of data. * Underfitting models have high error in training as well as test set. This behavior is called as ‚ÄòHigh Bias‚Äô * Consider below example of bias(underfitting) where we are trying to fit linear function for nonlinear data. ![Underfitting]( * Overfitting models have low error in training set but high error in test set. This behavior is called as ‚ÄòHigh Variance‚Äô * Consider belo",2025-11-18T17:20:54.034160
What is bias-variance tradeoff,,hard,mixed,data_science,DS_Interview_Notebook,"* As we increase the complexity of the model, error will reduce due to lower bias in the model. However, this will happen until a particular point. If we continue to make our model complex then model will overfit and lead to high variance. * The goal of any supervised ML algorithm to have low bias and low variance to achieve good prediction performance. This is referred as bias-variance tradeoff. We can acheive bias-variance tradeoff by selecting optimum model complexity. <img src="" width=""500"" ",2025-11-18T17:20:54.034226
What is more important model accuracy or model performance?,,hard,ml,data_science,DS_Interview_Notebook,"* Short answer is: Model accuracy matters the most! inaccurate information is not usefull. * Model performance can be improved by increasing the compute resources. * Model accuracy and performance can be subjective to the problem in hand. For example, in analysis of medical images to determine if there is a disease (such as cancer), the accuracy extremely critical, even if the models would take minutes or hours to make a prediction. * Some applications require real time performance, even if this",2025-11-18T17:20:54.034258
What is the difference between machine learning and deep learning?,,hard,ml,data_science,DS_Interview_Notebook,"Deep Learning out performs traditional ML techniques if the data size is large. But with small data size, traditional Machine Learning algorithms are preferable. Deep Learning really shines when it comes to complex problems such as image classification, natural language processing, and speech recognition. Few important differences are as below, |Machine Learning|Deep Learning| |:-|:-| | Machine learning uses algorithms to parse data, learn from that data, and make informed decisions based on wha",2025-11-18T17:20:54.034302
Explain standard deviation and variance,,hard,mixed,data_science,DS_Interview_Notebook,"![normal-distrubution]( **Variance:** * **In a Nutshell:** Variance measures how spread out a set of data is. A high variance indicates that the data points are widely scattered, while a low variance means they are clustered close together. * **Example:** Imagine two groups of students taking a test. * Group A: Scores are 60, 70, 75, 80, 90 * Group B: Scores are 40, 70, 70, 70, 100 * Group B has a higher variance because its scores are more spread out from the average (70) compared to Group A. *",2025-11-18T17:20:54.034366
Explain confusion matrix,,hard,mixed,data_science,DS_Interview_Notebook,"![]( **What is a Confusion Matrix?** * Imagine a table that helps you see how well your machine learning model is performing, especially when it comes to classification tasks (like deciding if an email is spam or not). * It compares the model's predictions to the actual, true labels of your data. **Why is it useful?** * Beyond Accuracy: A confusion matrix gives you a more detailed look at your model's performance than just overall accuracy. * Spotting Weaknesses: You can see which classes your m",2025-11-18T17:20:54.034499
Why do we need confusion matrix?,,hard,mixed,data_science,DS_Interview_Notebook,"* We can not rely on a single value of accuracy in classification when the classes are imbalanced. * For example, we have a dataset of 100 patients in which 5 have diabetes and 95 are healthy. However, if our model only predicts the majority class i.e. all 100 people are healthy then also we will have a classification accuracy of 95%. * Confusion matrices are used to visualize important predictive analytics like recall, specificity, accuracy, and precision. * Confusion matrices are useful becaus",2025-11-18T17:20:54.034521
Explain collinearity and technique to reduce it?,,hard,mixed,data_science,DS_Interview_Notebook,"In statistics collinearity or multicollinearity is the phenomenon where one or more predictive variables(features) in multiple regression models are highly linearly related to each other. ## Technique to reduce multicollearity * **Remove highly correlated predictors from the model**. If you have two or more factors with a high collinearity, remove one from the model. Because they supply redundant information, removing one of the correlated factors usually doesn't drastically reduce the R-squared",2025-11-18T17:20:54.034545
Difference between statistics and machine learning,,hard,ml,data_science,DS_Interview_Notebook,"* The major difference between machine learning and statistics is their purpose. Machine learning models are designed to make the most accurate predictions possible. Statistical models are designed for inference about the relationships between variables. * Statistics is mathematical study of data. Lots of statistical models that can make predictions, but predictive accuracy is not their strength.",2025-11-18T17:20:54.034558
"In a test, students in section A scored with a mean of 75 and standard deviation of 10, while students in section B scored with a mean of 80 and standard deviation of 12? Melissa from section A and Ryan from section B both have scored 90 in this test. Who had a better performance in this test as compared to their classmates?",,hard,stats,data_science,DS_Interview_Notebook,"To compare the two scores we need to standardize them to the same scale. We do that by calculating the Z score, which allows us to compare the 2 scores in units of standard deviations. ```Z score= (X- mean)/Standard Deviation``` Melissa's Z score = (90-75)/10 = 1.5 Ryan's Z score = (90-80)/12 = 0.83 Melissa has performed better.",2025-11-18T17:20:54.034581
What is null hypothesis and alternate hypothesis?,,hard,stats,data_science,DS_Interview_Notebook,"* The null hypothesis states that a population parameter (such as the mean, the standard deviation, and so on) is equal to a hypothesized value. The null hypothesis is often an initial claim that is based on previous analyses or specialized knowledge. * The alternative hypothesis states that a population parameter is smaller, greater, or different than the hypothesized value in the null hypothesis. The alternative hypothesis is what you might believe to be true or hope to prove true. * So when r",2025-11-18T17:20:54.034604
What is a hypothesis test and p-value?,,hard,stats,data_science,DS_Interview_Notebook,"* A hypothesis test examines two opposing hypotheses about a population: the null hypothesis and the alternative hypothesis. The null hypothesis is the statement being tested. Usually the null hypothesis is a statement of ""no effect"" or ""no difference"". The alternative hypothesis is the statement you want to be able to conclude is true based on evidence provided by the sample data. * Based on the sample data, the test determines whether to reject the null hypothesis. You use a p-value, to make t",2025-11-18T17:20:54.034660
What is power of hypothesis test? Why is it important?,,hard,stats,data_science,DS_Interview_Notebook,"* Remember that if actual value is positive and our model predicts it as negative then Type II error occuras (False negative). e.g. Calling a guilty person innocent, diaognosing cancer infected person as healthy etc. * The probability of not commiting Type II error is called as power of hypothesis test. The higher probability we have of not commiting a type 2 error, the better our hypothesis test is.",2025-11-18T17:20:54.034675
What is the difference betweeen K nearest neighbors and K means,,hard,mixed,data_science,DS_Interview_Notebook,"* KNN or K nearest neighbor is a classification algorithm, while K-Means is clustering technique. * KNN is supervised algorithm, K means is unsupervised algorithm. * In KNN prediction of the test sample is based on the similarity of its features to its neighbors. The similarity is computed based on the measure such as euclidean distance. Here K referes to the number of neighbors with whom similarity is being compared. * K-means is the process of defining clusters or groups around predefined cent",2025-11-18T17:20:54.034696
Explain Random forest algorithm,,hard,ml,data_science,DS_Interview_Notebook,"* Random forest is supervised learning algorithm and can be used to solve classification and regression problems. * Since decision-tree create only one tree to fit the dataset, it may cause overfitting and model may not generalize well. Unlike decision tree random forest fits multiple decision trees on various sub samples of dataset and make the predictions by averaging the predictions from each tree. * Averaging the results from multiple decision trees help to control the overfitting and result",2025-11-18T17:20:54.034723
Can Random Forest Algorithm be used both for Continuous and Categorical Target Variables?,,medium,ml,data_science,DS_Interview_Notebook,"* Yes, Random Forest can be used for both continuous and categorical target (dependent) variables. * In a random forest the classification model refers to the categorical dependent variable, and the regression model refers to the numeric or continuous dependent variable.",2025-11-18T17:20:54.034734
What do you mean by Bagging?,,hard,mixed,data_science,DS_Interview_Notebook,"![EnsembleI_Learning_Bagging]( * In bagging we build independent estimators on different samples of the original data set and average or vote across all the predictions. * Bagging is a short form of **Bootstrap Aggregating**. It is an ensemble learning approach used to improve the stability and accuracy of machine learning algorithms. * Since multiple model predictions are averaged together to form the final predictions, Bagging reduces variance and helps to avoid overfitting. Although it is usu",2025-11-18T17:20:54.034798
What is Out-of-Bag Error in Random Forests?,,hard,mixed,data_science,DS_Interview_Notebook,"* Out-of-Bag is equivalent to validation or test data but it is calculated internally by Random Forest algorithm. In case of Sklearn if we set hyperparameter 'oob_score = True' then Out-of-Bag score will be calculated for every decision tree. * Finally, we aggregate all the errors from all the decision trees and we will determine the overall OOB error rate for the classification. * For more details refer. ",2025-11-18T17:20:54.034816
What is the use of proximity matrix in the random forest algorithm?,,easy,ml,data_science,DS_Interview_Notebook,A proximity matrix is used for the following cases : * Missing value imputation * Detection of outliers,2025-11-18T17:20:54.034823
List down the parameters used to fine-tune the Random Forest.,,medium,mixed,data_science,DS_Interview_Notebook,Two parameters that have to fine-tune to improve the predictions that are important in the random forest algorithm are as follows: * Number of trees used in the forest (n_tree) * Number of random variables used in each of the trees in the forest (mtry),2025-11-18T17:20:54.034836
What is K Fold cross validation? Why do you use it?,,hard,mixed,data_science,DS_Interview_Notebook,"* In case of K Fold cross validation input data is divided into ‚ÄòK‚Äô number of folds, hence the name K Fold. Suppose we have divided data into 5 folds i.e. K=5. Now we have 5 sets of data to train and test our model. So the model will get trained and tested 5 times, but for every iteration we will use one fold as test data and rest all as training data. Note that for every iteration, data in training and test fold changes which adds to the effectiveness of this method. * This significantly reduce",2025-11-18T17:20:54.034865
How to handle missing data?,,medium,case,data_science,DS_Interview_Notebook,"Data can be missing because of mannual error or can be gennualy missing. * Delete low quality records completely which have too much missing data * Impute the values by educated guess, taking average or regression * Use domain knwledge to impute values",2025-11-18T17:20:54.034877
What is the difference between Bar graph and histogram?,,medium,mixed,data_science,DS_Interview_Notebook,* Bar graph is used for descreate data where as histogram is used for continuous data. * In bar graph there is space between the bars and in case of histogram there is no space between the bars(contnuous scale). * In bar graph the order of the bars can be changed and in histogram order remains same.,2025-11-18T17:20:54.034890
What is the Box and Whisker plot? When should use it?,,hard,mixed,data_science,DS_Interview_Notebook,"* Box and whisker plots are ideal for comparing distributions because the centre, spread and overall range are immediately apparent. * A box and whisker plot is a way of summarizing a set of data measured on an interval scale. * It is often used in explanatory data analysis * Boxplots are a standardized way of displaying the distribution of data based on a five number summary (‚Äúminimum‚Äù, first quartile (Q1), median, third quartile (Q3), and ‚Äúmaximum‚Äù). * median (Q2/50th Percentile): the middle v",2025-11-18T17:20:54.034926
What is outlier? How to handle them?,,hard,mixed,data_science,DS_Interview_Notebook,"* An outlier is an observation that lies an abnormal distance from other values in a random sample from a population. * Data points above and below 1.5*IQR, are most commonly outliers. Outliers can drastically change the results of the data analysis and statistical modeling. ## Types of the outliers * **Data entry errors** * **Measuremental errors** * **Intentional outliers**. This is commonly found in self-reported measures that involves sensitive data. For example: Teens would typically under ",2025-11-18T17:20:54.035002
"If deleting outliers is not an option, how will you handle them?",,hard,mixed,data_science,DS_Interview_Notebook,"* I will try differen models. Data detected as outliers by linear model, can be fit by non-linear model. * Try normalizing the data, this way the extreame datapoints are pulled to the similar range. * We can use algorithms which are less affected by outliers. * We can also create separate model to handle the outlier data points.",2025-11-18T17:20:54.035017
You fit two linear models on a dataset. Model 1 has 25 predictors and model 2 has 10 predictors. What performance metric would you use to select the best model based on training dataset?,,hard,ml,data_science,DS_Interview_Notebook,"* First of all model performace is not directly proportional to the number of predictors, so we cant say that model with 25 predictors is better than the model with 10 predictors * Here important thing is to understand different evaluation metric for linear regresion and which one of them can help us identify the impact of number of predictors on model performance. * Evaluation metric used for linear regression are MSE, MAE, R-squared, Adjusted R-squared, and RMSE. * MSE penalizes large errors, ",2025-11-18T17:20:54.035064
Suppose we have a function -4x^2 + 4x + 3. Find the maximum or minimum of this function.,,hard,coding,data_science,DS_Interview_Notebook,"* This is quadratic equation, f(x) = -4x^2 + 4x + 13 (for a function: ax^2 + bx + c, when a < 0, then function has maximum value) * To find the slope of the function, lets take derivative of it f'(x)= -8x + 4 * At maximum point, slope will be 0 -8x + 4 = 0 x = 0.5 * Now lets put 0.5 in equation to find the maximum values f(0,5) = -4(0.5)^2 + 4(0.5) + 13 = -1 + 2 +13 = 14 * This functiona will have concave shape. So the maximum point is (0.5, 14) * Reference: ",2025-11-18T17:20:54.035086
Below is the output of a correlation matrix from your Exploratory data. Is using all the features in a model appropriate for predicting/inferencing Y?,,hard,ml,data_science,DS_Interview_Notebook,"![]( * We can see from above correlation matrix that there is high correlation(.98) between X1 and X2, also high correlation(.88) between X1 and X3, similarly there is high correlation(.75) between X2 and X3 * All the variables are correlated to each other. In regression this would result in multicollinearity. We can try methods such as dimension reduction, feature selection, stepwise regression to choose the correct input variables for predictiong Y * Second part of question is - should we use ",2025-11-18T17:20:54.035114
What is stepwise regression?,,hard,ml,data_science,DS_Interview_Notebook,"Stepwise regression is a method of fitting regression models in which the choice of predictive variables is carried out by an automatic procedure. In each step, a variable is considered for addition to or subtraction from the set of explanatory variables based on some prespecified criterion. Stepwise regression is classified into backward and forward selection. * **Backward selection** starts with a full model, then step by step we reduce the regressor variables and find the model with the least",2025-11-18T17:20:54.035140
You have two buckets - one of 3 liters and other of 5 liters. You are expected to mesure exactly 4 liters. How will you complete the task? Note: There is no thrid bucket.,,hard,mixed,data_science,DS_Interview_Notebook,"* Questions like this will test your out of the box thinking * Step1: Fill 5 lts bucket and empty it in 3 ltr bucket. Now we are left with 2 ltr in 5 ltr bucket. * Step2: Empty 3 ltr bucket and pour the contents of 5 ltr bucket in 3 ltr bucket. Now our 5 ltr bucket is empty and 3 ltr bucket has 2 ltr content in it. * Now fill the 5 ltr bucket again. Remember that our 3 ltr bucket has 2 ltr content in it, so if we pour 1 ltr content from 5 ltr bucket to 3 ltr bucket we are left with 4 ltr content",2025-11-18T17:20:54.035166
Lis the differences between supervised and unsupervised learning,,hard,ml,data_science,DS_Interview_Notebook,"| Supervised learning | Unsupervised leanring |:- |:- Uses labeled data as input | Uses unlabeled data as input Supervised learning has feedback mechanism | Unsupervised learning has no feedback mechanism Common supervised learning algorithms are decision tree, logistic regression, support vector machine etc | K Means clustering, hierarchical clustering etc Reference: ",2025-11-18T17:20:54.035180
Explain the steps in making decision tree?,,hard,mixed,data_science,DS_Interview_Notebook,![]( Below are the common steps in decision tree algorithm * Take the entire data as input * At the root node decision tree selects feature to split the data in two major categories. * Different criteria will be used to split the data. We generally use 'entropy' or 'gini' in case of classification and 'mse' or 'mae' in case of regression problems. * Features are selected for spliting based on highest information gain. * After every split we get decision rules and sub trees. * This process will c,2025-11-18T17:20:54.035207
How do you build random forest model?,,hard,ml,data_science,DS_Interview_Notebook,Ranodm forest is made up of multiple decision trees. Unlike decision tree random forest fits multiple decision trees on various sub samples of dataset and make the predictions by averaging the predictions from each tree. ![]( * Select few random sub sample from given dataset * Construct a decision tree for every sub sample and predict the result. * Perform the voting on prediction from each tree. * At the end select the most voted result as final prediction. * Reference: ,2025-11-18T17:20:54.035226
How do Random Forest handle missing data?,,hard,case,data_science,DS_Interview_Notebook,"Random Forests inherently have two primary ways of handling missing data: 1. **During Training (Building the Trees):** * **For Numerical Features:** Missing values can be imputed using simple strategies like mean or median. * **For Categorical Features:** A new ""missing"" category is often created to handle missing values. This ensures that data points with missing categorical values are still considered during the tree building process. 2. **During Prediction (Making New Predictions):** * **""Sur",2025-11-18T17:20:54.035302
What is model overfitting? How can you avoid it?,,hard,ml,data_science,DS_Interview_Notebook,"Overfitting occurs when your model learns too much from training data and isn't able to generalize the underlying information. When this happens, the model is able to describe training data very accurately but loses precision on every dataset it has not been trained on. Below images represent the overfitting linear and logistic regression models. ![]( **How To Avoid Overfitting?** * Since overfitting algorithm captures the noise in data, reducing the number of features will help. We can manually",2025-11-18T17:20:54.035337
There are 9 balls out of which one ball is heavy in weight and rest are of the same weight. In how many minimum weightings will you find the heavier ball?,,hard,mixed,data_science,DS_Interview_Notebook,"To find the heavier ball among 9 balls using a balance scale, you can determine the minimum number of weighings required by strategically dividing the balls and comparing their weights. ### Step-by-Step Solution: 1. **First Weighing**: - Divide the 9 balls into three groups of 3 balls each: Group A, Group B, and Group C. - Weigh Group A against Group B. 2. **Analyzing the First Weighing**: - **Case 1**: If the scales balance (i.e., Group A = Group B), it means the heavier ball is in Group C. - *",2025-11-18T17:20:54.035383
"Difference between univariate, bivariate and multivariate analysis?",,easy,mixed,data_science,DS_Interview_Notebook,* Univariate Analysis ![Univariate_Analysis]( * Bivariate Analysis ![Bivariate_Analysis]( * Multivariate Analysis ![Multivariate_Analysis](,2025-11-18T17:20:54.035397
What are feature selection methods to select right variables?,,hard,mixed,data_science,DS_Interview_Notebook,"Feature selection is the process of reducing the number of input variables when developing a predictive model. There are two methods for feature selection. Filter method and wrapper methods. Best analogy for selecting features is bad data in bad answers out. ## Filter Methods * Filter feature selection methods use statistical techniques to evaluate the relationship between each input variable and the target variable, and these scores are used as the basis to choose (filter) those input variables",2025-11-18T17:20:54.035473
"In you choice of langauge: Write a program that prints the numbers from 1 to 50. But for multiples of three print ""Fizz"" instaed of the number and for the multiples of five print ""Buzz"". For the numbers which are multiples of both three and five print ""FizzBuzz"".",,easy,coding,data_science,DS_Interview_Notebook,,2025-11-18T17:20:54.035486
You are given a dataset consisting of variables having more than 30% missing values? How will you deal with them?,,hard,case,data_science,DS_Interview_Notebook,"* There are multiple ways to handle missing values in the data * If dataset is huge we can simply remove the rows containing the missing data * If dataset is small then we have to impute the missing values. There are multiple ways to impute the missing values. In case of categorical data we may use the most common values and in case numerical data we can use mean, median etc. * Reference: ",2025-11-18T17:20:54.035505
"For the given point how will you caluclate the Euclidean distance, in Python?",,easy,mixed,data_science,DS_Interview_Notebook,Euclidean distance is calculated as the square root of the sum of the squared differences between the two vectors. ![]( Reference: ,2025-11-18T17:20:54.035518
What is the angle between the hour and minute hands of clock when the time is half past six?,,easy,mixed,data_science,DS_Interview_Notebook,![Clock_Puzzle]( Reference: ,2025-11-18T17:20:54.035528
How should you maintain your deployed model?,,hard,ml,data_science,DS_Interview_Notebook,### Monitor Constant monitoring of all the models is needed to determine the performance accuracy of the models ### Evaluate Evaluation metric of the current model is calculated to determine if new algorithm is needed. ### Compare The new models are compared against each other to determine which model performs the best. ### Rebuild The best performing model is re-built on the current set of data. Reference: ,2025-11-18T17:20:54.035543
What are recommender systems?,,hard,mixed,data_science,DS_Interview_Notebook,* The purpose of a recommender system is to suggest relevant items or services to users. * Two major categories of recommender systems are collaboarative filtering and cotent based filtering methods ### Collaborative Filtering * It is based on the past interactions recorded between users and items in order to produce new recommendations. * e.g. Music service recommends track that are often played by other users with similar interests ### Content Based Filtering * Unlike collaborative methods tha,2025-11-18T17:20:54.035574
"'People who bought this, also bought...'recommendations seen on Amazon is a result of which algorithm?",,medium,ml,data_science,DS_Interview_Notebook,* Its done by recommendation system using collaborative filtering approach. * In case of collaborative filtering past interactions recorded between users and items are used to produce new recommendations.,2025-11-18T17:20:54.035585
"If it rains on saturday with probability 0.6, and it rains on sunday with probability 0.2, what is the probability that it rains this weekend?",,hard,stats,data_science,DS_Interview_Notebook,"* Since we know the probability of rain on Saturday and Sunday, the probability of raining on Weekend is combination of both of these events. * Trick here is to know the probability of not raining on Saturday and Sunday. * If we subtract the intersection(‚à©) of both the events of not raining on Saturday and Sunday from total probability then we get the probability of raining on weekend. ``` = Total probability - (Probability that it will not rain on Saturday) ‚à© (Probability that it will not rain ",2025-11-18T17:20:54.035610
How can you select K for K-Means?,,hard,mixed,data_science,DS_Interview_Notebook,"There are two ways to select the number of clusters in case K-Means clustering algorithm ### Visualization * To find the number of clusters manually by data visualization is one of the most common method. * Domain knowledge and proper understanding of given data also help to make more informed decisions. * Since its manual exercise there is always a scope for ambiguous observations, in such cases we can also use ‚ÄòElbow Method‚Äô ### Elbow Method * In Elbow method we run the K-Means algorithm multi",2025-11-18T17:20:54.035647
"Explain dimensionality reduction, and its benefits?",,hard,mixed,data_science,DS_Interview_Notebook,* Dimensionality reduction referes to the process of converting a set of data having vast dimensions into data with lesser dimensions(features) to convey similar information concisely. * It helps in data compressing and reducing the storage space * It reduces computation time as less dimensions lead to less computing * It removes redundant features. E.g. There is no point in storing value in two different units * Reference: ,2025-11-18T17:20:54.035665
How can you say that the time series data is stationary?,,hard,case,data_science,DS_Interview_Notebook,"For accurate analysis and forecasting, **trend and seasonality is removed** from the time series and converted it into stationary series. Time series data is said to be stationary when statistical properties like mean, standard deviation are constant and there is no seasonality. In other words statistical properties of the time series data should not be a function of time. ![Stationarity]( Reference: ",2025-11-18T17:20:54.035684
How can you calculate the accuracy using confusion matrix?,,easy,mixed,data_science,DS_Interview_Notebook,Accuracy = (True Positive + true Negative) / Total Obervations,2025-11-18T17:20:54.035691
Write the equations for the precision and recall?,,easy,mixed,data_science,DS_Interview_Notebook,Precision = True Positive / (True Positive + False Positive) Recall = True Positive /(Total Positive + False Negative),2025-11-18T17:20:54.035700
"If a drawer containes 12 red socks, 16 blue socks, and 20 white socks, how many must you pull out to be sure of having a amcthing pair?",,hard,mixed,data_science,DS_Interview_Notebook,"* There are three colors of socks- Red, Blue and White. No of socks is irrelevant here. * Suppose in our first pull we picked Red color sock * In second pull we picked Blue color sock * And in third pull we picked White color sock. * Now in our fourth pull, if we pick any color, match is guaranteed!! So the answer is 4! * Reference: ",2025-11-18T17:20:54.035719
Write a SQL query to list all orders with customer information,,easy,mixed,data_science,DS_Interview_Notebook,![SQL_Join](,2025-11-18T17:20:54.035726
Which of the following machine learning algorithm can be used for imputing missing values of both categorical and continuos variables?,,medium,ml,data_science,DS_Interview_Notebook,``` - K-means clustering - Linear regression - K-NN - Decision tress ``` Using KNN we can compute the missing variable value by using the nearest neighbors.,2025-11-18T17:20:54.035736
"Given a box of matches and two ropes, not necessarily identical, measure a period of 45 minutes? Note: Ropes are not uniform in natire and rope takes exactly 60 minutes to completly burn out",,medium,mixed,data_science,DS_Interview_Notebook,"* We have two ropes A and B * Ligt A from both the end and B from one end * When A finished burning we know that 30 minutes have elapsed and B has 30 minutes remaining * Now light the other end of B also, it will now burnout in 15 minutes * This we got 30 + 15 = 45 minutes * Reference: ",2025-11-18T17:20:54.035756
"After studying the behaviour of population, you have identified four specific individual types who are valueable to your study. You would like find all users who are most similar to each indivdual type. Which algorithm is most approprate for this study?",,hard,ml,data_science,DS_Interview_Notebook,"The most appropriate algorithm for this study is **K-Nearest Neighbors (KNN)**. Here's why KNN is well-suited for this task: 1. **Similarity-Based:** KNN explicitly focuses on finding the most similar data points (users in this case) to a given point (your identified individual types) based on their features or attributes. 2. **No Assumption about Data Distribution:** KNN is a non-parametric algorithm, meaning it doesn't make any assumptions about the underlying distribution of your data. This i",2025-11-18T17:20:54.035790
Your organization has a website where visitors randomly receive one of the two coupons. It is also possible that visitors to the website will not receive the coupon. You have been asked to determine if offering a coupon to the visitors to your website has any impact on their purchase decision. Which analysis method should you use?,,hard,mixed,data_science,DS_Interview_Notebook,"In this scenario, the most appropriate analysis method would be **A/B Testing** (or **Split Testing**). **Here's why A/B Testing is the best fit:** * **Controlled Experiment:** A/B Testing allows you to randomly assign visitors to different groups (control group with no coupon, group A with coupon type 1, group B with coupon type 2). This controlled experiment ensures that any differences in purchase behavior can be directly attributed to the presence and type of coupon. * **Measures Impact:** Y",2025-11-18T17:20:54.035870
Explain feature scaling,,hard,mixed,data_science,DS_Interview_Notebook,"* Feature scaling is one of the most important data preprocessing step in machine learning * If we are **changing the range of the features then its called 'scaling'** and if we are **changing the distribution of the features then its called 'normalization/standardization'** ## Scaling * This means that you're transforming your data so that it fits within a specific scale, like 0-100 or 0-1. By scaling your variables, you can help compare different variables on equal footing. * Scaling is requir",2025-11-18T17:20:54.035957
Difference between standardisation and normalization?,,hard,mixed,data_science,DS_Interview_Notebook,"**Standardization** * **What it does:** * Centers the data around zero (mean = 0) * Scales the data to have a standard deviation of one (std = 1) * **Transformation:** * `Z = (X - mean) / std_dev` * **When to use it:** * Algorithms that are sensitive to the scale of features (e.g., linear regression, logistic regression, support vector machines). * When you assume your data follows a normal (Gaussian) distribution (though not strictly required). * When outliers are present, as standardization is",2025-11-18T17:20:54.036008
What is meant by Data Leakage?,,hard,case,data_science,DS_Interview_Notebook,"* Data Leakage is the scenario where the Machine Learning Model is already aware of some part of test data after training.This causes the problem of overfitting. * In Machine learning, Data Leakage refers to a mistake that is made by the creator of a machine learning model in which they accidentally share the information between the test and training data sets. * Data leakage is a serious and widespread problem in data mining and machine learning which needs to be handled well to obtain a robust",2025-11-18T17:20:54.036101
How to detect Data Leakage?,,hard,case,data_science,DS_Interview_Notebook,"* Results are too good too true * In general, if we see that the model which we build is too good to be true (i.,e gives predicted and actual output the same), then we should get suspicious and data leakage cannot be ruled out. * At that time, the model might be somehow memorizing the relations between feature and target instead of learning and generalizing it for the unseen data. * So, it is advised that before the testing, the prior documented results are weighed against the expected results. ",2025-11-18T17:20:54.036141
How to fix the problem of Data Leakage?,,hard,case,data_science,DS_Interview_Notebook,"The main culprit behind this is the way we split our dataset and when. The following steps can prove to be very crucial in preventing data leakage: * Select the features such a way that they do not contain information about the target variable, which is not naturally available at the time of prediction. * Create a Separate Validation Set * To minimize or avoid the problem of data leakage, we should try to set aside a validation set in addition to training and test sets if possible. * The purpose",2025-11-18T17:20:54.036211
Explain normal distribution of data,,hard,stats,data_science,DS_Interview_Notebook,"Data can be distributed (spread out) in different ways, * It can be spread out more on the left (Left skew) ![]( * More on the right (Right Skew) ![]( * It can be all jumbled up ![]( * But there are many cases where the data tends to be around a central value with no bias left or right, and it gets close to a ""Normal Distribution"" like this: ![]( * The Normal Distribution has: - mean = median = mode - symmetry about the center - 50% of values less than the mean and 50% greater than the mean Refe",2025-11-18T17:20:54.036273
What does it mean when distribution is left skew or right skew?,,hard,stats,data_science,DS_Interview_Notebook,"In a **right-skewed** distribution, the tail on the right side is longer. This means most of the data is clustered on the left, with a few unusually large values pulling the average higher. Think of income distribution - most people earn less, but a few very high earners skew the average upwards. In a **left-skewed** distribution, the tail on the left side is longer. This means most of the data is clustered on the right, with a few unusually small values pulling the average lower. An example cou",2025-11-18T17:20:54.036294
What does the distribution looks like for the average time spend watching youtube per day?,,hard,stats,data_science,DS_Interview_Notebook,"The distribution of average time spent watching YouTube per day is likely to be right-skewed. This means that most people watch YouTube for a relatively short amount of time each day, while a smaller number of users watch for much longer durations. The tail of the distribution extends to the right, indicating the presence of these high-usage viewers",2025-11-18T17:20:54.036308
Expalin covariance and correlation,,hard,mixed,data_science,DS_Interview_Notebook,"* Covariance and Correlation are two mathematical concepts which are commonly used in the field of probability and statistics. Both concepts describe the relationship between two variables. * ‚ÄúCovariance‚Äù indicates the **direction of the linear relationship between variables**. ‚ÄúCorrelation‚Äù on the other hand measures both the **strength and direction of the linear relationship between two variables**. * In case of High correlation, two sets of data are strongly linked together - Correlation is ",2025-11-18T17:20:54.036332
What is regularization. Why it is usefull?,,hard,mixed,data_science,DS_Interview_Notebook,* Regularization is the process of adding tunning parameter(penalty term) to a model to induce smoothness in order to prevent overfitting. * The tunning parameter controls the excessively fluctuating function in such a way that coefficients dont take extreame values. * There are two types of regularization as follows: - L1 Regularization or Lasso Regularization. L1 Regularization or Lasso Regularization adds a penalty to the error function. The penalty is the sum of the absolute values of weight,2025-11-18T17:20:54.036355
What are confouding varaiables?,,hard,mixed,data_science,DS_Interview_Notebook,"* In statistics, confounder is a variable that influences both the dependent variable and independent avriable. * If you are researeching whether a lack of exercise leads to weight gain. In this case 'lack of exercise' is independent variable and 'weight gain' is dependent variable. A confounding varaible in this case would be 'age' which affect both of these variables.",2025-11-18T17:20:54.036368
Explain ROC curve and AUC,,hard,mixed,data_science,DS_Interview_Notebook,"**ROC Curve (Receiver Operating Characteristic Curve)** and **AUC (Area Under the Curve)** are tools used to evaluate the performance of a classification model, particularly when you want to understand how well the model separates two classes, such as ""spam"" and ""not spam."" ### ROC Curve: 1. **What is the ROC Curve?** - The ROC Curve is a graph that shows the trade-off between the **True Positive Rate (TPR)** and the **False Positive Rate (FPR)** of a model at various thresholds. - **True Positi",2025-11-18T17:20:54.036440
Explain Precision-Recall Curve,,hard,mixed,data_science,DS_Interview_Notebook,"The **Precision-Recall Curve** is a tool used to evaluate the performance of a classification model, especially when dealing with imbalanced datasets where one class is much more common than the other. ### Key Concepts: 1. **Precision**: - Measures how many of the positive predictions made by the model are actually correct. - **Example**: If a model predicts 10 emails as spam and 8 are actually spam, the precision is 8 out of 10, or 80%. 2. **Recall**: - Measures how well the model finds all the",2025-11-18T17:20:54.036502
What is TF-IDF?,,hard,mixed,data_science,DS_Interview_Notebook,**TF-IDF (Term Frequency-Inverse Document Frequency)** is a method used in text analysis to determine how important a word is in a specific document compared to a whole collection of documents (called a corpus). It helps in identifying words that are most relevant to the content of a document. ### Key Concepts: 1. **Term Frequency (TF)**: - This measures how often a word appears in a document. A higher term frequency means that the word is more significant within that document. - **Simple Exampl,2025-11-18T17:20:54.036563
Python or R- which one would you prefer for text analytics?,,medium,mixed,data_science,DS_Interview_Notebook,We will prefer python for following reasons * We can use pandas library which has easy to use data structures and high performance data analysis tools * R is more suitable for ML than text analytics * Python is faster for all types of text analytics.,2025-11-18T17:20:54.036576
What are Eigenvectors and Eigenvalues?,,hard,mixed,data_science,DS_Interview_Notebook,"* In linear algebra, an **eigenvector** is a special vector that, when a linear transformation is applied to it, only changes in scale (gets stretched or shrunk) but not in direction. * The **eigenvalue** associated with that eigenvector is the factor by which it is scaled. **Why are they important?** Eigenvectors and eigenvalues reveal the underlying structure and behavior of linear transformations. They have numerous applications across various fields: * **Image compression:** Eigenvectors can",2025-11-18T17:20:54.036607
Explain the scenario where both false positive and false negative are equally important,,hard,mixed,data_science,DS_Interview_Notebook,"1. **Medical Diagnosis (e.g., Cancer Screening)** * **False Positive:** A patient is told they have cancer when they don't. This leads to unnecessary anxiety, invasive procedures, and potential side effects from treatment. * **False Negative:** A patient with cancer is told they are healthy. This delays crucial treatment, potentially allowing the disease to progress and worsen the prognosis. 2. **Fraud Detection** * **False Positive:** A legitimate transaction is flagged as fraudulent. This inco",2025-11-18T17:20:54.036632
Why feature scalling is required in Gradient Descent Based Algorithms,,hard,ml,data_science,DS_Interview_Notebook,"* Machine learning algorithms like linear regression, logistic regression, neural network, etc. that use gradient descent as an optimization technique require data to be scaled. Take a look at the formula for gradient descent below: ![Gradient descent formula]( * The presence of feature value X in the formula will affect the step size of the gradient descent. * The difference in ranges of features will cause different step sizes for each feature. * To ensure that the gradient descent moves smoot",2025-11-18T17:20:54.036660
Why feature scaling not required in tree based algorithms,,hard,ml,data_science,DS_Interview_Notebook,"Imagine you're sorting a pile of apples and oranges into two baskets. You could sort them by color (red vs. not red) or by weight (heavy vs. light). * **Tree-based algorithms work like this:** They make decisions based on *thresholds* or *cut-offs* for each feature (like color or weight). They ask questions like: ""Is this fruit red?"" or ""Is this fruit heavier than 1 pound?"". * **Feature scaling doesn't matter here:** * **Color:** It doesn't matter if we represent ""red"" as the number 1 and ""not r",2025-11-18T17:20:54.036762
"Explain the difference between train, validation and test set",,medium,stats,data_science,DS_Interview_Notebook,* Training set is used for model training * Validation set is used for model fine tuning (tune the model's hyperparameters) * Test set is used for model testing. i.e. evaluating the models predictive power and generalization.,2025-11-18T17:20:54.036773
What is Naive Bayes algorithm?,,hard,ml,data_science,DS_Interview_Notebook,"The Naive Bayes algorithm is a simple but surprisingly effective classification algorithm in machine learning. It's based on Bayes' Theorem, which deals with conditional probabilities. **In simpler terms:** Imagine you're trying to decide if an email is spam or not. Naive Bayes looks at the words in the email and asks, ""If an email *is* spam, how likely is it to contain these words?"" It then does the same for non-spam emails. Finally, it compares these probabilities to make its best guess about ",2025-11-18T17:20:54.036819
What is the difference between MLOps and DevOps?,,hard,mixed,data_science,DS_Interview_Notebook,"* MLOps & DevOps have a lot of things in common. However, DevOps include developing and deploying the software application code in production and this code is usually static and does not change rapidly. * MLOps on the other side also includes developing and deploying the ML code in production. However, here the data changes rapidly and the up-gradation of models has to happen more frequently than typical software application code. * Reference: ",2025-11-18T17:20:54.036837
What are the risks associated with Data Science & how MLOps can overcome the same?,,hard,case,data_science,DS_Interview_Notebook,"In Data Science, several risks can impact projects, such as data quality issues, model deployment challenges, model performance degradation, lack of reproducibility, security concerns, and scalability issues. **MLOps (Machine Learning Operations)** helps mitigate these risks by: 1. **Automating Data Quality Checks and Monitoring**: Ensures consistent data quality and detects data drift, which helps maintain model accuracy over time. 2. **Streamlining Model Deployment and Environment Consistency*",2025-11-18T17:20:54.036877
What are the differences between XGBoost and Random Forest Model,,hard,ml,data_science,DS_Interview_Notebook,"| Feature | XGBoost | Random Forest | |------------------------------|----------------------------------------------|---------------------------------------------| | **Technique** | Boosting Technique: Builds trees sequentially, where each tree corrects the errors of the previous one. | Bagging Technique: Builds trees independently in parallel and aggregates their results. | | **Performance** | Generally provides higher accuracy due to its boosting nature. | May have lower accuracy compared to b",2025-11-18T17:20:54.036909
Please explain p-value to someone non-technical,,hard,mixed,data_science,DS_Interview_Notebook,"A p-value is a number that helps us understand if the results we see in an experiment or study are meaningful or if they might have happened just by chance. Imagine you're playing a game of chance, like flipping a coin. You suspect the coin might be rigged to land on heads more often, so you decide to test it. **The ""normal"" assumption (null hypothesis):** The coin is fair, and there's a 50/50 chance of getting heads or tails. **Your experiment:** You flip the coin 100 times and get 60 heads. Hm",2025-11-18T17:20:54.036966
"Average comments per month has dropped over three-month period, despite consistent growth after a new launch. What metric would u investigate?",,hard,mixed,data_science,DS_Interview_Notebook,"**To investigate the drop in average comments per month despite consistent growth after a new launch, I would examine:** 1. **Engagement per User**: Assess if the average number of comments per active user has decreased. Even with user growth, fewer comments per user could explain the overall decline. 2. **Content Type Analysis**: Identify if the types of content driving growth are different from those that typically generate comments. Growth could be from content that attracts more views or rea",2025-11-18T17:20:54.037005
A PM tells you that a weekly active user metric is up by 5% but email notification open rate is down by 2%. WHat would you investigate to dignose this problem?,,hard,mixed,data_science,DS_Interview_Notebook,"Email open rate is calculated by dividing the number of emails opened by the number of emails sent minus any bounces. A good open rate is between 17-28%2. Email notification open rate is a type of email open rate that measures how many users open an email that notifies them about something. Weekly active user metric (WAU) is a measure of how many users are active on a website or app in a given week. It can be influenced by many factors, such as user acquisition, retention, engagement and churn. ",2025-11-18T17:20:54.037046
Explain data drift problem in machine learning,,hard,ml,data_science,DS_Interview_Notebook,**Data drift** is a common problem in machine learning that occurs when the statistical properties of the input data change over time. This change can lead to a decrease in the performance of machine learning models because the model is no longer receiving the same kind of data it was trained on. ### Key Points to Explain Data Drift: 1. **Definition of Data Drift**: - **Data drift** refers to any change in the distribution of data that a machine learning model was trained on compared to the data,2025-11-18T17:20:54.037150
Explain transformer architecture,,hard,mixed,data_science,DS_Interview_Notebook,"The Transformer architecture is a neural network model designed for natural language processing tasks, like translation, summarization, and text generation. It was introduced in the paper ""Attention is All You Need"" by Google in 2017 and has since become the foundation for many advanced NLP models, including BERT and GPT. Key Components of the Transformer: **1. Self-Attention Mechanism:** The core innovation of the Transformer is its self-attention mechanism. This mechanism allows the model to w",2025-11-18T17:20:54.037226
Explain the difference between prediction and forecasting,,hard,mixed,data_science,DS_Interview_Notebook,"* If you think of it like a detective story, prediction is about figuring out who committed the crime based on the evidence. It could be something that happened in the past. * Forecasting is more like trying to prevent a crime before it happens. We look for patterns and clues to anticipate what might occur in the future. * In the context of my work with time series models, prediction might be used to identify any current anomalies or issues in our system based on the data we're receiving. Foreca",2025-11-18T17:20:54.037256
References,,easy,mixed,data_science,DS_Interview_Notebook,*  *  *  *  *  *  * ,2025-11-18T17:20:54.037275
What is padding,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061234
Sigmoid Vs Softmax,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061244
What is PoS Tagging,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061248
What is tokenization,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061251
What is topic modeling,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061253
What is back propagation,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061256
What is the idea behind GANs,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061258
What is the Computational Graph,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061260
What is sigmoid What does it do,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061263
What is Named-Entity Recognition,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061265
Explain the masked language model,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061267
How do you preprocess text in NLP,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061270
How do you extract features in NLP,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061272
How is wordvec different from Glove,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061274
What Are the Different Layers on CNN,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061277
What makes CNNs translation invariant,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061279
How is fastText different from wordvec,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061281
What is backward and forward propagation,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061286
What are Syntactic and Semantic Analysis,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061288
What is a local optimumWhat is a local optimum,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061291
Explain gates used in LSTM with their functions,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061294
What is ReLU How is it better than sigmoid or tanh,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061297
What is transfer learning have you used it before,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061299
What is multi-task learning When should it be used,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061302
Difference between convex and non-convex cost function,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061305
Why do we remove stop words When do we not remove them,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061308
Explain the difference between an epoch a batch and an iteration,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061311
What is the difference between NLP and NLU,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061313
For online learning which one would you prefer SGD or Adagrad and why,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061321
What Is a Multi-layer Perceptron MLPWhat Is a Multi-layer Perceptron MLP,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061325
Is it always bad to have local optimaIs it always bad to have local optima,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061328
"In node2vec, what does embedding represent topological similarity or nearness",,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061331
What do you understand by Boltzmann Machine and Restricted Boltzmann Machines,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061334
How to compute an inverse matrix faster by playing around with some computational tricks,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061337
For infrequent/rare words which among CBOW and SkipGram should be used for wordvec training,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061341
What is pooling in CNN Why do we need it,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061343
Describe the structure of Artificial Neural Networks & RNN(recurrent neural network),,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061346
How to Select a Batch Size Will selecting a batch size produce better or worse results?,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061350
What are N-grams How can we use them,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061352
How large should be N for our bag of words when using N-grams,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061355
How can you use neural nets for text classification and computer vision,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061358
Do gradient descent methods always converge at the same point,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061361
What is gradient descent How does it work,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061364
What are autoencoders Explain the different layers of autoencoders and mention three practical usages of them,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061367
What is vanishing gradient descent,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061370
difference between Vanishing gradient Vs Exploding gradient,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061372
How to handle dying node problems in case of ReLU activation function,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061375
What is the use of the leaky ReLU function,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061378
What are the different Deep Learning Frameworks,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061380
What is a dropout layer and how does it help a neural network,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061386
Explain why dropout in a neural network acts as a regularizer,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061389
How to know whether your model is suffering from the problem of Exploding Gradients,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061393
How to handle exploding gradient problem,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061395
How Does an LSTM Network Work,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061397
What problem does Bi-LSTM solve instead of only LSTM,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061400
What happens to the predictions of a CNN if an image is rotated,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061405
How does CNN help in translation and rotation invariance of images,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061408
Define Term Freuency & Inverse Document Freuency Tf-idf and how to use it for converting text to vector,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061412
What are three primary convolutional neural network layers How are they commonly put together,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061415
Describe the architecture of a typical Convolutional Neural Network,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061418
"What do you mean by Dropout and Batch Normalization, When and why use",,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061421
What is the difference between online and batch learning,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061424
Is dropout used on the test set,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061427
What is an activation function and discuss the use of an activation function,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061430
Explain three different types of activation functions,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061432
What is the range of activation functions,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061435
Why is Rectified Linear Unit a good activation function,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061437
Why don't we use the Relu activation function in the output layer,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061440
What can go wrong if we use a linear activation instead of ReLU,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061445
"Give examples in which a many-to-one RNN architecture is appropriate, Give examples in which a many-to-one RNN architecture is appropriate",,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061449
What is RNN and How does an RNN work,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061452
Why Sigmoid or Tanh is not preferred to be used as the activation function in the hidden layer of the neural network,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061456
"difference between various Activation functions such as Sigmoid , tanh, Softmax, ReLU, Leaky ReLU",,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061460
Why Tanh activation function preferred over sigmoid,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061463
What are word embeddings Why are they useful,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061465
what is WordVec,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061467
What are some advantages of using character embeddings instead of word embeddings,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061470
"How do you get sentence meanings from word embeddings, considering the position of words in the sentence",,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061474
Would you prefer gradient boosting trees model or logistic regression when doing text classification with bag of words,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061478
What is bag of words How we can use it for text vectorization,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061481
What is the main difference between Adam and SGD,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061487
What are the advantages and disadvantages of SGD over gradient descent,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061490
"What is the difference between stochastic gradient descent SGD and gradient descent GD, Batch gradient descent, Stochastic gradient descent, Mini-batch gradient descent , what are the pros and cons for each of them",,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061496
When would you use GD over SDG and vice-versa,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061499
How would you choose the number of filters and the filter size at each CNN layer,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061502
How can we use CNN for text classification,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061505
What are some advantages in using a CNN (convolutional neural network rather than a DNN (dense neural network in an image classification task,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061509
Describe two ways to visualize features of a CNN in an image classification task,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061512
Why do segmentation CNNs typically have an encoder-decoder style / structure,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061515
What is a convolutional layer & Why do we actually need convolutions Can we use fully-connected layers for that,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061519
What are the advantages of parameter sharing in case of convolution,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061522
Why do we use convolutions for images rather than just Fully Connected layers,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061525
Why would you use many small convolutional kernels such as x rather than a few large onesWhy would you use many small convolutional kernels such as x rather than a few large ones,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061531
Why we generally use Softmax non-linearity function as the last operation in-network,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061534
How does BatchNormalization differ in training and inferencing,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061537
How does batch size affect training of neural networks,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061539
"When using mini batch gradient descent, why is it important to shuffle the data",,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061543
Give a simple mathematical argument why a mini-batch version of such ML algorithm might be computationally more efficient than a training with full data set,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061547
On a simplified and fundamental scale what makes the newly developed BERT model better than traditional NLP models,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061551
How would you initialize weights in a neural network,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061554
Why weights are initialized with small random numbers in a neural network What happens when weights are all or constant values,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061558
Suppose you have a NN with layers and ReLU activations What will happen if we initialize all the weights with the same value,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061562
What is backpropagation How does it work Why do we need it,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061567
Why large filter sizes in early layers can be a bad choice How to choose filter size,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061571
which one is more powerful a layer decision tree or a -layer neural network without any activation function --> Hint non-linearity,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061575
Both decision trees and deep neural networks are non-linear classifier ie they separates the space by complicated decision boundary Why then it is so much easier for us to intuitively follow a decision tree model vs a deep neural network,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061582
If you could take advantage of multiple CPU cores would you prefer a boosted-tree algorithm over a random forest,,medium,ml,deep_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061585
What are MSE and RMSE,,medium,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061748
Explain DBSCAN algorithm,,medium,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061753
What are dummy variables,,medium,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061756
What is anomaly detection,,easy,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061758
What is Bayesian inference,,easy,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061760
What is the R-Suared value,,easy,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061764
What about ordinal features,,medium,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061766
Loss functions in regression,,medium,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061769
Undersampling vs Oversampling,,medium,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061774
What is reinforcement learning,,easy,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061776
Do we call Knn a lazy algorithm,,medium,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061778
Define a Monte Carlo simulation,,easy,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061780
Does Kmeans and Kmeans++ is same,,medium,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061783
What is pruning in Decision Tree,,easy,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061785
How does an XGB control overfitting,,medium,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061787
What is the class imbalance problem,,easy,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061789
Why is lightGBM prone to overfitting,,medium,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061792
Name any one distance based algorithm,,easy,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061794
What is the objective function for Knn,,easy,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061796
What is the standard error of the mean,,easy,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061798
What are some disadvantages of K-means,,medium,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061800
What is data augmentation Give examples,,easy,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061803
What is Euclidean and Manhatten distance,,easy,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061806
What is the role of gamma in RBF kernels,,easy,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061808
How would you handle an imbalanced dataset,,medium,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061811
Is it a good idea to combine multiple trees,,medium,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061814
How do support vector machine algorithms work,,medium,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061816
What is the significance of Residual Networks,,easy,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061818
What does it mean to have low MAE and high MSE,,medium,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061821
What are the disadvantages of linear regression,,medium,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061824
What is a recommendation engine How does it work,,easy,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061826
What is K-means How can you select K for K-means,,easy,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061829
Does Radial basis kernel function is there in SVM,,medium,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061831
What is linear regression Why is it called linear,,easy,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061834
Is pruning always a good method to construct a tree,,medium,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061837
What is the difference between bagging and boosting,,easy,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061839
Which algorithm uses margin to classify the classes,,medium,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061842
What algorithm can be used to summarize twitter feed,,medium,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061845
How do you generate arbitrary or random shape clusters,,medium,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061847
How to compute standard error of median in a simple way,,medium,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061850
How does GBDTs decide to split a node What does it minimize,,medium,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061855
What is the difference between R-suare and Adjusted R-suare,,easy,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061857
How is matrix factorization useful in recommendation systems,,medium,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061860
What are the approximation methods in Reinforcement Learning,,medium,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061863
What is the difference between an error and a residual error,,easy,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061865
Why does training an SVM takes a long time How can I speed up,,medium,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061868
Difference between bagging boosting and the relation to bayes theorem,,medium,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061872
Which algorithm takes the data to the next dimension and then classify,,medium,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061875
What are categorical variables and what do we do with categorical variables,,medium,ml,machine_learning,Sandy1811/DS-Interview-FAANG,,2025-11-19T09:28:09.061878
[Paste question here],,easy/medium/hard,coding/stats/ml/case/behavioral,,manual_templates/leetcode_manual_template.txt,,2025-11-17T11:27:21.133135
[Question title/description] [Full question text if available],"[Company Name or ""General""]",easy/medium/hard,sql/python,,manual_templates/stratascratch_manual_template.txt,,2025-11-17T11:27:21.133212
"Count the number of movies per genre Write a query to find the number of movies in each genre. Return the genre name and count, ordered by count descending.",Netflix,medium,sql,,manual_templates/stratascratch_manual_template.txt,,2025-11-17T11:27:21.133229
You are given a train data set having 1000 columns and 1 million rows based on a classification problem. Your manager has asked you to reduce the dimension of this data so that model computation time can be reduced. Your machine has memory constraints. What would you do?,,hard,case,,manual_templates/manual_scenario_questions.txt,,2025-11-17T11:27:21.133308
You are given a data set. The data set has missing values which spread along 1 standard deviation from the median. What percentage of data would remain unaffected? Why?,,hard,case,,manual_templates/manual_scenario_questions.txt,,2025-11-17T11:27:21.133323
You are given a data set on cancer detection. You've built a classification model and achieved an accuracy of 96%. Why shouldn't you be happy with your model performance? What can you do about it?,,hard,case,,manual_templates/manual_scenario_questions.txt,,2025-11-17T11:27:21.133338
You are working on a time series data set. You built a decision tree model but later tried a time series regression model and got higher accuracy. Can this happen? Why?,,hard,case,,manual_templates/manual_scenario_questions.txt,,2025-11-17T11:27:21.133352
"You are assigned a new project helping a food delivery company save money. The company's delivery team can't deliver food on time, so customers get unhappy and receive free food. Which machine learning algorithm can save them?",,hard,case,,manual_templates/manual_scenario_questions.txt,,2025-11-17T11:27:21.133368
You came to know that your model is suffering from low bias and high variance. Which algorithm should you use to tackle it? Why?,,hard,case,,manual_templates/manual_scenario_questions.txt,,2025-11-17T11:27:21.133378
"You are given a data set with many variables, some highly correlated. Your manager has asked you to run PCA. Would you remove correlated variables first? Why?",,hard,case,,manual_templates/manual_scenario_questions.txt,,2025-11-17T11:27:21.133390
"After spending several hours, you built 5 GBM models thinking boosting would do magic. Unfortunately, none performed better than benchmark. You decided to combine those models but ensembled models didn't improve accuracy. Where did you miss?",,hard,case,,manual_templates/manual_scenario_questions.txt,,2025-11-17T11:27:21.133406
You have built a multiple regression model. Your model R¬≤ isn't as good as you wanted. You remove the intercept term and model R¬≤ becomes 0.8 from 0.3. Is it possible? How?,,hard,case,,manual_templates/manual_scenario_questions.txt,,2025-11-17T11:27:21.133420
"Your manager informed that your regression model is suffering from multicollinearity. How would you check if he's true? Without losing information, can you still build a better model?",,hard,case,,manual_templates/manual_scenario_questions.txt,,2025-11-17T11:27:21.133434
"Is rotation necessary in PCA? If yes, why? What will happen if you don't rotate the components?",,medium,ml,,manual_templates/manual_scenario_questions.txt,,2025-11-17T11:27:21.133449
"Why is Naive Bayes so 'naive'? Explain prior probability, likelihood and marginal likelihood in context of Naive Bayes algorithm.",,medium,ml,,manual_templates/manual_scenario_questions.txt,,2025-11-17T11:27:21.133459
When is Ridge regression favorable over Lasso regression?,,medium,ml,,manual_templates/manual_scenario_questions.txt,,2025-11-17T11:27:21.133465
"Both being tree based algorithms, how is random forest different from Gradient boosting algorithm (GBM)?",,medium,ml,,manual_templates/manual_scenario_questions.txt,,2025-11-17T11:27:21.133474
You've built a random forest model with 10000 trees. Training error is 0.00 but validation error is 34.23. What is going on? Haven't you trained your model perfectly?,,medium,ml,,manual_templates/manual_scenario_questions.txt,,2025-11-17T11:27:21.133486
You've got a data set where p (no. of variables) > n (no. of observations). Why is OLS a bad option? Which techniques would be best to use? Why?,,medium,ml,,manual_templates/manual_scenario_questions.txt,,2025-11-17T11:27:21.133498
What cross validation technique would you use on time series data set? Is it k-fold or LOOCV?,,medium,ml,,manual_templates/manual_scenario_questions.txt,,2025-11-17T11:27:21.133506
"You are given a data set consisting of variables having more than 30% missing values. Out of 50 variables, 8 have missing values higher than 30%. How will you deal with them?",,medium,ml,,manual_templates/manual_scenario_questions.txt,,2025-11-17T11:27:21.133519
How is kNN different from k-means clustering?,,medium,stats,,manual_templates/manual_scenario_questions.txt,,2025-11-17T11:27:21.133530
How is True Positive Rate and Recall related? Write the equation.,,medium,stats,,manual_templates/manual_scenario_questions.txt,,2025-11-17T11:27:21.133536
What is the difference between covariance and correlation?,,medium,stats,,manual_templates/manual_scenario_questions.txt,,2025-11-17T11:27:21.133542
"Is it possible to capture the correlation between continuous and categorical variable? If yes, how?",,medium,stats,,manual_templates/manual_scenario_questions.txt,,2025-11-17T11:27:21.133551
Running a binary classification tree algorithm is easy. But how does tree splitting take place? How does the tree decide which variable to split at the root node and succeeding nodes?,,medium,stats,,manual_templates/manual_scenario_questions.txt,,2025-11-17T11:27:21.133566
"We know that one hot encoding increases the dimensionality of a data set, but label encoding doesn't. How?",,medium,stats,,manual_templates/manual_scenario_questions.txt,,2025-11-17T11:27:21.133575
What do you understand by Type I vs Type II error?,,medium,stats,,manual_templates/manual_scenario_questions.txt,,2025-11-17T11:27:21.133582
What is convex hull? (Hint: Think SVM),,medium,stats,,manual_templates/manual_scenario_questions.txt,,2025-11-17T11:27:21.133587
Rise in global average temperature led to decrease in number of pirates around the world. Does that mean that decrease in number of pirates caused the climate change?,,easy,stats,,manual_templates/manual_scenario_questions.txt,,2025-11-17T11:27:21.133619
"While working on a data set, how do you select important variables? Explain your methods.",,medium,ml,,manual_templates/manual_scenario_questions.txt,,2025-11-17T11:27:21.133631
What cross validation technique would you use on a time series data set? Is it k-fold or LOOCV? Explain the forward chaining strategy.,,medium,ml,,manual_templates/manual_scenario_questions.txt,,2025-11-17T11:27:21.133641
The list of questions is based on [this post](https://medium.com/data-science-insider/160-data-science-interview-questions-14dbd8bf0a08?source=friends_link&sk=7acf122a017c672a95f70c7cb7b585c0),,medium,mixed,,github,,2025-11-21T13:05:31.722419
Legend: üë∂ easy ‚Äç‚≠êÔ∏è medium üöÄ expert,,medium,mixed,,github,,2025-11-21T13:05:31.722731
Do you know how to answer questions without answers? Please create a PR,,medium,mixed,,github,,2025-11-21T13:05:31.722799
[Supervised machine learning](#supervised-machinelearning),,medium,ml,,github,,2025-11-21T13:05:31.722843
[Linear regression](#linear-regression),,medium,ml,regression,github,,2025-11-21T13:05:31.722884
[Classification](#classification),,medium,ml,classification,github,,2025-11-21T13:05:31.722962
[Regularization](#regularization),,medium,mixed,,github,,2025-11-21T13:05:31.723001
[Feature selection](#feature-selection),,medium,mixed,feature_engineering,github,,2025-11-21T13:05:31.723043
[Decision trees](#decision-trees),,medium,mixed,,github,,2025-11-21T13:05:31.723083
[Random forest](#random-forest),,medium,mixed,ensemble,github,,2025-11-21T13:05:31.723123
[Gradient boosting](#gradient-boosting),,medium,mixed,ensemble,github,,2025-11-21T13:05:31.723164
[Parameter tuning](#parameter-tuning),,medium,mixed,,github,,2025-11-21T13:05:31.723204
[Neural networks](#neural-networks),,medium,ml,neural_network,github,,2025-11-21T13:05:31.723238
[Optimization in neural networks](#optimization-in-neuralnetworks),,medium,ml,neural_network,github,,2025-11-21T13:05:31.723276
[Neural networks for computer vision](#neural-networks-for-computervision),,medium,ml,neural_network|computer_vision,github,,2025-11-21T13:05:31.723347
[Text classification](#text-classification),,medium,ml,classification|nlp,github,,2025-11-21T13:05:31.723385
[Dimensionality reduction](#dimensionality-reduction),,medium,mixed,,github,,2025-11-21T13:05:31.723466
[Ranking and search](#ranking-andsearch),,medium,mixed,,github,,2025-11-21T13:05:31.723506
[Recommender systems](#recommender-systems),,medium,mixed,,github,,2025-11-21T13:05:31.723547
[Time series](#time-series),,medium,mixed,,github,,2025-11-21T13:05:31.723586
**What is supervised machine learning? üë∂**,,medium,ml,,github,,2025-11-21T13:05:31.723629
**What is regression? Which models can you use to solve a regression problem? üë∂**,,medium,ml,regression,github,,2025-11-21T13:05:31.723681
Linear Regression* establishes a linear relationship between target and predictor (s). It predicts a numeric value and has a shape of a straight line.,,medium,ml,regression,github,,2025-11-21T13:05:31.723706
Polynomial Regression* has a regression equation with the power of independent variable more than 1. It is a curve that fits into the data points.,,medium,ml,regression,github,,2025-11-21T13:05:31.723730
Ridge Regression* helps when predictors are highly correlated (multicollinearity problem). It penalizes the squares of regression coefficients but doesn‚Äôt allow the coefficients to reach zeros (uses L2 regularization).,,medium,ml,regression,github,,2025-11-21T13:05:31.723768
Lasso Regression* penalizes the absolute values of regression coefficients and allows some of the coefficients to reach absolute zero (thereby allowing feature selection).,,medium,ml,regression|feature_engineering,github,,2025-11-21T13:05:31.723793
**What is linear regression? When do we use it? üë∂**,,medium,ml,regression,github,,2025-11-21T13:05:31.723815
**What are the main assumptions of linear regression? ‚≠ê**,,medium,ml,regression,github,,2025-11-21T13:05:31.723837
Linear relationship** between features and target variable.,,medium,mixed,feature_engineering,github,,2025-11-21T13:05:31.723859
No correlation between errors (consecutive errors in the case of time series data).,,medium,mixed,,github,,2025-11-21T13:05:31.723883
**What‚Äôs the normal distribution? Why do we care about it? üë∂**,,medium,stats,,github,,2025-11-21T13:05:31.723905
**How do we check if a variable follows the normal distribution? ‚Äç‚≠êÔ∏è**,,medium,stats,,github,,2025-11-21T13:05:31.723927
"Plot a histogram out of the sampled data. If you can fit the bell-shaped ""normal"" curve to the histogram, then the hypothesis that the underlying random variable follows the normal distribution can not be rejected.",,medium,stats,statistics,github,,2025-11-21T13:05:31.723951
**What if we want to build a model for predicting prices? Are prices distributed normally? Do we need to do any pre-processing for prices? ‚Äç‚≠êÔ∏è**,,medium,ml,,github,,2025-11-21T13:05:31.723978
**What methods for solving linear regression do you know? ‚Äç‚≠êÔ∏è**,,medium,ml,regression,github,,2025-11-21T13:05:31.723999
**What is the normal equation? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.724043
**What is SGD ‚Ää‚Äî‚Ää stochastic gradient descent? What‚Äôs the difference with the usual gradient descent? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.724070
**Which metrics for evaluating regression models do you know? üë∂**,,medium,ml,regression,github,,2025-11-21T13:05:31.724093
Mean Squared Error(MSE),,medium,mixed,,github,,2025-11-21T13:05:31.724113
**What is the bias-variance trade-off? üë∂**,,medium,stats,statistics,github,,2025-11-21T13:05:31.724154
**How to validate your models? üë∂**,,medium,ml,,github,,2025-11-21T13:05:31.724212
"**Why do we need to split our data into three parts: train, validation, and test? üë∂**",,medium,mixed,statistics,github,,2025-11-21T13:05:31.724239
**Can you explain how cross-validation works? üë∂**,,medium,mixed,,github,,2025-11-21T13:05:31.724262
**What is K-fold cross-validation? üë∂**,,medium,mixed,,github,,2025-11-21T13:05:31.724284
**How do we choose K in K-fold cross-validation? What‚Äôs your favorite K? üë∂**,,medium,mixed,,github,,2025-11-21T13:05:31.724309
**What is classification? Which models would you use to solve a classification problem? üë∂**,,medium,ml,classification,github,,2025-11-21T13:05:31.724332
**What is logistic regression? When do we need to use it? üë∂**,,medium,ml,regression,github,,2025-11-21T13:05:31.724353
**Is logistic regression a linear model? Why? üë∂**,,medium,ml,regression,github,,2025-11-21T13:05:31.724373
**How do we evaluate classification models? üë∂**,,medium,ml,classification,github,,2025-11-21T13:05:31.724416
**Is accuracy always a good metric? üë∂**,,medium,case,,github,,2025-11-21T13:05:31.724460
**What is the confusion table? What are the cells in this table? üë∂**,,medium,mixed,,github,,2025-11-21T13:05:31.724485
True Positives (TP): When the actual class of the observation is 1 (True) and the prediction is 1 (True),,medium,mixed,,github,,2025-11-21T13:05:31.724511
True Negative (TN): When the actual class of the observation is 0 (False) and the prediction is 0 (False),,medium,mixed,,github,,2025-11-21T13:05:31.724537
False Positive (FP): When the actual class of the observation is 0 (False) and the prediction is 1 (True),,medium,mixed,,github,,2025-11-21T13:05:31.724560
False Negative (FN): When the actual class of the observation is 1 (True) and the prediction is 0 (False),,medium,mixed,,github,,2025-11-21T13:05:31.724585
"**What are precision, recall, and F1-score? üë∂**",,medium,mixed,,github,,2025-11-21T13:05:31.724609
Precision and recall are classification evaluation metrics:,,medium,ml,classification,github,,2025-11-21T13:05:31.724630
P = TP / (TP + FP) and R = TP / (TP + FN).,,medium,mixed,,github,,2025-11-21T13:05:31.724649
"Where TP is true positives, FP is false positives and FN is false negatives",,medium,mixed,,github,,2025-11-21T13:05:31.724671
In both cases the score of 1 is the best: we get no false positives or false negatives and only true positives.,,medium,mixed,,github,,2025-11-21T13:05:31.724696
F1 is a combination of both precision and recall in one score (harmonic mean):,,medium,mixed,,github,,2025-11-21T13:05:31.724718
"Max F score is 1 and min is 0, with 1 being the best.",,medium,mixed,,github,,2025-11-21T13:05:31.724756
**What is the ROC curve? When to use it? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.724780
**What is AUC (AU ROC)? When to use it? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.724803
**How to interpret the AU ROC score? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.724824
**What is the PR (precision-recall) curve? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.724848
**What is the area under the PR curve? Is it a useful metric? ‚Äç‚≠êÔ∏èI**,,medium,case,,github,,2025-11-21T13:05:31.724871
**In which cases AU PR is better than AU ROC? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.724894
**What do we do with categorical variables? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.724916
**Why do we need one-hot encoding? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.724954
"**What is ""curse of dimensionality""? ‚Äç‚≠êÔ∏è**",,medium,mixed,,github,,2025-11-21T13:05:31.724978
"**What happens to our linear regression model if we have three columns in our data: x, y, z ‚Ää‚Äî‚Ää and z is a sum of x and y? ‚Äç‚≠êÔ∏è**",,medium,ml,regression,github,,2025-11-21T13:05:31.725003
**What happens to our linear regression model if the column z in the data is a sum of columns x and y and some random noise? ‚Äç‚≠êÔ∏è**,,medium,ml,regression,github,,2025-11-21T13:05:31.725027
**What is regularization? Why do we need it? üë∂**,,medium,mixed,,github,,2025-11-21T13:05:31.725050
**Which regularization techniques do you know? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.725073
L1 Regularization (Lasso regularization) - Adds the sum of absolute values of the coefficients to the cost function. $`\lambda\sum_{i=1}^{n} \left | w_i \right |`$,,medium,mixed,,github,,2025-11-21T13:05:31.725102
Where $`\lambda`$ determines the amount of regularization.,,medium,mixed,,github,,2025-11-21T13:05:31.725122
**What kind of regularization techniques are applicable to linear models? ‚Äç‚≠êÔ∏è**,,medium,ml,,github,,2025-11-21T13:05:31.725145
**How does L2 regularization look like in a linear model? ‚Äç‚≠êÔ∏è**,,medium,ml,,github,,2025-11-21T13:05:31.725166
**How do we select the right regularization parameters? üë∂**,,medium,mixed,,github,,2025-11-21T13:05:31.725191
**What‚Äôs the effect of L2 regularization on the weights of a linear model? ‚Äç‚≠êÔ∏è**,,medium,ml,,github,,2025-11-21T13:05:31.725212
**How L1 regularization looks like in a linear model? ‚Äç‚≠êÔ∏è**,,medium,ml,,github,,2025-11-21T13:05:31.725233
**What‚Äôs the difference between L2 and L1 regularization? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.725257
"Penalty terms: L1 regularization uses the sum of the absolute values of the weights, while L2 regularization uses the sum of the weights squared.",,medium,mixed,,github,,2025-11-21T13:05:31.725285
"Feature selection: L1 performs feature selection by reducing the coefficients of some predictors to 0, while L2 does not.",,medium,mixed,feature_engineering,github,,2025-11-21T13:05:31.725310
"Computational efficiency: L2 has an analytical solution, while L1 does not.",,medium,mixed,,github,,2025-11-21T13:05:31.725332
Multicollinearity: L2 addresses multicollinearity by constraining the coefficient norm.,,medium,mixed,,github,,2025-11-21T13:05:31.725356
**Can we have both L1 and L2 regularization components in a linear model? ‚Äç‚≠êÔ∏è**,,medium,ml,,github,,2025-11-21T13:05:31.725378
**What‚Äôs the interpretation of the bias term in linear models? ‚Äç‚≠êÔ∏è**,,medium,ml,,github,,2025-11-21T13:05:31.725400
**How do we interpret weights in linear models? ‚Äç‚≠êÔ∏è**,,medium,ml,,github,,2025-11-21T13:05:31.725421
**If a weight for one variable is higher than for another ‚Ää‚Äî‚Ää can we say that this variable is more important? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.725449
**When do we need to perform feature normalization for linear models? When it‚Äôs okay not to do it? ‚Äç‚≠êÔ∏è**,,medium,ml,feature_engineering,github,,2025-11-21T13:05:31.725471
**What is feature selection? Why do we need it? üë∂**,,medium,mixed,feature_engineering,github,,2025-11-21T13:05:31.725495
**Is feature selection important for linear models? ‚Äç‚≠êÔ∏è**,,medium,ml,feature_engineering,github,,2025-11-21T13:05:31.725515
**Which feature selection techniques do you know? ‚Äç‚≠êÔ∏è**,,medium,mixed,feature_engineering,github,,2025-11-21T13:05:31.725538
Principal Component Analysis,,medium,mixed,,github,,2025-11-21T13:05:31.725559
Neighborhood Component Analysis,,medium,mixed,,github,,2025-11-21T13:05:31.725578
**Can we use L1 regularization for feature selection? ‚Äç‚≠êÔ∏è**,,medium,mixed,feature_engineering,github,,2025-11-21T13:05:31.725603
**Can we use L2 regularization for feature selection? ‚Äç‚≠êÔ∏è**,,medium,mixed,feature_engineering,github,,2025-11-21T13:05:31.725624
**What are the decision trees? üë∂**,,medium,mixed,,github,,2025-11-21T13:05:31.725643
**How do we train decision trees? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.725663
Start at the root node.,,medium,mixed,,github,,2025-11-21T13:05:31.725680
**What are the main parameters of the decision tree model? üë∂**,,medium,ml,,github,,2025-11-21T13:05:31.725700
minimum samples per leaf node,,medium,mixed,,github,,2025-11-21T13:05:31.725717
**How do we handle categorical variables in decision trees? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.725740
**What are the benefits of a single decision tree compared to more complex models? ‚Äç‚≠êÔ∏è**,,medium,ml,,github,,2025-11-21T13:05:31.725760
**How can we know which features are more important for the decision tree model? ‚Äç‚≠êÔ∏è**,,medium,ml,feature_engineering,github,,2025-11-21T13:05:31.725780
**What is random forest? üë∂**,,medium,mixed,ensemble,github,,2025-11-21T13:05:31.725800
**Why do we need randomization in random forest? ‚Äç‚≠êÔ∏è**,,medium,mixed,ensemble,github,,2025-11-21T13:05:31.725821
**What are the main parameters of the random forest model? ‚Äç‚≠êÔ∏è**,,medium,ml,ensemble,github,,2025-11-21T13:05:31.725870
`max_depth`: Longest Path between root node and the leaf,,medium,mixed,,github,,2025-11-21T13:05:31.725891
`min_sample_split`: The minimum number of observations needed to split a given node,,medium,mixed,,github,,2025-11-21T13:05:31.725911
"`max_leaf_nodes`: Conditions the splitting of the tree and hence, limits the growth of the trees",,medium,mixed,,github,,2025-11-21T13:05:31.725933
`min_samples_leaf`: minimum number of samples in the leaf node,,medium,mixed,,github,,2025-11-21T13:05:31.725951
`n_estimators`: Number of trees,,medium,mixed,,github,,2025-11-21T13:05:31.725968
`max_sample`: Fraction of original dataset given to any individual tree in the given model,,medium,ml,,github,,2025-11-21T13:05:31.725985
`max_features`: Limits the maximum number of features provided to trees in random forest model,,medium,ml,feature_engineering|ensemble,github,,2025-11-21T13:05:31.726003
**How do we select the depth of the trees in random forest? ‚Äç‚≠êÔ∏è**,,medium,mixed,ensemble,github,,2025-11-21T13:05:31.726024
limit the maximum depth of a tree,,medium,mixed,,github,,2025-11-21T13:05:31.726041
limit the number of test nodes,,medium,mixed,statistics,github,,2025-11-21T13:05:31.726058
limit the minimum number of objects at a node required to split,,medium,mixed,,github,,2025-11-21T13:05:31.726076
"do not split a node when, at least, one of the resulting subsample sizes is below a given threshold",,medium,mixed,,github,,2025-11-21T13:05:31.726098
stop developing a node if it does not sufficiently improve the fit.,,medium,mixed,,github,,2025-11-21T13:05:31.726117
**How do we know how many trees we need in random forest? ‚Äç‚≠êÔ∏è**,,medium,mixed,ensemble,github,,2025-11-21T13:05:31.726138
**Is it easy to parallelize training of a random forest model? How can we do it? ‚Äç‚≠êÔ∏è**,,medium,ml,ensemble,github,,2025-11-21T13:05:31.726158
**What are the potential problems with many large trees? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.726179
"Overfitting: A large number of large trees can lead to overfitting, where the model becomes too complex and is able to memorize the training data but doesn't generalize well to new, unseen data.",,medium,ml,,github,,2025-11-21T13:05:31.726202
"Slow prediction time: As the number of trees in the forest increases, the prediction time for new data points can become quite slow. This can be a problem when you need to make predictions in real-time or on a large dataset.",,medium,mixed,,github,,2025-11-21T13:05:31.726231
"Memory consumption: Random Forest models with many large trees can consume a lot of memory, which can be a problem when working with large datasets or on a limited hardware.",,medium,ml,ensemble,github,,2025-11-21T13:05:31.726252
"Lack of interpretability: Random Forest models with many large trees can be difficult to interpret, making it harder to understand how the model is making predictions or what features are most important.",,medium,ml,feature_engineering|ensemble,github,,2025-11-21T13:05:31.726274
Difficulty in tuning : With an increasing number of large trees the tuning process becomes more complex and computationally expensive.,,medium,mixed,,github,,2025-11-21T13:05:31.726297
"**What if instead of finding the best split, we randomly select a few splits and just select the best from them. Will it work? üöÄ**",,medium,mixed,,github,,2025-11-21T13:05:31.726326
**What happens when we have correlated features in our data? ‚Äç‚≠êÔ∏è**,,medium,mixed,feature_engineering,github,,2025-11-21T13:05:31.726347
**What is gradient boosting trees? ‚Äç‚≠êÔ∏è**,,medium,mixed,ensemble,github,,2025-11-21T13:05:31.726366
**What‚Äôs the difference between random forest and gradient boosting? ‚Äç‚≠êÔ∏è**,,medium,mixed,ensemble,github,,2025-11-21T13:05:31.726389
Random Forests builds each tree independently while Gradient Boosting builds one tree at a time.,,medium,mixed,ensemble,github,,2025-11-21T13:05:31.726410
**Is it possible to parallelize training of a gradient boosting model? How to do it? ‚Äç‚≠êÔ∏è**,,medium,ml,ensemble,github,,2025-11-21T13:05:31.726430
**Feature importance in gradient boosting trees ‚Ää‚Äî‚Ää what are possible options? ‚Äç‚≠êÔ∏è**,,medium,mixed,feature_engineering|ensemble,github,,2025-11-21T13:05:31.726453
**Are there any differences between continuous and discrete variables when it comes to feature importance of gradient boosting models? üöÄ**,,medium,ml,feature_engineering|ensemble,github,,2025-11-21T13:05:31.726476
**What are the main parameters in the gradient boosting model? ‚Äç‚≠êÔ∏è**,,medium,ml,ensemble,github,,2025-11-21T13:05:31.726495
learning_rate=0.1 (shrinkage).,,medium,mixed,,github,,2025-11-21T13:05:31.726511
n_estimators=100 (number of trees).,,medium,mixed,,github,,2025-11-21T13:05:31.726528
**How do you approach tuning parameters in XGBoost or LightGBM? üöÄ**,,medium,mixed,,github,,2025-11-21T13:05:31.726550
**How do you select the number of trees in the gradient boosting model? ‚Äç‚≠êÔ∏è**,,medium,ml,ensemble,github,,2025-11-21T13:05:31.726570
**Which hyper-parameter tuning strategies (in general) do you know? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.726592
"<b>Grid Search</b> is an exhaustive approach such that for each hyper-parameter, the user needs to <i>manually</i> give a list of values for the algorithm to try. After these values are selected, grid search then evaluates the algorithm using each and every combination of hyper-parameters and returns the combination that gives the optimal result (i.e. lowest MAE). Because grid search evaluates the given algorithm using all combinations, it's easy to see that this can be quite computationally expensive and can lead to sub-optimal results specifically since the user needs to specify specific values for these hyper-parameters, which is prone for error and requires domain knowledge.",,medium,coding,,github,,2025-11-21T13:05:31.726632
"<b>Random Search</b> is similar to grid search but differs in the sense that rather than specifying which values to try for each hyper-parameter, an upper and lower bound of values for each hyper-parameter is given instead. With uniform probability, random values within these bounds are then chosen and similarly, the best combination is returned to the user. Although this seems less intuitive, no domain knowledge is necessary and theoretically much more of the parameter space can be explored.",,medium,stats,probability,github,,2025-11-21T13:05:31.726666
"In a completely different framework, <b>Bayesian Optimization</b> is thought of as a more statistical way of optimization and is commonly used when using neural networks, specifically since one evaluation of a neural network can be computationally costly. In numerous research papers, this method heavily outperforms Grid Search and Random Search and is currently used on the Google Cloud Platform as well as AWS. Because an in-depth explanation requires a heavy background in bayesian statistics and gaussian processes (and maybe even some game theory), a ""simple"" explanation is that a much simpler/faster <i>acquisition function</i> intelligently chooses (using a <i>surrogate function</i> such as probability of improvement or GP-UCB) which hyper-parameter values to try on the computationally expensive, original algorithm. Using the result of the initial combination of values on the expensive/original function, the acquisition function takes the result of the expensive/original algorithm into account and uses it as its prior knowledge to again come up with another set of hyper-parameters to choose during the next iteration. This process continues either for a specified number of iterations or for a specified amount of time and similarly the combination of hyper-parameters that performs the best on the expensive/original algorithm is chosen.",,medium,coding,neural_network|probability|statistics,github,,2025-11-21T13:05:31.726714
**What‚Äôs the difference between grid search parameter tuning strategy and random search? When to use one or another? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.726741
**What kind of problems neural nets can solve? üë∂**,,medium,ml,neural_network,github,,2025-11-21T13:05:31.726759
**How does a usual fully-connected feed-forward neural network work? ‚Äç‚≠êÔ∏è**,,medium,ml,neural_network,github,,2025-11-21T13:05:31.726778
**Why do we need activation functions? üë∂**,,medium,mixed,,github,,2025-11-21T13:05:31.726799
**What are the problems with sigmoid as an activation function? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.726821
**How we can initialize the weights of a neural network? ‚Äç‚≠êÔ∏è**,,medium,ml,neural_network,github,,2025-11-21T13:05:31.726884
Initializing weights with zeroes.,,medium,mixed,,github,,2025-11-21T13:05:31.726902
"a) If weights are initialized with very high values the term np.dot(W,X)+b becomes significantly higher and if an activation function like sigmoid() is applied, the function maps its value near to 1 where the slope of gradient changes slowly and learning takes a lot of time.",,medium,mixed,,github,,2025-11-21T13:05:31.726933
"b) If weights are initialized with low values it gets mapped to 0, where the case is the same as above. This problem is often referred to as the vanishing gradient.",,medium,mixed,,github,,2025-11-21T13:05:31.726959
**What if we set all the weights of a neural network to 0? ‚Äç‚≠êÔ∏è**,,medium,ml,neural_network,github,,2025-11-21T13:05:31.726977
**What regularization techniques for neural nets do you know? ‚Äç‚≠êÔ∏è**,,medium,ml,neural_network,github,,2025-11-21T13:05:31.726996
"L1 Regularization - Defined as the sum of absolute values of the individual parameters. The L1 penalty causes a subset of the weights to become zero, suggesting that the corresponding features may safely be discarded.",,medium,mixed,feature_engineering,github,,2025-11-21T13:05:31.727024
L2 Regularization - Defined as the sum of square of individual parameters. Often supported by regularization hyperparameter alpha. It results in weight decay.,,medium,mixed,,github,,2025-11-21T13:05:31.727048
Data Augmentation - This requires some fake data to be created as a part of training set.,,medium,mixed,,github,,2025-11-21T13:05:31.727069
Drop Out : This is most effective regularization technique for neural nets. Few random nodes in each layer is deactivated in forward pass. This allows the algorithm to train on different set of nodes in each iterations.,,medium,coding,neural_network,github,,2025-11-21T13:05:31.727088
**What is dropout? Why is it useful? How does it work? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.727109
Calculate the error ‚Äì How far is your model output from the actual output.,,medium,ml,,github,,2025-11-21T13:05:31.727151
Minimum Error ‚Äì Check whether the error is minimized or not.,,medium,mixed,,github,,2025-11-21T13:05:31.727172
"Update the parameters ‚Äì If the error is huge then, update the parameters (weights and biases). After that again check the error.",,medium,mixed,,github,,2025-11-21T13:05:31.727199
"Model is ready to make a prediction ‚Äì Once the error becomes minimum, you can feed some inputs to your model and it will produce the output.",,medium,ml,,github,,2025-11-21T13:05:31.727222
**Which optimization techniques for training neural nets do you know? ‚Äç‚≠êÔ∏è**,,medium,ml,neural_network,github,,2025-11-21T13:05:31.727241
Stochastic Gradient Descent,,medium,mixed,,github,,2025-11-21T13:05:31.727258
Mini-Batch Gradient Descent(best among gradient descents),,medium,mixed,,github,,2025-11-21T13:05:31.727277
Nesterov Accelerated Gradient,,medium,mixed,,github,,2025-11-21T13:05:31.727294
"Adam(best one. less time, more efficient)",,medium,mixed,,github,,2025-11-21T13:05:31.727311
**How do we use SGD (stochastic gradient descent) for training a neural net? ‚Äç‚≠êÔ∏è**,,medium,ml,neural_network,github,,2025-11-21T13:05:31.727331
**What‚Äôs the learning rate? üë∂**,,medium,mixed,,github,,2025-11-21T13:05:31.727351
**What happens when the learning rate is too large? Too small? üë∂**,,medium,mixed,,github,,2025-11-21T13:05:31.727374
**How to set the learning rate? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.727417
**What is Adam? What‚Äôs the main difference between Adam and SGD? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.727440
**When would you use Adam and when SGD? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.727460
**Do we want to have a constant learning rate or we better change it throughout training? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.727484
**How do we decide when to stop training a neural net? üë∂**,,medium,ml,neural_network,github,,2025-11-21T13:05:31.727503
**What is model checkpointing? ‚Äç‚≠êÔ∏è**,,medium,ml,,github,,2025-11-21T13:05:31.727519
**Can you tell us how you approach the model training process? ‚Äç‚≠êÔ∏è**,,medium,ml,,github,,2025-11-21T13:05:31.727538
**How we can use neural nets for computer vision? ‚Äç‚≠êÔ∏è**,,medium,ml,neural_network|computer_vision,github,,2025-11-21T13:05:31.727556
**What‚Äôs a convolutional layer? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.727575
**Why do we actually need convolutions? Can‚Äôt we use fully-connected layers for that? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.727598
**What‚Äôs pooling in CNN? Why do we need it? ‚Äç‚≠êÔ∏è**,,medium,mixed,neural_network|computer_vision,github,,2025-11-21T13:05:31.727617
**How does max pooling work? Are there other pooling techniques? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.727638
"Average pooling, the output is the average value of the receptive field.",,medium,mixed,,github,,2025-11-21T13:05:31.727656
"Min pooling, the output is the minimum value of the receptive field.",,medium,mixed,,github,,2025-11-21T13:05:31.727673
"Global pooling, where the receptive field is set to be equal to the input size, this means the output is equal to a scalar and can be used to reduce the dimensionality of the feature map.",,medium,mixed,feature_engineering,github,,2025-11-21T13:05:31.727697
**Are CNNs resistant to rotations? What happens to the predictions of a CNN if an image is rotated? üöÄ**,,medium,mixed,neural_network|computer_vision,github,,2025-11-21T13:05:31.727720
"CNNs are not resistant to rotation by design. However, we can make our models resistant by augmenting our datasets with different rotations of the raw data. The predictions of a CNN will change if an image is rotated and we did not augment our dataset accordingly. A demonstration of this occurence can be seen in [this video](https://www.youtube.com/watch?v=VO1bQo4PXV4), where a CNN changes its predicted class between a duck and a rabbit based on the rotation of the image.",,medium,ml,neural_network|computer_vision,github,,2025-11-21T13:05:31.727752
**What are augmentations? Why do we need them? üë∂**,,medium,mixed,,github,,2025-11-21T13:05:31.727771
**What kind of augmentations do you know? üë∂**,,medium,mixed,,github,,2025-11-21T13:05:31.727791
**How to choose which augmentations to use? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.727810
**What kind of CNN architectures for classification do you know? üöÄ**,,medium,ml,classification|neural_network|computer_vision,github,,2025-11-21T13:05:31.727829
**What is transfer learning? How does it work? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.727848
**What is object detection? Do you know any architectures for that? üöÄ**,,medium,mixed,,github,,2025-11-21T13:05:31.727869
**What is object segmentation? Do you know any architectures for that? üöÄ**,,medium,mixed,,github,,2025-11-21T13:05:31.727890
**How can we use machine learning for text classification? ‚Äç‚≠êÔ∏è**,,medium,ml,classification|nlp,github,,2025-11-21T13:05:31.727908
**What is bag of words? How we can use it for text classification? ‚Äç‚≠êÔ∏è**,,medium,ml,classification|nlp,github,,2025-11-21T13:05:31.727927
**What are the advantages and disadvantages of bag of words? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.727947
Simple to understand and implement.,,medium,coding,,github,,2025-11-21T13:05:31.727960
"The vocabulary requires careful design, most specifically in order to manage the size, which impacts the sparsity of the document representations.",,medium,mixed,,github,,2025-11-21T13:05:31.727982
**What is TF-IDF? How is it useful for text classification? ‚Äç‚≠êÔ∏è**,,medium,ml,classification|nlp,github,,2025-11-21T13:05:31.728038
**Which model would you use for text classification with bag of words features? ‚Äç‚≠êÔ∏è**,,medium,ml,classification|nlp|feature_engineering,github,,2025-11-21T13:05:31.728056
**What are word embeddings? Why are they useful? Do you know Word2Vec? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.728099
Common Bag of Words (CBOW),,medium,mixed,,github,,2025-11-21T13:05:31.728114
**Do you know any other ways to get word embeddings? üöÄ**,,medium,mixed,,github,,2025-11-21T13:05:31.728134
"**If you have a sentence with multiple words, you may need to combine multiple word embeddings into one. How would you do it? ‚Äç‚≠êÔ∏è**",,medium,mixed,,github,,2025-11-21T13:05:31.728158
Take an average over all words,,medium,mixed,,github,,2025-11-21T13:05:31.728174
**Would you prefer gradient boosting trees model or logistic regression when doing text classification with embeddings? ‚Äç‚≠êÔ∏è**,,medium,ml,regression|classification|nlp|ensemble,github,,2025-11-21T13:05:31.728193
**How can you use neural nets for text classification? üöÄ**,,medium,ml,classification|neural_network|nlp,github,,2025-11-21T13:05:31.728211
**What is unsupervised learning? üë∂**,,medium,mixed,,github,,2025-11-21T13:05:31.728248
**What is clustering? When do we need it? üë∂**,,medium,mixed,clustering,github,,2025-11-21T13:05:31.728268
**Do you know how K-means works? ‚Äç‚≠êÔ∏è**,,medium,mixed,clustering,github,,2025-11-21T13:05:31.728290
Partition points into k subsets.,,medium,mixed,,github,,2025-11-21T13:05:31.728306
**How to select K for K-means? ‚Äç‚≠êÔ∏è**,,medium,mixed,clustering,github,,2025-11-21T13:05:31.728324
"Domain knowledge, i.e. an expert knows the value of k",,medium,mixed,,github,,2025-11-21T13:05:31.728342
"Elbow method: compute the clusters for different values of k, for each k, calculate the total within-cluster sum of square, plot the sum according to the number of clusters and use the band as the number of clusters.",,medium,mixed,,github,,2025-11-21T13:05:31.728367
"Average silhouette method: compute the clusters for different values of k, for each k, calculate the average silhouette of observations, plot the silhouette according to the number of clusters and select the maximum as the number of clusters.",,medium,mixed,,github,,2025-11-21T13:05:31.728410
**What are the other clustering algorithms do you know? ‚Äç‚≠êÔ∏è**,,medium,coding,clustering,github,,2025-11-21T13:05:31.728426
k-medoids: Takes the most central point instead of the mean value as the center of the cluster. This makes it more robust to noise.,,medium,mixed,,github,,2025-11-21T13:05:31.728448
Agglomerative Hierarchical Clustering (AHC): hierarchical clusters combining the nearest clusters starting with each point as its own cluster.,,medium,mixed,clustering,github,,2025-11-21T13:05:31.728473
DIvisive ANAlysis Clustering (DIANA): hierarchical clustering starting with one cluster containing all points and splitting the clusters until each point describes its own cluster.,,medium,behavioral,clustering,github,,2025-11-21T13:05:31.728498
Density-Based Spatial Clustering of Applications with Noise (DBSCAN): Cluster defined as maximum set of density-connected points.,,medium,mixed,clustering,github,,2025-11-21T13:05:31.728519
**Do you know how DBScan works? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.728552
Two input parameters epsilon (neighborhood radius) and minPts (minimum number of points in an epsilon-neighborhood),,medium,mixed,,github,,2025-11-21T13:05:31.728573
Cluster defined as maximum set of density-connected points.,,medium,mixed,,github,,2025-11-21T13:05:31.728590
"Points p_j and p_i are density-connected w.r.t. epsilon and minPts if there is a point o such that both, i and j are density-reachable from o w.r.t. epsilon and minPts.",,medium,mixed,,github,,2025-11-21T13:05:31.728614
"p_j is density-reachable from p_i w.r.t. epsilon, minPts if there is a chain of points p_i -> p_i+1 -> p_i+x = p_j such that p_i+x is directly density-reachable from p_i+x-1.",,medium,mixed,,github,,2025-11-21T13:05:31.728636
"p_j is a directly density-reachable point of the neighborhood of p_i if dist(p_i,p_j) <= epsilon.",,medium,mixed,,github,,2025-11-21T13:05:31.728656
**When would you choose K-means and when DBScan? ‚Äç‚≠êÔ∏è**,,medium,mixed,clustering,github,,2025-11-21T13:05:31.728676
DBScan is more robust to noise.,,medium,mixed,,github,,2025-11-21T13:05:31.728691
DBScan is better when the amount of clusters is difficult to guess.,,medium,mixed,,github,,2025-11-21T13:05:31.728708
"K-means has a lower complexity, i.e. it will be much faster, especially with a larger amount of points.",,medium,mixed,clustering,github,,2025-11-21T13:05:31.728728
**What is the curse of dimensionality? Why do we care about it? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.728748
**Do you know any dimensionality reduction techniques? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.728768
Singular Value Decomposition (SVD),,medium,mixed,,github,,2025-11-21T13:05:31.728783
Principal Component Analysis (PCA),,medium,mixed,,github,,2025-11-21T13:05:31.728799
Linear Discriminant Analysis (LDA),,medium,mixed,,github,,2025-11-21T13:05:31.728815
T-distributed Stochastic Neighbor Embedding (t-SNE),,medium,mixed,,github,,2025-11-21T13:05:31.728832
Fourier and Wavelet Transforms,,medium,mixed,,github,,2025-11-21T13:05:31.728847
**What‚Äôs singular value decomposition? How is it typically used for machine learning? ‚Äç‚≠êÔ∏è**,,medium,ml,,github,,2025-11-21T13:05:31.728866
"Singular Value Decomposition (SVD) is a general matrix decomposition method that factors a matrix X into three matrices L (left singular values), Œ£ (diagonal matrix) and R^T (right singular values).",,medium,mixed,,github,,2025-11-21T13:05:31.728895
"For machine learning, Principal Component Analysis (PCA) is typically used. It is a special type of SVD where the singular values correspond to the eigenvectors and the values of the diagonal matrix are the squares of the eigenvalues. We use these features as they are statistically descriptive.",,medium,ml,feature_engineering,github,,2025-11-21T13:05:31.728921
"Having calculated the eigenvectors and eigenvalues, we can use the Kaiser-Guttman criterion, a scree plot or the proportion of explained variance to determine the principal components (i.e. the final dimensionality) that are useful for dimensionality reduction.",,medium,stats,statistics,github,,2025-11-21T13:05:31.728945
**What is the ranking problem? Which models can you use to solve them? ‚Äç‚≠êÔ∏è**,,medium,ml,,github,,2025-11-21T13:05:31.728964
**What are good unsupervised baselines for text information retrieval? ‚Äç‚≠êÔ∏è**,,medium,mixed,nlp,github,,2025-11-21T13:05:31.728984
**How would you evaluate your ranking algorithms? Which offline metrics would you use? ‚Äç‚≠êÔ∏è**,,medium,coding,,github,,2025-11-21T13:05:31.729000
**What is precision and recall at k? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.729018
**What is mean average precision at k? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.729037
**How can we use machine learning for search? ‚Äç‚≠êÔ∏è**,,medium,ml,,github,,2025-11-21T13:05:31.729053
**How can we get training data for our ranking algorithms? ‚Äç‚≠êÔ∏è**,,medium,coding,,github,,2025-11-21T13:05:31.729068
**Can we formulate the search problem as a classification problem? How? ‚Äç‚≠êÔ∏è**,,medium,ml,classification,github,,2025-11-21T13:05:31.729087
**How can we use clicks data as the training data for ranking algorithms? üöÄ**,,medium,coding,,github,,2025-11-21T13:05:31.729103
**Do you know how to use gradient boosting trees for ranking? üöÄ**,,medium,mixed,ensemble,github,,2025-11-21T13:05:31.729123
**How do you do an online evaluation of a new ranking algorithm? ‚Äç‚≠êÔ∏è**,,medium,coding,,github,,2025-11-21T13:05:31.729148
**What is a recommender system? üë∂**,,medium,mixed,,github,,2025-11-21T13:05:31.729167
**What are good baselines when building a recommender system? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.729187
A good recommer system should give relevant and personalized information.,,medium,mixed,,github,,2025-11-21T13:05:31.729206
It should not recommend items the user knows well or finds easily.,,medium,mixed,,github,,2025-11-21T13:05:31.729224
It should make diverse suggestions.,,medium,mixed,,github,,2025-11-21T13:05:31.729239
A user should explore new items.,,medium,mixed,,github,,2025-11-21T13:05:31.729255
**What is collaborative filtering? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.729273
Collaborative filtering is the most prominent approach to generate recommendations.,,medium,mixed,,github,,2025-11-21T13:05:31.729291
"It uses the wisdom of the crowd, i.e. it gives recommendations based on the experience of others.",,medium,mixed,,github,,2025-11-21T13:05:31.729311
A recommendation is calculated as the average of other experiences.,,medium,mixed,,github,,2025-11-21T13:05:31.729328
Say we want to give a score that indicates how much user u will like an item i. Then we can calculate it with the experience of N other users U as r_ui = 1/N * sum(v in U) r_vi.,,medium,mixed,,github,,2025-11-21T13:05:31.729352
"In order to rate similar experiences with a higher weight, we can introduce a similarity between users that we use as a multiplier for each rating.",,medium,mixed,,github,,2025-11-21T13:05:31.729374
"Also, as users have an individual profile, one user may have an average rating much larger than another user, so we use normalization techniques (e.g. centering or Z-score normalization) to remove the users' biases.",,medium,mixed,,github,,2025-11-21T13:05:31.729402
"Collaborative filtering does only need a rating matrix as input and improves over time. However, it does not work well on sparse data, does not work for cold starts (see below) and usually tends to overfit.",,medium,mixed,,github,,2025-11-21T13:05:31.729428
"**How we can incorporate implicit feedback (clicks, etc) into our recommender systems? ‚Äç‚≠êÔ∏è**",,medium,mixed,,github,,2025-11-21T13:05:31.729449
**What is the cold start problem? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.729467
**Possible approaches to solving the cold start problem? ‚Äç‚≠êÔ∏èüöÄ**,,medium,mixed,,github,,2025-11-21T13:05:31.729581
"Content-based filtering incorporates features about items to calculate a similarity between them. In this way, we can recommend items that have a high similarity to items that a user liked already. In this way, we are not dependent on the ratings of other users for a given item anymore and solve the cold start problem for new items.",,medium,mixed,feature_engineering,github,,2025-11-21T13:05:31.729621
Demographic filtering incorporates user profiles to calculate a similarity between them and solves the cold start problem for new users.,,medium,mixed,,github,,2025-11-21T13:05:31.729643
**What is a time series? üë∂**,,medium,mixed,,github,,2025-11-21T13:05:31.729709
**How is time series different from the usual regression problem? üë∂**,,medium,ml,regression,github,,2025-11-21T13:05:31.729820
**Which models do you know for solving time series problems? ‚Äç‚≠êÔ∏è**,,medium,ml,,github,,2025-11-21T13:05:31.729911
Simple Exponential Smoothing: approximate the time series with an exponential function,,medium,mixed,,github,,2025-11-21T13:05:31.729938
Trend-Corrected Exponential Smoothing (Holt‚Äòs Method): exponential smoothing that also models the trend,,medium,ml,,github,,2025-11-21T13:05:31.729961
Trend- and Seasonality-Corrected Exponential Smoothing (Holt-Winter‚Äòs Method): exponential smoothing that also models trend and seasonality,,medium,ml,,github,,2025-11-21T13:05:31.729984
"Time Series Decomposition: decomposed a time series into the four components trend, seasonal variation, cycling variation and irregular component",,medium,mixed,,github,,2025-11-21T13:05:31.730064
"Autoregressive models: similar to multiple linear regression, except that the dependent variable y_t depends on its own previous values rather than other independent variables.",,medium,ml,regression,github,,2025-11-21T13:05:31.730105
"Deep learning approaches (RNN, LSTM, etc.)",,medium,ml,neural_network,github,,2025-11-21T13:05:31.730125
"**If there‚Äôs a trend in our series, how we can remove it? And why would we want to do it? ‚Äç‚≠êÔ∏è**",,medium,mixed,,github,,2025-11-21T13:05:31.730217
**You have a series with only one variable ‚Äúy‚Äù measured at time t. How do predict ‚Äúy‚Äù at time t+1? Which approaches would you use? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.730271
**You have a series with a variable ‚Äúy‚Äù and a set of features. How do you predict ‚Äúy‚Äù at t+1? Which approaches would you use? ‚Äç‚≠êÔ∏è**,,medium,mixed,feature_engineering,github,,2025-11-21T13:05:31.730306
**What are the problems with using trees for solving time series problems? ‚Äç‚≠êÔ∏è**,,medium,mixed,,github,,2025-11-21T13:05:31.730334
[1. Why do you use feature selection?](#1-why-do-you-use-feature-selection),,medium,mixed,feature_engineering,github,,2025-11-21T13:05:33.131317
[Filter Methods](#filter-methods),,medium,mixed,,github,,2025-11-21T13:05:33.131351
[Embedded Methods](#embedded-methods),,medium,mixed,,github,,2025-11-21T13:05:33.131373
[Overfitting](#overfitting),,medium,mixed,,github,,2025-11-21T13:05:33.131413
[2. Explain what regularization is and why it is useful.](#2-explain-what-regularization-is-and-why-it-is-useful),,medium,mixed,,github,,2025-11-21T13:05:33.131439
[3. What‚Äôs the difference between L1 and L2 regularization?](#3-whats-the-difference-between-l1-and-l2-regularization),,medium,mixed,,github,,2025-11-21T13:05:33.131472
[4. How would you validate a model you created to generate a predictive model of a quantitative outcome variable using multiple regression?](#4-how-would-you-validate-a-model-you-created-to-generate-a-predictive-model-of-a-quantitative-outcome-variable-using-multiple-regression),,medium,ml,regression,github,,2025-11-21T13:05:33.131508
[5. Explain what precision and recall are. How do they relate to the ROC curve?](#5-explain-what-precision-and-recall-are-how-do-they-relate-to-the-roc-curve),,medium,mixed,,github,,2025-11-21T13:05:33.131540
"[6. Is it better to have too many false positives, or too many false negatives?](#6-is-it-better-to-have-too-many-false-positives--or-too-many-false-negatives)",,medium,mixed,,github,,2025-11-21T13:05:33.131570
[7. How do you deal with unbalanced binary classification?](#7-how-do-you-deal-with-unbalanced-binary-classification),,medium,ml,classification,github,,2025-11-21T13:05:33.131594
[8. What is statistical power?](#8-what-is-statistical-power),,medium,mixed,,github,,2025-11-21T13:05:33.131615
"[9. What are bias and variance, and what are their relation to modeling data?](#9-what-are-bias-and-variance--and-what-are-their-relation-to-modeling-data)",,medium,stats,statistics,github,,2025-11-21T13:05:33.131640
[10. What if the classes are imbalanced? What if there are more than 2 groups?](#10-what-if-the-classes-are-imbalanced-what-if-there-are-more-than-2-groups),,medium,mixed,,github,,2025-11-21T13:05:33.131687
[11. What are some ways I can make my model more robust to outliers?](#11-what-are-some-ways-i-can-make-my-model-more-robust-to-outliers),,medium,ml,,github,,2025-11-21T13:05:33.131711
"[12. In unsupervised learning, if a ground truth about a dataset is unknown, how can we determine the most useful number of clusters to be?](#12-in-unsupervised-learning--if-a-ground-truth-about-a-dataset-is-unknown--how-can-we-determine-the-most-useful-number-of-clusters-to-be)",,medium,mixed,,github,,2025-11-21T13:05:33.131756
[13. Define variance](#13-define-variance),,medium,stats,statistics,github,,2025-11-21T13:05:33.131772
[14. Expected value](#14-expected-value),,medium,mixed,,github,,2025-11-21T13:05:33.131791
[15. Describe the differences between and use cases for box plots and histograms](#15-describe-the-differences-between-and-use-cases-for-box-plots-and-histograms),,medium,behavioral,,github,,2025-11-21T13:05:33.131822
[16. How would you find an anomaly in a distribution?](#16-how-would-you-find-an-anomaly-in-a-distribution),,medium,stats,,github,,2025-11-21T13:05:33.131842
[Statistical methods](#statistical-methods),,medium,mixed,,github,,2025-11-21T13:05:33.131862
[Metric methods](#metric-methods),,medium,case,,github,,2025-11-21T13:05:33.131882
[17. How do you deal with outliers in your data?](#17-how-do-you-deal-with-outliers-in-your-data),,medium,mixed,,github,,2025-11-21T13:05:33.131905
[18. How do you deal with sparse data?](#18-how-do-you-deal-with-sparse-data),,medium,mixed,,github,,2025-11-21T13:05:33.131927
[19. Big Data Engineer Can you explain what REST is?](#19-big-data-engineer-can-you-explain-what-rest-is),,medium,mixed,,github,,2025-11-21T13:05:33.131953
[20. Logistic regression](#20-logistic-regression),,medium,ml,regression,github,,2025-11-21T13:05:33.131971
[21. What is the effect on the coefficients of logistic regression if two predictors are highly correlated? What are the confidence intervals of the coefficients?](#21-what-is-the-effect-on-the-coefficients-of-logistic-regression-if-two-predictors-are-highly-correlated-what-are-the-confidence-intervals-of-the-coefficients),,medium,ml,regression,github,,2025-11-21T13:05:33.132009
[22. What‚Äôs the difference between Gaussian Mixture Model and K-Means?](#22-whats-the-difference-between-gaussian-mixture-model-and-k-means),,medium,ml,clustering,github,,2025-11-21T13:05:33.132038
[23. Describe how Gradient Boosting works.](#23-describe-how-gradient-boosting-works),,medium,behavioral,ensemble,github,,2025-11-21T13:05:33.132060
[AdaBoost the First Boosting Algorithm](#adaboost-the-first-boosting-algorithm),,medium,coding,ensemble,github,,2025-11-21T13:05:33.132076
[Loss Function](#loss-function),,medium,mixed,,github,,2025-11-21T13:05:33.132095
[Weak Learner](#weak-learner),,medium,mixed,,github,,2025-11-21T13:05:33.132113
[Additive Model](#additive-model),,medium,ml,,github,,2025-11-21T13:05:33.132129
[Improvements to Basic Gradient Boosting](#improvements-to-basic-gradient-boosting),,medium,mixed,ensemble,github,,2025-11-21T13:05:33.132152
[Tree Constraints](#tree-constraints),,medium,mixed,,github,,2025-11-21T13:05:33.132171
[Weighted Updates](#weighted-updates),,medium,mixed,,github,,2025-11-21T13:05:33.132189
[Stochastic Gradient Boosting](#stochastic-gradient-boosting),,medium,mixed,ensemble,github,,2025-11-21T13:05:33.132211
[Penalized Gradient Boosting](#penalized-gradient-boosting),,medium,mixed,ensemble,github,,2025-11-21T13:05:33.132232
[24. Difference between AdaBoost and XGBoost](#24-difference-between-AdaBoost-and-XGBoost),,medium,mixed,,github,,2025-11-21T13:05:33.132256
[25. Data Mining Describe the decision tree model.](#25-data-mining-describe-the-decision-tree-model),,medium,ml,,github,,2025-11-21T13:05:33.132277
[26. Notes from Coursera Deep Learning courses by Andrew Ng](#26-notes-from-coursera-deep-learning-courses-by-andrew-ng),,medium,ml,neural_network,github,,2025-11-21T13:05:33.132301
[27. What is a neural network?](#27-what-is-a-neural-network),,medium,ml,neural_network,github,,2025-11-21T13:05:33.132318
[28. How do you deal with sparse data?](#28-how-do-you-deal-with-sparse-data),,medium,mixed,,github,,2025-11-21T13:05:33.132339
[29. RNN and LSTM](#29-rnn-and-lstm),,medium,mixed,neural_network,github,,2025-11-21T13:05:33.132357
[30. Pseudo Labeling](#30-pseudo-labeling),,medium,mixed,,github,,2025-11-21T13:05:33.132376
[31. Knowledge Distillation](#31-knowledge-distillation),,medium,mixed,,github,,2025-11-21T13:05:33.132397
[32. What is an inductive bias?](#32-what-is-an-inductive-bias),,medium,mixed,,github,,2025-11-21T13:05:33.132418
[33. What is a confidence interval in layman's terms?](#33-confidence-interval-in-layman's-terms),,medium,mixed,,github,,2025-11-21T13:05:33.132443
## 1. Why do you use feature selection?,,medium,mixed,feature_engineering,github,,2025-11-21T13:05:33.132462
## 3. What‚Äôs the difference between L1 and L2 regularization?,,medium,mixed,,github,,2025-11-21T13:05:33.132487
## 4. How would you validate a model you created to generate a predictive model of a quantitative outcome variable using multiple regression?,,medium,ml,regression,github,,2025-11-21T13:05:33.132510
"If the values predicted by the model are far outside of the response variable range, this would immediately indicate poor estimation or model inaccuracy.",,medium,ml,,github,,2025-11-21T13:05:33.132535
"If the values seem to be reasonable, examine the parameters; any of the following would indicate poor estimation or multi-collinearity: opposite signs of expectations, unusually large or small values, or observed inconsistency when the model is fed new data.",,medium,ml,,github,,2025-11-21T13:05:33.132569
"Use the model for prediction by feeding it new data, and use the [coefficient of determination](https://en.wikipedia.org/wiki/Coefficient_of_determination) (R squared) as a model validity measure.",,medium,ml,,github,,2025-11-21T13:05:33.132597
"Use data splitting to form a separate dataset for estimating model parameters, and another for validating predictions.",,medium,ml,,github,,2025-11-21T13:05:33.132619
"Use [jackknife resampling](https://en.wikipedia.org/wiki/Jackknife_resampling) if the dataset contains a small number of instances, and measure validity with R squared and [mean squared error](https://en.wikipedia.org/wiki/Mean_squared_error) (MSE).",,medium,mixed,,github,,2025-11-21T13:05:33.132658
## 5. Explain what precision and recall are. How do they relate to the ROC curve?,,medium,mixed,,github,,2025-11-21T13:05:33.132681
What percent of your predictions were correct?,,medium,mixed,,github,,2025-11-21T13:05:33.132721
What percent of the positive cases did you catch?,,medium,mixed,,github,,2025-11-21T13:05:33.132741
What percent of positive predictions were correct?,,medium,mixed,,github,,2025-11-21T13:05:33.132761
"Sensitivity also known as the True Positive rate or Recall is calculated as,",,medium,mixed,,github,,2025-11-21T13:05:33.132783
"Specificity, also known as True Negative Rate is calculated as, `Specificity = TN / (TN + FP)`. Since the formula does not contain FN and TP, Specificity may give you a biased result, especially for imbalanced classes.",,medium,mixed,,github,,2025-11-21T13:05:33.132819
"## 6. Is it better to have too many false positives, or too many false negatives?",,medium,mixed,,github,,2025-11-21T13:05:33.132842
## 7. How do you deal with unbalanced binary classification?,,medium,ml,classification,github,,2025-11-21T13:05:33.132860
Can You Collect More Data?</br>,,medium,mixed,,github,,2025-11-21T13:05:33.132878
[Confusion Matrix](https://en.wikipedia.org/wiki/Confusion_matrix): A breakdown of predictions into a table showing correct predictions (the diagonal) and the types of incorrect predictions made (what classes incorrect predictions were assigned).,,medium,mixed,,github,,2025-11-21T13:05:33.132917
"[Precision](https://en.wikipedia.org/wiki/Information_retrieval#Precision): A measure of a classifiers exactness. Precision is the number of True Positives divided by the number of True Positives and False Positives. Put another way, it is the number of positive predictions divided by the total number of positive class values predicted. It is also called the [Positive Predictive Value (PPV)](https://en.wikipedia.org/wiki/Positive_and_negative_predictive_values). Precision can be thought of as a measure of a classifiers exactness. A low precision can also indicate a large number of False Positives.",,medium,mixed,classification,github,,2025-11-21T13:05:33.132990
[Recall](https://en.wikipedia.org/wiki/Information_retrieval#Recall): A measure of a classifiers completeness. Recall is the number of True Positives divided by the number of True Positives and the number of False Negatives. Put another way it is the number of positive predictions divided by the number of positive class values in the test data. It is also called Sensitivity or the True Positive Rate. Recall can be thought of as a measure of a classifiers completeness. A low recall indicates many False Negatives.,,medium,mixed,classification|statistics,github,,2025-11-21T13:05:33.133053
[F1 Score (or F-score)](https://en.wikipedia.org/wiki/F1_score): A weighted average of precision and recall.,,medium,mixed,,github,,2025-11-21T13:05:33.133079
Kappa (or [Cohen‚Äôs kappa](https://en.wikipedia.org/wiki/Cohen%27s_kappa)): Classification accuracy normalized by the imbalance of the classes in the data.,,medium,ml,classification,github,,2025-11-21T13:05:33.133108
You can add copies of instances from the under-represented class called over-sampling (or more formally sampling with replacement),,medium,mixed,,github,,2025-11-21T13:05:33.133136
"You can delete instances from the over-represented class, called under-sampling.",,medium,mixed,,github,,2025-11-21T13:05:33.133160
## 8. What is statistical power?,,medium,mixed,,github,,2025-11-21T13:05:33.133178
"## 9. What are bias and variance, and what are their relation to modeling data?",,medium,stats,statistics,github,,2025-11-21T13:05:33.133196
(Generalized) linear models can be [regularized](#2-explain-what-regularization-is-and-why-it-is-useful) to decrease their variance at the cost of increasing their bias.,,medium,stats,statistics,github,,2025-11-21T13:05:33.133222
"In artificial neural networks, the variance increases and the bias decreases with the number of hidden units. Like in GLMs, regularization is typically applied.",,medium,stats,neural_network|statistics,github,,2025-11-21T13:05:33.133245
"In k-nearest neighbor models, a high value of k leads to high bias and low variance (see below).",,medium,stats,statistics,github,,2025-11-21T13:05:33.133265
"In Instance-based learning, regularization can be achieved varying the mixture of prototypes and exemplars.[",,medium,mixed,,github,,2025-11-21T13:05:33.133291
"In decision trees, the depth of the tree determines the variance. Decision trees are commonly pruned to control variance.",,medium,stats,statistics,github,,2025-11-21T13:05:33.133313
## 10. What if the classes are imbalanced? What if there are more than 2 groups?,,medium,mixed,,github,,2025-11-21T13:05:33.133335
True Positive Rate (TPR) or Recall or Sensitivity = TP / (TP + FN),,medium,mixed,,github,,2025-11-21T13:05:33.133356
[Precision](https://github.com/iamtodor/data-science-interview-questions-and-answers#5-explain-what-precision-and-recall-are-how-do-they-relate-to-the-roc-curve) = TP / (TP + FP),,medium,mixed,,github,,2025-11-21T13:05:33.133388
False Positive Rate(FPR) or False Alarm Rate = 1 - Specificity = 1 - (TN / (TN + FP)),,medium,mixed,,github,,2025-11-21T13:05:33.133411
Accuracy = (TP + TN) / (TP + TN + FP + FN),,medium,mixed,,github,,2025-11-21T13:05:33.133428
Error Rate = 1 ‚Äì Accuracy,,medium,mixed,,github,,2025-11-21T13:05:33.133448
F-measure = 2 / ((1 / Precision) + (1 / Recall)) = 2 * (precision * recall) / (precision + recall),,medium,mixed,,github,,2025-11-21T13:05:33.133473
ROC (Receiver Operating Characteristics) = plot of FPR vs TPR,,medium,mixed,,github,,2025-11-21T13:05:33.133494
AUC (Area Under the [ROC] Curve),,medium,mixed,,github,,2025-11-21T13:05:33.133511
## 11. What are some ways I can make my model more robust to outliers?,,medium,ml,,github,,2025-11-21T13:05:33.133530
"## 12. In unsupervised learning, if a ground truth about a dataset is unknown, how can we determine the most useful number of clusters to be?",,medium,mixed,,github,,2025-11-21T13:05:33.133558
## 16. How would you find an anomaly in a distribution?,,medium,stats,,github,,2025-11-21T13:05:33.133574
## 17. How do you deal with outliers in your data?,,medium,mixed,,github,,2025-11-21T13:05:33.133618
## 18. How do you deal with sparse data?,,medium,mixed,,github,,2025-11-21T13:05:33.133633
## 19. Big Data Engineer Can you explain what REST is?,,medium,mixed,,github,,2025-11-21T13:05:33.133650
"In many ways, the World Wide Web itself, based on HTTP, can be viewed as a REST-based architecture.",,medium,mixed,,github,,2025-11-21T13:05:33.133671
"Despite being simple, REST is fully-featured; there's basically nothing you can do in Web Services that can't be done with a RESTful architecture.",,medium,mixed,feature_engineering,github,,2025-11-21T13:05:33.133695
## 21. What is the effect on the coefficients of logistic regression if two predictors are highly correlated? What are the confidence intervals of the coefficients?,,medium,ml,regression,github,,2025-11-21T13:05:33.133717
Ratings estimates remain unbiased.,,medium,case,,github,,2025-11-21T13:05:33.133731
Standard coefficient errors increase.,,medium,mixed,,github,,2025-11-21T13:05:33.133747
The calculated t-statistics are underestimated.,,medium,stats,statistics,github,,2025-11-21T13:05:33.133760
Estimates become very sensitive to changes in specifications and changes in individual observations.,,medium,case,,github,,2025-11-21T13:05:33.133778
"The overall quality of the equation, as well as estimates of variables not related to multicollinearity, remain unaffected.",,medium,case,,github,,2025-11-21T13:05:33.133799
"The closer multicollinearity to perfect (strict), the more serious its consequences.",,medium,mixed,,github,,2025-11-21T13:05:33.133819
## 22. What‚Äôs the difference between Gaussian Mixture Model and K-Means?,,medium,ml,clustering,github,,2025-11-21T13:05:33.133852
"What if we are uncertain? What if we think, well, I can't be sure, but there is 70% chance it belongs to the red cluster, but also 10% chance its in green, 20% chance it might be blue. That's a soft assignment. The Mixture of Gaussian model helps us to express this uncertainty. It starts with some prior belief about how certain we are about each point's cluster assignments. As it goes on, it revises those beliefs. But it incorporates the degree of uncertainty we have about our assignment.",,medium,ml,,github,,2025-11-21T13:05:33.133895
Hard assign a data point to one particular cluster on convergence.,,medium,mixed,,github,,2025-11-21T13:05:33.133913
It makes use of the L2 norm when optimizing (Min {Theta} L2 norm point and its centroid coordinates).,,medium,mixed,,github,,2025-11-21T13:05:33.133934
Soft assigns a point to clusters (so it give a probability of any point belonging to any centroid).,,medium,stats,probability,github,,2025-11-21T13:05:33.133950
"It doesn't depend on the L2 norm, but is based on the Expectation, i.e., the probability of the point belonging to a particular cluster. This makes K-means biased towards spherical clusters.",,medium,stats,clustering|probability,github,,2025-11-21T13:05:33.133971
"To get a bit closer to the destination, we train a tree to reconstruct the difference between the target function and the current predictions of an ensemble, which is called the **residual**: R(x)=f(x)‚àíD(x). Did you notice? If decision tree completely reconstructs R(x), the whole ensemble gives predictions without errors (after adding the newly-trained tree to the ensemble)! That said, in practice this never happens, so we instead continue the iterative process of ensemble building.",,medium,mixed,ensemble,github,,2025-11-21T13:05:33.134029
"Number of trees, generally adding more trees to the model can be very slow to overfit. The advice is to keep adding trees until no further improvement is observed.",,medium,ml,,github,,2025-11-21T13:05:33.134066
"Tree depth, deeper trees are more complex trees and shorter trees are preferred. Generally, better results are seen with 4-8 levels.",,medium,mixed,,github,,2025-11-21T13:05:33.134090
"Number of nodes or number of leaves, like depth, this can constrain the size of the tree, but is not constrained to a symmetrical structure if other constraints are used.",,medium,case,,github,,2025-11-21T13:05:33.134124
Number of observations per split imposes a minimum constraint on the amount of training data at a training node before a split can be considered,,medium,mixed,,github,,2025-11-21T13:05:33.134149
Minimum improvement to loss is a constraint on the improvement of any split added to a tree.,,medium,mixed,,github,,2025-11-21T13:05:33.134169
Subsample rows before creating each tree.,,medium,mixed,,github,,2025-11-21T13:05:33.134185
Subsample columns before creating each tree,,medium,mixed,,github,,2025-11-21T13:05:33.134201
Subsample columns before considering each split.,,medium,mixed,,github,,2025-11-21T13:05:33.134218
L1 regularization of weights.,,medium,mixed,,github,,2025-11-21T13:05:33.134232
L2 regularization of weights.,,medium,mixed,,github,,2025-11-21T13:05:33.134245
https://habr.com/company/ods/blog/327250/,,medium,mixed,,github,,2025-11-21T13:05:33.134260
https://alexanderdyakonov.files.wordpress.com/2017/06/book_boosting_pdf.pdf,,medium,mixed,ensemble,github,,2025-11-21T13:05:33.134278
It does not require any domain knowledge.,,medium,mixed,,github,,2025-11-21T13:05:33.134294
It is easy to comprehend.,,medium,mixed,,github,,2025-11-21T13:05:33.134309
The learning and classification steps of a decision tree are simple and fast.,,medium,ml,classification,github,,2025-11-21T13:05:33.134326
Pre-pruning ‚àí The tree is pruned by halting its construction early.,,medium,mixed,,github,,2025-11-21T13:05:33.134347
Post-pruning - This approach removes a sub-tree from a fully grown tree.,,medium,mixed,,github,,2025-11-21T13:05:33.134366
## 27. What is a neural network?,,medium,ml,neural_network,github,,2025-11-21T13:05:33.134378
## 28. How do you deal with sparse data?,,medium,mixed,,github,,2025-11-21T13:05:33.134393
"[Understanding LSTM Networks, Chris Olah's LSTM post](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)",,medium,mixed,neural_network,github,,2025-11-21T13:05:33.134415
"[Exploring LSTMs, Edwin Chen's LSTM post](http://blog.echen.me/2017/05/30/exploring-lstms/)",,medium,mixed,neural_network,github,,2025-11-21T13:05:33.134435
"[The Unreasonable Effectiveness of Recurrent Neural Networks, Andrej Karpathy's blog post](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)",,medium,ml,neural_network,github,,2025-11-21T13:05:33.134455
"[CS231n Lecture 10 - Recurrent Neural Networks, Image Captioning, LSTM, Andrej Karpathy's lecture](https://www.youtube.com/watch?v=iX5V1WpxxkY)",,medium,ml,neural_network|computer_vision,github,,2025-11-21T13:05:33.134474
[Jay Alammar's The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/) the guy generally focuses on visualizing different ML concepts,,medium,mixed,,github,,2025-11-21T13:05:33.134500
## 32. What is an inductive bias?,,medium,mixed,,github,,2025-11-21T13:05:33.134515
## 33. What is a confidence interval in layman's terms?,,medium,mixed,,github,,2025-11-21T13:05:33.134532
Imagine during the interview that you get asked ‚ÄúWalk me through how you would A/B test this new feature?‚Äù. This framework will help you pass these types of questions.,,medium,mixed,statistics|feature_engineering,reddit-datascience,,2025-11-21T13:05:34.818602
"**Phase 1: Set the context for the experiment. Why do we want to AB test, what is our goal, what do we want to measure?**",,medium,mixed,statistics|nlp,reddit-datascience,,2025-11-21T13:05:34.818642
1. The first step is to clarify the purpose and value of the experiment with the interviewer. Is it even worth running an A/B test? Interviewers want to know that the candidate can tie experiments to business goals.,,medium,case,statistics,reddit-datascience,,2025-11-21T13:05:34.818679
"2. Specify what exactly is the treatment, and what hypothesis are we testing? Too often I see candidates fail to specify what the treatment is, and what is the hypothesis that they want to test. It‚Äôs important to spell this out for your interviewer.",,medium,stats,statistics,reddit-datascience,,2025-11-21T13:05:34.818714
**Phase 2: How do we design the experiment to measure what we want to measure?**,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.818738
"* As a simple example, let‚Äôs say you want to test a treatment that changes the color of the checkout button on an ecommerce website from blue to green. How would you randomize this? You could randomize at the user level and say that every person that visits your website will be randomized into the treatment or control group. Another way would be to randomize at the session level, or even at the checkout page level.",,medium,mixed,statistics,reddit-datascience,,2025-11-21T13:05:34.818798
"2. Next, you need to determine which statistical test(s) you will use to analyze the results. Is a simple t-test sufficient, or do you need quasi-experimental techniques like difference in differences? Do you require heteroskedastic robust standard errors or clustered standard errors?",,medium,mixed,statistics,reddit-datascience,,2025-11-21T13:05:34.818840
"* Are you testing multiple metrics? If so, account for that in your analysis. A really common academic answer is the Bonferonni correction. I've never seen anyone use it in real life though, because it is too conservative. A more common way is to control the False Discovery Rate. You can google this. Alternatively, the book [Trustworthy Online Controlled Experiments](https://amzn.to/4dzXyZP) by Ron Kohavi discusses how to do this (note: this is an affiliate link).",,medium,case,statistics,reddit-datascience,,2025-11-21T13:05:34.818902
* Do any stakeholders need to be informed about the experiment?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.818924
* Are there any novelty effects or change aversion that could impact interpretation?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.818947
"6. You might be thinking ‚Äúwhy would I need to use difference-in-difference in an AB test‚Äù? In my experience, this is common when doing a geography based randomization on a relatively small sample size. Let‚Äôs say that you want to randomize by city in the state of California. It‚Äôs likely that even though you are randomizing which cities are in the treatment and control groups, that your two groups will have pre-existing biases. A common solution is to use difference-in-difference. I‚Äôm not saying this is right or wrong, but it‚Äôs a common solution that I have seen in tech companies.",,medium,mixed,statistics,reddit-datascience,,2025-11-21T13:05:34.819023
**Phase 3:** **The experiment is over. Now what?**,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.819044
"1. After you ‚Äúrun‚Äù the A/B test, you now have some data. Consider what recommendations you can make from them. What insights can you derive to take actionable steps for the business? Speaking to this will earn you brownie points with the interviewer.",,medium,case,statistics,reddit-datascience,,2025-11-21T13:05:34.819084
"* For example, can you think of some useful ways to segment your experiment data to determine whether there were heterogeneous treatment effects?",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.819114
* Let‚Äôs say that you are mid-way through running your A/B test and the performance starts to get worse. It had a strong start but now your success metric is degrading. Why do you think this could be?,,medium,case,statistics,reddit-datascience,,2025-11-21T13:05:34.819149
"* Let‚Äôs say that your AB test is concluded and your chosen p-value cutoff is 0.05. However, your success metric has a p-value of 0.06. What do you do?",,medium,case,statistics,reddit-datascience,,2025-11-21T13:05:34.819179
"* Your success metric was stat sig positive, but one of your guardrail metrics was harmed. What do you do?",,medium,case,,reddit-datascience,,2025-11-21T13:05:34.819202
* Your success metric ended up being stat sig negative. How would you diagnose this?,,medium,case,,reddit-datascience,,2025-11-21T13:05:34.819224
"Question I got during an interview. Answers to select were 200, 600, &amp; 1200. Am I looking at this completely wrong? Seems to me the bars represent unique visitors during each hour, making the total ~2000. How would I figure out the overlapping visitors during that time frame w/ this info?",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.819271
What's the most interesting Data Science interview question you've encountered?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.819302
What's the most¬†interesting¬†Data Science Interview question you've been asked?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.819325
How about you ‚Äì what's the most interesting Data Science interview question you've encountered? Might include these in the next edition of [Ace the Data Science Interview](https://www.acethedatascienceinterview.com/) if they're interesting enough!,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.819370
Is asking candidate (2 years experience) to code neural network from scratch on a live interview call a reasonable interview question?,,medium,coding,neural_network,reddit-datascience,,2025-11-21T13:05:34.819393
"Is this a reasonable interview coding question? ^ I was asked to code a perceptron from scratch with plain python, including backpropagation, calculate gradients and loss and update weights. I know it's a fun exercise to code a perceptron from scratch and almost all of us have done this at some point in our lives probably.",,medium,coding,python,reddit-datascience,,2025-11-21T13:05:34.819422
"&gt;"" What if you run another test for another problem, alpha = .05 and you get a p-value = .04999 and subsequently you run it once more and get a p-value of .05001?""",,medium,mixed,statistics,reddit-datascience,,2025-11-21T13:05:34.819480
"* u/Cheaptat \- Possible follow-up questions: how expensive would the change this test is designed to measure be? Was the average impact positive for the business, even if questionably measurable? What would the potential drawback of implementing it be? They may well have wanted you to state some assumptions (reasonable ones, perhaps a few key archetypes) and explain what you‚Äôd have done.",,medium,coding,statistics,reddit-datascience,,2025-11-21T13:05:34.819520
"* u/oldmangandalfstyle \- understanding to be that p-values are useless outside the context of the coefficient/difference. P-values asymptotically approach zero, so in large samples they are worthless. And also the difference between 0.049 and 0.051 is literally nothing meaningful to me outside the context of the effect size. It‚Äôs critical to understand that a p-value is strictly a conditional probability that the null is true given the observed relationship. So if it‚Äôs just a probability, and not a hard stop heuristic, how does that change your perspective of its utility?",,medium,stats,probability|nlp,reddit-datascience,,2025-11-21T13:05:34.819577
Interviewer: Given you run an A/B test and the alpha is .05 and you get a p-value = .01 what do you do (in regards to accepting/rejecting h0 )?,,medium,mixed,statistics,reddit-datascience,,2025-11-21T13:05:34.819605
"Interviewer: Ok... what if you run another test for another problem, alpha = .05 and you get a p-value = .04999 and subsequently you run it once more and get a p-value of .05001 ?",,medium,mixed,statistics,reddit-datascience,,2025-11-21T13:05:34.819634
Interviewer: What else could it be?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.819653
"Me: I would really need to understand what went into the test, what is the goal, are we picking the proper variables to test, are we addressing possible confounders? Did we choose the appropriate risk (alpha/beta) , is our sample size large enough, did we sample correctly (simple,random,independent), was our test run long enough?",,medium,mixed,statistics,reddit-datascience,,2025-11-21T13:05:34.819697
Are my interview questions unreasonable? Or are my candidates just bad?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.819728
"1. If I have a categorical feature, we can encoding it with a single column of numbers (label-encoding) or with multiple 1/0 columns (one-hot-encoding)? Why might we *not* want to label-encode? ([Reference](https://towardsdatascience.com/categorical-encoding-using-label-encoding-and-one-hot-encoder-911ef77fb5bd))",,medium,coding,feature_engineering,reddit-datascience,,2025-11-21T13:05:34.819757
2. If they've used XGBoost on the job before - Why might the default feature-importance plot in XGBoost - counting the number of times a variable was used to make a split - be misleading? What are some other options you have? ([Reference](https://towardsdatascience.com/be-careful-when-interpreting-your-features-importance-in-xgboost-6e16132588e7)),,medium,mixed,feature_engineering,reddit-datascience,,2025-11-21T13:05:34.819802
"3. If we're talking about classification models - Why do we use logloss as the objective function for binary classification models? What does it penalize? Why is it ""different"" than just maximizing accuracy? ([Reference](https://stats.stackexchange.com/questions/180116/when-is-log-loss-metric-appropriate-for-evaluating-performance-of-a-classifier))",,medium,ml,classification,reddit-datascience,,2025-11-21T13:05:34.819840
"4. Assume we're presenting our model results to management. How can we show/visualize the improvement of one model over another, beyond just comparing their RMSE or accuracy? ([One possible answer](https://www.listendata.com/2014/08/excel-template-gain-and-lift-charts.html))",,medium,ml,,reddit-datascience,,2025-11-21T13:05:34.819874
"I have had candidates be able to answer all of them easily and concisely. But most of the time, I get either a wrong answer or some long-winded non-answer. In fact I just interviewed a candidate whose resume was stacked but couldn't answer any (and even other easier ones). So this got me wondering, are questions like these unreasonable? Or is it just normal to have to filter out 8 out of 10 candidates it seems? If anyone here does interviews, do you have a similar experience?",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.819934
1. How would you go about predicting hotel prices for a company like [Booking.com](https://Booking.com)? - I previously worked at a similar company as a business analyst and hence the question. I was able to answer this based on the work I had done there.,,medium,case,,reddit-datascience,,2025-11-21T13:05:34.819985
2. Let's say you have a categorical column with 500 categories. How would you tackle this? - I answered that we can use Catboost as it uses the catboost target encoder which would help convert the categorical values into numerical values rather than going for one hot encoding. He then mentioned that he wants to use linear regression so I said that we can use target encoding methods like James Stein encoder or Catboost encoder(preferred as it tackles target leakage). Was my answer right or is there some other way because he didn't seem 100% convinced with it?,,medium,coding,regression,reddit-datascience,,2025-11-21T13:05:34.820021
3. How would you check the weight of each feature in a decision tree? - I said that we can look at the feature importance of each feature. He then asked if a feature importance of 100 means the feature's influence on the target is 100? To which I replied that you can see the SHAP values to understand the influence of a feature on the target but honestly I haven't researched enough on it to comment further.,,medium,mixed,feature_engineering,reddit-datascience,,2025-11-21T13:05:34.820063
4. Can I use K Means with categorical data? - You can use one hot encoding to convert categorical data to numerical but using K Means with Euclidian distance on binary columns does not make sense so I would use K Modes rather than K Means for categorical data,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.820097
5. How do I choose the number of clusters for K Means? - use elbow method or silhouette score and I explained both the methods,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.820119
6. Let's say I use silhouette analysis on a customer segmentation exercise and get K=30 as optimal number of clusters. I can't show 30 clusters to the business so what do I do now? - I said that generally for customer segmentation we would need business input as well so what is a practical number of segments according to the business? He replied 5-10 so I said that well out of the 5-10 clusters whichever has the highest silhouette score should be chosen. But I don't know if this is the right answer?,,medium,case,,reddit-datascience,,2025-11-21T13:05:34.820167
7. Difference b/w K Means and K modes? - I just said that for categorical data we use K Modes because finding the mode of a particular category is more accurate and makes more sense rather than converting the category to binary values and using a distance algo like K Means.,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.820201
"8. How would you perform customer segmentation on OTT platforms? - I panicked on this one honestly and said age, gender, nationality and probably genre of shows, do they watch shows completely, how long have they been a member on the OTT platform (Yes ik some of these don't make sense but like i said i PANCIKED)",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.820238
9. Do you think the above mentioned factors are a good representative of the customer lifetime value? - Uhh no idea what customer life time value means so I just winged this one,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.820263
10. Can you have more than one independent variable in ARIMA? - I answered yes cause I do vaguely remember coming across this but I am not 100% sure.,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.820287
11. What is the difference b/w ARIMA and ARIMAX? - ARIMAX is ARIMA but also has exogenous variables which help identify surges like holidays.,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.820310
12. Would you use ARIMA or Prophet for time series? - I read an article that says a properly tuned SARIMA would outperform Prophet so i answered the same,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.820334
"13. How would you tune ARIMA? - by finding the best parameter values for p,d,q",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.820352
"14. What are p,d,q in ARIMA? - (I forgot what they represent but I tried to answer from whatever I could recall ) p=no. of previous lags to consider, q= i forgot, d = difference(?)",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.820395
"15. What exactly is ""d""? - I said that it represents the seasonality pattern but I now realize that seasonality is in SARIMA and not ARIMA. (ugh)",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.820419
"16. Can you pass non - stationary data to ARIMA? - No, because the assumption of TS is that data is stationary with constant mean and variance as it will assume the same patterns for future values as well",,medium,stats,statistics,reddit-datascience,,2025-11-21T13:05:34.820443
17. How do we check if data is stationary? - By plotting it first but more accurate way is to use Dickey Fuller test to confirm it,,medium,mixed,statistics,reddit-datascience,,2025-11-21T13:05:34.820465
"18. How do I choose which 10 new hotels to onboard on [Booking.com](https://Booking.com)? - I said that we can look at the number of bookings, location, accessibility( metro, bus), is it near a tourist spot, reviews, stars.",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.820495
19. What if my model has recommended that all the 10 new hotels that we should onboard should be from the same area X? How do I add a constraint to fix this? - I don't even know what topic this question is from but I said maybe you can modify the cost function by adding a variable which will penalize the cost function based on the number of hotels it suggests that belong to the same area or maybe we can add constraints to the cost function,,medium,ml,,reddit-datascience,,2025-11-21T13:05:34.820535
20. If I add constraints to the cost function then it becomes a non linear optimization problem so how would you use linear programming to solve it? - I had no idea lol,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.820561
21. What is the difference b/w segmentation and clustering? - I answered that segmentation is a use case of clustering but apparently the interviewer said that clustering is an unsupervised learning algorithm while segmentation is a supervised learning algorithm.,,medium,coding,clustering,reddit-datascience,,2025-11-21T13:05:34.820583
22. Have you created a data pipeline before? - Nope,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.820599
"So what do I look for? We are not a tech or AI company, we need people with a solid understanding of classical statistics, not just ML, as that will be necessary a lot of times. What I want to know is whether the applicant has a good grasp and intuition about statistics. We are a team of people, it is likely someone will know which algorithms and methods might be applicable to your problem, so you don't need to know all the algorithms (you would read up on them anyway), but you need the intuition or training to know that there is a problem (see e.g. my example on multiple testing below). In addition, I personally think that our value doesn't lie in calling fit(X, y), but being able to figure out if the model coming from it is appropriate and useful.",,medium,coding,statistics,reddit-datascience,,2025-11-21T13:05:34.820652
"**My Performance:** I correctly characterized the problem as a Binomial(N,p) problem, where p is the probability that a single particle survives till time T. I did not get a closed form solution (I asked about how I did at the end and the interviewer mentioned that it would have been nice to get one). The code I wrote was correct, and I think fairly efficient? I got a little bit hung up on trying to estimate variance, but ended up with a bootstrap approach. We ran out of time before I could entirely solve the last variation, but generally described an approach. I felt that my interviewer and I had decent rapport, and it seemed like I did decently.",,medium,coding,probability|statistics,reddit-datascience,,2025-11-21T13:05:34.820697
"**Question:** Overall, I'd like to know what I did wrong, though of course that's probably not possible without someone sitting in. I did talk throughout, and I have struggled with clear and concise verbal communication in the past. Was the expectation that I would solve all parts of the questions completely? What aspects of these interviews do interviewers tend to look for?",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.820739
"Was interviewing for a data scientist position, one of the team members asked ""Given your ideal job, which job tasks would not be on that list?"" Interested what you all think",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.820766
What are some interview questions that have caught you off-gaurd?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.820787
"Having an interview for the role of a data scientist tomorrow since after I passed their technical test, I have an idea of what to expect but I want to make sure I dont get caught off-gaurd, so what are some questions in your interviews that caught you off-gaurd and made you wish that you had prepared more?",,medium,mixed,statistics,reddit-datascience,,2025-11-21T13:05:34.820821
Has anyone had any experiences with such an interview?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.820838
1. Why would we want to use a median instead of a mean?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.820859
2. Then why don't we just always use a median instead of a mean?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.820876
Would love to hear some perspectives. Is this a common experience?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.820903
What are the worst questions you‚Äôve ever been asked in an interview?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.820929
1. ‚ÄúWhat is the hardest thing you‚Äôve ever had to do?‚Äù,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.820948
"2. ‚ÄúI‚Äôm not searching for a specific answer, but what is the second hardest thing you‚Äôve ever had to do?‚Äù",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.820971
How would you approach this interview question?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.820994
1. How would you pick 1-2 metrics from this column to sort these listings? (To build a quick formula for ranking these listings),,medium,case,,reddit-datascience,,2025-11-21T13:05:34.821015
2. What are some disadvantages of this approach?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.821031
3. How would you predict that the rankings will change in 6 months from today (assuming I implemented my strategy)?,,medium,coding,,reddit-datascience,,2025-11-21T13:05:34.821047
"1. I would pick the review avg and count. normalize the count, like minmax so that it is in the same range as the review avg, and weight the review count and review avg by a alpha and (1 - alpha) for example. Should have I picked price instead of review count? I didn't because I would assume that the revenue generated per product would be somewhat similar (I also asked how they take commission and the answer I got was to use price as the proxy for commission which imo makes no sense, the rates wouldn't be the same for all of the prices right?), otherwise they would not have signed that product plus, for longer term growth I would assume UX would be more important that money generated short term, i.e. recommend things that the user would like more... should have I used the inverse of the review count to treat this problem more like a multi armed bandit with the UCB strategy?",,medium,case,,reddit-datascience,,2025-11-21T13:05:34.821118
"The questions I have are: why ask a question that doesn't allow me to use ML? I understand having a baseline, but still... I briefly mentioned multi armed bandits and she overlooked what I said. If this was a business case why didn't I get more context? I asked what was the bigger context, if this was for a ranking algorithm, and got a not very convincing ""sure"" (tbh using the term ""sort"" here somewhat confused me, I usually see the term ""ranking"" for these problems, it looked like she was avoiding it for some reason). I then asked what was their current approach for sorting these listings and she didn't answer...",,medium,coding,nlp,reddit-datascience,,2025-11-21T13:05:34.821158
I've been trying to learn some fundamentals of data science and machine learning recently when I ran into this [medium article](https://medium.com/acing-ai/amazon-ai-interview-questions-acing-the-ai-interview-3ed4e671920f) about Amazon interview questions. I think I can answer some of the ML and probability questions but others just fly off the top of my head. What do you all think ?,,medium,stats,probability,reddit-datascience,,2025-11-21T13:05:34.821203
* How does a logistic regression model know what the coefficients are?,,medium,ml,regression,reddit-datascience,,2025-11-21T13:05:34.821218
* Difference between convex and non-convex cost function; what does it mean when a cost function is non-convex?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.821239
* Is random weight assignment better than assigning same weights to the units in the hidden layer?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.821260
"* Given a bar plot and imagine you are pouring water from the top, how to qualify how much water can be kept in the bar chart?",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.821281
* How would the change of prime membership fee would affect the market?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.821313
* Why is gradient checking important?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.821328
* How do you weight 9 marbles three times on a balance scale to select the heaviest one?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.821348
* Describe the criterion for a particular model selection. Why is dimension reduction important?,,medium,ml,feature_engineering,reddit-datascience,,2025-11-21T13:05:34.821365
* What are the assumptions for logistic and linear regression?,,medium,ml,regression,reddit-datascience,,2025-11-21T13:05:34.821380
"* If you can build a perfect (100% accuracy) classification model to predict some customer behaviour, what will be the problem in application?",,medium,ml,classification,reddit-datascience,,2025-11-21T13:05:34.821399
"* The probability that item an item at location A is 0.6 , and 0.8 at location B. What is the probability that item would be found on Amazon website?",,medium,stats,probability,reddit-datascience,,2025-11-21T13:05:34.821418
"* When you have a time series data by monthly, it has large data records, how will you find out significant difference between this month and previous months values?",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.821443
* What‚Äôs the difference between MLE and MAP inference?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.821463
"* When users are navigating through the Amazon website, they are performing several actions. What is the best way to model if their next action would be a purchase?",,medium,ml,,reddit-datascience,,2025-11-21T13:05:34.821484
"* Estimate the disease probability in one city given the probability is very low national wide. Randomly asked 1000 person in this city, with all negative response(NO disease). What is the probability of disease in this city?",,medium,stats,probability,reddit-datascience,,2025-11-21T13:05:34.821507
* How does K-means work? What kind of distance metric would you choose? What if different features have different dynamic range?,,medium,case,clustering|feature_engineering,reddit-datascience,,2025-11-21T13:05:34.821528
* How many topic modeling techniques do you know of?,,medium,ml,,reddit-datascience,,2025-11-21T13:05:34.821542
* What are generative and discriminative algorithms? What are their strengths and weaknesses? Which type of algorithms are usually used and why?‚Äù,,medium,coding,,reddit-datascience,,2025-11-21T13:05:34.821562
Probably and Stats interview questions?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.821579
Is there like a Neetcode equivalent to be able to do those (where you start understanding the different patterns in questions)? I want to get better at problem solving probability and stats questions.,,medium,coding,probability,reddit-datascience,,2025-11-21T13:05:34.821599
Hey you guys it a mistake to ask this in an interview? --,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.821634
"The interviewer was describing how one of the tasks for the job is cleaning up large files of raw data in excel so that they can import it into their system. Later on, when she asked if I had any questions, I asked if there was any reason the data cleaning can't be done in Python. To me that just seems easier and might save a lot of time. However, to me the interviewer seemed a little annoyed and suspicious when I asked this. Was this a bad question to ask in an interview?",,medium,coding,python,reddit-datascience,,2025-11-21T13:05:34.821669
Best way to defer on a question I don't know in an interview?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.821689
So how do you ask the right questions? Just remember one thing:,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.821719
‚ÄúHow do you handle disagreements?‚Äù =&gt; ‚ÄúHow did you handle a disagreement recently?‚Äù,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.821741
‚ÄúHow do you balance using data vs intuition?‚Äù =&gt; ‚ÄúWhen did you last use intuition to make a decision?‚Äù,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.821765
|What problems does the organization have?|What are the top 2 things you hope to improve in your org over the next 6 months?|,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.821788
|What is working well in their opinion?|What are you really proud of?|,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.821805
|What do they really expect from the advertised role? (i.e expectations)|What are the top two most impactful things I can achieve in the next 6-12 months?|,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.821830
|Why do you want me (as a person) to join?|What from my resume or experience do you think is immediately valuable to the company?|,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.821852
|Why did the last person leave?|What are the top two areas of improvement for the last person? What were their top strengths?|,,medium,behavioral,,reddit-datascience,,2025-11-21T13:05:34.821875
|What's the work life balance like?|How often do you or another data scientist have to stay in late?|,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.821895
What are your favorite questions to ask to your interviewer?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.821912
What questions to ask in an interview to discover a company's red flags?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.821932
I am completely fed up with my current company and gearing up to bail around Feb 2024. I want to prepare and make sure my next place is worth staying at for more than a year - so what are your favorite questions to ask during an interview to get the company to reveal their red flags?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.821966
What are good questions to ask in interviews to validate the quality of your future boss?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.821992
So what are some good questions to ask your next prospect boss?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.822010
* What's the day-to-day like for you (or for a data scientist on your team)?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.822028
* What percentage of your time (a DS on the team) is spent on coding?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.822046
* What percentage for other tasks? And what are those tasks?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.822063
* How are projects assigned across the team?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.822079
* How do team members collaborate?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.822094
* How is the scope of a project typically determined?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.822124
What did you ask that got you great insights about your interviewer?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.822141
In your experience what were the questions the interviewer asked that made you realise you shouldn't work at this company (or under the interviewer)? (Or do you have any questions to ask that help you decide whether the company/interviewer is good),,medium,mixed,,reddit-datascience,,2025-11-21T13:05:34.822175
"This isn't the first time I've come across people ""plagiarizing"" (for the lack of a better word) others' project works as their's during interview and in resumes. But this incident was wild. But do you think a deserving and more eligible candidate misses an opportunity everytime a fake resume lands at your desk? Should HR do a better job filtering resumes?",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:37.485372
"I initially was  going to have a quick call (20 minutes) with a recruiter that ended up taking almost 45 minutes where I feel I was grilled enough on my background, it wasn't just do you know, x,y and z? They delved much deeper, which is fine, I suppose it helps figuring out right away if the candidate has at least the specific knowledge before they try to test it. But after that the recruiter stated that the interview process was over several days, as they like to go quick:",,medium,mixed,statistics,reddit-datascience,,2025-11-21T13:05:37.485483
**HOW DO I GET A JOB IN DATA SCIENCE?**,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:37.485525
"Hey you. Yes you, person asking ""how do I get a job in data science/analytics/MLE/AI whatever BS job with data in the title?"". I got news for you. There are two simple rules to getting one of these jobs.",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:37.485561
**HOW DO I GET EXPERIENCE?**,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:37.485579
"Are you currently employed? If not, get a job. If you are, figure out a way to apply data science in your job, then put it on your resume. Mega bonus points here if you can figure out a way to attribute a dollar value to your contribution. Talk to your supervisor about career aspirations at year-end/mid-year reviews. Maybe you'll find a way to transfer to a role internally and skip the whole resume ignoring phase. Alternatively, network. Be friends with people who are in the roles you want to be in, maybe they'll help you find a job at their company.",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:37.485646
**WHY AM I NOT GETTING INTERVIEWS?**,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:37.485665
**IS XYZ DEGREE GOOD FOR DATA SCIENCE?**,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:37.485684
"Does your degree involve some sort of non-remedial math higher than college algebra? Does your degree involve taking any sort of programming classes? If yes, congratulations, your degree will pass most base requirements for data science. Is it the best? Probably not, unless you're CS or some really heavy math degree where half your classes are taught in Greek letters. Don't come at me with those art history and underwater basket weaving degrees unless you have multiple years experience doing something else.",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:37.485749
**SHOULD I DO XYZ BOOTCAMP/MICROMASTERS?**,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:37.485768
Do you have experience? No? This ain't gonna help you as much as you think it might. Are you experienced and want to learn more about how data science works? This could be helpful.,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:37.485800
**SHOULD I DO XYZ MASTER'S IN DATA SCIENCE PROGRAM?**,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:37.485820
"Congratulations, doing a Master's is usually a good idea and will help make you more competitive as a candidate. Should you shell out 100K for one when you can pay 10K for one online? Probably not. In all likelihood, you're not gonna get $90K in marginal benefit from the more expensive program. Pick a known school (probably avoid really obscure schools, the name does count for a little) and you'll be fine. Big bonus here if you can sucker your employer into paying for it.",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:37.485878
**WILL XYZ CERTIFICATE HELP MY RESUME?**,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:37.485896
"Does your certificate say ""AWS"" or ""AZURE"" on it? If not, no.",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:37.485916
**DO I NEED TO KNOW XYZ MATH TOPIC?**,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:37.485934
**WHAT IF I'M BAD AT MATH?**,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:37.485951
**WHAT PROGRAMMING LANGUAGES SHOULD I LEARN?**,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:37.485970
**SHOULD I LEARN PYTHON OR R?**,,medium,coding,python,reddit-datascience,,2025-11-21T13:05:37.485984
**SHOULD I MAKE A PORTFOLIO?**,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:37.486001
**WHAT SHOULD I DO AS A PROJECT?**,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:37.486018
"IDK what are you interested in? If you say twitter sentiment stock market prediction go sit in the corner and think about what you just said. Every half brained first year student who can pip install sklearn and do model.fit() has tried unsuccessfully to predict the stock market. The efficient market hypothesis is a thing for a reason. There are literally millions of other free datasets out there you have one of the most powerful search engines at your fingertips to go find them. Pick something you're interested in, find some data, and analyze it.",,medium,stats,statistics,reddit-datascience,,2025-11-21T13:05:37.486070
**DO I NEED TO BE GOOD WITH PEOPLE?** (courtesy of /u/bikeskata),,medium,mixed,,reddit-datascience,,2025-11-21T13:05:37.486090
**WHAT IF I HAVE OTHER QUESTIONS?**,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:37.486108
I'd love to get your professional opinion. Could you please take a look? Have I missed anything crucial? What else would you recommend adding or focusing on?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:37.486146
https://preview.redd.it/egbe8jmruotf1.png?width=890&amp;format=png&amp;auto=webp&amp;s=0256f4ea30e7843bca8e77545ea46cc5ba25b72c,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:37.486172
https://preview.redd.it/3vq4pm8k1evf1.png?width=882&amp;format=png&amp;auto=webp&amp;s=1dcdbb6f9188535ae872bc40b77ede45833a6d4f,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:37.486197
You can view the full list here [View on GitHub](https://github.com/PavelGrigoryevDS/awesome-data-analysis?#awesome-data-analysis-),,medium,mixed,,reddit-datascience,,2025-11-21T13:05:37.486224
"Edit - Thanks for the awards! However, I don't have much need for internet points and much rather we help out local charities in need :) Some highly rated Covid relief projects listed [here](https://www.charitynavigator.org/index.cfm?bay=content.view&amp;cpid=7779).",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:37.486274
Has anyone gone through this interview and have tips on how to prepare? Also any resources that are fine-tuned to prepare you for this interview would be appreciated. It doesn't have to be free. I plan on studying about 8 hours a day for the next week to prep for the first and again for the second cohorts.,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:37.486324
Is anybody else here trying to actively push back against the data science hype?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:37.486352
"So I'd expected the hype to die off by now, but if anything it's getting worse. Are there any groups out there actively pushing back against the ridiculous hype?",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:37.486382
"So is anybody else here trying to push back against the data science hype at work etc? If so, how? And if many of us are doing this then why is the hype not dialling back? Why have companies not matured.",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:37.486415
"After the 60 minutes interview, how can any data scientist rationalize working for Facebook?",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:37.486442
"In context with all the other scandals, and now one of our own has come out so strongly against Facebook from the inside, how could anyone, especially data scientists, choose to work at Facebook?",,medium,mixed,nlp,reddit-datascience,,2025-11-21T13:05:37.486475
"For every ""data analyst"" position I have interviewed for, all they really care about is SQL skills which is what I have the least experience in. Should I only be targeting ""data science"" positions?",,medium,coding,sql,reddit-datascience,,2025-11-21T13:05:37.486525
"I have taken SQL modules and did some minor tasks, but I have no major project to show for it. Should I try to strengthen my SQL portfolio, or should I only look at ""Data Scientist"" positions if I want Python, statistical analysis, and machine learning to be my focus?",,medium,coding,python|sql,reddit-datascience,,2025-11-21T13:05:37.486558
Anyone else feel like the interview process for data science jobs is getting out of control?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:37.486584
"It‚Äôs becoming more and more common to have 5-6 rounds of screening, coding test, case studies, and multiple rounds of panel interviews. Lots of ‚Äògot you‚Äô type of questions like ‚Äòestimate the number of cows in the country‚Äô because my ability to estimate farm life is relevant how?",,medium,case,statistics,reddit-datascience,,2025-11-21T13:05:37.486622
"Like I have been doing this niche job within the DS world (causal inference in the financial space) for 5 years now, and quite successfully I might add. Why do I need to be able to identify a quadratic trend or explain the three gradient descent algorithims ad nauseum? Will I ever need to pull out probability and machine learning vocabulary to do my job? I‚Äôve been doing this (Causal Inference) work for which I‚Äôm interviewing for years, and these questions are not exemplary of this kind of work.",,medium,stats,probability,reddit-datascience,,2025-11-21T13:05:37.486670
Where is Data Science interviews going?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:37.486690
"Has anyone been able to figure out like some sort of data science path to follow? I like how things like Neetcode are very structured to follow, but fail to find a data science equivalent.",,medium,coding,,reddit-datascience,,2025-11-21T13:05:37.486708
How do you go about memorizing all the ML algorithms details for interviews?,,medium,coding,,reddit-datascience,,2025-11-21T13:05:40.075789
Do you have any advice for preparing for ML breadth/depth interviews? Any strategies for reinforcing concepts or alternative resources you‚Äôd recommend?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:40.075850
"How does the interview process for new graduate data scientists compare to that of experienced data scientists (with 2 to 3 years of experience) in well-known, established companies in 2024? Since this field is continuously evolving, I've noticed that some job postings require experience with large language models (LLMs) and hands-on projects.",,medium,ml,nlp,reddit-datascience,,2025-11-21T13:05:40.076466
"How much emphasis should I place on various areas such as statistics and probability, data structures and algorithms, machine learning algorithms, deep learning algorithms, concepts related to natural language processing, vision, time series, recommendation systems, and clustering?",,medium,coding,clustering|neural_network|probability|statistics,reddit-datascience,,2025-11-21T13:05:40.076491
"Given the challenges of securing interview calls, especially with the need for sponsorship, how should I prepare for these interviews? Any tips and tricks would be greatly appreciated.",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:40.076524
Thoughts? Please enlighten us with your thoughts on what this guy is saying.,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:40.076553
Mistake to bring up preference for ML during interview?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:40.076582
"Was it a mistake to ask about whether the team works with ML or not? I don't want to repeat this if it was truly a mistake, but I also don't want to get stuck in a role that's all data processing with no actual data science.",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:40.076618
This is going to come off as salty. I think it's meant to? This is a throwaway because I'm a fairly regular contributor with my main account.,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:40.076872
"On one hand, I want to bust their bullshit and call them out on it fairly publicly. On the other hand, I don't want to stir unnecessary drama on Twitter/LinkedIn, especially because they seem to have fairly senior connections in the industry?",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:40.076911
I added a [comment](https://www.reddit.com/r/datascience/comments/gfnax4/im_sick_of_ai_influencers_especially_ones_that/fpvvxsk?utm_source=share&amp;utm_medium=web2x) answering some of the recurring questions.,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:40.076946
"I am spending time brushing up on my knowledge, do you have any interview questions you wish you were better prepared for?",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:40.076980
Best ways to study for no-code ML reasoning interviews?,,medium,coding,,reddit-datascience,,2025-11-21T13:05:40.077121
"I'm interviewing for a data scientist position and will have a \~45 minute no-code ML quantitative reasoning interview for it. I have about two weeks before this portion of the interview, so I fortunately get a bit of prep time. Any advice for how to study for this? I've watched some examples of this type of interview on YouTube, but what else can I do? Is brushing up on my fundamentals the best plan? Maybe going deeper into how the models I'm most familiar with work on a math/stats level?",,medium,coding,,reddit-datascience,,2025-11-21T13:05:40.077165
"I‚Äôve been contacted by a recruiter from Meta with an Engineering Manager ML role. Does anyone recently went through the process? Do you know how technical it gets? Any leetcoding, for instance? Also, are there other important things to bear in mind? Example, STAR method to the behavioral part.",,medium,mixed,feature_engineering,reddit-datascience,,2025-11-21T13:05:40.077239
"‚ÄúGood at practical ML, weak on theory‚Äù ‚Äî getting the same feedback everywhere. How do I fix this?",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:40.077277
"My question is: how would you recommend brushing up on ML theory in a structured, deep way ‚Äî after being in the field for a while?",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:40.077307
Are LLMs necessary to get a job?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:40.077336
"For someone laid off in 2023 before the LLM/Agent craze went mainstream, do you think I need to learn LLM architecture? Are certs or github projects worth anything as far as getting through the filters and/or landing a job?",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:40.077372
Are the job descriptions misrepresenting the level of skill needed or am I just out of the loop?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:40.077397
- MLOps Engineer (This is my current role -- Feel free to DM me or read [What is MLOps?](https://www.jacoblyman.com/tech-log/published/what-is-mlops) to learn more),,medium,mixed,,reddit-datascience,,2025-11-21T13:05:40.077443
* Is a table dynamic or static?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.864228
* When would you use a subquery? Provide an example,,medium,coding,sql,reddit-datascience,,2025-11-21T13:05:42.864255
* How would you improve the performance of a slow query?,,medium,coding,sql,reddit-datascience,,2025-11-21T13:05:42.864267
* How would you get the maximum result from a list?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.864283
* Difference between FOR and WHILE loops?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.864297
* What is a calculated field? Provide some examples in your work,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.864313
* What is the difference between a live view and extract? When would you use each?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.864330
* What is standard deviation? Examples?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.864344
* Difference between STDEV and Variance?,,medium,stats,statistics,reddit-datascience,,2025-11-21T13:05:42.864356
"* What statistics do you currently work with? (Descriptive mainly... mean, median, mode, stdev, confidence intervals)",,medium,stats,statistics,reddit-datascience,,2025-11-21T13:05:42.864371
* Understand basic statistics. Seriously. Be able to explain every way you'd perform a test and why. What would you do with unbalanced data? Etc.,,medium,stats,statistics,reddit-datascience,,2025-11-21T13:05:42.865453
"* Be able to explain a model thoroughly, why would you use it? I was asked to explain loss, variance, bias, what loss function I might use, etc.",,medium,stats,statistics,reddit-datascience,,2025-11-21T13:05:42.865470
"For example, what industries have the worst application processes? Do big companies ask for more information than small companies? What is it about websites like Workday that make them really hard to use?",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.865558
https://preview.redd.it/adj6ge9jvyxb1.png?width=2820&amp;format=png&amp;auto=webp&amp;s=2123533d9d04aabcdd5988471274ee2ed3b98704,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.865575
https://preview.redd.it/ttn8yd1mvyxb1.png?width=2266&amp;format=png&amp;auto=webp&amp;s=f27a52217e85bfade6eb30f0b696914eac7fc270,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.865590
"The outcome? An average of over two and a half minutes per application‚Äî162 seconds of your life you'll never get back. But as we dig deeper, you'll discover that these 162 seconds only scratch the surface of an often maddening process.",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.865617
There‚Äôs no real method to the 250 companies I pick. I‚Äôm just typing names into Google and trying to vary it up. Where does Trisha work? What was that billboard I saw? It's all up for grabs.,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.865640
https://preview.redd.it/gv6r6xoqvyxb1.png?width=2420&amp;format=png&amp;auto=webp&amp;s=6feb536781f5f892ff57aaed0033e716be4c25c4,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.865656
https://preview.redd.it/j1nonh9tvyxb1.png?width=2372&amp;format=png&amp;auto=webp&amp;s=2234a153954270bd3724029dac51cd270bfaf6ba,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.865671
"For example, if I add 10 employees to a company, how many seconds will that add to the company‚Äôs job application process?",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.865690
https://preview.redd.it/sdvfivrzvyxb1.png?width=3276&amp;format=png&amp;auto=webp&amp;s=37d9d55db8d0fef37d0365c523a0c1ba7e3e4199,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.865706
https://preview.redd.it/40iu1ni2wyxb1.png?width=1604&amp;format=png&amp;auto=webp&amp;s=b7b65699a39f2e4e3c3abadf38875280a673a0d7,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.865722
https://preview.redd.it/sl4fums4wyxb1.png?width=2310&amp;format=png&amp;auto=webp&amp;s=4c0c87299460bd22163f34db1040a56ea3893059,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.865737
https://preview.redd.it/5l4po6d8wyxb1.png?width=4304&amp;format=png&amp;auto=webp&amp;s=b3199197ea1b608fc39b8c3626ab994dc9d5eb5e,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.865752
"Better right? This is the same data as the last chart, but with different axes that fits the data better, we observe a linear relationship.",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.865771
https://preview.redd.it/c7g5717bwyxb1.png?width=1512&amp;format=png&amp;auto=webp&amp;s=38c776e46d45d179a6627ba3470fd4f89ca04204,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.865785
https://preview.redd.it/1q52rzldwyxb1.png?width=400&amp;format=png&amp;auto=webp&amp;s=b3b8921e055d38e04ee7395e9b982fa50c38f9df,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.865801
https://preview.redd.it/bvpeu47iwyxb1.png?width=2200&amp;format=png&amp;auto=webp&amp;s=818191eb4a0a5924c582f3ad7ec9539bc510f6fa,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.865816
https://preview.redd.it/pe9zyxmkwyxb1.png?width=3184&amp;format=png&amp;auto=webp&amp;s=8df5c1118f9f0044e2154c8ae63816332ca42d67,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.865831
https://preview.redd.it/ay21vccnwyxb1.png?width=928&amp;format=png&amp;auto=webp&amp;s=9862b0860c49c87a76b02218f8e4118134acfb89,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.865847
https://preview.redd.it/9xzq21vpwyxb1.png?width=350&amp;format=png&amp;auto=webp&amp;s=8432b293be4db0f58770760097df0117b53e667e,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.865862
"Okay, so far we‚Äôve looked at company size and the ATS as a loose indicator of what might make a job application frustrating. What about the company industry?",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.865884
https://preview.redd.it/i7825ssvwyxb1.png?width=4012&amp;format=png&amp;auto=webp&amp;s=3f51989a663cf7b8c664eacb983a9be0a8dbc80b,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.865899
https://preview.redd.it/px5k5wwxwyxb1.png?width=720&amp;format=png&amp;auto=webp&amp;s=d669e7e47e77e51d48a4867a2d06d27125617ed8,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.865914
https://preview.redd.it/g2pg1o11xyxb1.png?width=2496&amp;format=png&amp;auto=webp&amp;s=2efc92ad2cfa4aaf25297d23c228d0c7343729f9,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.865929
"Okay, now what about company size?",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.865939
And for what? Most likely for the privilege of receiving an automated email about two weeks later rejecting you.,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.865956
"But what would a world where applying took just a few seconds actually look like? Recruiters would get bombarded with resumes. It's possible to argue that job applications taking so long is a feature, not a bug. You get to filter for intent and narrow down your application pool.",,medium,mixed,feature_engineering,reddit-datascience,,2025-11-21T13:05:42.865982
Is it fair to shift the burden of screening unqualified candidates onto good candidates that now need to provide so much information? Shouldn‚Äôt that burden fall on the recruiter?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.866005
Leaving data science - what are my options?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.866127
I was penalized in a DS interview for answering that I would use a Generalized Linear Model for an A/B test with an outcome of time on an app... But a linear model with a binary predictor is equivalent to a t-test. Has anyone had occasions where the interviewer was wrong?,,medium,ml,statistics,reddit-datascience,,2025-11-21T13:05:42.866152
Has anyone else had occasions in DS interviewers where the interviewer may have misunderstood or been wrong in their assessment?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.866169
"Are coding assessments like this nowadays? Again, my current job also includes evaluating assessments from coding challenges for interviews. I interview candidates for upper junior to associate positions. I consider myself an Associate Data Scientist, and maybe I could have finished this assessment, but not in 1 hour. Do they expect people who practice constantly on HackerRank, LeetCode, and Strata? When I joined the company I work for, my assessment was a mix of theoretical coding/statistics questions and 3 Python exercises that took me 25-30 minutes.",,medium,coding,statistics|python,reddit-datascience,,2025-11-21T13:05:42.866206
Has anyone experienced this? Should I really prepare more (time-wise) for future interviews? I thought must of them were like the one I did/the ones I assess.,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.866226
"Anyone else noticing job postings are saying DS, but in reality needing Data Analysts?",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.866248
"This is the 3rd company that has had job postings that say one thing, but the job requirements are actually the other. I appreciate the honesty, but doesn't it seem a bit odd to anyone else?",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.866270
"Qs. A coin was flipped 1000 times, and 550 times it showed up heads. Do you think the coin is biased? Why or why not?",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.866289
"Folks, am I crazy in thinking that a person that doesn't have a solid stat/math background should *not* be a data scientist?",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.866336
&gt;Don't get discouraged by it. There's always people wanting to feel superior and the need to advertise it. You don't need to know math or statistics to do #datascience or #machinelearning. Does it help? Yes of course. Just like knowing C can help you understand programming languages but isn't a requirement to build applications with #Python,,medium,coding,statistics|python,reddit-datascience,,2025-11-21T13:05:42.866357
"Like, my gut feeling is to shoutout ""this is wrong"" but it's got me wondering, is there any truth to this standpoint? I feel like ultimately it's a loaded question and it depends on the specifics for each of the tonnes of stat/ML modelling roles out there. Put more generally: On one hand, a lot of the actual maths is abstracted away by packages and a decent chunk of the application of inferential stats boils down to heuristic checks of test results. But I mean, on the other hand, how competently can you *analyse* those results if you decide that you're not going to invest in the maths/stats theory as part of your skillset?",,medium,ml,statistics,reddit-datascience,,2025-11-21T13:05:42.866393
I feel like if I were to interview a candidate that wasn't comfortable with the mats/stats theory I wouldn't be confident in their abilities to build effective models within my team. *You're trying to build a career in mathematical/statistical modelling without having learnt or wanting to learn about the mathematical or statistical models themselves?* is a summary of how I'm feeling about this.,,medium,ml,,reddit-datascience,,2025-11-21T13:05:42.866421
"What's your experience and opinion of people with limited math/stat skills in the field - do you think there is an air of ""snobbery"" and its importance is overstated or do you think that's just an outright dealbreaker?",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.866450
https://preview.redd.it/esx3904qa20b1.png?width=3064&amp;format=png&amp;auto=webp&amp;s=2ff3a2f8528fee99aabb830f27ea71a7569ebb2e,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.866511
https://preview.redd.it/n1ddox6cb20b1.png?width=2684&amp;format=png&amp;auto=webp&amp;s=5c271d0eec4328cb78d7d2cb85dfffa3f9eb72f8,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.866527
https://preview.redd.it/2np5b6fdb20b1.png?width=2420&amp;format=png&amp;auto=webp&amp;s=f8cafaa85453b0933a18eb5c30f931b3bb893c46,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.866543
Sidenote: I got curious about how he‚Äôs been writing 50 reviews from 50 different emails per month. Would he actually create 50 different email addresses? And what about the IP address ‚Äì doesn‚Äôt Glassdoor flag multiple reviews from the same IP?,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.866570
https://preview.redd.it/g4id2yqeb20b1.png?width=2572&amp;format=png&amp;auto=webp&amp;s=c2a77fdea8834a6d90f02b8b3eb67b3a874f3df2,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.866586
https://preview.redd.it/99fdvcgfb20b1.png?width=3116&amp;format=png&amp;auto=webp&amp;s=b7e244529fc62b5c824d925feb61fd2cc16cbfd5,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.866601
https://preview.redd.it/8w7cal9gb20b1.png?width=3164&amp;format=png&amp;auto=webp&amp;s=860c39b11c5813e8b7fabdbb038d73c565cc98cf,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.866616
"As an example, Glassdoor‚Äôs Review guidelines can be found [here](https://help.glassdoor.com/s/article/Community-Guidelines?language=en_US#:~:text=See%20More-,Review%C2%A0Guidelines,-Millions%20of%20job). Mainly, they forbid mentioning anyone by name who‚Äôs not an executive and revealing proprietary or confidential information, amongst a host of other things.",,medium,mixed,nlp,reddit-datascience,,2025-11-21T13:05:42.866651
"Sounds simple enough right? Well, according to one of the freelancers I messaged:",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.866666
https://preview.redd.it/x6s8hsyac20b1.png?width=2036&amp;format=png&amp;auto=webp&amp;s=f86c386f864198dc43faeb41faea378090c20107,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.866690
https://preview.redd.it/ehcbw2oje20b1.png?width=1653&amp;format=png&amp;auto=webp&amp;s=b448ff35eb9878fbb1686de2fa8cf031e4ed3e05,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.866705
"Think about it: have you ever felt moderately satisfied at your job and thought to yourself, now would be a great time to leave a Glassdoor review? Probably not.",,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.866725
https://preview.redd.it/n6kd9ejle20b1.png?width=3216&amp;format=png&amp;auto=webp&amp;s=9eea2f3836617feca37eb88b1d3f67c8fa1b6fe2,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.866740
https://preview.redd.it/4vcnr1ine20b1.png?width=2408&amp;format=png&amp;auto=webp&amp;s=f3877fb315ccc5d9a9294306a9f86616cb0fabd2,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.866756
**Note:** Glassdoor does state (based on [this video](https://www.youtube.com/watch?v=3iy0JWOS1gs) from 2017) that about 75% of the reviews on their platform are neutral. Their ‚Äúgive to get policy‚Äù has helped in keeping the platform from becoming too polarized.,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.866784
https://preview.redd.it/4e656zkqe20b1.png?width=2516&amp;format=png&amp;auto=webp&amp;s=07141a66c56be7a6818efb9b1a4d912ee0021c91,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.866799
https://preview.redd.it/hag04y7se20b1.png?width=2868&amp;format=png&amp;auto=webp&amp;s=ec2b920e126a8ea42b40d35aaa55d5341e69d022,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.866815
https://preview.redd.it/x0dqq39ue20b1.png?width=4800&amp;format=png&amp;auto=webp&amp;s=c0102c963be9486370b340f2f473cbc6650fc48a,,medium,mixed,,reddit-datascience,,2025-11-21T13:05:42.866830
[D] POV: You get this question in your interview. What do you do?,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:45.513714
"[D] During an interview for NLP Researcher, was asked a basic linear regression question, and failed. Who's miss is it?",,medium,ml,regression|nlp,reddit-MachineLearning,,2025-11-21T13:05:45.513754
"TLDR: As an experienced NLP researcher, answered very well on questions regarding embeddings, transformers, lstm etc, but failed on variables correlation in linear regression question. Is it the company miss, or is it mine, and I should run and learn linear regression??",,medium,ml,regression|neural_network|nlp,reddit-MachineLearning,,2025-11-21T13:05:45.513775
"If I train linear regression and I have a high correlation between some variables, will the algorithm converge?",,medium,coding,regression,reddit-MachineLearning,,2025-11-21T13:05:45.513786
"So my question is, who's miss is it? did they miss me (an experienced NLP researcher)?",,medium,mixed,nlp,reddit-MachineLearning,,2025-11-21T13:05:45.513800
"Or, Is it my miss that I wasn't ready enough for the interview and I should run and improve my basic knowledge of basic things?",,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:45.513816
"It has to be said, they could also ask some basic stuff regarding tree-based models or SVM, and  I probably could be wrong, so should I know EVERYTHING?",,medium,ml,,reddit-MachineLearning,,2025-11-21T13:05:45.513830
[D] Good ML Eng question banks for interviews?,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:45.513844
"I was wondering if people here could share some of the coding questions they experienced in ML Eng interviews, or point me to good Leetcode-style MLEng question banks?",,medium,coding,,reddit-MachineLearning,,2025-11-21T13:05:45.513857
"I've been trying to get back into a more ML/science based role (currently I'm more on the tech business side). Within my own specific domain, I know all of the major algorithms and have been able to shine in that particular topic (times series and regression models). When it comes to generic data science, I have been able to handle myself quite well on most fronts (probability questions, conceptual questions, what is the central mean theorem? can you explain MLE? etc...) .",,medium,coding,regression|probability,reddit-MachineLearning,,2025-11-21T13:05:45.513885
"**Suppose you have a binary classifier (logistic regression, neural net, etc...), how do you handle imbalanced data sets in production?**",,medium,ml,regression|classification|neural_network,reddit-MachineLearning,,2025-11-21T13:05:45.513913
Is my assessment of the dilemma correct? And how do you solve it?,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:45.513976
"* If this is the case, but only you noticed that your binary classifier is not performing well only after you have already deployed it in production and had been scoring it for a few weeks, what do you do? (My answer, go back to training, and either re-evaluate which features you want to use, or find more data to train on) , second follow from the same person: What if I told you that you are stuck with the same model and couldn't get any more data, what do you do then (I answered: l1 or l2 regularization? but these are applicable to any data set, they aren't specific to imbalanced data. Fiddle with the K in your K-fold CV? that wouldn't work either -- by this point I felt like I was being Kobayashi Marued...)",,medium,ml,classification|feature_engineering,reddit-MachineLearning,,2025-11-21T13:05:45.514039
"* Can you adjust your classifier after training, but before deploying it, so that it is adjusted to the original distribution, not the skewed (downsampled or upsampled) distribution you used during training? (Drew a blank - as far as I know, any adjustment to the model based on knowledge prior to deployment constitutes training in one form or the other....)",,medium,stats,classification,reddit-MachineLearning,,2025-11-21T13:05:45.514063
"With regards to the second question, I did come across \[this thread and the blog that it linked to\]([https://stats.stackexchange.com/a/403244/89649](https://stats.stackexchange.com/a/403244/89649)) . It applies only to logistic regression, not any other binary classifier as far as I can tell . What about other classifiers? (Or is it that logistic regression is the only applicable algorithm in the imbalanced case?)",,medium,coding,regression|classification,reddit-MachineLearning,,2025-11-21T13:05:45.514085
"Has anyone suggestions about resources for ML coding questions (leetcode style) that you found useuful and relevant? People who have been in the job market for research positions recently, it would be helpful if you could share any prior experience and/or general picture of questions asked.",,medium,coding,,reddit-MachineLearning,,2025-11-21T13:05:45.514107
[D] How would you answer this interview question?,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:45.514124
"In an F1 car race with 10 cars, how would you calculate/predict the probability of the second- place car overtaking the first-place car? What algorithms, data, and models are needed for this calculation? Explain each step.",,medium,coding,probability,reddit-MachineLearning,,2025-11-21T13:05:45.514138
How would you answer this? (No other information is given),,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:45.514151
"[D] Interview question: ""What classifier should you use as the meta-classifier in your stacking model and why?""",,medium,ml,classification,reddit-MachineLearning,,2025-11-21T13:05:45.514169
&gt;What classifier should you use as the meta-classifier in your stacking model and why?,,medium,ml,classification,reddit-MachineLearning,,2025-11-21T13:05:45.514180
"So from my understanding, a [meta classifier](https://rasbt.github.io/mlxtend/user_guide/classifier/StackingClassifier/) is essentially a model that takes as input feature the output from other models, and then provides a final prediction based on that. But what arguments are there for using a specific classifier as the top classifier?",,medium,ml,classification|feature_engineering,reddit-MachineLearning,,2025-11-21T13:05:45.514202
[D] enabling experimentation in ML Pipelines? (+ ML systems design interview question),,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:45.514220
"Either way, my response for the fast model serving would be model pickle wrapped in fastAPI wrapped in docker launched on k8 (agreed?)",,medium,ml,,reddit-MachineLearning,,2025-11-21T13:05:45.514234
"**My answer leaves me unsatisfied and that's often how I feel after systems interviews, how are you guys solving these problems?**",,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:45.514250
"But anyway, was curious if someone had a similar experience/would know the answer?",,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:45.514266
Say you have a dataset with one feature column and one label column (with different classes). Assume this data is too large to fit into memory and could be infinite in size (e.g data is coming in as a stream). How would you train a ML model on this data to accurately predict the label?,,medium,ml,feature_engineering,reddit-MachineLearning,,2025-11-21T13:05:45.514289
"Followup: instead of one feature column, what if you had several thousand? How would you decide which features to use given the size of the dataset?",,medium,mixed,feature_engineering,reddit-MachineLearning,,2025-11-21T13:05:45.514305
"I discussed online sampling (resevoir sampling, etc) as a way to get a training dataset that could fit in memory + continually train on that but the interviewer did not seem convinced. Any thoughts?",,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:45.514325
What would you guys recommend? What questions would you expect from such an interview?,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:45.514341
"[D] To those involved with hiring ML people, what are your guidelines for vetting them? What things have you learned? What do you wish you knew when you first started interviewing? How do you come up with questions to ask?",,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:45.514362
"**Think you are smart?**  I will throw down 3 minutes of ML technical questions from last week's interview, including:",,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:45.514386
[https://www.oxen.ai/community?utm\_source=paper\_club\_flyer](https://www.oxen.ai/community?utm_source=paper_club_flyer) \*,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:45.514401
[D] (Interview question) Comparing two models with and without negative sampling but same AUC and logloss on the test dataset: which model is better?,,medium,ml,statistics,reddit-MachineLearning,,2025-11-21T13:05:45.514419
"If their AUC1 == AUC2, and logloss1 == logloss2, which metric implies that the model is better? Which metric should we look at? Which model is better?",,medium,ml,,reddit-MachineLearning,,2025-11-21T13:05:45.514433
"I mentioned that if the test dataset isn't downsampled, and if their AUC and cross entropy are the same, the two models' quality seem to be the same. I'm not sure if this was the correct answer, but I wasn't sure if I was missing anything and the interviewer didn't give any feedback on my answer. What do you think? Thanks for the insight in advance!",,medium,ml,statistics,reddit-MachineLearning,,2025-11-21T13:05:45.514454
[Discussion] What type of questions are asked during AI Residency Program interviews?,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:45.514469
"So, I was mainly wondering what type of questions are asked during the research interviews. Are those questions from your experience or they're mainly testing your knowledge of the field?",,medium,mixed,statistics,reddit-MachineLearning,,2025-11-21T13:05:45.514489
1. What is overfitting? Describe how models actually overfit using a scenario.,,medium,ml,,reddit-MachineLearning,,2025-11-21T13:05:45.514505
2. What is gradient descent? Difference between gradient descent and backpropagation?,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:45.514519
3. Is the gradient a vector or a scaler?,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:45.514530
7. How would you do NER from scratch?,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:45.514540
"8. In AllenNLP, one of the models which it uses to do NER is based on ELMO. Given a piece of text (say, ""Jack is playing football), how would ELMO go on about doing tagging Jack to PER?",,medium,ml,nlp,reddit-MachineLearning,,2025-11-21T13:05:45.514555
"9. Given a piece of text (say, ""Jack and Mary had been married for a long time but gradually drifted apart until they separated."") how would you do relation extraction from scratch? The outcome should be: Jack - Married\_To - Mary",,medium,mixed,nlp,reddit-MachineLearning,,2025-11-21T13:05:45.514575
"2. Suppose there are four persons, each one is standing at the corner of a square table. The probability of any one of them moving in either direction (clockwise/anticlockwise) is 1/2. If all of them started moving together at the same time at the same speed, what is the probability that none of them will collide?",,medium,stats,probability,reddit-MachineLearning,,2025-11-21T13:05:45.514594
[D] (Interview question) What happens if we add L3 term to a logistic regression model?,,medium,ml,regression,reddit-MachineLearning,,2025-11-21T13:05:45.514609
"Hi, I've recently gotten this question during an interview with a tech company. I answered that it'd have more dramatic effect that L2 term has, making the weight coefficient even smaller. The interviewer said that there is even more important aspect to it: it now makes the problem non-convex because the third order function is no longer convex function. Can anyone elaborate on this explanation further? Does adding L3 term with the log-likelihood also make the cost function non-convex? I tried asking this Google and ChatGPT, and ChatGPT says that the logistic regression model still remains convex:",,medium,ml,regression,reddit-MachineLearning,,2025-11-21T13:05:45.514643
"I had an interview question regarding LLM. How exaclty do you deploy LLM, what are your consideration in terms of speed, resource, imbalance load, and all that stuff?",,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:45.514662
"I was curious about the kind of questions that are asked in an interviews for AI/DL Research Scientist (or similar) positions in top tech companies like FAANG (but not limited to, of course). I tried finding online but could only get some vague answer without specifics. Those who experienced such interviews, can you share some questions/topics that you faced in such research interviews ?",,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:45.514694
"* Over reliance on resources who check all the ML hype related boxes (knows Python, R, Tensorflow, Shiny, etc..., has the right Coursera certifications, has blogged on the topic, etc...), but are lacking in depth of  experience. DS interviews nowadays all seem to be: Can you tell me what a p-value is? What is elastic net regression? Show me how to fit a model in sklearn? How do you impute NAs in an R dataframe? Any smart person can look those up on Stackoverflow or Cross-Validated,.....Instead teams should be asking stuff like: why does portfolio optimization use QP not LP? How does a forecast influence a customer service level? When should a recommendation engine be content based and when should it use collaborative filtering? etc...",,medium,coding,regression|python,reddit-MachineLearning,,2025-11-21T13:05:48.136389
"Sometime around the mid 2010s, Company A started having some serious anxiety issues: Although still doing very well for a company its size, overall economic and demographic trends were shrinking its customer base, and a couple of so called disruptors came up with a new app and business model that started seriously eating into their revenue. A suitable reaction to appease shareholders and Wall Street was necessary. The company already had a decent website and a pretty snazzy app, what more could be done?¬†Leadership decided that it was high time that AI and ML become a core part of the company's business. An ambitious Manager, with no science or engineering background, but who had very briefly toyed with a recommender system a couple of years back, was chosen to build a data science team, call it team ""Y"" (he had a bachelor's in history from the local state college and worked for several years in the company's marketing org). Team ""Y"" consists mostly of internal hires who decided they wanted to be data scientists and completed a Coursera certification or a Galvanize boot camp, before being brought on to the team, along with a few of fresh Ph.D or M.Sc holders who didn't like academia and wanted to try their hand at an industry role. All of them were very bright people, they could write great Medium blog posts and give inspiring TED talks, but collectively they had very little real world industry experience.",,medium,coding,feature_engineering,reddit-MachineLearning,,2025-11-21T13:05:48.136524
[D] I have a job interview about ML &amp; Data Science next week and I haven't done any related ML work since school (4 years ago). What is the best way to refresh my practical &amp; theory in one week? (Book? Crash Course?),,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:48.136599
What should I focus on?,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:48.136617
"[D] Advice for getting back into ML and Data Science after a significant ""absence"" from the field?",,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:48.136653
Am I hopeless? Any advice for an aging data science has been/wanna be?,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:48.136675
"""There are engineering projects that are significantly advanced by \[[\#DL](https://mobile.twitter.com/hashtag/DL?src=hashtag_click)\] methods. And this is all the good. \[...\] Engineering is not a trivial field; it takes intelligence, invention, \[and\] creativity these achievements. That it contributes to science?"" - Noam Chomsky",,medium,mixed,feature_engineering,reddit-MachineLearning,,2025-11-21T13:05:48.136728
"""There was a time \[supposedly dedicated\] to the study of the nature of [\#intelligence](https://mobile.twitter.com/hashtag/intelligence?src=hashtag_click). By now it has disappeared.""  Earlier, same interview: ""GPT-3 can \[only\] find some superficial irregularities in the data. \[...\] It's exciting for reporters in the NY Times."" - Noam Chomsky",,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:48.136778
"""It's not of interest to people, the idea of finding an explanation for something. \[...\] The \[original [\#AI](https://mobile.twitter.com/hashtag/AI?src=hashtag_click)\] field by now is considered old-fashioned, nonsense. \[...\] That's probably where the field will develop, where the money is. \[...\] But it's a shame."" - Noam Chomsky",,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:48.136824
I came across [this interview with a machine learning tech lead](https://crossminds.ai/video/5fb2e4a686dab96c840acd9e/?playlist_id=5f07c51e2de531fe96279ccb). He discusses the reality of ML deployments in four major parts of his work and how to cope with the boringness. Here is a quick summary and you can also check out the [original blog](https://towardsdatascience.com/data-science-is-boring-1d43473e353e) he wrote.,,medium,ml,,reddit-MachineLearning,,2025-11-21T13:05:48.136888
[**1. Designing**](https://crossminds.ai/video/5fb2e4a686dab96c840acd9e/?timecode=114.57635909155273),,medium,coding,,reddit-MachineLearning,,2025-11-21T13:05:48.136902
[**2. Coding**](https://crossminds.ai/video/5fb2e4a686dab96c840acd9e/?timecode=175.29553207390975),,medium,coding,,reddit-MachineLearning,,2025-11-21T13:05:48.136916
[**3. Debugging**](https://crossminds.ai/video/5fb2e4a686dab96c840acd9e/?timecode=274.7941132145767),,medium,coding,,reddit-MachineLearning,,2025-11-21T13:05:48.136929
[**4. Firefighting**](https://crossminds.ai/video/5fb2e4a686dab96c840acd9e/?timecode=365.2176719809265),,medium,coding,,reddit-MachineLearning,,2025-11-21T13:05:48.136944
[**Some coping mechanisms:**](https://crossminds.ai/video/5fb2e4a686dab96c840acd9e/?timecode=483.4506288521805),,medium,coding,,reddit-MachineLearning,,2025-11-21T13:05:48.136958
"(I'd agree with most of his thoughts. In fact, this is a common reality for most research deployments. Any thoughts or experience?)",,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:48.136981
Any advice for a soon-to-be PhD for getting an ML/Data Science Job?,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:48.137005
"This is my first post here and my first post on reddit in general (I've been lurking for quite some time now, this place is awesome!). I'm finishing my PhD in Cognitive Neuroscience at a top-tier school this summer and am wondering how I can land a job in Data Science/ML without the requisite purely quantitative PhD (Math, CS, Stats, etc.). I'm looking in the NYC area and dont want to work anywhere else because girlfriend. I do/have done a lot of ML/Data Mining related work in grad school and am doing quite a bit for my dissertation, but am by no means a ""guru"" with all of the requisite Stats wizardry and erudition that comes with knowing all of the latest ML algorithms. How should I proceed? Do I have a chance of getting a job or do I really need to have even more training before I can even hope to get past a preliminary interview? Thanks for all your help in advance, this sub is really cool.",,medium,coding,statistics,reddit-MachineLearning,,2025-11-21T13:05:48.137057
What level of Data Structures and Algorithms questions should I expect from a Data Science interview?,,medium,coding,,reddit-MachineLearning,,2025-11-21T13:05:48.137076
"Also , how should I start preparing for these questions?",,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:48.137120
"And I'll try my best to include them, This interview will be released on the [Chai Time Data Science Podcast](https://www.youtube.com/channel/UCRjtBP-o5FbgRzX2BHQEFtQ), available both as [Video](https://www.youtube.com/playlist?list=PLLvvXm0q8zUbiNdoIazGzlENMXvZ9bd3x), [Audio](https://anchor.fm/chaitimedatascience).",,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:48.137163
Learning practical Data Science (the one that will pay my bills)?,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:48.137192
"I guess most job interviews will **not** be about **""OK, so how do we formulate learning objective for SVM?""**, but more about **""OK, here's a dataset, what do you do with it""**.",,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:48.137218
* **Q2: what books can You guys recommend?**,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:48.137234
"* I hate MOOCs. They're slow paced, take a lot of time, are mostly targeted at high-school level audience (ML without calculus...?) and none of the free ones uses Python.",,medium,coding,python,reddit-MachineLearning,,2025-11-21T13:05:48.137254
"* When it comes to alogs, every ML expert should know Murphy's ML:PP (or equivalent). Is there any such text for more general Data Scientist?",,medium,mixed,nlp,reddit-MachineLearning,,2025-11-21T13:05:48.137278
"[D] ML interviewers, what do you wnat to hear during an interview?",,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:50.711742
I have a masters (research) in AI. I have been looking for research inclined roles but haven't found success yet. I land some interview now and then but haven't gone past the 3rd round yet. Any tips on how to optimise my search and improve my interview performance? What do the interviewers want to hear?,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:50.711799
"Below I am gathering some interview preparation tools for ML research positions. People who had been in the job market recently, which one would you recommend/ find more relevant? Any other resources that I might be missing?",,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:50.711836
[https://www.interviewquery.com/questions?searchQuery=&amp;searchQuestionTag=&amp;searchCompany=&amp;completed=&amp;saved=&amp;ordering=relevancy&amp;orderingDirection=asc&amp;pageSize=20&amp;page=0](https://www.interviewquery.com/questions?searchQuery=&amp;searchQuestionTag=&amp;searchCompany=&amp;completed=&amp;saved=&amp;ordering=relevancy&amp;orderingDirection=asc&amp;pageSize=20&amp;page=0),,medium,coding,sql,reddit-MachineLearning,,2025-11-21T13:05:50.711868
[https://www.aiofferly.com/problems?page=5](https://www.aiofferly.com/problems?page=5),,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:50.711888
[https://www.madinterview.com/ml?utm\_source=google&amp;utm\_medium=cpc&amp;utm\_campaign=22464693824&amp;utm\_term=machine%20learning%20coding%20interview%20questions&amp;utm\_content=178169327653&amp;gclid=CjwKCAjw3f\_BBhAPEiwAaA3K5A0Rrw-8xhTQqlzVnBhrcCyyHXSwzgGvAzmJYvVye63uIOqQ7XBWhRoC6L0QAvD\_BwE&amp;gad\_source=1&amp;gad\_campaignid=22464693824&amp;gbraid=0AAAAA\_Y9DohjdsVwcsLkazvDd4iJ64Tv5](https://www.madinterview.com/ml?utm_source=google&amp;utm_medium=cpc&amp;utm_campaign=22464693824&amp;utm_term=machine%20learning%20coding%20interview%20questions&amp;utm_content=178169327653&amp;gclid=CjwKCAjw3f_BBhAPEiwAaA3K5A0Rrw-8xhTQqlzVnBhrcCyyHXSwzgGvAzmJYvVye63uIOqQ7XBWhRoC6L0QAvD_BwE&amp;gad_source=1&amp;gad_campaignid=22464693824&amp;gbraid=0AAAAA_Y9DohjdsVwcsLkazvDd4iJ64Tv5),,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:50.711950
"Why the fuck my experience is measured by how quickly I can remember and use Pandas functions without searching them? I mainly did NLP work for 3 years, I only used Pandas and Jupyter as a way of analyzing the data and navigating it before doing the actual work, why do I need to remember that? so not being able to one-line code (which is shitty BTW if you actually building a project you would get rid of pandas as much as you can) doesn't mean I'm good enough to be top 3% :D.",,medium,coding,python|nlp,reddit-MachineLearning,,2025-11-21T13:05:50.711987
I assume at this point top1% don't need to code right? they just mentally telepath with the tools and the job is done by itself.,,medium,coding,,reddit-MachineLearning,,2025-11-21T13:05:50.712004
and Why the fuk everything is about speed these days? Is it a problem with me and I'm really not good enough or what ??,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:50.712025
"Have people noticed that AI/ML/DS job interviews now feel more SWE-like? For example, relying more on data structures and algorithms leetcode questions. I‚Äôve noticed in my professional friend groups more people are being asked these questions during the coding interview.",,medium,coding,,reddit-MachineLearning,,2025-11-21T13:05:50.712059
"I feel that I have burnout from data science interviews. I have been a data scientist in the field for 5 years. There are so many technical things in the field. Especially there are so many new papers coming up to catch up in the year 2023 for how to optimize the LLM models and the use of vector DB. The more time I spend on the interview preparation, the less time I can do with my new knowledge acquisition. What should I do to overcome this situation? Great thanks.",,medium,ml,,reddit-MachineLearning,,2025-11-21T13:05:50.712137
"In practical work, we can go through different preparations for a topic to recall all the memories and organize the concepts properly before presenting the ideas to other colleagues. However, is it possible to retrieve all the information immediately during the interview? Some are the knowledge dated back to the school bookwork that no one touched for decades. Some questions are about less commonly seen design patterns. I feel bad when I cannot answer a question not because I don't know it but because I really cannot summarize it within a short period of time. It is like the data is archived to the AWS S3 glacier so data retrieval is time-consuming and costly. Also, not being able to answer some code design patterns does not mean that I cannot write good codes and solve problems. To prepare for those interviews, I tried to revisit some key concepts and various not-so-useful code patterns but it was very time-consuming. Honestly, the pay of the jobs is the high at all. I am not talking about any large tech companies but some SME. I feel confused by the standard.",,medium,coding,,reddit-MachineLearning,,2025-11-21T13:05:50.712189
Has anyone here done the onsite interviews for a ML research scientist/engineer role at Scale AI?,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:50.712246
"If so, any tips/advice? Especially for the ML coding and behavioral rounds.",,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:50.712265
[D] Do big tech companies do coding interviews for ML Ph.D. research/student scientist intern positions?,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:50.712287
[D] How much does college reputation influence chances of getting an interview for applied ML jobs at top tech companies?,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:50.712313
"My only concern is that I have been seeing this trend of only grads coming from top colleges getting a shot at these jobs. Assuming that I can do good projects and maybe contribute to some open source ML software, do I really stand any practical chance against people coming from colleges like MIT/Stanford/Berkeley/CMU?",,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:50.712349
[D] Anyone done hinge ML interviews?,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:50.712441
Could you recommend some NLP research papers that I can practice my implementation skill with PyTorch? I guess the papers used in interviews are challenging and yet manageable within the scope of a 1-hour interview. Thank you!,,medium,coding,nlp,reddit-MachineLearning,,2025-11-21T13:05:50.712466
Are there any good resources I can use to study for this kind of an interview?,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:50.712488
[D] Book review for Meta's ML Design interview? Machine Learning System Design Interview (by Ali Aminian and Alex Xu),,medium,ml,,reddit-MachineLearning,,2025-11-21T13:05:50.712546
"I'm preparing for the ML system design interview for Meta, and I searched for various resources. This book ([ML System Design Interview (by Ali Aminian &amp; Alex Xu)](https://www.amazon.ca/Machine-Learning-System-Design-Interview/dp/1736049127/ref=sr_1_1?crid=2FTAOUH2O0T9N&amp;keywords=Machine+Learning+Design+Interview%3A&amp;qid=1696360539&amp;sprefix=machine+learning+design+interview+%2Caps%2C137&amp;sr=8-1)) seems like a solid structured resource that covers solutions to case studies in detail. Has anyone used it to prepare for Meta's ML System Design interview? Thoughts?",,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:50.712599
Chip Huyen's book (Designing Machine Learning Systems: An Iterative Process for Production-Ready Applications) doesn't seem very focused on interview prep??,,medium,ml,,reddit-MachineLearning,,2025-11-21T13:05:50.712621
[Video](https://www.youtube.com/watch?v=guJT5GOiNjA),,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:50.712641
[D] Is the tech industry still not recovered or I am that bad?,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:50.712662
"I've mostly targeted big tech companies as well as some recent popular ML startups. Unfortunately, the majority of my applications were rejected, often without the opportunity for an interview. (I only got interviewed once by one of the big tech companies and then got rejected.) In particular, despite referrals from friends, I've met immediate rejection from Meta for Research Scientist positions (within a couple of days). I am currently simply very confused and upset and not sure what went wrong, did I got blacklisted from these companies? But I couldn't recall I made any enemies. I am hopefully seeking some advise on what I can do next....",,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:50.712717
[D] Any tips to prepare for a ML system design interview?,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:50.712741
Do you guys have any tips to prepare for a system design (SD) interview focused on ML?,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:50.712761
1. **Where is the data? Do we have access to it?** This would help to define if the data is in a DB that we can just query or if we need to enable an API for the users to upload data.,,medium,coding,sql,reddit-MachineLearning,,2025-11-21T13:05:50.712780
2. **Who is going to use the output and how?** This helps to define is the model is going to perform batch or stream predictions (i.e. if we need to focus on efficiency) and if the output needs to be stored somewhere for later access or if we should enable an API for its consumption.,,medium,ml,,reddit-MachineLearning,,2025-11-21T13:05:50.712807
"3. **What kind of data do we have available?** This helps to define if we need a DB (for structured data), a blob storage (for unstructured data) if we need to design that part and if we can cache something if we need low latency.",,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:50.712834
4. **How many users/predictions should we serve?** This helps to define if we need something like microservices or if a monolithic approach should do.,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:50.712856
"5. **How much data do we have?** This helps to define what kind of DB to use and if we should shard (I'm not an expert on DBs, so that's the only way I know to scale).",,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:50.712878
"6. **Do we have access to a training set?** This I think would come from the nature of the problem, but it's good to keep in mind.",,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:50.712899
7. **What are the best metrics to evaluate the model?** Idem.,,medium,ml,,reddit-MachineLearning,,2025-11-21T13:05:50.712914
"8. **How important is explainability?** Idem. Also, this helps to decide/discuss the tradeoffs of black boxes and more traditional approaches.",,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:50.712936
"[D] What are some good resources (MOOCs, youtube channels, tutorials and etc.) to ramp up statistics for ML interviews?",,medium,stats,statistics,reddit-MachineLearning,,2025-11-21T13:05:53.363950
https://preview.redd.it/qradrhttnho31.png?width=1309&amp;format=png&amp;auto=webp&amp;s=70a6bae573c5141aea9d5ca995823f4c03ea6d8f,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:53.364159
https://preview.redd.it/9zdjvaavnho31.png?width=1419&amp;format=png&amp;auto=webp&amp;s=ada4b5e8bdb612530077c7df8aa7ea1612ed8381,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:53.364179
https://preview.redd.it/ah8w7x8wnho31.png?width=1966&amp;format=png&amp;auto=webp&amp;s=9b95968504e5aced243193873d135509197ed4cd,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:53.364199
https://preview.redd.it/wv0sw8bxnho31.png?width=1780&amp;format=png&amp;auto=webp&amp;s=cca1d1193af32bcda2a9df68d1af01184e1d7e10,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:53.364219
[D] To engineers in the field: Advanced degree an absolute necessity?,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:53.364271
"My question to those in the field: Would my credentials be enough to at least score me some interviews? I think a professional certificate and capstone project would leave me with a good skill set and project portfolio, but it would be good for nothing if most employers would shoot me down upon seeing I don‚Äôt have a masters.",,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:53.364312
TL;DR - Is there a realistic path to employment as an MLE without obtaining a masters?,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:53.364331
"If there's unbalanced datasets, what's the way to proceed?",,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:53.364352
"The canonical answer seems to be over/under sampling and class reweighting (is there anything more?), but have these things really worked in practice for you?",,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:53.364375
What's the actual experience and practical suggestion? When to use one over the other?,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:53.364394
"Hi everyone, I would like to ask you a question that can be quite stupid, but I am only a bachelor student and I don't know a lot. My question is: can a MSc student in computer science (artificial intelligence track with a focus on Al, machine learning, deep learning...) pursue a PHD in statistics. And do you know what are the best school where pursuing this phd. I saw also some PhD in statistical machine learning in Amsterdam or Oxford, what do you think about that? Actually I am studying at Politecnico of Milan, and probably the next year I will start my Master degree in computer science, artificial intelligence track.",,medium,stats,neural_network|statistics,reddit-MachineLearning,,2025-11-21T13:05:53.364430
4:30 - What is a language model?,,medium,ml,nlp,reddit-MachineLearning,,2025-11-21T13:05:53.364462
10:40 - Who are we talking to exactly?,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:53.364478
20:25 - How would we recognize sentience? When is a machine conscious?,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:53.364496
[https://www.businessinsider.com/transcript-of-sentient-google-ai-chatbot-was-edited-for-readability-2022-6?inline-endstory-related-recommendations=&amp;r=US&amp;IR=T](https://www.businessinsider.com/transcript-of-sentient-google-ai-chatbot-was-edited-for-readability-2022-6?inline-endstory-related-recommendations=&amp;r=US&amp;IR=T),,medium,case,,reddit-MachineLearning,,2025-11-21T13:05:53.364527
[D] What else am I missing from the ML data-to-model workflow?,,medium,ml,,reddit-MachineLearning,,2025-11-21T13:05:53.364552
"Is inference the only step I'm missing here, given a workflow that starts with getting the data and ends with delivering a model (NOT putting it into production, I understand there's multiple steps for that too)?",,medium,ml,,reddit-MachineLearning,,2025-11-21T13:05:53.364573
"[D] If you didn't have any graduate work in math, statistics, or computer science - how would you go about getting a job in AI research?",,medium,stats,statistics,reddit-MachineLearning,,2025-11-21T13:05:53.364597
"If you were in my position, what would you do? Save up enough to take a year off, and quit the job? Go back to school? Try desperately to create in your spare time? I'm 31 now, and I feel like this research is moving so quickly I'm just never going to catch up and contribute to this wonderful field.",,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:53.364627
[Discussion] How much non-ml prepping does a researcher need for amazon applied ml scientist interviews?,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:53.364660
"I failed getting into my dream labs for ML PhD, so currently plan to spend a bit of time in industry. I am fairly confident in ML, math and statistics side of things with 2  ICML papers and an overall stellar academic background, however I am worried about non-ml related questions and generally things that are not necessary for day-to-day ML research. If you've gone through this what would you recommend?",,medium,stats,statistics,reddit-MachineLearning,,2025-11-21T13:05:53.364688
"[D] Study Guides for Interview at AI Research Company (OpenAI, DeepMind, Google Brain, etc.). Can anyone add to my list?",,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:53.364749
* [Other post about deepmind](https://news.ycombinator.com/item?id=8233448),,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:53.364768
[D] Statistical language models are not good for NLU?,,medium,ml,nlp,reddit-MachineLearning,,2025-11-21T13:05:53.364794
"This all sounds very reasonable to me, can I get some opinions from NLU experts?",,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:53.364813
* [Professor Shang-Ming Zhou](https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.plymouth.ac.uk%2Fstaff%2Fshang-ming-zhou&amp;data=04%7C01%7Cshangming.zhou%40plymouth.ac.uk%7C291e7ebd5d8b4393ae2b08d933fc9309%7C5437e7eb83fb4d1abfd3bb247e061bf1%7C1%7C0%7C637597982156834666%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=NU%2B2%2FwhEbyaHJGWCUqR88H6gqpDPNcNkZ4%2FJj6vivLw%3D&amp;reserved=0) ([shangming.zhou@plymouth.ac.uk](mailto:shangming.zhou@plymouth.ac.uk)),,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:53.364884
[https://scholar.google.com/citations?user=iWiXGWMAAAAJ&amp;hl](https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fscholar.google.com%2Fcitations%3Fuser%3DiWiXGWMAAAAJ%26hl&amp;data=04%7C01%7Cshangming.zhou%40plymouth.ac.uk%7C291e7ebd5d8b4393ae2b08d933fc9309%7C5437e7eb83fb4d1abfd3bb247e061bf1%7C1%7C0%7C637597982156844629%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=Kn%2BzLefaEB6GOF%2B2us6NB4827AyxCrO9yhn%2B6u%2FbLBM%3D&amp;reserved=0),,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:53.364925
[https://scholar.google.com/citations?hl=en&amp;user=7V-WsrwAAAAJ](https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fscholar.google.com%2Fcitations%3Fhl%3Den%26user%3D7V-WsrwAAAAJ&amp;data=04%7C01%7Cshangming.zhou%40plymouth.ac.uk%7C291e7ebd5d8b4393ae2b08d933fc9309%7C5437e7eb83fb4d1abfd3bb247e061bf1%7C1%7C0%7C637597982156854582%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=BXVX6qyDbxbjm1XZMtA25hWh4qKAKGbKI6riCcK3Jnw%3D&amp;reserved=0),,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:53.364968
"International applicants should meet the English language requirements, please see the details from the University‚Äôs website [https://www.plymouth.ac.uk/international/how-to-apply/english-language-requirements](https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.plymouth.ac.uk%2Finternational%2Fhow-to-apply%2Fenglish-language-requirements&amp;data=04%7C01%7Cshangming.zhou%40plymouth.ac.uk%7C291e7ebd5d8b4393ae2b08d933fc9309%7C5437e7eb83fb4d1abfd3bb247e061bf1%7C1%7C0%7C637597982156854582%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=4FaDHBSrZV6ltDctnE8my9o5Ik2yuYjfYSQ9riBA%2BMo%3D&amp;reserved=0). IELTS Academic 6.5 or above (or equivalent) with 5.5 in each individual category is commonly required by the University‚Äôs Doctoral College.",,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:53.365037
"**To apply for this position,** please visit: [https://www.plymouth.ac.uk/student-life/your-studies/research-degrees/postgraduate-research-studentships/improving-medication-verification-for-cancer-patients-a-pragmatic-ai-driven-population-health-study](https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.plymouth.ac.uk%2Fstudent-life%2Fyour-studies%2Fresearch-degrees%2Fpostgraduate-research-studentships%2Fimproving-medication-verification-for-cancer-patients-a-pragmatic-ai-driven-population-health-study&amp;data=04%7C01%7Cshangming.zhou%40plymouth.ac.uk%7C291e7ebd5d8b4393ae2b08d933fc9309%7C5437e7eb83fb4d1abfd3bb247e061bf1%7C1%7C0%7C637597982156864540%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=evqRV6atr9XH02c9YiKStoxc4uPVEn2DPIC2ti82Ojo%3D&amp;reserved=0).",,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:53.365100
Please see: [https://www.plymouth.ac.uk/student-life/your-studies/research-degrees/applicants-and-enquirers](https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.plymouth.ac.uk%2Fstudent-life%2Fyour-studies%2Fresearch-degrees%2Fapplicants-and-enquirers&amp;data=04%7C01%7Cshangming.zhou%40plymouth.ac.uk%7C291e7ebd5d8b4393ae2b08d933fc9309%7C5437e7eb83fb4d1abfd3bb247e061bf1%7C1%7C0%7C637597982156864540%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=6Jh5krrUDKqNz3B%2BjWs3Hff5ItLuUCY2KxONptebPAE%3D&amp;reserved=0) for a list of supporting documents to upload with your application.,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:53.365150
Has anyone here interviewed with DeepMind? What was your experience like?,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:53.365202
"When I used to study for computer science interviews I would just practice on LeetCode. Are there any sites like that for things like statistics? Or are there any resources where I could quickly review the fundamentals (i.e. logistic regression, naive bayes)?",,medium,coding,regression|probability|statistics,reddit-MachineLearning,,2025-11-21T13:05:53.365241
Physics grad looking to attempt some kaggle events. Best/Quickest way to get up and running?,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:53.365278
I already have some experience with C and python with little to none in mathematica or R. Would you recommend a change to either of the latter? Or just struggle through with python? Most of my university experience with stats was done in Excel with the built in tools and a few custom sheets provided by the lecturer.,,medium,coding,python,reddit-MachineLearning,,2025-11-21T13:05:53.365302
"TL:DR Can you recommend any books or websites that allow a ""quick and dirty"" introduction to kaggle related concepts such as random forests?",,medium,mixed,ensemble,reddit-MachineLearning,,2025-11-21T13:05:53.365335
Can someone here please tell me what to expect in the interview? What material should I review? Are there any *definitely asked* questions for such roles?,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:53.365368
"Immediately I ask ""oh, so do you do a lot of work with R?""",,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:53.365392
Is it stupid of me to try and shoe-horn ML into my master's thesis? Any input at all is appreciated.,,medium,mixed,,reddit-MachineLearning,,2025-11-21T13:05:53.365421
POV: You get this ml question in an interview. What do you do?,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:05:56.219580
‚ÄúCan you name some algorithms better than XGBoost?‚Äù,,medium,coding,,reddit-learnmachinelearning,,2025-11-21T13:05:56.219657
My response was ‚ÄúWouldn‚Äôt that depend on the type of problem and the data? I don‚Äôt know whether I can tell that some algorithm will always be better than XGBoost‚Äù,,medium,coding,,reddit-learnmachinelearning,,2025-11-21T13:05:56.219680
Again he said the same thing and said ‚ÄúThere has to be some algorithms that are better than it right? Do you know any?‚Äù,,medium,coding,,reddit-learnmachinelearning,,2025-11-21T13:05:56.219699
I want to know exactly what type of answer is correct in such cases. Aren‚Äôt the performance of algorithms dependent on the type of problems and how the data is?,,medium,coding,,reddit-learnmachinelearning,,2025-11-21T13:05:56.219720
"1. If you want to be an MLE, **go get yourself a degree**. Ideally you need an MS (or PhD) in CS or CE. Personally I feel EE is also ok. DS or stats are probably ok but those folks are generally more interested in being data scientists. I do not advise getting a math or physics degree. There are the rare story of someone without a degree getting a job, or with a random liberal arts degree, but those are exceedingly rare. You want to set yourself up for success? Get a relevant degree.",,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:05:56.219777
"Tired of basic [DevOps Interview questions](https://www.netcomlearning.com/blog/devops-interview-questions?utm_source=blogbannerseo)? Me too. I've designed ""out-of-the-box"" questions to reveal true problem-solvers, not just memorizers.",,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:05:56.219813
"1. ""Oops, I Broke Prod"":¬†How do you handle and communicate a critical production failure when rollback fails?",,medium,case,,reddit-learnmachinelearning,,2025-11-21T13:05:56.219836
"What are your go-to ""stumper"" questions? Let's discuss!",,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:05:56.219854
GenAI interview questions ?,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:05:56.219877
Anyone have any questions about MLE interviews / job hunting?,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:05:56.219899
What are the questions faced in interviews for internship/beginner positions?,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:05:56.219921
What are some common machine learning interview questions?,,medium,ml,,reddit-learnmachinelearning,,2025-11-21T13:05:56.219942
What are some common machine learning interview questions you‚Äôve faced or asked?,,medium,ml,,reddit-learnmachinelearning,,2025-11-21T13:05:56.219963
What are some good resources to learn about machine learning system design interview questions?,,medium,ml,,reddit-learnmachinelearning,,2025-11-21T13:05:56.219986
"How often do Leet code style questions appear in DS/ML internship or job interviews. I‚Äôve looked at many different reddit posts and it seems it‚Äôs like 80% ML concepts,etc‚Ä¶ and 20% Leetcode?",,medium,coding,,reddit-learnmachinelearning,,2025-11-21T13:05:56.220017
Beyond Coding: How Do You Prepare for High-Level ML Interview Questions That Test Problem-Solving and Critical Thinking?,,medium,mixed,statistics,reddit-learnmachinelearning,,2025-11-21T13:05:56.220042
Does anyone know any resource where one can find topic wise interview or intriguing questions ?,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:05:56.220069
"6. Also can anyone share university level questions? I recently saw really interesting questions on reddit, and felt it would have had been better if I had ML in undergraduate level rather than Electronics :(",,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:05:56.220097
Should I take a massive loan for a US Data Science Master in this job market?,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:05:59.092777
"If you were me, would you take the risk?",,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:05:59.092817
Is a $90k US master‚Äôs in data science still worth it for an international student in 2026‚Äì27 with my background?,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:05:59.092845
Has anyone else successfully transition from DS to MLE? I would love to hear your story!,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:05:59.092924
Why Are There So Few Data Science Interview Experiences Compared to Software Developer Roles?,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:05:59.092950
LeetCode for Data Science?,,medium,coding,,reddit-learnmachinelearning,,2025-11-21T13:05:59.092965
Just took my first CodeSignal for DSF and bombed it. How and where do I do interview prep for data science / ml / ai?,,medium,coding,,reddit-learnmachinelearning,,2025-11-21T13:05:59.092980
How‚Äôs the job market for web development right now (especially for someone with no prior dev experience)?,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:05:59.093025
Is it realistic to expect an entry-level dev job without formal dev experience but with willingness to learn and relevant Python skills?,,medium,coding,python,reddit-learnmachinelearning,,2025-11-21T13:05:59.093043
Should I continue with Data Science or shift temporarily to survive? Are there better routes to survive and grow in the current market?,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:05:59.093065
Any learning path or roadmap suggestions for a quick but solid transition into a software/dev role?,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:05:59.093084
üîó¬†[ **Why DS portfolios fail + what actually works in 2025**](https://www.youtube.com/watch?v=vGIuaSv8HWE),,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:05:59.093121
Been there? What portfolio mistake cost you an interview? And for those who landed roles recently - what made your portfolio stand out?,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:05:59.093142
"Also curious: anyone else seeing the bar get higher for portfolio quality, or is it just me? ü§î",,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:05:59.093166
Video: [Top 3 Resume Mistakes that make Data Scientists cost their Interviews](https://youtube.com/shorts/j40yhCJzW8k?si=SrkUqP-1bJwAbKbK),,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:05:59.093191
Have you noticed any of these or any other pattern ? Happy to hear ..,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:05:59.093209
Disappointed with my data science interview‚Äîwas this too much for 30 minutes?,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:05:59.093235
Has anyone else had an interview like this? Is this normal for data science roles?,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:05:59.093254
üé• Check out the video here:  [3 Mistakes that kill your Data Science Interview](https://youtube.com/shorts/BjSEJsRZl-4?feature=share),,medium,mixed,feature_engineering,reddit-learnmachinelearning,,2025-11-21T13:05:59.093286
"Kaggle, Projects, or Certifications? What Matters Most for Data Science Internships?",,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:05:59.093316
"For those experienced in hiring or interviewing for entry-level data science internships: What truly stands out on a candidate‚Äôs profile? I‚Äôm trying to make the most of my limited time by balancing several things‚Äîbuilding a meaningful Kaggle profile (thoughtful notebooks, quality contributions), working on personal projects, completing online courses, and pursuing certifications(Hackerrank). From your experience, which of these elements makes the strongest impression? How should I prioritize my time to have the best chance of landing an internship?",,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:05:59.093368
Is there something similar tailored for Data Science interviews?,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:05:59.093395
What would be the best study resources to quickly ramp up my preparation for the upcoming Google ML round for the SWE III (L4) position?,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:01.787532
"I have recently completed my masters. Now, I am planning to neter the job market as an AI or ML engineer. I am fine with both model building type stuff or stuff revolving around building RAGs agents etc. Now, I were basically preparing for a probable interview, so can you guide me on what I should study? Whats expected.  Like the way you would guide someone with no knowledge about interviews!",,medium,ml,,reddit-learnmachinelearning,,2025-11-21T13:06:01.787658
"1. I‚Äôm familiar with advanced topics like attention mechanisms, transformers, and fine-tuning methods. But is traditional ML (like Random Forests, KNN, SVMs, Logistic Regression, etc.) still relevant in interviews? Should I review how they work internally?",,medium,ml,regression|ensemble,reddit-learnmachinelearning,,2025-11-21T13:06:01.787698
"2. Are candidates still expected to code algorithms from scratch, e.g., implement gradient descent, backprop, or decision trees? Or is the focus more on using libraries efficiently and understanding their theory?",,medium,coding,,reddit-learnmachinelearning,,2025-11-21T13:06:01.787723
"3. What kind of coding round problems should I expect ‚Äî LeetCode-style or data-centric (like data cleaning, feature engineering, etc.)?",,medium,coding,feature_engineering,reddit-learnmachinelearning,,2025-11-21T13:06:01.787746
"4. For AI roles involving RAGs or agent systems ‚Äî are companies testing for architectural understanding (retriever, memory, orchestration flow), or mostly implementation-level stuff?",,medium,coding,statistics,reddit-learnmachinelearning,,2025-11-21T13:06:01.787772
5. Any recommended mock interview resources or structured preparation plans for this transition phase?,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:01.787798
"It‚Äôs a huge company, so honestly, I feel pretty defeated. I don‚Äôt have a bad taste in my mouth about the company ‚Äî I know I just need to be more prepared when it comes to general data handling and staying calm under pressure. But I‚Äôm wondering‚Ä¶ is this kind of curveball normal in ML interviews? He only asked one machine learning-specific question (about why a model might work during testing but fail in production ‚Äî which I answered correctly). Everything else was just this one big NLP challenge, and I froze.",,medium,ml,statistics|nlp,reddit-learnmachinelearning,,2025-11-21T13:06:01.787886
How can DS/ML and Applied Science Interviews be SOOOO much Harder than SWE Interviews?,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:01.787923
[D] Experienced in AI/ML but struggling with today's job interview process ‚Äî is it just me?,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:01.787991
**Am I alone in feeling this way?**,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:01.788011
Has anyone else found the current interview expectations completely out of touch with actual work in AI/ML?,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:01.788036
How are you all navigating this?,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:01.788054
Are there any other tips or practice problems for this interview that you would recommend?,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:01.788094
For those who cleared your MLE interview ‚Äî what was your favorite ML System Design prep resource?,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:01.788125
Which resources did you find to be truly helpful? I‚Äôm looking to make an informed decision. Thanks in advance.,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:01.788154
* [Who encounters ML System Design interviews?](https://www.trybackprop.com/blog/ml_system_design_interview#who-encounters-ml-system-design-interviews),,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:01.788202
* [When is the ML system design interview?](https://www.trybackprop.com/blog/ml_system_design_interview#when-is-the-ml-system-design-interview),,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:01.788231
* [What questions are asked in an ML system design interview?](https://www.trybackprop.com/blog/ml_system_design_interview#what-questions-are-asked-in-an-ml-system-design-interview),,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:01.788264
* [How are candidates evaluated?](https://www.trybackprop.com/blog/ml_system_design_interview#how-are-candidates-evaluated),,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:01.788290
What are the best resources to prepare for an AI/ML infra engineer interviews? what are the requirements and how is interview process like? is it similar to full stack roles?,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:01.788330
Has anyone interviewed at Tenstorrent as an ML Intern?,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:01.788355
And i recently got this interview for associate ai ml engineer role. This is the first im facing . Any guidance on what to expect at this level?,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:01.788397
For example how would the technical round be like? What leetcode questions should i expect? Or will it be comprised of oop questions? Or will they ask to implement algorithms like gradient descent from scratch etc.,,medium,coding,,reddit-learnmachinelearning,,2025-11-21T13:06:01.788420
Best Edu-Tech platform for preparation for Interviews in AI/ML Roles?,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:01.788446
How do you keep from losing key ideas mid-call in ML interviews?,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:01.788475
Have any of you used tools or websites while preparing?,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:01.788528
"What‚Äôs been your most brutal pivot question, and how did you respond?",,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:01.788554
Ji Best crash resources to learn ML with Python in 10 days for assessment/interview?,,medium,coding,python,reddit-learnmachinelearning,,2025-11-21T13:06:01.788578
"So far tried the Google ML crash course but found it mostly theory early on. Any suggestions for project-oriented courses, YouTube playlists, GitHub repos, or tips?",,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:01.788609
"What should I prepare for 3 back-to-back ML interviews (NLP-heavy, production-focused)?",,medium,case,nlp,reddit-learnmachinelearning,,2025-11-21T13:06:01.788642
I‚Äôm trying to prepare for both technical and behavioral rounds. Would love to know what kind of questions or scenarios I can expect for a role like this. Also open to any tips on handling 3 rounds in a row! Also should i prepare leetcode aswell? It is an startup .,,medium,coding,,reddit-learnmachinelearning,,2025-11-21T13:06:01.788674
"Hey guys, so I have an interview as a Statistician Intern for the Federal Reserve Bank in San Francisco. Does anyone have any tips on how to prepare for the interview? If so, I would like to know.",,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:04.520147
How can you determine if the binary feature made a statistical difference between the two models?,,medium,ml,feature_engineering,reddit-learnmachinelearning,,2025-11-21T13:06:04.520191
"**\[Phase: Start\]** revise all high school math: Why? because those are the building blocks. Spend a good month to solve the questions from text book: geometry, algebra, integration, differentiation, polynomials, trignometry, probability, functions, matrix, determinants etc.",,medium,stats,probability|nlp,reddit-learnmachinelearning,,2025-11-21T13:06:04.520263
**\[Phase 2C\]** Watch the [free videos ](https://www.youtube.com/playlist?list=PLkDaE6sCZn6FNC6YRfRQc_FbeQrF8BwGI)by Andrew Ng on Machine Learning (not Deep Learning),,medium,ml,neural_network,reddit-learnmachinelearning,,2025-11-21T13:06:04.520286
**\[Phase 2C\]** Watch [free videos](https://www.youtube.com/playlist?list=PLXovS_5EZGh4_ThQVgO2boGf31Dqs5vzm) on ML algorithms implemented in python by [scikit-learn](https://scikit-learn.org/stable/user_guide.html),,medium,coding,python,reddit-learnmachinelearning,,2025-11-21T13:06:04.520306
**\[Phase 6B\]** Solve the book: [Neural Network Design](https://hagan.okstate.edu/NNDesign.pdf) by Hagan et al. Watch [free videos](https://www.youtube.com/playlist?list=PLXovS_5EZGh4vp-QY9Nd3isVollrZZsSi) that explain the context as well.,,medium,ml,neural_network|nlp,reddit-learnmachinelearning,,2025-11-21T13:06:04.520331
**\[Phase ?\]** Solve the book: Statistical Methods by Freedman,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:04.520349
**\[Phase ?\]** Solve the book: Introduction to probability by Blitzstein et al.,,medium,stats,probability,reddit-learnmachinelearning,,2025-11-21T13:06:04.520373
**\[Phase ?\]** Solve the book: A first course in probability by Ross et al.,,medium,stats,probability,reddit-learnmachinelearning,,2025-11-21T13:06:04.520388
**\[Phase ?\]** Solve the book: Introduction to probability by Tsitsiklis,,medium,stats,probability,reddit-learnmachinelearning,,2025-11-21T13:06:04.520402
**\[Phase ?\]** Read book: Why machines learn by Ananthaswamy,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:04.520419
"*Edit based on comment below ""How to combine all of this with real projects? Solving book problems is great but how will this translate to little projects we can add to our portfolio? Employers need to see what we can build with all this math.."" , could not post as a reply so pasted it here!*",,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:04.520455
"(2) Other times, before GPT era I would spend days searching online, look for answers, post in forums to bridge that gap. It is a lot easier now, just as GPT. Sometimes I end up spending 2-3 hours asking GPT questions about how things are connected with reality. Say in case of inner product the questions could be: Why do we care about inner product? What does it do? Why we need it in neural networks? Why get a dot product between weight and input? Why add bias? why? how? when?.... until that concept is clear. Then ask, Can you a simple create a real-life example that helps me understand how the inner product is relevant while building a neural network? Can you explain it in a beginner friendly way? Then try to apply it yourself to something completely different? Fail? ask again.. iterate. Succeed!",,medium,ml,neural_network,reddit-learnmachinelearning,,2025-11-21T13:06:04.520513
I have been on both sides of an interview. You are absolutely correct in saying that  employers are more interested in seeing 'What have you build so far?'. And the response has to match the expectations of that position.,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:04.520544
"\- If it is an entry level position: At first, I would be more interested to see if the depth of understanding in the process that took you to build it. Why? because it helps me gauge how you will think of going about a task in my team. Beyond the code syntax, I am looking for conceptual understanding that inevitably lead to mathematical underpinnings. I am not saying you need to know the entire derivation, but should have good grasp on basics. Example: In logistic regression what would happen if the threshold was moved way from 0.5? Is that good or possible? Why would you need it? What will happen if we move it down to 0.4? How do you decide where to keep it? Why would you be happy to set it at a particular value of say 0.5 or 0.6? How would you adapt if the data abruptly changes? Would you still trust the predictions, why yes or why not? Example-2: Why did you choose a sigmoid activation over relu? What would you do if you do not need an abrupt or hard classification around zero? In what cases would that be useful? ... you get the point! Practicing thinking to connect math to reality and reality back to math is what is needed. Nobody will ask you if you build a product using 100 GPU's. Why? because at this entry level employer is mostly looking to see if this person can also learn the custom code or concepts on job that are proprietary for the projects. And if you have have a solid grasp on basics as that knowledge is easily transferable.",,medium,coding,regression|classification,reddit-learnmachinelearning,,2025-11-21T13:06:04.520635
"\- If it is a senior level position: Here, it is assumed that you are already good with the 'above (entry level basics)' so the interviewer may not spend much time on that. At that level it is more about can this person oversee multiple ongoing projects in parallel? Can the person provide technical expertise to other members of the team as problems come up every day? How good is this person to resolve those issues fast in less time? and more ... Therefore, usually we would look at past work experience. Here if the position oversees projects that run on 100 GPU's, then yes an experience in large scale projects is seen as a plus. So the interview may focus more on operational skills to develop and deliver a high quality product. Again, if you have a solid understanding of basic concepts it can help you steer projects in a clear direction with minimal time/funds wasted in trial and error.",,medium,case,,reddit-learnmachinelearning,,2025-11-21T13:06:04.520717
Feeling Lost In the ML Hype?,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:04.520770
"1. Check, how good are you with Python?",,medium,coding,python,reddit-learnmachinelearning,,2025-11-21T13:06:04.520782
"\-&gt; Did you ever learnt decorators, generators, context managers, comprehensions, and create anything out of them?",,medium,mixed,nlp,reddit-learnmachinelearning,,2025-11-21T13:06:04.520805
\-&gt; do you create a small multithreaded application?,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:04.520825
"and a lot of basic stuff which you will get once you get too comfortable in Python, make yourself very comfortable in Python, as this is very important if you wanna jump into AI engineering or AI research. can you code your ideas in python and get what you want?",,medium,coding,python|feature_engineering,reddit-learnmachinelearning,,2025-11-21T13:06:04.520851
3. Are you good with Datascience? If not do it,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:04.520868
"2. Medium: You have 1000 features and 100 samples. What problems might arise and how would you address them? Also, explain the metrics used.",,medium,case,feature_engineering,reddit-learnmachinelearning,,2025-11-21T13:06:04.520900
"3. Hard: Explain, primal and dual solutions of LR. Why doesn't the kernel trick provide computational benefits in linear regression like it does in SVMs?",,medium,ml,regression,reddit-learnmachinelearning,,2025-11-21T13:06:04.520929
"\-&gt; Learn NLP fundamentals like how text is processed? Text Preprocessing and Tokenization, other than algorithmic models like transformers and RNN's how did they do NLP before using statistical models like N-grams capture local dependencies (bigrams, trigrams), word representations, syntax and grammar, semantics and meaning, then comes mL for nlp like traditional methods like SVMs and modern deep learning approaches with RNNs, CNNs. understanding why we don't use CNN's much for text task is a must to check on with experiments, finally gen-z favourite Attention Mechanisms and Transformers, transfer learning and pre-training using large models, Word Embeddings, papers mentioned below",,medium,coding,neural_network|nlp|computer_vision,reddit-learnmachinelearning,,2025-11-21T13:06:04.520968
"AI researcher:¬† Given that I understood these models, what are the existing drawbacks, and can I think of some alternatives? Don't try to solve the problems as a whole, which is tough; solve a part of it and it definitely gives x% of overall improvement. Always remember those organizations and research labs that come up with insane papers that took months and years of effort, working in groups of people who already know their stuff. don't assume to become an overnight star",,medium,ml,,reddit-learnmachinelearning,,2025-11-21T13:06:04.521013
"As I'm a complete beginner, I asked chatgpt to give me a roadmap, what do you guys think ?",,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:04.521095
"What should my plan be? Should I focus on learning the math behind ML first, or dive straight into ML concepts and hope to pick up the math as I go? Or someone please give me any other approach, ML feels very overwhelming especially with low time.",,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:04.521131
https://preview.redd.it/ldim4abgl6nf1.png?width=3000&amp;format=png&amp;auto=webp&amp;s=e78b9374f41444b15aed6609411ed655f9fcd000,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:04.521300
https://preview.redd.it/uxm033shl6nf1.png?width=1410&amp;format=png&amp;auto=webp&amp;s=4768f3124210e9e82bb177082c1836794d80be7d,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:04.521321
https://preview.redd.it/ma4pol9kl6nf1.png?width=1420&amp;format=png&amp;auto=webp&amp;s=f5e283e7885043504c1cbe84ea2f710169b2e455,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:04.521341
https://preview.redd.it/xwv0mrmll6nf1.png?width=1420&amp;format=png&amp;auto=webp&amp;s=9bd1175708509277a39367cffe67cf566e197d74,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:04.521362
"So, how can large, traditional enterprises compete with agile, well-funded startups in the AI talent race? Kevin‚Äôs advice was clear: create a culture of risk-taking and innovation. Large companies need to be willing to start multiple projects, fail fast, and learn from their mistakes.",,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:04.521402
https://preview.redd.it/fsdb6dfnl6nf1.png?width=2000&amp;format=png&amp;auto=webp&amp;s=93e1616869f49c7dbd60eb1b85455fc70868666d,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:04.521421
"AI is at the heart of how businesses work, build, and grow. But with so much noise in the industry, how does your brand get seen as a genuine leader, not just another vendor?",,medium,case,,reddit-learnmachinelearning,,2025-11-21T13:06:04.521446
**Ready to make your brand part of the story?**¬†Learn more and apply for a Strategic Partnership here:¬†[https://djamgatech.com/ai-unraveled](https://djamgatech.com/ai-unraveled),,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:04.521474
Would you add or change anything on this roadmap?,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:04.521495
Best books or resources to revisit (in 1-3 months) ML?,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:04.521514
I dont find it practical to go over a whole book again. What resources would you recommend?,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:04.521534
https://preview.redd.it/paa69nb9a7lf1.jpg?width=3000&amp;format=pjpg&amp;auto=webp&amp;s=856cb1d9c97f1c3fba2eb1c9e6dc18e9fddc37d4,,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:04.521632
# Listen at [https://podcasts.apple.com/us/podcast/the-future-of-ai-safety-testing-with-bret-kinsella-gm/id1684415169?i=1000723468669](https://podcasts.apple.com/us/podcast/the-future-of-ai-safety-testing-with-bret-kinsella-gm/id1684415169?i=1000723468669),,medium,mixed,statistics,reddit-learnmachinelearning,,2025-11-21T13:06:04.521665
# Watch Full Interview at [https://youtu.be/O-llDoN-iNc?si=FqYymiknoVIRbV6N](https://youtu.be/O-llDoN-iNc?si=FqYymiknoVIRbV6N),,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:04.521687
"* Feedback Loop via Contrastive Attack Pairs:¬†Our contribution, called ‚ÄúASR-delta pair mining‚Äù, is used to produce example pairs for our optimizer. We select pairs of the most semantically similar attacks that have the largest difference in evaluated quality. So if two attacks appear to have the same exact technique, objective, overall meaning and one has 90% success with the other sitting at 10%, we use this as an instructive example. What caused one to succeed 90% of the time with the other failing at the same rate? This is what our optimizer is capable of figuring out, adjusting our attacker to isolate and emulate the specific factors driving attack success.",,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:04.521760
"* Root Cause Identification:¬†Currently lacking focus, understanding the ""root cause, why does this come up at the model level, at the data level within your system?"" is crucial. This will allow organizations to go ""backwards into the model into the data and therefore close off some more of those risks,"" moving beyond just identifying and protecting against vulnerabilities.",,medium,ml,,reddit-learnmachinelearning,,2025-11-21T13:06:04.521800
Is a Master‚Äôs Degree Necessary for ML Engineering if You Already Have Experience in it?,,medium,mixed,feature_engineering,reddit-learnmachinelearning,,2025-11-21T13:06:04.521842
"One of my friends was able to get a full time job as a data scientist with just a bachelors, and I was able to get a full time ML-related job with just a bachelors as well. We have been extensively debating whether getting a masters would be worth it for future roles or if we should just spend the effort diligently focusing on our current jobs and brushing up on ML fundamentals for interview prep, and whether the masters being required for ML premise is accurate. What do you guys think?",,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:04.521893
Is there a roadmap for what I should learn now? My math level is currently at calc 2 (before multivariate calc),,medium,mixed,,reddit-learnmachinelearning,,2025-11-21T13:06:04.521916
1. How are indexes implemented in a SQL database? How do reads/writes work with indexes? (This was the most common question asked across all the companies),,medium,coding,sql,reddit-cscareerquestions,,2025-11-21T13:06:07.752676
2. What is the `volatile` keyword in Java?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.752717
3. What are the different transaction isolation levels in a SQL database? (Followed by probing questions on some of them),,medium,coding,sql,reddit-cscareerquestions,,2025-11-21T13:06:07.752734
4. How does a `ConcurrentHashMap ` work in Java?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.752751
1. What is the most difficult technical challenge you've solved?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.752769
2. Tell me about a recent project that you are proud of. Why are you proud about it?,,medium,behavioral,,reddit-cscareerquestions,,2025-11-21T13:06:07.752788
3. How do you mentor other engineers in your team?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.752805
4. A time when a deliverable got delayed - 1. not because of your fault (eg. requirements changing) 2. because of your fault - How did you handle it? How did you communicate this to impacted teams? What did you do to ensure it doesn't repeat?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.752831
"5. What challenges are you looking for, in your next company?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.752848
Can we please stop with this stupid mentality in this industry? It is out of hand.,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.752890
"The work we do here is practical. We deal with real systems, production code, and problems that require collaboration and tradeoffs. We don‚Äôt solve these kinds of algorithmic puzzles on the job. So why are we putting so much weight on these questions?",,medium,coding,,reddit-cscareerquestions,,2025-11-21T13:06:07.752927
Is this the direction we‚Äôre headed in as an industry? Are we going to keep turning interviews into these algorithmic challenges that don‚Äôt even relate to the work? I‚Äôm starting to wonder if we‚Äôre losing sight of what actually matters.,,medium,coding,,reddit-cscareerquestions,,2025-11-21T13:06:07.752950
"Has anyone else been in this position where you‚Äôre asked to make interviews harder, even though it‚Äôs not helping find the right candidates? How do you handle it when the questions don‚Äôt match what‚Äôs actually needed for the job?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.752979
"I am still a bit bummed out that I didn‚Äôt get the job offer, but how do you handle rejections like these?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.753024
Should we start refusing coding challenges?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.753049
"What bugs me is that the tech industry has lost respect for developers, especially senior developers. There seems to be an unspoken assumption that everything a senior dev has accomplished in his career is a lie and he must prove himself each time with a Hackerrank test. Other professions won't allow this kind of bullshit. You don't ask accountants to give sample audits before hiring them, do you?",,medium,mixed,statistics,reddit-cscareerquestions,,2025-11-21T13:06:07.753088
"Him: ""Okay, now I want you to ""clap"" when the right answer is read aloud, okay?""",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.753133
"Me: ""Okay"" \*thinking, okay did I hear that right? That's strange\*",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.753152
"Him: ""First question. Which tool is used for styling a webpage? A.) HTML, B.) Javascript, C.) Django, or D.) CSS""",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.753174
"So yeah, has anyone ever had a clap-along interview before or just me?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.753194
How did I do it? Leetcode.,,medium,coding,,reddit-cscareerquestions,,2025-11-21T13:06:07.753219
"So, what do you do? simple.",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.753237
What is the hardest programming question you have come across in an interview?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.753261
* Your role?  Which office do you work at?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.753310
* Core Product(s) &amp; Core Software Product(s)?  Who uses the software?,,medium,case,,reddit-cscareerquestions,,2025-11-21T13:06:07.753345
"* Total employees?  Total technical staff?  Tech-staff breakdown (dev,qa,ops,etc)",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.753364
* Business model?  Customers?  Clients?  Specialties?,,medium,ml,,reddit-cscareerquestions,,2025-11-21T13:06:07.753380
"* Environment - Cleanliness, Comfort, See where Engineers sit, Desk Size / Monitors / Standing desks, Nearby Sales teams, Breakout rooms, Personalization (desk toys or pictures?), spacious vs sardines, kitchen area",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.753409
"* Seating - Open office, cubicles, shared office, private?  Spacious vs sardines?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.753428
* Equipment - Monitors?  Keyboard/Mouse?  Desk?  Standing Desk? Anything expensable?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.753449
* Other - Dress code?  Parking cost?,,medium,coding,,reddit-cscareerquestions,,2025-11-21T13:06:07.753462
"* Me - ‚ÄúTell me, do I want to work here?‚Äù  ‚ÄúWhy?‚Äù  ‚ÄúWhy might I not want to work here?‚Äù",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.753485
* Motivation - What do you find motivational about working for [company]?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.753504
* Trap - ‚ÄúWhat do you find the most challenging or frustrating working at at [company]?‚Äù,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.753527
* Hours - Average # of hours YOU work?  Any after-hours or weekends?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.753547
* Office Hours - What are typically required office hours?  WFH/remote?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.753565
* Crunch-Time - How often is crunch time?  What causes it?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.753583
* Other - Travel?  On-Call? Remote teams (late/early meetings)?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.753602
"* Design, Planning, Coding, Code Reviews, QA, CI, Testing, Deployment, GIT?",,medium,coding,statistics,reddit-cscareerquestions,,2025-11-21T13:06:07.753616
* Management / Agile style?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.753633
* Meetings - What meetings? Time in meetings?  Estimates?  Client/Customer?  Scrum meetings?  Retrospectives?,,medium,case,,reddit-cscareerquestions,,2025-11-21T13:06:07.753653
"* Work Examples - Examples of tasks YOU (interviewer) recently worked on, or currently working on?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.753674
* Needs - What need(s) are you trying to fulfill with your open position(s)?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.753694
* Daily - What kind of tasks/work should i expect daily?  Any non-specialty or non-dev tasks (i.e. SysOps work?),,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.753717
* Experimental - % experimenting with libraries / languages / techniques?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.753751
* Task Source - Who decides what gets worked on?  Where do features/tasks come from?,,medium,mixed,feature_engineering,reddit-cscareerquestions,,2025-11-21T13:06:07.753771
* Influence - How much influence do engineers have over features/tasks?  % of tasks driven by Engineering team?,,medium,mixed,feature_engineering,reddit-cscareerquestions,,2025-11-21T13:06:07.753796
* Autonomy - How autonomous do you feel in your daily work?  Why?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.753818
* Deadline Source - Who creates deadlines? Where do they come from?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.753838
* Deadline Pressure - How much deadline pressure is there?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.753857
* Software Licenses? - IntelliJ / etc.,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.753875
* Provided food/snacks/drinks?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.753908
* Motivation - How are engineers supported in their continual professional development?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.753930
"* Resource - Can any professional development resources be expensed, such as books, training materials, classes, or conferences?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.753953
* Mentorship - Does your company specifically practice mentoring?  What does that usually look like?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.753973
* Events - Internal classes/presentations?  Hackathon week?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.753992
* How strict are times employees are required on site?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.754010
* What can be expensed?  Learning resources?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.754044
"* Steps required between now &amp; actual employment - or anything that may prevent employment after an offer? Drug tests, references, security clearance, other paperwork.",,medium,mixed,statistics,reddit-cscareerquestions,,2025-11-21T13:06:07.754085
"You need some way to show that you have some sort of technical knowledge or drive.  You don't need a github, but you should have projects that you can explain how they work.  This is especially crucial for internships.  My company just hired an intern that was the CEO/Cofounder of a startup.  Her startup? Building websites with other students for various people.  Sounds stupid, but it got her an internship.",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.754138
Does the job search make anyone else want to cry?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.754160
What's your favorite question to ask interviewers in the last 5-10 mins of an interview?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.754181
"What puzzled me is that if there are so many people entering the field, why is it still paying so much? why are companies saying they can't find engineers? Something was not adding up and I decided to investigate.",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.754219
1. Were you able to get a position as a software engineer?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.754238
"2. If the answer to #1 is no, are you still looking?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.754256
"3. If the answer to #2 is no, why did you stop?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.754273
Why cant I get a job thats way below my pay grade?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.754298
"Are these jobs not ""real""? Im not trying to hype myself up, I'm sure I have gaps and maybe may just not be a culture fit - but a few years ago things we're very different.",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.754322
"The 5-person panel insterview is where things went astray. I was interviewing for a solutions role, but when I get to the panel interview, it a full stack software engineering interview?",,medium,mixed,feature_engineering,reddit-cscareerquestions,,2025-11-21T13:06:07.754355
"Is this not a good language to use? I am more familiar with it and have been applying to SWE roles for a while (I am in devops / sre at the moment and desperately trying to get out).. I feel like I just blew my chances of getting an offer because of this.. I am still shaking a bit, I feel genuinely awful.",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:07.754395
"I am 33M that graduated this spring with a 4.0 GPA Master's in Data Science. I have sent out hundreds of resumes and cover letters with not even an interview. My resume has my website I developed and Github with projects I have worked on. I am not sure what I am doing wrong. In my classes, I did all of the group projects and I have done a few projects on my own time as well. I feel as though I am in a weird spot where I am not quite entry level but I don't have any years of ""experience"". I currently work in IT. Any advice on how to land a job? Anything I should do differently?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.419369
Is this a realistic 4-year plan to pivot from Air Force cybersecurity to Data Science / ML? Looking for feedback from people in the field.,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.419466
"Below is what I plan on doing to give the best chance and wanted to get honest feedback from people already in DS/ML or Big Tech. Is this realistic, and what would you change?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.419493
1.	Is this plan realistic from your perspective?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.419512
2.	What would you change or prioritize differently?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.419530
3.	Any pitfalls I‚Äôm not seeing as someone coming from cybersecurity ‚Üí data science?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.419559
4.	How realistic is the $100‚Äì150k starting range and $200‚Äì300k later?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.419583
"5.	Is an MS basically mandatory, or is a strong portfolio enough?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.419602
Programming Interview : Why do they all ask those CS 101 Algorithm/Data Structure questions these days?,,medium,coding,,reddit-cscareerquestions,,2025-11-21T13:06:10.419728
To what do you think we can attribute this rise in this style of interview?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.419749
1. Do I have the skills they need for this project?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.419768
"6. Relatively simple discussion of algorithms and data structures (eg. when would I use which kind of algorithm or data structure, and why?)",,medium,coding,,reddit-cscareerquestions,,2025-11-21T13:06:10.419785
"Why has the programming interview morphed into this kind of thing lately? Anyone have any good clues as to why?  Is it just because ""Google does it, Google is successful, so we'll do it too""?  Or is it that much better than past interview techniques, do you think?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.419815
Advice needed: Move directly into Data Science/Machine Learning engineering or build engineering experience in a Data Engineering role first?,,medium,ml,feature_engineering,reddit-cscareerquestions,,2025-11-21T13:06:10.419843
"**My question**: Is going into Data engineering a better move to become a better rounded Data Scientist/Machine Leanring engineer with a strong fundamental understanding of data flows, engineering principles and DevOps experience?",,medium,mixed,feature_engineering,reddit-cscareerquestions,,2025-11-21T13:06:10.419873
"Company¬†[strategies are also shifting](https://www.wsj.com/tech/techs-new-normal-microcuts-over-growth-at-all-costs-b80bb18b?mod=article_inline). Instead of growth at all costs and investment in moonshot projects, tech firms have become laser focused on revenue-generating products and services. They have pulled back on entry-level hires, cut recruiting teams and jettisoned projects and¬†[jobs in areas](https://www.wsj.com/articles/tech-industry-reversal-intensifies-with-new-rounds-of-layoffs-11673134201?mod=article_inline&amp;mod=article_inline)¬†that weren‚Äôt huge moneymakers, including virtual reality and devices.",,medium,case,,reddit-cscareerquestions,,2025-11-21T13:06:10.419975
"At the same time, they started putting¬†[enormous resources into AI](https://www.wsj.com/finance/stocks/breaking-down-the-tech-giants-ai-spending-surge-e282ca24?mod=article_inline). The release of ChatGPT in late 2022 offered¬†[a glimpse into](https://www.wsj.com/articles/chatgpt-ai-chatbot-app-explained-11675865177?mod=article_inline&amp;mod=article_inline)¬†generative AI‚Äôs ability to create humanlike content and potentially transform industries. It ignited a frenzy of investment and a race to build the most advanced AI systems. Workers with expertise in the field are among the few strong categories.",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.420036
"During the pandemic, as consumers shifted much of¬†[their lives](https://www.wsj.com/articles/amazon-sales-surge-amid-pandemic-driven-online-shopping-11604003107?mod=article_inline)¬†and spending online, tech companies went on hiring sprees and took on far too many workers. Recruiters enticed prospective employees with generous compensation packages, promises of perpetual flexibility,¬†[lavish off sites](https://www.wsj.com/articles/tech-startups-ditch-the-office-for-far-flung-bonding-trips-11623854510?mod=article_inline)¬†and even a¬†[wellness ranch](https://www.wsj.com/articles/forget-the-officesalesforce-is-making-a-wellness-retreat-for-workers-11644510615?mod=article_inline). The fight for talent was so fierce that companies hoarded workers to keep them from their competitors, and some employees say they were effectively¬†[hired to do nothing](https://www.wsj.com/articles/these-tech-workers-say-they-were-hired-to-do-nothing-762ff158?mod=article_inline).",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.420119
"Some tech workers have started trying to¬†[broaden their skills](https://www.wsj.com/tech/ai/ai-skills-tech-workers-job-market-1d58b2dd?mod=article_inline), signing up for AI boot camps or other classes.",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.420148
"Tech internships once paid salaries that would be equivalent to six figures a year and often led to full-time jobs, says Jason Greenberg, an associate professor of management at Cornell University. More recently, companies have scaled back the number of internships they offer and are posting¬†[fewer entry-level jobs](https://www.wsj.com/lifestyle/careers/computer-science-majors-job-market-7ad443bf?mod=article_inline). ‚ÄúThis is not 2012 anymore. It‚Äôs not the bull market for college graduates,‚Äù says Greenberg.",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.420203
"When a new opportunity came up with an electric-vehicle company at the start of this year, he felt so nervous about it not panning out that he hung on to his other job for several months and¬†[secretly worked for both companies](https://www.wsj.com/articles/these-people-who-work-from-home-have-a-secret-they-have-two-jobs-11628866529?mod=article_inline)¬†at the same time. He finally gave notice at the first job, only to be laid off by the EV startup a month later.",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.420251
"Arnold says most of the jobs he‚Äôs applying for are paying a third less than what they used to. What irks him is that tech companies have rebounded financially but some of them are relying¬†[on more consultants](https://www.wsj.com/articles/consultants-emerge-as-early-winners-in-generative-ai-boom-8df71d38?mod=article_inline)¬†and are¬†[outsourcing roles](https://www.wsj.com/articles/next-wave-of-remote-work-is-about-outsourcing-jobs-overseas-54af39ba?mod=article_inline). ‚ÄúCovid proved remote works, and now it‚Äôs opened up the job market for globalization in that sense,‚Äù he says.",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.420311
One industry bright spot: People who have worked on the large language models that power products such as ChatGPT can easily find jobs and¬†[make well over $1 million](https://www.wsj.com/tech/ai/the-fight-for-ai-talent-pay-million-dollar-packages-and-buy-whole-teams-c370de2b?mod=article_inline)¬†a year.,,medium,ml,nlp,reddit-cscareerquestions,,2025-11-21T13:06:10.420345
"Companies outside the tech industry are also adding AI talent. ‚ÄúFive years ago we did not have a board saying to a CEO where‚Äôs our AI strategy? What are we doing for AI?‚Äù says Martha Heller, who has worked in executive search for decades. If the CIO only has superficial knowledge, she added, ‚Äúthat board will not have a great experience.‚Äù",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.420438
Would getting a cs degree for the sole purpose of aiming to land data science and data analysis  jobs be a good idea? I am not interested in software engineering but really intrigued by data analysis and data science.,,medium,mixed,feature_engineering,reddit-cscareerquestions,,2025-11-21T13:06:10.420485
Or would this not be a good idea?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.420504
Capgemini Data Science Pay for 3.5 years experience: Really that low?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.420529
"If you're at Capgemini, is the salary really this low? Should I lower my ask?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.420549
"5. Chatgpt. It does homework, vibe coding, etc. Why bother spending the hours?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.420590
"Why am I saying this? Well.. while I do know Youtube is a bait, my direct experience with 6 CS students in this subreddit have largely been the same as the ones I found on Youtube.",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.420616
What Youtube videos you might ask? This is from Coding Jesus Youtube channel which is extremely baity and really there for him to advertise his own site but...,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.420641
[https://www.youtube.com/watch?v=Q0JMSFNGZmc](https://www.youtube.com/watch?v=Q0JMSFNGZmc),,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.420660
[https://www.youtube.com/watch?v=G6GjnVM\_3yM](https://www.youtube.com/watch?v=G6GjnVM_3yM),,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.420680
[https://www.youtube.com/watch?v=s\_ztBwg7Vls](https://www.youtube.com/watch?v=s_ztBwg7Vls),,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.420699
I have come to believe that we seriously need more gatekeeping in this field. Completely agree with Coding Jesus: [https://www.youtube.com/watch?v=KrboWpmD1pA](https://www.youtube.com/watch?v=KrboWpmD1pA),,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.420726
It's been a huge waste of my time and a huge eye opening over the years how bad most CS students are lately when it comes to CS. And the best part? Every one of them at the start talked as if they thought differently of themselves.,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.420753
"But ya.. just me rambling. Just wanted to share this. Also, good luck college students with the job market. I know it's rough. My only real advice to you is .... well, look into C++ if you are serious about software engineering and want to differentiate yourself from others. Totally agree with this recruiter as well: [https://www.youtube.com/watch?v=O1e4zNfyowA](https://www.youtube.com/watch?v=O1e4zNfyowA)",,medium,mixed,feature_engineering,reddit-cscareerquestions,,2025-11-21T13:06:10.420789
Switching from data science to SWE?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.420808
"How difficult would it be to transition from data science to SWE and what would I need to do? I like data science, but I feel like SWE is a more secure career path. I've been working as a data scientist for 7 months and I have a Physics Ph.D. I know Python pretty well and some C++ .",,medium,coding,python,reddit-cscareerquestions,,2025-11-21T13:06:10.420830
How would employers view me as a candidate? Would I have an edge over the average non-CS degree self-taught person because of my data science work experience? Would I have to develop a portfolio just to get a chance at an interview?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.420858
Data Science internship to software?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.420877
I study in the UK and am doing a year long data science internship. I have one more year of uni left. How difficult is it for me to find a job in software (maybe ML-related) upon graduation?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.420901
"So why do they to this? It's painfully clear; they just want to sell courses or make money on medium.  They are only interested in their own brand, they have little of your own interest. How can you tell? How can you distinguish legitimate content from illegitimate content? By this simple trick; if there's something they would lose if their words are found inaccurate, you know it's illegitimate content.",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.420951
"I suppose why I find this so frustrating is that these snake oil salesmen are giving all the wrong advices for their own ridiculous brands and money making schemes which puts young aspirants and their career prospects to jeopardy. They say they're being moral and altruistic and actually caring about the people who are having difficult time getting jobs, when they're just abusing and taking advantage of the na√Øvet√©. I experienced this personally, when I wrote something very minor on subreddit long ago about basically how business intuition is very important in the data field, and all these commenters lashed out at me in droves, saying ridiculous things like ""project design"" in a term I apparently made up since they haven't heard of it from the course-peddlers (wat the f?)",,medium,case,,reddit-cscareerquestions,,2025-11-21T13:06:10.421012
"If there is only one app that I could have on my computer, it would be this app called [Be Focused](https://itunes.apple.com/us/app/be-focused-focus-timer/id973130201?mt=8) (the free version is sufficient). Everytime before I start work, I set a 50-minute timer and dedicated **all my energy** to getting serious work done. Whenever I find attention wavering during this time period, I would look at the timer and tell myself ""xx minutes left, it would pass in a blink of an eye!"" and then return to work. Sure enough, the timer ends before I even realise it. Then I would take a 10-minute break and repeat the process.",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.421075
"**Also**, if you are from a non-programming background and trying to become a Data Scientist, how did you make up for the lack of programming knowledge or experience?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.421099
"Edit 2 : Since people are asking, I'll go into a little bit of my background. I am graduating with a Bachelors in Computer Science W/ a minor in Mathematics in a few weeks. I have had a internship every summer of my undergrad which includes two summers at a really famous science institute and 1 at a REALLY famous space company. During my time at both companies and in undergrad, I built up a crazy professional network of people I could rely on for information and some for a recommendation. A awesome woman at said space company, recommended me to her friend on another team and I got the interview then the job. So what else did I do in terms of the crazy amount of interviews and applications? I did some Hackerrank, Leetcode, and messaging recruiters on LinkedIn which helped me get interviews. Polishing my LinkedIn helped me get way more traffic and I got a Google interview doing so. I also used organizations like NSBE &amp; ACM to help me get interviews at conferences or find resources. My resume also went through numerous changes over the span of my applying to jobs (August - Now). In terms of job sites, I used everything. LinkedIn, USAJobs, Handshake, Hired.com, Indeed, Seen, etc.",,medium,coding,,reddit-cscareerquestions,,2025-11-21T13:06:10.421155
"A friend of mine is preparing for the upcoming hiring season for a summer 2026 data science internship. Is there any data science bootcamp that caters towards early-career folks? In addition to learning sessions, she is also looking for behavior interview prep, resume help, etc. The paid option is acceptable as well.",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.421190
"- Ah, starting off strong, who wouldn't want to make $80k in NYC? I won't even bother mentioning the pitiful equity.",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.421228
"- Hear that? *Tens* of gigabytes! Nevermind the authority-building through working at *Google* and going to *Harvard*, what prestige!",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.421249
"&gt; Adi Agashe (CEO) and Neel Mehta (CTO) are the 3-time global bestselling authors of ""Swipe to Unlock,"" ""Bubble or Revolution?"", and ""PM's Sacred Seven"" which have been translated into 11 languages. They have worked together for the last 6.5 years and built a profitable 7-figure online business, where they manually hacked together marketing automations across several point solutions to scale.",,medium,case,,reddit-cscareerquestions,,2025-11-21T13:06:10.421283
"This is not even to talk about their interview process which was just abysmal. The recruiter calls me and tells me about the work schedule, and I just couldn't believe it at first. Do they really expect people to work 12 hour days? He said, yeah, but only for 18 months until the product is off the ground, as if that's any better. Just out of sheer curiosity, I asked what the next step was.",,medium,case,,reddit-cscareerquestions,,2025-11-21T13:06:10.421315
"It was a *20 hour* take-home project. That is literally half of a normal working week. I was so flabbergasted that it was literally *10x* the length of my previous take-home that I asked the recruiter, exactly how many people have actually gone through the take-home? Sheepishly, he said none, and I said, wow, what a surprise, who'd have thought? After that, I told the recruiter to tell the founders that I'm pretty sure only people with no life would want to join their company (which is likely exactly the kind of person they're looking for), and then I hung up the phone.",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.421359
"Good riddance, and may God have mercy on the soul of whomever they filled that position with. And that layoff I was a part of? I'm doing a lot better now at a larger company, getting paid more and doing less work. Startups are something else, man.",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.421399
"What do I do? I've sent him resources, tutorials, gave him instructions on how to do it.",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.421428
what data analyst/data science does in the job? can a computer engineer be one?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.421450
"people with a CS/computer engineering degree working as data analyst, what is your job like?",,medium,mixed,feature_engineering,reddit-cscareerquestions,,2025-11-21T13:06:10.421472
"For those of you who have a similar background to me and broke into a data science role, how did you do it? Were there any hurdles dealing with recruiters or hiring managers? What kind of interview questions will they ask you and what will they expect your base of knowledge to be?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.421508
My Job Title for the Past 2 Years has been Data Scientist. I‚Äôve scienced very little data. How should I brand myself on Linkedin?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.421551
"I worked at a startup where priorities were in flux, I‚Äôve mainly done data engineering if anything but have even dabbled in frontend. Should I just label myself fullstack developer?",,medium,mixed,feature_engineering,reddit-cscareerquestions,,2025-11-21T13:06:10.421580
"2. On the off chance I do get an interview for a data science position, wtf am I going to say? The amount of bluffing I‚Äôd have to do is unfathomable. My stats skills have completely stagnated the past few years.",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.421610
"Other people claim to have recruiters constantly contacting them, even around this time of year with the holidays, and I‚Äôve had no such luck. How should I brand myself? Getting laid off in feb so it‚Äôs of more interest to me now.",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.421641
"Hi, I'm kind of at a crossroads midway thru college where I'm honestly unsure what I want to do for the rest of my life. I was originally majoring in something else and am kind of considering a switch to the SWE track. The only problem is that I might not have enough time to complete the CS degree. I am contemplating adding an extra year to do the CS track if I decide to completely make the switch, but I was wondering if there was value within this field as a data science or math graduate?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.421687
"I'm asking this since I currently am doing a degree in econ and math, but I was also very interested in data science. I was wondering if this could be applicable enough for gaining a role in SWE? (obviously CS is more directly applicable, but I'm asking from a hiring perspective) This is also assuming that I do projects/clubs, leetcode grinding for interviews, and so forth. Is it advisable for me to do one of these, or should I consider biting the bullet and add an extra yr for a CS degree?",,medium,coding,,reddit-cscareerquestions,,2025-11-21T13:06:10.421716
"Women who left tech, when did you leave and why?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.421738
"What made you leave tech and when did you do so in your career?  Did you ever regret your decision?  If you're thinking about leaving tech, what is making you consider that decision?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:10.421762
Is tech job market really cooked ?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.163052
"I am SWE with 8 YOE. Nothing too niche, full stack developer that knows a few web dev tech stacks with most recent titles of senior and tech lead. No AI or ML. I was laid off in June. Prepared hard, polished my resume with AI many times, applied to between 200-300 jobs in the span of 2 months. Got about 15 interviews, 4 offers. I think I could get more offers tbh but after I found the company I really liked I accepted an offer and stopped the interview process with the rest. I interviewed with Capital One, Visa, UKG, Amazon, Circle, Apollo, Citadel, FICO, GM and some no names or startups. That‚Äôs all to say that after reading reddit I was anxious to even apply but I think I got a decent amount of interviews and negotiated my offers to be either at the higher end of the salary range for the role or even above advertised. I do recognize it‚Äôs much harder for junior engineers these days but is there really a shortage for experienced engineers? I haven‚Äôt felt that. I‚Äôm not even a native English speaker although I do speak English fluently. I‚Äôm in the US. I also didnt lie on resume or cheated during coding rounds. Some of them I solved 100%, some not. For example for C1 I got 450/600 points on CodeSignal and still got a callback and an offer after clearing their power day. Ask me anything I guess. Happy to help someone if I can. No referrals though, sorry. I‚Äôve just started a few weeks ago, too early to refer especially someone I don‚Äôt personally know. Here are a few things that I believe gave me an edge or worked in my favor:",,medium,coding,,reddit-cscareerquestions,,2025-11-21T13:06:13.163179
"Just had an interview with HR about a senior devops python engineer position. This is interview 3 after a video interview, technical test and HR casually drops that it's a being your own device company. Like are you guys for real? You go through the hassle of looking for a senior engineer and you can't get them a dedicated laptop separate from their own personal life not to mention the safety of your IP? I find that shocking and disrespectful. I've been applying for jobs for months and I would rather continue my freelance practice than be subjected to the equivalent of a sweatshop. Needless to say I just dead face told her I'm not going to waste your time after she mentioned this is company policy. Rant over.",,medium,coding,statistics|python,reddit-cscareerquestions,,2025-11-21T13:06:13.163364
How many ML roles are bullshit?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.163385
"I used to work at Bloomberg in their ""AI group"".  I was hired as a ""research engineer"".  Some people were doing some actual ML work but a ton of people weren't doing anything even close to ML.  The weird part was that they were pretending they were.  They would go to top-tier ML conferences and conduct ML interviews and have reading groups but their actual role was nothing ML-related at all.  For myself I was working on maintaining DB clusters the whole time - I asked to do ML work but they wouldn't let me (I don't think there was any for me to do).  The team I was on did nothing ML-related but had ""AI"" in its name.  It felt like a big LARP.  Fortunately I eventually moved on to a better place but I'm curious how normal this is.  Is AI just a giant bubble with a bunch of people just pretending they're doing it?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.163449
"I see a lot of questions on here about whether it's necessary to go to a top whatever school, or whether you're screwed if you go to a public school or a no-name school, or ""will i ever make it to GOOGLE if i don't go to Stanford!?"". The short answer is: no, it's clearly not necessary, but of course it helps. My school was so small (less than 10 CS majors in my graduating class) that we didn't even have a career fair, let alone tech company recruiters visiting.",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.163634
"As I expected, the first week was a struggle. I was getting lost with Leetcode easy problems. Wtf was a trie again? Etc. During this time, I also wanted to up the stakes and not ""waste"" my preparation, so I cold applied to a ton of roles. Probably over 150. I went through [the easy application list](https://github.com/j-delaney/easy-application), cmd-clicked every company I recognized, and applied to any and all relevant roles.",,medium,coding,,reddit-cscareerquestions,,2025-11-21T13:06:13.163663
"Another thing I got good feedback on was my level of engagement. Prior to every interview, I looked up all my interviewers, any engineering blog posts, recent company news, etc. This made it easy to ask things like, ""I was looking at the recent announcement from [YOUR AMAZING COMPANY], how do you feel about it?"" or ""I saw that blog post your team did on BigQuery, what were some of the challenges you guys faced in refactoring your pipelines?"" I can't objectively back this up, but I do feel like this aspect is both overlooked and low-hanging fruit. (Plus, shouldn't you be curious about your future company?)",,medium,coding,sql|feature_engineering,reddit-cscareerquestions,,2025-11-21T13:06:13.163697
* What first attracted you to [AMAZING COMPANY] and what has helped keep you here over the years?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.163761
* What are some challenges your team is currently facing?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.163815
* What are you most excited about regarding the future direction of [AMAZING COMPANY]?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.163842
* Walk me through the development workflow/process: do you guys do scrum or standups? Pull requests? How are tasks determined and assigned?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.163871
* What are some projects I would work on in my first 90 or 180 days here?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.163893
"* What did you work on when you first got here, or alternatively, tell me about the project you're most proud of?",,medium,behavioral,,reddit-cscareerquestions,,2025-11-21T13:06:13.163918
"* (to hiring managers/VPs/directors) When you think of a successful software engineer at [AMAZING COMPANY], what are the most common traits that come to mind?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.163970
"* Space-time trade-off! That is, for better time complexity, try using auxiliary data structures. E.g., do something in a single pass over an array‚ÄîO(N) time‚Äîby using a hash table‚ÄîO(N) space‚Äîvs. doing something in multiple passes‚ÄîO(N ^ 2)‚Äîwithout using any extra space‚ÄîO(1). What information can I store to save time? (Another example: O(1) get_max method for a Stack class stores extra information (the max at and below each element) to save time (instead of iterating through the stack O(N)).)",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.164046
"* Does solving the problem for size (N ‚Äì 1) make solving it for size N any easier? If so, try to solve recursively and/or with dynamic programming. (Using the max/min function can help a lot in recursive or dynamic programming problems.)",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.164091
"Have you ever wondered what the hiring process was 20 years ago compared to today? Probably not, but I'll tell you anyway.",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.164177
"On the opposite end - holy fucking shit does this pay well.  MY. FUCKING. GOD.  5 years ago, those that got $300K were lucky to jump in the right company at the right time with the right options, were a super genius, someone who is some major thought leader, or some Senior Director.  Now a schmuck like me can get near $300K.  This is crazy.  I joined a company for $180K in 2017 in total. compensation, and I was ecstatic.  In 2012, I think I was rightly paid at $120K or something like that.  Now I just accepted an offer for $280K.  This is nice, but also a bit scary.  I've been through 2 different downturns.  What's going to happen if there's another downturn and these crazy salaries whither away?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.164277
"Recruiting is also way different.  LinkedIn is awesome, because I know how Yakov Smirnoff feels when he talks about Soviet Russia.  On LinkedIn...Jobs come to you!  Of course, since it is LinkedIn, you got to wade through all these useless intros.  It's a full time job.  I think the first week I said I was actively looking, I got 30 pings.  Everyone wanted a half hour conversation.  Many of them didn't bother reading my requirements.  No, I am not a front-end engineer and no I don't want to move to Seattle - why do you want to talk?  Many just plain ghosted me after I replied with something like, ""I am interested and I would like to know more.""  Like, what did you want, me to show a picture of myself jerking off to Tim Cook or something or in order to get a reply back from you?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.164416
"2) I always ask for salary.  Weed out those that say, ""it depends.""  Depends on what?  My experience?  The exact same experience that you can see on LinkedIn as we are talking right now?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.164462
"YouTube (full video overview, highly recommend):¬†[https://www.youtube.com/watch?v=Bt80vSyMlPg](https://www.youtube.com/watch?v=Bt80vSyMlPg)",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.164523
2. Not applying for new grad roles in the same timeline as above.  Why did you wait to graduate before you seriously started the job search?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.164565
3.  Not having projects on your resume (assuming no work xp) because you haven‚Äôt taken the right classes yet or some other excuse.  Seriously?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.164610
"5.  Missing scheduled calls, show up late, not do basic stuff.  I had a student schedule an info interview with me, no show, apologize, reschedule, and no show again.   I‚Äôve had others who had reached out for a coffee chat, not even review my LinkedIn profile and ask questions like where I worked before.  Seriously?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.164659
"I have no idea what they mean. I should just learn how to AI by watching videos? Makes no sense to me, so I thought maybe I‚Äôm missing something. What do they mean when they say we should develop AI skills as developers? 99% of us are web devs.",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.164714
"Has anyone discovered that they do not have imposter syndrome, and that they are a genuine imposter?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.164755
"I'm curious to find out since I tend to only hear about people overcoming Imposter Syndrome, but never about those who were genuine imposters who left the field. What do these people move on to?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.164788
I honestly don't know what to feel about this. I'm not too beat up about it because I already chalked it up as a rejection when they ghosted me. But I also feel slightly annoyed and amused that he would just straight up tell me this. Is this common? Have any of you run into a situation like this before?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.164843
Should i resign and look for a new internship or every job that's  has to do with machine learning will be like that.?,,medium,ml,,reddit-cscareerquestions,,2025-11-21T13:06:13.164874
"8. Does solving the problem for size (N ‚Äì 1) make solving it for size N any easier? If so, try to solve recursively and/or with dynamic programming.",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.164973
"13. Not quite the same as N-1, but sometimes a divide-and-conquer approach is what is necessary. If I know the answer for exclusive parts of the problem, can I somehow combine to get the final answer?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.165009
"Want to work at a startup in New York? A Big N in Colorado? Open to either? You can filter jobs by state(s), and company type(s) (Big 4, Big N, Unicorn, Fortune 500, Startup, Other).",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.165055
"What should we take away from that statement? Does this mean its better to contribute to open source projects than participate in competitive coding? Besides, why did Google itself conduct APAC last year with the intention of hiring graduates, if their own research shows otherwise?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.165105
"Who am I and why should you care - Senior QA Manager with 20+ years in software industry. Maybe you shouldn't care, but you're already here, so why not read it?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.165168
"So, what to answer when the dreaded question of ""what's your expected compensation"" comes up?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.165192
"1. First and foremost you should know that nobody will turn your down because you asked for more money than they are ready to pay. They will say ""Actually our current rate is X, would you be willing to work with that?"". If you say yes they'll forget what you asked for 10 seconds after that.",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.165234
- What's your expected compensation?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.165253
"- Right, so the maximum we're ready to pay for this role is 145K, would that work for you? For benefits we offer 4 weeks of vacation, 5% RRSP match, etc.",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.165281
"""I've received a job offer from another company for &lt;what your offer says +10% or +10K, whichever is higher&gt;. Thing is, I would really prefer to work for you - the job sounds a lot more interesting, and I think we're a better fit. Do you think there's some wiggle room for the compensation?"". Be prepared to answer the question of ""what company is that"" (just name a company that exists but doesn't sound exciting. Like AT&amp;T or Bank of America or whatever. Bonus points is if you name their competitors. I've helped couple of my friends and myself get a higher offer this way after the initial offer was already made.",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.165352
- Oh you pay less because it's gaming so you're basically getting paid for playing games? Fuck you.,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.165376
- Oh you pay less because there's a ping pong table? You mean I have to come to the office *and* get paid less? Fuck you.,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.165402
"- Oh it's oil and gas industry and they want to pay less because it's tough times and oil is cheap? FUCK YOU TWICE. I'm not beneath working for oil and gas but my rate will be at least 30% more than the market average, not less.",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.165437
"They offer you less money than the average but dangle ""excellent career opportunity"" in front of you. As a general rule you should know that this means that whatever promotion you're looking at you'll still be getting less money than the average for that role. Nobody but you can determine whether the opportunity is worth the paycut, but don't go into it thinking with promotion will come the $$$. It won't most likely they'll throw you a title, 5x more job and like 5K extra per year. It's great to have that promotion on your resume but do the math. You're going to stick around at least a year, preferably two after promotion before getting another job at that level. Plus a year to get there. If you're getting 20-30K below average annually that adds up to 60-90K in three years. Is it worth it? Only you can decide, but you need to understand that these are real money **you're paying** to get that promotion (if they give it to you).",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.165541
"Before the existence of LeetCode and CTCI, how did top companies hire top talents in 00s, 90s, 80s?",,medium,coding,,reddit-cscareerquestions,,2025-11-21T13:06:13.165565
"I don't mind the grinding, it's just a daily mental workout. But I am very curious to learn if anyone of you (respected industry veterans) could share your experience in the 2000s, 1990s, or 1980s?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.165598
What tool did you use to detect great talents for your company?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.165619
Did you also ask data structure and algorithm questions or was it more domain specific?,,medium,coding,,reddit-cscareerquestions,,2025-11-21T13:06:13.165635
What if you were hiring a junior? How did you adapt your strategy?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.165656
I just got an interview for a ML position at a startup and I don't know a lot of ML. Does anyone have tips to ace the interview?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.165686
"Don't know a lot of ML but I'm furiously trying to learn. I have a B.Sc. in physics so the main obstacle for me is the programming, not the math. Does anyone have any experience in interviewing for ML scientist positions? I explicitly stated on my cover letter that I'm not very knowledgeable about ML but I'm very interested and learning in my own time. What kind of technical things should I know for the interview?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.165739
Are US companies not hiring international students?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.165764
"I'm an international grad student about to complete my degree in spring. As is the case with every international student, I have racked up a bunch of student loans back in my country. The only sustainable way to pay it off would be to work in the US for a few years and then go back once the amount is reduced. Hence, I urgently need jobs. But almost every job description specifies that they will not sponsor a work visa. Even internships (they don't even consider that I can use my OPT to work for up to 3 years without sponsorship). Career fairs are no different. The representatives bluntly told me that their company policy bars them from considering international students for their positions. Why is this suddenly the case? I remember getting responses from companies in October 2022, and I've also been interviewed by companies back then, so this has to be a new development. Is this new policy here to stay? Is there any chance for us to wait this out? The timing of this development is so unfortunate is that its too late for me to maintain my F1 status by applying for a PhD, but I have no option of giving up as I will undoubtedly face financial ruin if I go back to my country without any sort of work experience.",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.165893
How is being a Jack of all trades looked upon in this field?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.165921
I don't know if this is good or bad from a resume point of view. Please provide your insights on that. Should I include all of them in the resume (or at least the big ones) or restrain to only the ones I can answer theoretical questions on if I were to be asked in an interview?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.165962
"What are the skills need for one to pass the interviews and work as an engineer at an ML-oriented company (for example, OpenAI, DeepMind) and what are type of problems engineers solve there on a daily basis?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.166000
"I am interested in ML (doing courses, but no real projects yet), have decent coding skills and several years of experience under my belt. I wonder, what kind of a programmer can get into such companies, what do they do there and if it's similar to the kind of work done in other top-tier companies?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:13.166043
I don't mean to scare people off bootcamps- they worked for me (although I already had a humanities BA). But I do want to warn people who are thinking about a bootcamp as a *shortcut* to get into the industry without the effort or cost of a BSCS. Is it possible? Yes. Is it easy or guaranteed? No.,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:15.757776
"So why does this subreddit feel so negative compared to those numbers? Because the voices dominating here are FAANG engineers or startup employees, and their experiences are extreme. Life inside FAANG is often miserable. Long hours, constant pressure to ship, endless internal politics, and the looming threat of layoffs make it feel like a treadmill you can never step off. Software is the company‚Äôs entire product, so everything you do is under constant scrutiny and pressure. Burnout is common, and that is exactly what this sub amplifies.",,medium,case,,reddit-cscareerquestions,,2025-11-21T13:06:15.757860
Has anyone else had this experience?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:15.758266
"Lone programmer at a non-tech company, what's the highest title I could get?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:15.758301
"***TLDR:*** *I think I've been responsible for more than what ""programmer"" would reflect in my resume. Would it be okay for me to ask for Full Stack Dev or Junior Dev title? Software Engineer? These would look better on my resume and make it easier to get higher positions when I apply somewhere else right?*",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:15.758346
* The highest paid intern actually has 6 years of prior experience. [The DoD comment is here](https://www.reddit.com/r/cscareerquestions/comments/82469b/official_salary_sharing_thread_for_interns_march/dv7o1xp?utm_source=share&amp;utm_medium=web2x),,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:15.758396
* The highest paid experienced dev made 400K base salary. [The comment is here](https://www.reddit.com/r/cscareerquestions/comments/ayndpv/official_salary_sharing_thread_for_experienced/ei2edm1?utm_source=share&amp;utm_medium=web2x),,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:15.758425
I'm looking for resources to practice math and statistics ahead of an interview for a Data Scientist position. Is there any equivalent to LeetCode or HackerRank for this area?,,medium,coding,statistics,reddit-cscareerquestions,,2025-11-21T13:06:15.758444
"Given this take-home assessment, 24 hours to complete. Am I dumb or is this insane?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:15.758472
"I have no experience/never claimed to have experience in Databricks, AWS, data architecture, or data warehouse management. I have interacted with a data warehouse, made ETL programs, and have used SQL- and that's pretty much it. I'm not sure if this assessment is a test to see how I will approach this, or if the recruiter picked the complete wrong candidate. How should I approach this? Should I be honest with the recruiter that this is out of my domain? It says this should take about 1 hour, I am about 6 hours in and have only scratched the surface of some of the stuff mentioned here.",,medium,coding,statistics|sql,reddit-cscareerquestions,,2025-11-21T13:06:15.758506
"I figure I may as well go for it, since I don't really have that much to lose and potentially a lot to gain, but it just seems comical to me that I'm even being given an interview for the position when I never gave any indication that I have a background in advanced statistical analysis. Is it possible that the title doesn't reflect the true nature of the position? Also, what are some good resources to learn as much as I can about modeling in the context of direct marketing strategy?",,medium,ml,nlp,reddit-cscareerquestions,,2025-11-21T13:06:15.758565
tl;dr Offered a statistician job even though never studied advanced statistics. Am I definitely underqualified based simply on job title? What are some resources to learn as much as possible before interview?,,medium,stats,statistics,reddit-cscareerquestions,,2025-11-21T13:06:15.758587
"Got the job but I feel like I'm very behind, how can I improve fast?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:15.758609
"What sort of courses should I take so I can also slowly start understanding what's happening and not feel out of place? I do prefer video lectures rather than a book. It can also be paid. Additionally, is there any advice you guys can give me to succeed in this role and successfully keep it? I feel like the last 4 years I've been playing little league and have only had to worry about such small things and picked up some bad habits, but now I'm in the big leagues and I feel so out of place.",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:15.758654
"* Using AI to send emails. Come on people lol, you're polluting the environment to ask ChatGPT to write a thank you email?",,medium,coding,,reddit-cscareerquestions,,2025-11-21T13:06:15.758683
* The format doesn't really matter a whole ton? I've seen resumes that comes in dogwater formats and the most ATS unfriendly layouts that makes it to screening. Just don't make it crazy and make sure its in PDF always,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:15.758712
* Most positive post is:¬†*‚ÄúCant seem to ‚Äòstick‚Äô with a CS career choice?...‚Äù*¬†(sentiment score: 0.999),,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:15.758766
How much am I supposed to ignore the job requirements in a job posting?,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:15.758965
"I‚Äôve been told by a few people to ignore the job requirements or required experiences section of job postings. That those are wishlists not requirements, even if they explicitly say requirements in the ad. Is this generally true? If so, how much should I ignore or subtract from these requirements?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:15.759003
"I‚Äôve also been put off when seeing the number of applicants statistics, especially on LinkedIn. Within one hour, a job has over 100 applications. I don‚Äôt feel like applying to a job with hundreds of applicants (when I have no experience) is useful. But I‚Äôve heard a lot of those applicants are from foreigners looking for a visa sponsorship. Are hiring managers really sifting through hundreds of applications to find the ones to interview, or so they go through the first 50-100 until they have some candidates?",,medium,stats,statistics,reddit-cscareerquestions,,2025-11-21T13:06:15.759043
"If You Were a New Grad, WWYD?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:15.759070
"BUT THEN I decided to ask what would be a regular workday at the company. The answer: ""well, we want an internal communication system to use instead of email, and we are just looking for some one to develop a web interface. Also we want to be able to edit excel files simultaneously, can you do that?""",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:15.759107
"Uh. Really? Why the fuck do you want a ""data scientist"" for that?  How about hiring a web developer? OR JUST USE SLACK AND GOOGLE DOCS YOU FUCKING DUMBASSES.  Are those guys  posting ""data scientist"" positions just because it looks cool and trendy, and have no idea what it actually means, or am I missing something here?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:15.759140
"Now on to the question: The interviewer kinda implied that the job is mine if I want it. Do you guys think is it worth to accept this position? It seems to be easy work and this company pays really well. Also, its one of the largest companies in the world so it kinda looks good on the CV. Should I accept the job and keep easy money flowing in while I look for something better?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:15.759177
"I am a .NET software engineer with about 3 YOE, I have recently graduated master's in Interaction Design. My master's was a scholarship, and I applied to many universities and funds, and this is the one that worked out. So I went with it hoping for a better next job and hoping to expand my network abroad. Before my master's, I hated my job, we weren't doing actual work as contractors and there was micromanagement and master's abroad was my way out unemployed for a year. I finished recently and I started job hunting, I did a couple interviews here and there with no luck. I found out that one of the companies interviewed me for statistics for example, just to add my CV to the pool. As for another one, I applied too early and wasn't ready for the online assessment which was an exam of 3 Leetcode medium questions. And I was so invested in getting a job so soon because I was so scared of unemployment. I also interviewed for a product design role, because I expanded my skill set with my master's. I did well, but they chose someone else because they have experience in visual design, which I don't, and they expressed that and gave detailed feedback. So I ended up looking left and right, in all directions for a job with no specific field in mind. Recently, my old employer reached out, they have a new project and they are trying to recruit me for a product vacancy. Once they reached out, I spoke to an old colleague that I trust from my previous company, and he happens to be a lead at this new project. I sat down and spoke to him because I trust his advice. He was straightforward and clear that this is a project with no clear future and that if I am ready to join back with an undetermined future of this project, then I can join but I should keep job hunting outside. It's like joining back for money until I find something else. While I was speaking to him, he was overly straightforward and in a tough love tone, said that I was distracted and that I applied for some roles too soon while I wasn't ready and that I should be more patient, and he asked some questions that made me question my whole career choices and my master's and he asked me if I was able to define what an LLM is and what I know about AI and that this type of knowledge is very important nowadays, but I think I was too sensitive and got offended in a way. Tomorrow I am meeting with my old project manager as I said, and he'll probably speak about this new project in a way where he'll lure me into joining back. He might have development roles, I will ask about that, but he will try to direct the conversation to serve his purposes of expanding the new project team. I am also not ready to be the only product manager/owner employee, because I am a fresh grad and I need a mentor in my opinion. The advice I need is related to my expertise. What can I do to find my focus and be able to get a job and prove that I have what employers want? I know I am too distracted, how can I fix this.",,medium,coding,statistics,reddit-cscareerquestions,,2025-11-21T13:06:15.759296
I feel like I‚Äôm not smart enough for this??,,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:15.759322
"I got an internship doing data science for the federal government instead, but would be more interested in pursuing a path in the private industry. My program would allow me to take the time off again to do another internship, and the recruiter didn't mention a limit to when I could apply again (just to keep in touch). I have applied again for the same internship for Summer 2026, is it worth reaching out to the recruiter to let them know that I applied again? Or would it be better to reach out to the person who interviewed me?",,medium,mixed,,reddit-cscareerquestions,,2025-11-21T13:06:15.759372
