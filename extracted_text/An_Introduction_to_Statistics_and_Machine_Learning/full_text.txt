
================================================================================
PAGE 1
================================================================================

Matthias Plaue
Data
Science
An Introduction to Statistics and
Machine Learning


================================================================================
PAGE 2
================================================================================

Data Science


================================================================================
PAGE 3
================================================================================

MatthiasPlaue
Data Science
An Introduction to Statistics
and Machine Learning


================================================================================
PAGE 4
================================================================================

Matthias Plaue
MAPEGY GmbH
Berlin, Germany
ISBN 978-3-662-67881-7 ISBN 978-3-662-67882-4 (eBook)
https://doi.org/10.1007/978-3-662-67882-4
© Springer-Verlag GmbH Germany, part of Springer Nature 2023
Translation from the German language edition: “Data Science” by Matthias Plaue, © Der/die Herausgeber
bzw. der/die Autor(en), exklusiv lizenziert an Springer-Verlag GmbH, DE, ein Teil von Springer Nature
2021. Published by Springer Berlin Heidelberg. All Rights Reserved.
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of
the material is concerned, specifically the rights of translation, reprinting, reuse of illustrations, recitation,
broadcasting, reproduction on microfilms or in any other physical way, and transmission or information
storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology
now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication
does not imply, even in the absence of a specific statement, that such names are exempt from the relevant
protective laws and regulations and therefore free for general use.
The publisher, the authors, and the editors are safe to assume that the advice and information in this book
are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or the
editors give a warranty, expressed or implied, with respect to the material contained herein or for any errors
or omissions that may have been made. The publisher remains neutral with regard to jurisdictional claims
in published maps and institutional affiliations.
This Springer imprint is published by the registered company Springer-Verlag GmbH, DE, part of Springer
Nature.
The registered company address is: Heidelberger Platz 3, 14197 Berlin, Germany
Paper in this product is recyclable.


================================================================================
PAGE 5
================================================================================

For Katja.


================================================================================
PAGE 6
================================================================================

Preface
Preface to the original German edition.
I wrote a large portion of this book in 2020, the year that saw the start of the
COVID-19 pandemic. Data analysis was prominent in the media at the time,
withgeographicmapsshowingparticularlyaffectedareas(oftenbrightlycolored
inred)andtimeseriesgraphsillustratingtheincreaseanddecreaseofconfirmed
cases or available hospital beds. Forecasts based on epidemiological models were
made, and terms like “basic reproduction number” became common knowledge.
These analyses and forecasts were rightfully used as the basis for significant
political decisions, as they provide solid numerical evidence. However, due to
their statistical nature, such analyses only allow for conclusions and actions to
be taken with a high degree of uncertainty.
The world has been shaped by the advent of the information age in the twenty-
first century. Significant advances in artificial intelligence are paving the way
for its use in everyday life: search engines scour the World Wide Web for
relevant content and attempt to capture the meaning of user input. Algorithms
automatically sort vacation photos by image content, and “smart” household
appliances are becoming more and more commonplace.
Whether we refer to statistics, big data, or machine learning, there can be little
doubt that data science will continue to play a significant role in the coming
decades. This book is designed to help its readers get started in this exciting
and forward-looking field.
In my opinion, a successful study of data science requires two pillars. First,
aspiring data scientists should gain practical experience by “playing” with
data in a meaningful way, for example by programming their own models and
performing their own parameter studies. Numerous tutorials, code examples,
and datasets are available on the web for this purpose. The second important
pillar is a comprehensive knowledge of methods and a deep understanding of
the principles and ideas underlying data science methodology. This book helps
arrive at such knowledge and understanding.
VII


================================================================================
PAGE 7
================================================================================

VIII Preface
Iwouldliketoexpressmyspecialthankstomydoctoraladvisorandoldpartner
in crime Mike Scherfner. Furthermore, I also thank Fred Hamprecht, Günter
Bärwolff, Hartmut Schwandt, and Peter Walde for their guidance in my career
as a data scientist. I am grateful to Alex Dirmeier for proofreading, and for his
knowledgable and valuable comments. Finally, I would like to acknowledge the
editors and staff of Springer who supported and made this project possible—my
special thanks go to Andreas Rüdinger.
August 29, 2021
Berlin, Germany Matthias Plaue
Preface to the revised, English edition.
This text is a translation of my German textbook, Data Science – Grundlagen,
Statistik und maschinelles Lernen. The intention of publishing this translation
is to make the content accessible to a wider, international readership. To that
end, I have replaced some of the original book’s application examples to make
them more accessible to this audience.
As I continued working on the manuscript, it became clear that it would not
merely be a translation but a complete revision of the original book. I corrected
a number of errors that appeared in the German edition, and I would like to
thank Andreas Zeh-Marschke and David Conti for identifying some of them.
I have added many new references to the literature, some of which highlight
more recent developments. This edition now includes exercises for readers to
test their understanding of the subject matter (Chap. A).
I have also added a quick reference for the tools from linear algebra and
calculus used throughout the book, making the book more self-contained
(Chap.B).Otheradditionsincludesubsectionsonstackedandgroupedbarcharts
(Sect. 2.2.3.2), power transforms (Sect. 4.4.1.1), regularization (Sect. 6.1.2.1),
and performance measures for regression (Sect. 6.1.3.1).
I thank Stefanie Adam and Andreas Rüdinger from Springer for their support,
and I am grateful to Michael Wiley for proofreading the manuscript.
To prepare the manuscript, I found the machine translation service DeepL1 to
be helpful. Additionally, the virtual assistants ChatGPT2 and Claude3 were
consulted to copy-edit some parts of it.
July 1, 2023
Berlin, Germany Matthias Plaue
1 https://www.deepl.com/
2 https://openai.com/product/chatgpt
3 https://www.anthropic.com/product


================================================================================
PAGE 8
================================================================================

Contents
Introduction.................................................... 1
Part I Basics
1 Elements of data organization .............................. 11
1.1 Conceptual data models................................... 12
1.1.1 Entity–relationship models .......................... 12
1.2 Logical data models ...................................... 13
1.2.1 Relational data models.............................. 14
1.2.2 Graph-based data models ........................... 17
1.2.3 Hierarchical data models ............................ 19
1.3 Data quality ............................................. 21
1.3.1 Data quality dimensions............................. 22
1.4 Data cleaning ............................................ 23
1.4.1 Validation ......................................... 23
1.4.2 Standardization .................................... 24
1.4.3 Imputation ........................................ 24
1.4.4 Augmentation...................................... 26
1.4.5 Deduplication...................................... 27
References ................................................... 33
2 Descriptive statistics........................................ 35
2.1 Samples ................................................. 35
2.2 Statistical charts ......................................... 37
2.2.1 Bar charts and histograms........................... 38
2.2.2 Scatter plots....................................... 39
2.2.3 Pie charts, grouped and stacked bar charts, heatmaps... 41
2.3 Measures of central tendency............................... 43
2.3.1 Arithmetic mean and sample median.................. 43
2.3.2 Sample quantiles ................................... 48
2.3.3 Geometric and harmonic mean ....................... 49
IX


================================================================================
PAGE 9
================================================================================

X Contents
2.4 Measures of variation ..................................... 50
2.4.1 Deviation around the mean or the median ............. 51
2.4.2 Shannon index ..................................... 53
2.5 Measures of association ................................... 54
2.5.1 Sample covariance and Pearson’s correlation coefficient.. 55
2.5.2 Rank correlation coefficients ......................... 56
2.5.3 Sample mutual information and Jaccard index ......... 58
References ................................................... 64
Part II Stochastics
3 Probability theory .......................................... 67
3.1 Probability measures...................................... 68
3.1.1 Conditional probability ............................. 72
3.1.2 Bayes’ theorem..................................... 76
3.2 Random variables ........................................ 79
3.2.1 Discrete and continuous random variables ............. 79
3.2.2 Probability mass and density functions................ 82
3.2.3 Transformations of random variables.................. 85
3.3 Joint distribution of random variables....................... 88
3.3.1 Joint probability mass and density functions ........... 88
3.3.2 Conditional probability mass and density functions ..... 90
3.3.3 Independent random variables ....................... 91
3.4 Characteristic measures of random variables ................. 92
3.4.1 Median, expected value, and variance ................. 92
3.4.2 Covariance and correlation .......................... 98
3.4.3 Chebyshev’s inequality..............................102
3.5 Sums and products of random variables .....................103
3.5.1 Chi-squared and Student’s t-distribution .............. 107
References ...................................................110
4 Inferential statistics ........................................ 111
4.1 Statistical models ........................................112
4.1.1 Models of discrete random variables ..................112
4.1.2 Models of continuous random variables................115
4.2 Laws of large numbers ....................................118
4.2.1 Bernoulli’s law of large numbers......................118
4.2.2 Chebyshev’s law of large numbers ....................123
4.2.3 Variance estimation and Bessel correction .............125
4.2.4 Lindeberg–Lévy central limit theorem.................126
4.3 Interval estimation and hypothesis testing ...................129
4.3.1 Interval estimation .................................129
4.3.2 Z-test ............................................ 131
4.3.3 Student’s t-test ....................................134
4.3.4 Effect size .........................................136
4.4 Parameter and density estimation .......................... 137


================================================================================
PAGE 10
================================================================================

Contents XI
4.4.1 Maximum likelihood estimation ......................139
4.4.2 Bayesian parameter estimation.......................145
4.4.3 Kernel density estimation ........................... 149
4.5 Regression analysis ....................................... 151
4.5.1 Simple linear regression ............................. 151
4.5.2 Theil–Sen regression ................................ 156
4.5.3 Simple logistic regression ............................ 157
References ................................................... 159
5 Multivariate statistics ...................................... 161
5.1 Data matrices............................................ 161
5.2 Distance and similarity measures ........................... 163
5.2.1 Distance and similarity measures for numeric variables ..164
5.2.2 Distance and similarity measures for categorical variables166
5.2.3 Distance and similarity matrices......................168
5.3 Multivariate measures of central tendency and variation .......170
5.3.1 Centroid and geometric median, medoid............... 171
5.3.2 Sample covariance and correlation matrix .............173
5.4 Random vectors and matrices .............................. 174
5.4.1 Expectation vector and covariance matrix ............. 174
5.4.2 Multivariate normal distributions.....................176
5.4.3 Multinomial distributions ........................... 179
References ................................................... 181
Part III Machine learning
6 Supervised machine learning................................185
6.1 Elements of supervised learning ............................ 187
6.1.1 Loss functions and empirical risk minimization .........190
6.1.2 Overfitting and underfitting ......................... 192
6.1.3 Training, model validation, and testing................196
6.1.4 Numerical optimization ............................. 202
6.2 Regression algorithms..................................... 206
6.2.1 Linear regression ................................... 206
6.2.2 Gaussian process regression.......................... 212
6.3 Classification algorithms................................... 216
6.3.1 Logistic regression.................................. 216
6.3.2 K-nearest neighbors classification ....................220
6.3.3 Bayesian classification algorithms..................... 221
6.4 Artificial neural networks.................................. 229
6.4.1 Regression and classification with neural networks ...... 231
6.4.2 Training neural networks by backpropagation of error ...235
6.4.3 Convolutional neural networks .......................238
References ................................................... 246


================================================================================
PAGE 11
================================================================================

XII Contents
7 Unsupervised machine learning .............................249
7.1 Elements of unsupervised learning ..........................249
7.1.1 Intrinsic dimensionality of data ......................250
7.1.2 Topological characteristics of data .................... 251
7.2 Dimensionality reduction ..................................254
7.2.1 Principal component analysis ........................254
7.2.2 Autoencoders ......................................258
7.2.3 Multidimensional scaling ............................259
7.2.4 t-distributed stochastic neighbor embedding (t-SNE)....260
7.3 Cluster analysis ..........................................264
7.3.1 K-means algorithm.................................266
7.3.2 Hierarchical cluster analysis .........................269
References ...................................................275
8 Applications of machine learning............................ 277
8.1 Supervised learning in practice .............................278
8.1.1 MNIST: handwritten text recognition .................278
8.1.2 CIFAR-10: object recognition ........................280
8.1.3 Large Movie Review Dataset: sentiment analysis .......284
8.2 Unsupervised learning in practice........................... 287
8.2.1 Text mining: topic modelling......................... 287
8.2.2 Network analysis: community structure................288
References ...................................................293
Appendix
A Exercises with answers ..................................... 301
A.1 Exercises ................................................ 301
A.2 Answers.................................................308
References ...................................................324
B Mathematical preliminaries................................. 327
B.1 Basic concepts ........................................... 327
B.1.1 Numbers and sets .................................. 327
B.1.2 Maps and functions.................................329
B.1.3 Families, sequences and tuples ....................... 331
B.1.4 Minimum/maximum and infimum/supremum ..........332
B.2 Linear algebra ...........................................332
B.2.1 Vectors and points..................................332
B.2.2 Matrices ..........................................333
B.2.3 Subspaces and linear maps ..........................335
B.2.4 Eigenvectors and eigenvalues.........................336
B.3 Multivariate calculus...................................... 337
B.3.1 Limits ............................................ 337
B.3.2 Continuous functions ...............................338
B.3.3 Differentiable functions..............................340


================================================================================
PAGE 12
================================================================================

Contents XIII
B.3.4 Integrals .......................................... 342
References ................................................... 347
Supplementary literature .......................................349
Index...........................................................353


================================================================================
PAGE 13
================================================================================

Notation
a:=b assignment, definition; object a is declared
through object or formula b
Z set of integers {0,−1,1,−2,2,...}
N set of natural numbers {0,1,2,...}
{0,1,...,D} set of the first D+1 natural numbers
R set of real numbers
(x ,...,x ) D tupel of elements (e.g., of real numbers)
1 D
RD set of all D tupels of real numbers
]a,b[, [a,b], ]a,b] open, closed, half-open interval with endpoints
a,b∈R
]−∞,b], [a,∞[ improper intervals
x∈A x is an element of the set A
∅ empty set
B ⊆A B is a subset of A
B ⊂A B is a proper subset of A
S A union with finite or countable index set I, e.g.,
i∈I i
S
A =A ∪A ∪A
i∈{2,3,5} i 2 3 5
f: X →Y, f is a map with domain X and codomain Y,
x7→f(x) where each x∈X maps to f(x)∈Y
g◦f composition of maps: (g◦f)(x)=g(f(x))
f (·|θ;β) map x7→f (x|θ;β) from a family of maps, de-
α α
termined by parameters α,β,θ
{x∈A|B[x]} setofallelementsinAthatsatisfythecondition
B
XV


================================================================================
PAGE 14
================================================================================

XVI Notation
|A| number of elements of a finite set A
|B| area/volume/measureofadomainofintegration
B ⊆RD
|x| modulus of a real number x
sgn(x) the sign function: sgn(x)=−1, if x<0 etc.
⌊x⌋, ⌈x⌉ x∈R rounded down/up to the closest integer
x≈y the value x is approximately equal to y (in some
suitable sense)
x≫y the value x is much larger than y (in some suit-
able sense)
x∼ =y objectsxandy arestructurallyidenticalinsome
suitable sense
PK x sum of the form x +x +···+x
k=1 k 1 2 K
P x sum with finite or countable index set I, e.g.,
k∈I k
P
x =x +x +x
k∈{2,3,5} k 2 3 5
QK x product of the form x ·x ···x
k=1 k 1 2 K
⟨x,y⟩ scalar product of two vectors x and y
∥x∥ length/norm of a vector x
f ∝g the vectors/functions f ̸= 0 and g ≠ 0 are
collinear/linearly dependent, i.e., there exists
a scalar/constant λ, such that f =λg
AT transposed matrix; the matrix A after swapping
columns with rows
det(A) determinant of a square matrix A
∢(x,y) angle between vectors x and y
diag(d ,...,d ) a diagonal matrix; square matrix with entries
1 K
d ,...,d on the diagonal, all other elements
1 K
are zero
minA, maxA minimum/maximum (smallest/largest element)
of a (finite) set A⊂R
min{x } minimumofa(finite)setorsequenceofnumbers
n
n
x ,...
1
infA, supA infimum/supremum(largestlower/upperbound)
of a set A⊆R
inf {f(ξ)} infimum of a function f with domain A
ξ∈A
lim n→∞ a n limit of a sequence (a n ) n∈N
lim f(ξ) limit of a function f
ξ→∞


================================================================================
PAGE 15
================================================================================

Notation XVII
lim f(ξ) limit of a function f from above
ξ↘u
∂ f(x ,x ) partial derivative of a (continuously differ-
∂x2 1 2
entiable) function f; alternative notation:
∂ f(x ,x )
2 1 2
gradf(x) gradient of f; column vector of first derivatives
(∂ f)
i
Hessf(x) Hesse matrix of a (twice continuously differen-
tiable) function f: matrix of second derivatives
(∂ ∂ f)
i j
Df(x)= df(x) Jacobianmatrixofa(continuouslydifferentiable,
dx
vector-valued) function f: matrix of first deriva-
tives (∂ f )
i j
∇ f(x,y ,y ) Nabla operator; partial gradient: ∇ f =
y 1 2 y
(∂ f,∂ f)T
2 3
Rb f(x)dx integral of an (integrable) function with bounds
a
a,b∈R
Rb f(x)dx improper integral of a function
−∞


================================================================================
PAGE 16
================================================================================

List of Figures
0.1 Line diagram of changes in temperature ...................... 2
1.1 Entity–relationship diagram ................................ 13
1.2 Node–link diagram ........................................ 17
1.3 Multigraph ............................................... 18
1.4 Property graph ........................................... 19
1.5 Acyclic graph with undirected cycle.......................... 19
1.6 Rooted tree............................................... 20
1.7 Levels of hierarchy in a rooted tree .......................... 20
2.1 Frequency distribution of self-reported body weight ............ 38
2.2 Scatter plot of body height vs. body weight................... 39
2.3 Scatter plot of Broca vs. body mass index .................... 40
2.4 Doughnut chart ........................................... 41
2.5 Grouped bar chart......................................... 42
2.6 Stacked bar chart ......................................... 42
2.7 Bar charts and histograms.................................. 44
2.8 Heatmap and choropleth map............................... 45
2.9 Histogram of a positively skewed distribution ................. 48
2.10 Deviation around the mean and the median................... 52
2.11 Anscombe’s quartet........................................ 63
3.1 Venn diagrams of the probability of events.................... 72
3.2 Cumulative distribution function of a discrete random variable .. 83
3.3 Standard normal distribution ............................... 85
3.4 Chi-squared distribution and Student’s t-distribution ..........109
4.1 Parametric families of probability mass functions ..............119
4.2 Parametric families of probability density functions ............120
4.3 Lindeberg–Lévy central limit theorem........................128
4.4 Confidence intervals for large and small samples...............138
4.5 Fit of a Pareto distribution to higher incomes in Germany ...... 141
XIX


================================================================================
PAGE 17
================================================================================

XX List of Figures
4.6 Normal fit to distribution of body height .....................142
4.7 Yeo–Johnson transforms....................................144
4.8 Data resembling a normal distribution after applying a Box–Cox
transform ................................................145
4.9 Maximum a posteriori estimate of body height with increasing
sample size ...............................................148
4.10 Principle behind kernel density estimation ....................149
4.11 Kernel density estimates of different bandwidth ............... 151
4.12 Time series of average global air temperature with regression line154
4.13 Confidence and prediction bands for linear regression ..........155
4.14 Theil–Sen regression vs. simple linear regression ...............156
5.1 Probability density function of a bivariate normal distribution ..176
5.2 Centroid, geometric median, and covariance error ellipse........180
6.1 Average global air temperature and regression polynomials of
varying degree ............................................193
6.2 Gradient descent .......................................... 207
6.3 Time series of average global air temperature with quadratic
regression polynomial ......................................209
6.4 Time series of average global air temperature with Gaussian
process regression curve ....................................215
6.5 Decision boundary of logistic regression ...................... 217
6.6 Nonlinear classification via logistic regression .................222
6.7 K-nearest neighbor classification ............................223
6.8 Feedforward neural network ................................230
6.9 Sigmoid function ..........................................230
6.10 Neurons and interneural synapses of a nematode ..............239
6.11 Classification with an artificial neural network ................240
6.12 2D convolution in image processing ..........................242
6.13 Architecture of the convolutional neural network VGG-16 ......245
7.1 Data points along a curve .................................. 251
7.2 Covering data points by disks with varying radius .............253
7.3 “Eigendigits” of the MNIST dataset.......................... 257
7.4 Image reconstruction from principal components .............. 257
7.5 Principal component analysis of the MNIST dataset ........... 261
7.6 Autoencoding the MNIST dataset ...........................262
7.7 Sammon projection and t-distributed stochastic neighbor
embedding (t-SNE)........................................265
7.8 K-means clustering........................................272
7.9 Kernel K-means clustering .................................273
7.10 Hierarchical cluster analysis of international cities .............274
8.1 Cross-validation of a K-nearest neighbor model ...............279
8.2 MNIST: false positives for identifying the digit one ............279
8.3 MNIST: false negatives for identifying the digit one............280


================================================================================
PAGE 18
================================================================================

List of Figures XXI
8.4 CIFAR-10: false positives for identifying a cat................. 281
8.5 CIFAR-10: false negatives for identifying a cat ................ 281
8.6 MNIST and CIFAR-10 dataset.............................. 282
8.7 Example code: convolutional neural network ..................283
8.8 Topic maps for family films and science fiction films ...........290
8.9 Collaboration network of actors/actresses..................... 291
8.10 Hierarchical cluster analysis of a collaboration network of
actors/actresses ........................................... 292
A.1 COVID-19 deaths by vaccination status ......................303
A.2 Vaccination status of people that died of COVID-19 ...........303
A.3 Entity–relationship diagram of movie productions .............308
A.4 Frequency of faculty members consulting Wikipedia by field of
expertise ................................................. 309
A.5 Frequency of faculty members citing Wikipedia in academic papers310
A.6 Demographics of the wiki4HE survey ........................ 311
A.7 Selected answers to the wiki4HE survey ......................312
A.8 Probability that two people share a birthday..................313
B.1 Set operations ............................................ 328
B.2 Graphs of exponential and logarithmic functions ..............330
B.3 Points and vectors......................................... 333
B.4 Area of a parallelogram; determinant of a matrix ..............335
B.5 Reflection in the plane ..................................... 337
B.6 Convergent sequence in the plane............................ 338
B.7 Plot of a vector field ....................................... 339
B.8 Normal domain of integration............................... 343
B.9 Graph, contour lines, and gradient of a bivariate function.......346


================================================================================
PAGE 19
================================================================================

List of Tables
1.1 Customer data ............................................ 14
1.2 Heterogeneous, non-standardized data ....................... 24
1.3 Missing attribute values .................................... 25
1.4 Mean substitution ......................................... 25
1.5 Use of imputation classes................................... 26
1.6 Data quality dimensions.................................... 32
2.1 Frequency of human body height ............................ 35
2.2 CDC sample.............................................. 36
2.3 Data types ............................................... 37
2.4 Size of correlation effects ................................... 56
2.5 Rank statistics of school grades ............................. 57
2.6 Correlation coefficients computed for Anscombe’s quartet....... 58
2.7 Contingency table of party preference vs. opinion on migration
control................................................... 60
2.8 Jaccard index as a measure for vote retention ................. 62
3.1 Keyword extraction via pointwise mutual information.......... 75
4.1 Critical values as a function of confidence level ................130
4.2 Critical values as a function of sample size....................135
4.3 Effect size according to Cohen’s d ........................... 137
4.4 Outcomes of a lottery...................................... 143
5.1 Measurements of sepal and petal of iris flowers ................165
6.1 Cost matrix of a spam filter ................................ 190
6.2 True/false positive/negative results .......................... 199
6.3 Confusion matrix for spam detection......................... 201
6.4 Layer types of a convolutional neural network.................243
8.1 Performance of different classifiers applied to the MNIST dataset 278
XXIII


================================================================================
PAGE 20
================================================================================

XXIV List of Tables
8.2 Performance of different classifiers applied to the CIFAR-10
dataset...................................................280
8.3 Positive/negative movie reviews .............................284
8.4 Words that indicate a positive movie review ..................285
8.5 Words that indicate a negative movie review ..................285
8.6 Performance of different methods for sentiment analysis ........285
8.7 Examples of N-grams......................................286
8.8 Performance of naive Bayes classifiers based on N-grams .......286
8.9 Misclassified movie reviews .................................286
8.10 Noun phrases typically associated with certain film genres ......288
A.1 Dirty organization data ....................................302
A.2 University admission rates by department and gender ..........305
A.3 Analysis of university admission rates ........................316
A.4 Performance of classifiers applied to the Oxford Parkinson’s
Disease Detection Dataset ..................................320
A.5 Cluster centroids of customer segments produced by K-means... 321
A.6 Performance of regression models applied to the Concrete
Compressive Strength Dataset ..............................323
B.1 Derivatives of elementary functions ..........................342


================================================================================
PAGE 21
================================================================================

Introduction
AccordingtotheInternationalOrganizationforStandardization(ISO)[1],data
are “a reinterpretable representation of information in a formalized manner,
suitable for communication, interpretation, or processing.” Merriam–Webster
[2] provides another characterization: data are “factual information (such as
measurements or statistics) used as a basis for reasoning, discussion, or calcula-
tion.”
The collection, processing, interpretation, and communication of data with
the goal of obtaining robust and useful knowledge—usually with the aid of
information technology—is the main function of data science.
Intheempiricalsciences,suchasthenaturalsciences,thecollectionandanalysis
of data have long been an essential part of gaining knowledge. Modern physics,
for example, would hardly be conceivable without the interaction of theory
and experiment: the deviations from experimental data reveal the limits of
theoretical models. One success of Newtonian celestial mechanics, for example,
was the precise description and prediction of the motion of planets and other
celestial bodies in the solar system. However, the theory could not explain
the orbital perturbations of Mercury [3] that were measured to a high degree
of accuracy in the nineteenth century by Urbain Le Verrier. These orbital
perturbations could only be explained at a later time through the application
of Einstein’s theory of gravity, the general theory of relativity.
In a business context, the collection and analysis of data have also become
increasingly important. Data can be seen as the raw material from which
knowledge is produced, an economic good. Data analysis supports management
in decision making and in understanding the impact that decisions have on the
business (business intelligence, business analytics). For example, patent
data can be used to show the innovation and networking activities of various
organizations in a competitive environment, informing strategic decisions in
innovation or technology management [4, 5].
1


================================================================================
PAGE 22
================================================================================

2 Introduction
Demographics are another discipline where data analysis is imperative. For
example, statistical data are used to describe regional differences in human
mobility behavior (cf. [6, 7]) and to provide actionable insights for urban
planning.
Results from data analysis can be communicated to humans through language
and through visual and graphical representations. The following diagram shows
time series data on the air temperature measured at two meters above the
ground in the district Tegel in Berlin, Germany for the year 2018 [8]:
40
30
20
10
0
-10
Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec
C°
ni
erutarepmet
ria
Fig. 0.1. Line diagram of changes in temperature
The gray ribbon represents the daily variation between the minimum and
maximum temperatures. The following findings can easily be seen:
• The coldest days that year were in late February and early March.
• Obviously, it is colder in winter than in summer. However, the chart also
illustrates how much more the daytime and nighttime temperatures differ in
summer in comparison to the winter. Notice how the gray ribbon is much
wider in the summer than in the winter.
The same information could not as easily or efficiently be determined from a
table of measurements. The subfield of data analysis that focuses on graphical
representation is called data visualization.
Another way of communicating data is to convert the data into acoustic non-
linguisticsignals,aprocesscalled sonification.However,thisprocessisamuch
less common practice than graphical representation.
In summary:
Data analysis aims to obtain relevant information and useful knowledge
by systematic organization, statistical processing, and/or graphical (fur-


================================================================================
PAGE 23
================================================================================

Introduction 3
thermore: acoustic, audiovisual) representation of data (in this context
also called raw data).
The following forms of data analysis are characterized by their respective
objectives:
• Descriptive statistics are used to organize and summarize data.
• Exploratory data analysis finds hidden patterns in the data in order to
formulate new hypotheses.
• Inferential statistics aim at describing observations by fitting them to
statistical models and test the plausibility of hypotheses based on data.
When exploratory data analyses are performed on a large scale, they are also
referred to as data mining. Possible descriptions of data mining are “the
process of discovering interesting patterns from massive amounts of data” [9,
Sec. 1.8] or “the practice of searching through large amounts of computerized
data to find useful patterns or trends” [10].
Another central task of data science today is the development of algorithms for
intelligent and autonomous systems using machine learning, so that these
systems operate by rules that were not given explicitly but are mostly “learned”
from training data.
This book describes concepts and methods from mathematics, statistics, and
the computational sciences that are designed to accomplish the tasks described
above. It is divided into three parts. The first part deals with aspects of data
organization: the conceptual and logical structuring of data and how to
ensure their quality. In that part, we also introduce the toolset of descriptive
statistics, which aim to summarize and present essential characteristics of
collected data.
The second part serves as an introduction to the mathematical field of stochas-
tics, which includes probability theory and inferential statistics. These provide
the conceptual and methodological foundation for reasoning under uncertainty.
In the last part of the book, we discuss aspects of statistical learning theory
and present algorithmic methods for machine learning, which make substantial
use of stochastics concepts.
This volume is an introductory text that presents essential topics and methods
of data science. At the very end of the book, the reader will find a compilation
of supplementary literature for further reading.
Aprerequisiteforthesuccessfulstudyofthisbookishavingmathematicalskills
that include an understanding of linear algebra, calculus, and some aspects of
multivariate calculus. These topics are typically taught during the first two to
three semesters of an academic curriculum in science, technology, engineering,
or mathematics (STEM). The appendix of this book provides a short summary
and refresher.


================================================================================
PAGE 24
================================================================================

4 Introduction
“Practice makes perfect,” they say—this holds especially true for the study
of data science. This edition’s appendix includes a number of exercises to
test the reader’s understanding of the subject matter. Additionally, the book
contains numerous application examples based on data that are freely available.
Readersareinvitedtoreproducetheseresultsusingaprogramminglanguagefor
statistical computing of their choice—for example, R [11] or Python [12]—and
be creative, adding their own analyses and data-driven stories.
Many of the illustrations in this volume were generated using the data visualiza-
tion package ggplot2 for R [13]. Manually layed out diagrams and graphs were
drawn with the LATEXpackage TikZ [14]. Other examples of program libraries
forRthatwereusedintheproductionofexamplesbutnotexplicitlymentioned
in the text include Cairo [15], cowplot [16], dplyr [17], extrafont [18], fastcluster
[19],FNN[20],forcats[21],ggdendro[22]ggforce[23],ggrepel[24],Gmedian[25],
gridExtra [26], igraph [27], latex2exp [28], lubridate [29], magick [30], mapproj
[31], MASS [32], mlbench [33], mvtnorm [34, 35], neuralnet [36], nominatimlite
[37], proxy [38], randomNames [39], reshape2 [40], rtweet [41], scales [42], sna
[43], sp [44, 45], stringdist [46], stringr [47], tidyverse [48], tidytext [49], tsne
[50], and usedist [51].


================================================================================
PAGE 25
================================================================================

References 5
References
[1] ISO Central Secretary. Information technology – Vocabulary. Standard
ISO/IEC 2382:2015. Genf, Schweiz: International Organization for Stan-
dardization, 2015, p. 2121272.
[2] Merriam–Webster. Data. Accessed Apr. 10, 2022. url: https://www.
merriam-webster.com/dictionary/data.
[3] Clifford M. Will. Theory and Experiment in Gravitational Physics. Cam-
bridge University Press, Sept. 2018. doi: 10.1017/9781316338612.
[4] Holger Ernst. “Patent information for strategic technology management”.
In: World Patent Information 25.3 (Sept. 2003), pp. 233–242. doi: 10.
1016/s0172-2190(03)00077-2.
[5] PeterWaldeetal.“ErstellungvonTechnologie-undWettbewerbsanalysen
mithilfevonBigData”.In:Wirtschaftsinformatik & Management5.2(Feb.
2013), pp. 12–23. doi: 10.1365/s35764-013-0274-7.
[6] RobertFollmerandDanaGruschwitz. Mobility in Germany – short report
(edition 4.0). Accessed Apr. 18, 2022. Bonn, Berlin, Sept. 2019. url: http:
//www.mobilitaet-in-deutschland.de/pdf/MiD2017_ShortReport.pdf.
[7] Fábio Duarte and Ricardo Álvarez. “The data politics of the urban age”.
In: Palgrave Communications 5.1 (May 2019). doi: 10.1057/s41599-019-
0264-3.
[8] Deutscher Wetterdienst – Zentraler Vertrieb Klima und Umwelt. Klima-
daten Deutschland. Accessed Apr. 1, 2020. Offenbach. url: https://www.
dwd.de/DE/leistungen/klimadatendeutschland/klimadatendeutschland.
html.
[9] Jiawei Han, Micheline Kamber, and Jian Pei. Data Mining: Concepts and
Techniques. 3rd ed. Elsevier, 2012.
[10] Merriam-Webster. Data mining. Accessed Apr. 10, 2022. url: https:
//www.merriam-webster.com/dictionary/data%20mining.
[11] R Core Team. R: A Language and Environment for Statistical Computing.
R Foundation for Statistical Computing. 2020. url: https://www.R-
project.org/.
[12] GuidovanRossumandFredL.Drake. Python 3 Reference Manual.Scotts
Valley, USA: CreateSpace, 2009.
[13] Hadley Wickham. ggplot2. Elegant Graphics for Data Analysis. Springer,
New York, 2009. doi: 10.1007/978-0-387-98141-3.
[14] Till Tantau. The TikZ and PGF Packages. Manual for version 3.1.7. Nov.
2020. url: https://pgf-tikz.github.io/pgf/pgfmanual.pdf.
[15] SimonUrbanekandJeffreyHorner. Cairo: R Graphics Device using Cairo
Graphics Library for Creating High-Quality Bitmap (PNG, JPEG, TIFF),
Vector (PDF, SVG, PostScript) and Display (X11 and Win32) Output. R
package. 2020. url: https://CRAN.R-project.org/package=Cairo.
[16] Claus O. Wilke. cowplot: Streamlined Plot Theme and Plot Annotations
for ’ggplot2’. R package. 2020. url: https://CRAN.R-project.org/
package=cowplot.
[17] Hadley Wickham et al. dplyr: A Grammar of Data Manipulation. R
package. 2020. url: https://CRAN.R-project.org/package=dplyr.


================================================================================
PAGE 26
================================================================================

6 Introduction
[18] Winston Chang. extrafont: Tools for using fonts. R package. 2014. url:
https://CRAN.R-project.org/package=extrafont.
[19] Daniel Müllner. “fastcluster: Fast Hierarchical, Agglomerative Clustering
RoutinesforRandPython”.In:JournalofStatisticalSoftware53.9(2013),
pp. 1–18. url: http://www.jstatsoft.org/v53/i09/.
[20] Alina Beygelzimer et al. FNN: Fast Nearest Neighbor Search Algorithms
and Applications. R package. 2019. url: https://CRAN.R-project.org/
package=FNN.
[21] Hadley Wickham. forcats: Tools for Working with Categorical Variables
(Factors). R package. 2020. url: https://CRAN.R-project.org/package=
forcats.
[22] Andrie de Vries and Brian D. Ripley. ggdendro: Create Dendrograms and
Tree Diagrams Using ’ggplot2’. R package. 2020. url: https://CRAN.R-
project.org/package=ggdendro.
[23] Thomas Lin Pedersen. ggforce: Accelerating ’ggplot2’. R package. 2020.
url: https://CRAN.R-project.org/package=ggforce.
[24] KamilSlowikowski. ggrepel: Automatically Position Non-Overlapping Text
Labels with ’ggplot2’. R package. 2020. url: https://CRAN.R-project.org/
package=ggrepel.
[25] Herve Cardot. Gmedian: Geometric Median, k-Median Clustering and
Robust Median PCA. R package. 2020. url: https://CRAN.R-project.
org/package=Gmedian.
[26] Baptiste Auguie. gridExtra: Miscellaneous Functions for ’Grid’ Graphics.
R package. 2017. url: https://CRAN.R-project.org/package=gridExtra.
[27] Gabor Csardi and Tamas Nepusz. “The igraph software package for
complex network research”. In: InterJournal Complex Systems (2006),
p. 1695. url: https://igraph.org.
[28] Stefano Meschiari. latex2exp: Use LaTeX Expressions in Plots. R package.
2015. url: https://CRAN.R-project.org/package=latex2exp.
[29] Garrett Grolemund and Hadley Wickham. “Dates and Times Made Easy
with lubridate”. In: Journal of Statistical Software 40.3 (2011), pp. 1–25.
url: https://www.jstatsoft.org/v40/i03/.
[30] Jeroen Ooms. magick: Advanced Graphics and Image-Processing in R. R
package. 2020. url: https://CRAN.R-project.org/package=magick.
[31] Doug McIlroy et al. mapproj: Map Projections. R package. 2020. url:
https://CRAN.R-project.org/package=mapproj.
[32] W.N.VenablesandB.D.Ripley.ModernAppliedStatisticswithS.4thed.
Springer, New York, 2002. doi: 10.1007/978-0-387-21706-2.
[33] Friedrich Leisch and Evgenia Dimitriadou. mlbench: Machine Learning
Benchmark Problems. R package. 2010. url: https://CRAN.R-project.
org/package=mlbench.
[34] Alan Genz et al. mvtnorm: Multivariate Normal and t Distributions. R
package. 2020. url: https://CRAN.R-project.org/package=mvtnorm.
[35] Alan Genz and Frank Bretz. Computation of Multivariate Normal and
t Probabilities. Lecture Notes in Statistics. Springer, Berlin, Heidelberg,
2009.


================================================================================
PAGE 27
================================================================================

References 7
[36] StefanFritsch,FraukeGünther,andMarvinN.Wright.neuralnet:Training
of Neural Networks. R package. 2019. url: https://CRAN.R-project.org/
package=neuralnet.
[37] Diego Hernangómez. nominatimlite: Interface with ’Nominatim’ API
Service. R package. 2022. doi: 10.5281/zenodo.5113195. url: https:
//dieghernan.github.io/nominatimlite/.
[38] David Meyer and Christian Buchta. proxy: Distance and Similarity Mea-
sures. R package. 2020. url: https://CRAN.R-project.org/package=
proxy.
[39] DamianW.Betebenner. randomNames: Function for Generating Random
Names and a Dataset. R package. 2019. url: https://cran.r-project.org/
package=randomNames.
[40] HadleyWickham.“ReshapingDatawiththereshapePackage”.In:Journal
of Statistical Software 21.12 (2007), pp. 1–20. url: http://www.jstatsoft.
org/v21/i12/.
[41] Michael W. Kearney. “rtweet: Collecting and analyzing Twitter data”. In:
Journal of Open Source Software 4.42 (2019). R package, p. 1829. doi:
10.21105/joss.01829.
[42] Hadley Wickham and Dana Seidel. scales: Scale Functions for Visualiza-
tion. R package. 2020. url: https://CRAN.R-project.org/package=scales.
[43] Carter T. Butts. sna: Tools for Social Network Analysis. R package. 2020.
url: https://CRAN.R-project.org/package=sna.
[44] Edzer J. Pebesma and Roger S. Bivand. “Classes and methods for spatial
data in R”. In: R News 5.2 (Nov. 2005), pp. 9–13. url: https://CRAN.R-
project.org/doc/Rnews/.
[45] Roger S. Bivand, Edzer Pebesma, and Virgilio Gomez-Rubio. Applied
spatial data analysis with R. 2nd ed. Springer, New York, 2013. url:
https://asdar-book.org/.
[46] Mark P. J. van der Loo. “The stringdist package for approximate string
matching”. In: The R Journal 6 (1 2014), pp. 111–122. url: https://
CRAN.R-project.org/package=stringdist.
[47] Hadley Wickham. stringr: Simple, Consistent Wrappers for Common
String Operations. R package. 2019. url: https://CRAN.R-project.org/
package=stringr.
[48] Hadley Wickham et al. “Welcome to the tidyverse”. In: Journal of Open
Source Software 4.43 (2019), p. 1686. doi: 10.21105/joss.01686.
[49] JuliaSilgeandDavidRobinson.“tidytext:TextMiningandAnalysisUsing
TidyDataPrinciplesinR”.In: JOSS1.3(2016). doi:10.21105/joss.00037.
[50] Justin Donaldson. tsne: t-Distributed Stochastic Neighbor Embedding for
R (t-SNE).Rpackage.2016.url:https://CRAN.R-project.org/package=
tsne.
[51] Kyle Bittinger. usedist: Distance Matrix Utilities. R package. 2020. url:
https://CRAN.R-project.org/package=usedist.


================================================================================
PAGE 28
================================================================================

Part I
Basics


================================================================================
PAGE 29
================================================================================

1
Elements of data organization
We use the term database to refer to all data captured, stored, organized, and
made available for access and processing. A large collection of data is often
heterogeneous, as it is the result of data integration, the merging of data
fromdifferentanddiversedata sources.Whenplanningtobuildalargeand/or
heterogeneous database (buzzword: big data) while ensuring the quality of the
collected data, special challenges arise that we address in this chapter.
First, we describe approaches to modeling data. The primary goal of data
modeling is to capture the meaning of the data and to structure it to best serve
the use case at hand.
Three stages or milestones of the data modeling process can be distinguished,
each of which serves to answer the following questions [1]:
1. Conceptual data model: What are the relevant objects of the knowledge
domainthatthedatadescribe?Whatpropertiescanweassociatewiththose
objects, and how do they relate to each other?
2. Logical data model: How are the data structured (i.e., how are they
arranged, grouped, combined, or compared)?
3. Physical data model: What are the technical specifications of the hard-
ware and software used to capture and store the data?
The conceptual data model is a systematic description of the semantics of
the data in the context of the knowledge domain, while the logical data model
focuses on formal structure. In practice, the key difference between these stages
lies in the level of detail: the conceptual data model aims at a broad, global
description of the underlying concepts, while the logical data model usually
provides a greater level of detail. It is not uncommon for both stages to be
combined.
Physical data modeling focuses on the technical challenges associated with,
for example, the collection and validation, performant processing, and scalable
© Springer-Verlag GmbH Germany, part of Springer Nature 2023 11
M. Plaue, Data Science, https://doi.org/10.1007/978-3-662-67882-4_1


================================================================================
PAGE 30
================================================================================

12 Elements of data organization
storage of data using a specific database management system (DBMS). We
do not elaborate on these challenges of data engineering in this book.
Hereafter, we present criteria and procedures for measuring and ensuring the
quality of data.
1.1 Conceptual data models
Inordertobeausefulresource,ratherthanameaninglesscollectionofnumerical
values, strings, etc., data must be connected to the real world and represent
information about the domain of interest.
Data represent information about individually identifiable real or abstract
objects, in this context called entities or information objects.
Entities could be, for example, persons in a customer database, and data that
describe each entity include name and place of residence.
If the entities described by the data are themselves data, then the descriptive
data are also referred to as metadata. The data documentation (more on
this topic in Sect. 1.3.1) represents an important example of metadata.
A conceptual data model is a systematic representation of the entities,
their relevant properties, and their relationships with each other. Such a model
can be helpful, for example, in planning a data analysis project to determine
information needs.
1.1.1 Entity–relationship models
A frequently used systematic representation of a data model is the entity–
relationship model(ERM)[2].First,notethatsimilarentitiescanbegrouped
into entity types by way of abstraction. For example, in a database that
contains data about customers of a retail chain, each customer may be regarded
as an instance of the entity type customer.
After determining which entity types to use in the data model, each entity can
be assigned specific attributes, the properties that define an entity type. For
example,first name,family name,andaddress areattributesthatmaybeuseful
for the entity type customer.
A specific assignment of an attribute is an attribute value. Possible attribute
values for the attribute first name of a customer may be, for example, “Anna”
or “Carl.” In the context of statistics or machine learning, attributes are also
known as variables or features, respectively.
Given a knowledge domain, there is no standard way to model the underlying
data. Any distinction between attributes and entities must make sense for
the use case at hand. For example, a customer’s place of residence might be


================================================================================
PAGE 31
================================================================================

1.2. Logical data models 13
understood as an attribute or it might be interpreted as an entity type on its
own, represented by the address.
Finally, entities are connected by relationships. For example, when customers
of a retail company make their purchases in the company’s physical stores, the
customers can be linked to those stores by a relationship type shops at.
The data model described can be summarized in an entity–relationship
diagram like the following:
M N
name customer shops at store
address
Fig. 1.1. Entity–relationship diagram
The above graphical representation of an ERM is also called Chen notation.
In Chen notation, entity types are represented by rectangles, attributes by oval
graphical elements, and relationship types are diamond-shaped.
ThedescriptorsM,N intheabovediagramdenotethe maximum cardinality
of the relationship type, as described below between two entity types X and Y:
• 1:1 relationship: Given a single entity of type Y, at most one entity of
type X is related to it, and vice versa. For example, every motor vehicle
is related to one and only one license plate (with the odd exception of
changeable/seasonal license plates).
• 1:N relationship: Given a single entity of type Y, at most one entity of
type X is related to it. Conversely though, an entity of type X may be
related to multiple entities of type Y. For example, a person has only a
single (primary) place of residence, but several persons may live at the same
address.
• M:N relationship: There is no numerical limit on the number of entities
that are related to each other. An example is the relationship type customer
x shops at store y: a store usually has more than one customer, and one
customer may make purchases in multiple stores.
1.2 Logical data models
Aconceptualdatamodelstructuresaknowledgedomain—anentity–relationship
model achieves this goal by definition of entities, attributes, and relationships
between the entities. These real-world objects are associated to data that
represent them. For example, a person’s first name corresponds to a particular
string of characters, and their place of residence can be stored as latitude


================================================================================
PAGE 32
================================================================================

14 Elements of data organization
and longitude coordinates in the form of a pair of floating point numbers (e.g.
52.512652, 13.316714). In order to process data with information technology, it
should be structured in a suitable manner. A logical data model structurally
mirrors the conceptual data model.
We can understand a logical data model as an organization of smallest units:
A data item is the smallest organizational unit of data. A dataset is
a collection of data items that are structured (i.e., arranged, grouped,
combined, or compared) in the same way.
Inthefollowingsections,wedescribeessentialcharacteristicsofsomecommonly
used logical data models.
1.2.1 Relational data models
A very common way of structuring data items is to arrange and group them in
tabular form. Here is an example of a dataset of fictitious customer data:
ID last name first name street str. no. zip code city
1 Smith Anna First Street 1 12345 Model City
2 Miller Robert Second place 3 54321 Example Village
3 Miller Carl Second place 3 54321 Example Village
Table 1.1. Customer data
Each row of such a data table may be called a data record or data tuple.
The primary key attribute, ID in the first column of the table above, uniquely
identifies each entity that is represented and described by a data record. It may
be as simple as a consecutive sequence of positive integers, as shown in the
example.
Anygivenentity–relationshipmodelcanbemappedontoarelationaldata
model by applying the concepts of entities, attributes, and relationships.
In this context, a data table is also referred to as a relation.
Entities: Each entity type corresponds to a relation. Each data record
corresponds to an entity (in the above example, a person/customer).
Attributes: Each column corresponds to an attribute. The attribute
values in a single row constitute a data record/tuple.
Relationships: Each relationship type corresponds to a relation. Each
data record represents a relationship by listing the values of the primary
keys of the related entities.


================================================================================
PAGE 33
================================================================================

1.2. Logical data models 15
To illustrate how this framework can be applied, let us once more consider
the hypothetical retail company’s database, which may also include the below
example data about stores and customers.
ID name city
1 Good Buy Example Village
2 Cheap Buy Model City
The relation type shops at can be stored as shown by the following relation:
customer ID store ID
1 2
2 1
2 2
3 1
The customer with primary key “1” (= Smith, Anna) shops at the store with
primary key “2” (= Cheap Buy), and so on.
Relations can be processed by operations that make up the so-called relational
algebra. To explain these operations, it is helpful to think of a relation as a
set of tuples. For a quick reminder on the mathematical concept of a set, and
set operations like intersection and union, we refer to the appendix (Sect. B.1).
Thus, a relation R with D =D(R) columns/attributes that yield values taken
from the sets R ,...,R , and N rows/data records/tuples can be written as
1 D
follows:
R= (cid:8)(cid:0) r1 ,...,r1 (cid:1) , (cid:0) r2 ,...,r2 (cid:1) ,..., (cid:0) rN ,...,rN (cid:1)(cid:9)
1 D 1 D 1 D
Here, rn ∈ R for all d ∈ {1,...,D} and n ∈ {1,...,N} is the entry in the
d d
n-th row and the d-th column of the relation. In the following, the row index
will not be important, so we write more briefly: R={(r ,...,r )}.
1 D
Two relations, R and S, are called type-compatible if they are described
by identical attributes: the number of attributes D of both relations is
identical and it holds R =S ,R =S ,...,R =S .
1 1 2 2 D D
For type-compatible relations R and S, the usual set operations are well-
defined: union R∪S, intersection R∩S, (set) difference R\S.
Forarbitraryrelationsthatarenotnecessarilytype-compatible,theCarte-
sian product is also well-defined:
R×S ={(r ,...,r ,s ,...,s )}
1 D(R) 1 D(S)
Wecanperformaprojectionontocertainattributesorcolumnsasfollows:
R={(r ,...,r )}7→{(r ,...,r )}=π (R)
1 D ι(1) ι(K) ι(1),...,ι(K)
where ι: {1,...,K}→{1,...,D}, K ≤D.


================================================================================
PAGE 34
================================================================================

16 Elements of data organization
Given some condition, B, imposed on the attribute values, we can collect
the data records that satisfy that condition—this operation is called a
selection:
R[B]={r ∈R|B[r]}
The join operation is the composition of Cartesian product and selection:
R▷◁ S =(R×S)[B]
B
Let us give a concrete example for applying these operations. Consider again
therelationsrepresentingtheentitytypes customer (=:A)andstores (=:B)as
well as the relation type shops at (=:R). We want to construct a new relation
that lists the last name and city of residence of those customers who shop at
stores in “Model City” (=:x).
This can, for example, be achieved as follows:
1. Join the individual relations via their primary keys. We obtain the new
relation A▷◁ R▷◁ B.
a1=r1 r2=b1
2. Selection by the desired stores: A▷◁ R▷◁ B[b =x].
a1=r1 r2=b1 3
3. By projecting on the attributes last name and city of the individuals
(2nd and 7th column, respectively) we finally obtain:
π (A▷◁ R▷◁ B[b =x])
2,7 a1=r1 r2=b1 3
In practice, a standard for implementing these operations is the widely used
database language SQL (Structured Query Language). SQL has a simple and
explainable syntax. A database query written in SQL for the above example
can look something like this:
SELECT
c.last_name,
c.city
FROM customers c
JOIN buys_at r ON c.id = r.id_customer
JOIN stores s ON s.id = r.id_store
WHERE s.city = 'Model City';
SQLalsoenablestheimplementationofimportantoperationsthathavenotbeen
presentedsofar.Forexample,recordscanbegroupedandtheirattributevalues
aggregated. A database query to determine the total number of customers for
each store might look something like this:
SELECT
s.id, s.name, s.city,
COUNT(DISTINCT c.id) AS number_customers
FROM customers c


================================================================================
PAGE 35
================================================================================

1.2. Logical data models 17
JOIN buys_at r ON c.id = r.id_customer
JOIN stores s ON s.id = r.id_store
GROUP BY s.id;
Database management systems that implement relational data models include
MySQL [3], MariaDB [4], and PostgreSQL [5].
1.2.2 Graph-based data models
Mathematically, relational data models represent data as sets of data tuples,
and these sets can be combined by operations defined by the relational alge-
bra. Graph-based data models on the other hand are based on the following
mathematical concept:
A directed graph G is a pair G=(V,E) that consists of a finite set V
and a set E ⊆V ×V.
The elements of V are called nodes or vertices, the elements of E are
called directed edges.
The above meaning of the term “graph” must not be confused with that of a
function graph. We can think of a directed edge (u,v)∈E as connecting the
start node u∈V to the end node v ∈V.
Interpreting edges as directed connections between nodes allows a directed
graph to be represented as a node–link diagram, as shown below.
a b c e f
d
Fig. 1.2. Node–link diagram
The figure shows the directed graph G=(V,E) with vertex set V ={a,...,f}
and edges E ={(a,b),(b,a),(b,c),(c,d),(d,b),(e,e)}.
An undirected graph differs from a directed graph in that the edges do not
exhibit a preferred direction. In other words, there is no distinction being made
between start and end nodes.
In data modeling practice, the term “graph” is usually understood to mean
multigraph. In a multigraph, nodes may be connected by more than one edge.
A directed multigraph G=(V,E) consists of a finite set of vertices V
and a set of enumerated directed edges
E ⊆{(u,v,n)|u,v ∈V,n∈{1,2,3,...}}.


================================================================================
PAGE 36
================================================================================

18 Elements of data organization
More precisely, “enumerated” means: for all u,v ∈V and n∈N, n>1 the
following holds: if (u,v,n) is an edge, then (u,v,n−1) is also an edge.
Instead of denoting the edge of a multigraph by (u,v,n), we can also write
(u,v) to more clearly distinguish the edge number from start and end nodes
n
notationally. We illustrate by example:
1
2 1
a b c
1
1
1
2
d
Fig. 1.3. Multigraph
The figure above shows a node–link diagram of the multigraph with nodes
V ={a,...,e} and edges:
E ={(a,b) ,(a,b) ,(b,a) ,(b,c) ,(c,d) ,(c,d) ,(d,b) }
1 2 1 1 1 2 1
An entity–relationship model can be mapped onto a logical structure
known as a property graph as follows [6, Chap. 3]:
Entities:Eachentitycorrespondstoanode.Entitytypesaredistinguished
byso-calledlabels.Forexample,anoderepresentingapersonwouldcarry
the label “person.” In general, several labels can be assigned to a node.
Attributes: Attribute data are stored with nodes or edges in the form of
key–value pairs, i.e. the properties. For example, a node that is labeled
as a person could have the property ("first_name" : "Carl").
Relationships: Each relationship between two entities corresponds to an
edgebetweenthecorrespondingnodes.Relationshiptypesaredistinguished
from each other by labels.
Anexampleofagraph-baseddatabasemanagementsystemisneo4j[7].Aquery
using the Cypher database language in neo4j might look like the following:
MATCH (c:customer)-[:shops_at]->(s:store)
WHERE s.city = 'Model City'
RETURN c.name, c.city
While relationally structured data are best represented as tables in order to be
read and processed by humans, a node–link diagram such as the following is
suitable for visualizing a property graph.


================================================================================
PAGE 37
================================================================================

1.2. Logical data models 19
Customer Customer Customer
first name: Anna first name: Robert first name: Carl
last name: Smith last name: Miller last name: Miller
shops at
Store Store
city: Model City city: Example Village
Fig. 1.4. Property graph
1.2.3 Hierarchical data models
Hierarchical data models are built on the mathematical concept of a tree. Trees
are graphs that have a special shape, starting from a particular node—the
“root”—there is only one direction in which we can walk along the edges, toward
the “leaves.” Before we can formally define trees, we first need to explain some
additional terminology from graph theory.
Let G=(V,E) be a directed graph. A directed walk with a start node
u∈V and an end node w ∈V of length N ≥1 is an alternating sequence
of nodes and edges u = v ,e ,v ,e , ..., v ,e ,v = w such that
0 1 1 2 N−1 N N
e =(v ,v ) for all n∈{1,...,N}.
n n−1 n
Foranundirected walk,e =(v ,v )ore =(v ,v )mayhold.In
n n−1 n n n n−1
other words, an undirected walk may also make steps against the direction
of the edges.
Ifallofthenodesu,v ,...,v ,wofadirected/undirectedwalkarepairwise
1 N
distinct, it may also be called a directed/undirected path.
A directed/undirected cycle is a directed/undirected walk where the start
and end nodes are identical, u=w, but all of the remaining path nodes,
v ,...,v , are pairwise distinct.
1 N
Graphs that do not contain a directed cycle are called acyclic.
The following graph is an example of an acyclic graph:
a b c
d
Fig. 1.5. Acyclic graph with undirected cycle


================================================================================
PAGE 38
================================================================================

20 Elements of data organization
This graph does not contain a directed cycle—so there is no closed path that
can be traversed in the direction of the arrows. Rather, the graph contains an
undirected cycle with the vertex sequence b,c,d,b.
Acyclic graphs also serve us in Sect. 6.4 to describe artificial neural networks.
Finally, we can define the mathematical structure that hierarchical data models
are based on.
A rooted tree is a directed graph G=(V,E) that does not contain an
undirected cycle, together with a distinguished node r ∈V, the root of G,
such that for all v ∈V with v ̸=r there exists a directed path from r to v.
The leaves of a tree are the nodes that are different from the root and
have only one neighboring node.
The following node–link diagram shows an example of a tree with root a:
e c
f g
a b
h
d
Fig. 1.6. Rooted tree
Each node can be assigned a hierarchical level by the (uniquely determined)
length of the path from the root node. On the “zeroth” level, there is only the
root node a, on the first level the node b, the second level consists of the nodes
c and d, and so on. The leaves are given by the nodes d, f, g and h.
The following diagram shows the same tree again, but in this representation
the hierarchical structure is more apparent since nodes at the same hierarchical
level are shown in the same column:
f
a b c e g
d h
Fig. 1.7. Levels of hierarchy in a rooted tree


================================================================================
PAGE 39
================================================================================

1.3. Data quality 21
Trees can be used to represent the results of a hierarchical cluster analysis,
which we will discuss in Sect. 7.3.2.
Example. The following is a small excerpt of a so-called Extensible Markup
Language (XML) file submitted by an RSS feed [8]:
<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:dc="http://purl.org/dc/elements/1.1/"
xmlns:content="http://purl.org/rss/1.0/modules/content/"
xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"
xmlns:cc="http://cyber.law.harvard.edu/rss/
creativeCommonsRssModule.html">
<channel>
<title><![CDATA[Towards Data Science - Medium]]></title>
<description><![CDATA[A Medium publication sharing
concepts, ideas, and codes. - Medium]]></description>
<link>https://towardsdatascience.com?source=rss
----7f60cf5620c9---4</link>
<item>
<title><![CDATA[Why Psychologists Can Be Great
Data Scientists]]></title>
<guid isPermaLink="false">https://medium.com/p/
970552b5223</guid>
<category><![CDATA[careers]]></category>
<category><![CDATA[machine-learning]]></category>
<dc:creator><![CDATA[Maarten Grootendorst]]>
</dc:creator>
<pubDate>Fri, 18 Sep 2020 14:00:02 GMT</pubDate>
<atom:updated>2020-09-18T14:00:02.568Z</atom:updated>
</item>
<item>
...
</item>
</channel>
</rss>
XML files are examples of hierarchically structured data. Each node of the
tree is referred to as an element in this context. Each element and the
elementsofthehierarchylevelsbelowthatelementareenclosedbytagsofthe
form <element> and </element>. In this example, the root is represented
by the tags <rss>...</rss>, which enclose all other elements.
1.3 Data quality
Theprincipalpurposeofdatascienceistogeneratetrustedandusefulknowledge
from data. A high-quality dataset is a prerequisite for fulfilling this purpose.


================================================================================
PAGE 40
================================================================================

22 Elements of data organization
1.3.1 Data quality dimensions
The Data Management Association UK proposes an assessment of the quality
of data based on six key characteristics that they call data quality dimensions
[9]: completeness, consistency, validity, uniqueness, accuracy, and time-
liness. Tab. 1.6 lists these data quality dimensions, with each one explained in
the table in the form of a probing question. The table also provides examples
of typical data defects. Data profiling is the practice of collecting metrics
in order to assess data quality. The last column of the table lists such metrics,
which measure the severity or frequency of data defects.
Data quality measures the extent to which a dataset can be used as
intended. Consequently, the significance of each data quality dimension
and the priority with which data defects need to be managed depend on
the use case at hand.
For example, the validity of data is important for automated processing. Invalid
inputs, for example when inputs are outside of the domain of the system’s
functions, can lead to software errors if they are not caught by some form of
exception handling. In general, the accuracy of data plays only a minor role in
the automated processing stage. On the other hand, accuracy is a vital feature
for information that is presented to and evaluated by a human.
Completeness of metadata is also a relevant indicator of high data quality,
especially when it comes to data documentation. Good data documentation
ensures reproducibility of results and transparency of the analysis process. Data
documentation may include information such as:
• the context of data collection, underlying hypotheses, and goals of the
associated data analysis project;
• the semantics of the data, a conceptual data model, e.g., an entity–
relationship diagram;
• the logical data model; a description of attributes, properties, etc. including
their range of valid values, units of measurement, etc.; in the context of
survey research, the codebook [10, Chap. 5];
• an evaluation of data quality, results of data profiling, or a description of
any data cleaning measures performed on the dataset (see next section);
• the location, time, and modality of data collection: methods, software,
measurement apparatus used, data sources tapped into, etc.;
• information about data versioning, differences between different versions;
• technical information, such as interfaces for access or the physical size of
files;
• terms of use, data protection measures.


================================================================================
PAGE 41
================================================================================

1.4. Data cleaning 23
1.4 Data cleaning
In the following section, we present a few methods to identify and manage data
defects. In general, it is highly recommended to keep a historical record of such
data preprocessing tasks, which may include maintaining the original raw
data with the database or a backup thereof. Such a historical record is called
data provenance, and it helps with tracking down the cause of data quality
issues.
1.4.1 Validation
Formally or syntactically incorrect, invalid attribute values can, under certain
circumstances,leadtomalfunctionsofthedataprocessingsoftware.Implausible
values outside of a permissible range may also skew the results of data analysis.
Invalid attribute values can be identified with the help of validation rules. On
the one hand, such rules can refer to the syntax. For example, a birth date can
be required to be stored in the format YYYY-MM-DD, where YYYY is a four-digit
year, MM is a two-digit month (with a leading zero if applicable), and TT is a
two-digit number that represents the day. According to this validation rule,
2010-12-01 would be a valid date, but 10-12-01 or 2010-12-1 would not be.
On the other hand, values can be recognized as invalid if they lie outside of a
specified valid range. Thus, 2010-23-01 would be a valid date according to the
above validation rule—but not if 1 <= MM <= 12 was also required.
Additionally, necessary conditions for the accuracy of the attribute value can
be checked, i.e., their plausibility. Thus, birth dates can be marked as invalid
when they lie in the future at the time of the creation of the dataset, or also if
they are too far in the past.
In many cases, invalid or implausible attribute values are handled by deleting
them. For other cases, a transformation can be performed to correct the data
defect. For example, dates of the form YYYY-MM-D can be transformed to the
valid syntax YYYY-MM-DD by inserting a leading zero: JJJJ-MM-0D. Of course,
this procedure is only recommendable if the data’s provenance and the data
generating process imply that the result obtained is not only valid but also
accurate.
We summarize:
Invalidorimplausibleattributevaluescanbeidentifiedbycheckingagainst
validation and/or plausibility rules. Removing invalid values or con-
verting them into a valid format may be part of such a data validation
process.
For the implementation of data validation processes, so-called regular ex-
pressions are often helpful. With the help of regular expressions, syntactic


================================================================================
PAGE 42
================================================================================

24 Elements of data organization
patterns in strings can be searched and replaced. They are included with many
programming languages and standard libraries [11].
1.4.2 Standardization
Themaingoalofdataintegrationistocombinedatafromdifferentdatasources.
Significantchallengesarisefromtheheterogeneityofthesources,suchasvarying
datamodelsordifferenttechnicalmeanstostoreorsendthedata(e.g.,different
file formats or interfaces). Consequently, an important aspect of successful data
integration is data harmonization, which aims to reduce heterogeneity.
An important subtask of harmonizing a dataset is to standardize the data so
that the data are available in a uniform syntax and with the same units of
measurement. Here is a fictitious example of two datasets with different syntax
or unit of measurement:
name Rose Smith Smith, Rose
phone no. +498932168 +4989-321-68
date of birth 1981-12-07 12/07/1981
organization Example Incorporated Example Inc.
body height 180cm 5’ 11”
Table 1.2. Heterogeneous, non-standardized data
In order to standardize the dates, we can choose the target syntax YYYY-MM-DD,
where the letters stand for year, month, and day. Other date formats such as
MM/DD/YYYY can be mapped onto this syntax in the obvious way. Similarly,
data that represent lengths or distances can be converted to the same unit of
measurement. For example, all body heights across data sources can be given
in centimeters.
Data standardization aims to align a heterogeneous syntax or units
of measurement. For this purpose, attribute values are converted into a
specified target syntax and common units of measurement.
1.4.3 Imputation
Missing attribute values in a dataset can occur for various reasons. In the case
of a survey, a respondent may have refused to provide information. In the case
of a physical measurement, the measuring device may have been impaired in
its functionality. Missing values will also occur if invalid values were discarded
during a data validation process.
Data imputation is the process of completing data by replacing missing
attribute values with synthetic but plausible values.


================================================================================
PAGE 43
================================================================================

1.4. Data cleaning 25
Missing attribute values can lead to a bias in the results of data analysis. The
primary goal of data imputation is not to determine the correct attribute values
but to supplement the data in order to improve the results.
An alternative to imputation is the complete case analysis, a simple and
commonly used procedure. With this approach, data tuples that are missing
relevant values are excluded from the analysis.
1.4.3.1 Imputation with measures of central tendency
Even when some information objects have no value assigned to a certain
attribute, a substitute value can be determined on the basis of the remaining
existing values of the same attribute. The arithmetic mean is a popular choice
forcomputingsuchasubstitutevalue.InSect.2.3,weintroduceothermeasures
of central tendency, like the mode or median. The missing attribute values can
be replaced by this substitute value. This procedure is referred to as mean
substitution, especially when using the arithmetic mean.
Example. The following table represents a small sample of results from
a 2018 telephone survey of U.S. citizens provided by the U.S. Centers for
Disease Control and Prevention (CDC) [12]:
sex age height weight
in years in cm in kg
male 35 170 98
male 66 NA NA
female 67 155 NA
. . . .
. . . .
. . . .
Table 1.3. Missing attribute values
Here, the attribute values “NA” represent missing data. The missing data
in this case is because the respondent provided no data, invalid data, or
insufficient data.
The mean body height and mean body weight, determined from the entire
dataset as provided by the CDC, are 170cm and 82kg, respectively. Thus,
the mean-substituted dataset is the following:
sex age height weight
in years in cm in kg
male 35 170 98
male 66 170 82
female 67 155 82
Table 1.4. Mean substitution


================================================================================
PAGE 44
================================================================================

26 Elements of data organization
The dataset can also be partitioned into convenient imputation classes in
order to apply a mean substitution to each of them. In the above example,
instead of averaging across the entire dataset, missing data can instead be
replaced by the mean value with respect to each sex. Taking into account
that male respondents typically have larger body weight and body height, the
imputed data table becomes:
sex age height weight
in years in cm in kg
male 35 170 98
male 66 178 90
female 67 155 75
Table 1.5. Use of imputation classes
1.4.3.2 Imputation via regression and classification
Inthechaptersoninferentialstatisticsandmachinelearning(Chap.4and6),we
willpresentvariousproceduresbywhichamissingorinvalidvalueofanattribute
can be predicted by the remaining attribute values of the same entity. These
procedurescanalsobeusedfordataimputation.Infact,meansubstitutionmay
be thought of as a simple regression procedure where only a single parameter
is inferred from the data. Nearest-neighbor imputation ([13], see Section 6.3.2)
replacesthemissingattributevalueswithvaluesofotherwisesimilardatatuples
of the same dataset.
1.4.4 Augmentation
In some cases, it may make sense or even be necessary to expand the dataset
with new data records if coverage is insufficient for the use case at hand.
Data coverage can be increased by tapping into new data sources and collecting
moredata.However,especiallyinthefieldofmachinelearning, synthetic data
is also used to provide additional data for training algorithms.
Data augmentation refers to an extension of the dataset by artificially
generated data records. Typically, these data records are generated by a
suitable transformation of already existing data records.
Similar to imputation, augmentation is not about adding accurate data but
instead aims to avoid bias in the results due to “lack of data.” It can be used to
improve the robustness of a machine learning model that was trained with the
data, and it is used especially to avoid so-called overfitting (see Sect. 6.1.2).
• In image or video analysis, already available images can be subjected to
various image transformations to generate new data [14], such as with geo-
metrictransformations,likeshear,zoom,reflection,orrotation.Additionally,


================================================================================
PAGE 45
================================================================================

1.4. Data cleaning 27
image sharpness, contrast, brightness, or color temperature can be changed
to create additional images.
• In text analysis, possible techniques [15] include the replacement of words
with synonyms [16] or back translation [17].
1.4.5 Deduplication
A particular challenge for data harmonization is posed by unstructured data
that does not follow a fixed syntax. For example, the date may have been
entered manually into a free text field so that the strings December 7, 1981,
7 December 81, 07 Dec. 1981, etc. all represent the same date. They might
even contain typographic errors, like Decebmer 7, 1981. In this case, more
complex rules must be developed for an extraction of month, day, and year.
Organization names can be especially difficult to harmonize. The following list
comes from the patent database PATSTAT [18, 19] and shows a small selection
of spellings with which the German multinational conglomerate corporation
Siemens can appear as the applicant of a patent:
SIEMENES AKTIENGESELLSCHAFT; Siemens; Siemens A.G.; Siemens AG;
SIEMENS AG (DE); SIEMENS AG, 8000 MUNICH, DE;
SIEMENS AG, 80333 MUNICH, DE; Siemens Akteingesellschaft;
Siemens Aktiengellschaft; Siemens Aktiengesellscahft;
Siemens Aktiengesesellschaft; SIMENS AKTSIENGEZELL'SHAFT
These examples exhibit the many causes for such heterogeneity: typographic
errors, abbreviated spellings, address information included with the name, or
transcription.
Even determining the number of patents registered by Siemens thus becomes a
non-trivial task, since the organization is not represented in a unique way.
Data deduplication is the task of identifying the data records that
describe a single entity in order to merge them into a single representative
data record.
At their core, many commonly used automated duplicate detection and data
fusion procedures are based on so-called cluster analysis. In cluster analysis,
sufficientlysimilarinformationobjectsaregroupedtogether.Moreaboutcluster
analysis can be found in Sect. 7.3. The terms object identification, entity
resolution, and record linkage are also commonly used to describe the task
of data deduplication.
1.4.5.1 Distance and similarity measures for strings
One approach to data deduplication is to fuse data records that have, in an
appropriate sense, a sufficiently large similarity or small “distance,” respectively.
In Sect. 5.2, we will introduce a few distance and similarity measures that can


================================================================================
PAGE 46
================================================================================

28 Elements of data organization
be used to compare data tuples. At this point, we would like to introduce such
metrics for comparing lists of symbols, or strings, which may be particularly
useful for detecting duplicates in lists of organization names or person names.
Metrics of this type are also used in other contexts, such as in information
retrieval for fuzzy search or in bioinformatics for comparing DNA sequences
[20].
A very simple but also rather crude definition for the distance between two
strings a and b is the discrete metric:
(
0 if a=b
δ(a,b)=
1 if a̸=b
Thisdistancedefinitionisuniversalinthatitcanbeappliedtootherdatatypes.
However, it obviously does not allow gradual comparison between objects. The
strings a=SIEMENS and b=IEMENS are “just as different” under the discrete
metric as the strings a = SIEMENS and c = GRUNDIG. Intuitively, however, it
seems clear that the strings a and b have a greater similarity than the strings a
and c. A meaningful distance measure should reflect this fact numerically.
To be able to define less coarse distance measures than the discrete metric, we
first note the different ways in which strings can be transformed, or edited.
The following elementary edit operations can be applied to strings:
Delete a character: SIEMENS 7→ SIMENS
Insert a character: SIEMENS 7→ SIEMENES
Replace a character: SIEMENS 7→ SOEMENS
Swap two adjacent characters: SIEMENS 7→ SEIMENS
Given any two strings, one can be transformed into the other by a suitable
sequence of the above edit operations. The basic idea of an edit distance is to
determine the number of elementary edit operations necessary to convert two
strings into each other. The more operations necessary, the more different the
strings can be considered to be.
Let a and b be strings.
The Levenshtein distance between a and b is given by the minimum
number of insert, delete, and replace operations required to convert a into
b.
The Damerau–Levenshtein distance between a and b is given by the
minimum number of swap, insert, delete, and replace operations required
to convert a into b.
For example, the Levenshtein distance between a=SIEMENS and b=SOEMEN is
two, since at least one replace and one delete operation is necessary to get b


================================================================================
PAGE 47
================================================================================

1.4. Data cleaning 29
from a. Conversely, at least one replace and one insert operation is necessary to
get a from b.
We denote the lengths of the strings by |a| and |b|, respectively, e.g. |xyYz|=4.
Let lev (a,b) be the Levenshtein distance between the first i characters of
i,j
a and the first j characters of b. In order to calculate the full Levenshtein
distance, lev(a,b)=lev (a,b), the following recursive algorithm can be used
|a|,|b|
[21, Theorem 2]:
 max{i,j} if min{i,j}=0,


lev (a,b)+1
lev (a,b)=  i−1,j
i,j  min

l
l
e
e
v
v
i,j−1 (a,
(
b
a
)
,b
+
)
1
+δ(a ,b )
otherwise
i−1,j−1 i j
Here, a is the character at the i-th position of a, and b is the character at the
i j
j-th position of b, and:
(
0 if a =b
δ(a ,b )= i j
i j 1 if a ̸=b
i j
We have 0 ≤ lev(a,b) ≤ max{|a|,|b|}, so the normalized Levenshtein dis-
tance (with value at most one) can be defined as follows:
lev(a,b)
lev (a,b)=
norm max{|a|,|b|}
The number 1 − lev (a,b) can then be understood as a measure of the
norm
similarity of the two strings. Identical strings have a maximum possible Leven-
shtein similarity of one, while the “maximally different” strings have a vanishing
similarity measure.
The Damerau–Levenshtein distance is always at most as large as the Leven-
shtein distance, since every swap operation is the product of two replacement
operations, e.g., SIEMENS 7→ SIIMENS 7→ SEIMENS.
While Levenshtein distance or similarity measures are used for a variety of
different applications, the similarity measures described below were developed
specifically for comparing person names [22].
For two strings, a and b, of length |a| and |b|, respectively, we first perform the
following construction: Let a∩b=a ···a with i <···<i be the string
i1 im 1 m
that emerges from a by stepwise selection of characters a , starting from the
i
beginning of the string for which there is a corresponding character b , with
j
a =b and |j−i|≤ 1max{|a|,|b|}−1. Incase of repeating characters within a
i j 2
string, a one-to-one correspondence shall be established by selecting b starting
j
from the beginning of the string.
Similarly, we define b∩a. Necessarily, b∩a consists of the same characters as
a∩b, those characters contained in both a and b that are not too far apart. In
general, however, a∩b and b∩a may differ in the order of characters.


================================================================================
PAGE 48
================================================================================

30 Elements of data organization
Fortwostrings,aandb,letm=|a∩b|=|b∩a|,andlettbetheminimum
number of permutations of not necessarily adjacent characters required to
convert a∩b to b∩a.
The Jaro similarity between a and b is then given as follows:
( 0 if m=0
jaro(a,b)= (cid:16) (cid:17)
1 · m + m + m−t otherwise
3 |a| |b| m
As a concrete example, we want to determine the Jaro similarity between
the strings a = SIEMENS and b = SIMESN. We have 1max{|a|,|b|} − 1 =
2
1max{7,6}−1=2.5, so only characters with a distance of at most two are put
2
intocorrespondence.Thisgivesa∩b=SIEMNSandb∩a=SIMESN,consequently
m=6 and t=2. Finally:
(cid:18) (cid:19)
1 6 6 6−2
jaro(a,b)= · + + ≈0.84
3 6 7 6
Let a and b be strings of length |a| and |b|, and L∈N,p∈R with L≥1
and 0≤p≤ 1 are fixed parameters. For the case L=0, the choice of p is
L
arbitrary.
Let l = l(a,b) ∈ N be the largest number, such that l ≤ min{|a|,|b|,L}
holds and the first l characters of a and b match as strings: a ···a =
1 l
b ···b .
1 l
Then, the Jaro–Winkler similarity is given as follows:
jw (a,b)=jaro(a,b)+l(a,b)·p·(1−jaro(a,b))
p,L
Typical choices for the parameters of the Jaro–Winkler similarity are L = 4
and p = 0.1. The basic idea of the Winkler correction is to give more weight
to the matching of the first L characters. For example, the string a=SIEMENS
has equal Jaro similarity with the strings b=SIEMENX and c=SXEMENS:
jaro(a,b)=jaro(a,c)≈0.90
However, the Jaro–Winkler similarities are different, since l(a,b) = 4 and
l(a,c)=1:
jw (a,b)=0.90+4·0.1·(1−0.90)=0.94
0.1,4
jw (a,c)=0.90+1·0.1·(1−0.90)=0.91
0.1,4
Finally, we sketch how distance measures between strings can be used for
deduplication, again drawing on the example of a list of company names.
First of all, descriptors of the legal entity type of the company, such as “Inc.”


================================================================================
PAGE 49
================================================================================

1.4. Data cleaning 31
or “Aktiengesellschaft,” can be removed or normalized. For example, regular
expressions can be used to take into account frequently occurring typos and
misspellings. This preprocessing may lead to a list of organization names like
the following:
SIEMENES; Siemens; SIMENS; Bosch; BOSH
We further assume that for this particular dataset, it is not relevant whether
the name is written in upper or lower case letters. Therefore, we can replace all
characters with the corresponding capitalized letters.
A pairwise comparison of these harmonized names via the normalized Leven-
shtein similarity leads to the following matrix:
SIEMENES SIEMENS SIMENS BOSCH BOSH
SIEMENES 1.00 0.88 0.75 0.00 0.00
SIEMENS 0.88 1.00 0.86 0.00 0.00
SIMENS 0.75 0.86 1.00 0.00 0.00
BOSCH 0.00 0.00 0.00 1.00 0.80
BOSH 0.00 0.00 0.00 0.80 1.00
WecanchoosetomergeallentitieswithaLevenshteinsimilarityofatleast0.80,
for example. According to that rule, we obtain the pairs (SIEMENES, SIEMENS),
(SIEMENS, SIMENS), and (BOSCH, BOSH). After obtaining the pairs, we can then
merge the corresponding data records.
SIEMENES and SIMENS are also matched, due to their common similarity to
SIEMENS, even though the pairing does not exceed the similarity threshold,
yielding the group of data records S = {SIEMENES,SIEMENS,SIMENS}. After
the merging process, there is still the problem of providing unique information
with the final data record. In particular, we would like to pick an organization
name to include. If all names can be considered equally reliable information,
we can determine a medoid of the group. A medoid (see also Sect. 5.3.1) is an
element, s∈S, that maximizes the sum over the similarities, thus minimizing
the sum over the distances P lev (s,t). In this case, the medoid provides
t∈S norm
the correct name SIEMENS.
In addition to names, other information from the data records can be used for
deduplication, such as the address/location of the headquarters or the year
that the organization was founded in, if available. A general methodological
framework for statistical data deduplication is the Fellegi–Sunter model,
formulated in 1969 [23, 24]. This model is equivalent to the naive Bayes classifi-
cation procedure that we discuss in Sect. 6.3.3. The Fellegi–Sunter model and
other machine learning techniques are increasingly used today for the purpose
of record linkage [25].


================================================================================
PAGE 50
================================================================================

32 Elements of data organization
description data defect example data profiling exam-
ple
complete- Have all relevant data Some persons in the number, proportion,
ness been collected and customer database are or percentage of cus-
stored? missing address infor-tomers with missing
mation. address information
consisten- Areredundantlystored Customer addresses proportion of cus-
cy dataconsistent,ordoes stored at a branch tomers with inconsis-
the information contra-location are different tent addresses
dict itself? from those stored at
the central location.
validity Are the data formally Customer addresses proportion of cus-
correct? That is, are contain postal codes tomers with invalid
they syntactically cor-with invalid characters,postal code, calculated
rect,ofthecorrecttype,such as letters, e.g.,by matching against:
within the valid range“123Q5”
• a complete and cor-
of values?
rect list of postal
codes, or
• a fixed pattern, for
example: exactly
five digits, no
letters
unique- Can the data associ-Several different pri-identifypotentialdupli-
ness ated with any given en-marykeyshavebeenas-cates, see Sect. 1.4.5;
tity be uniquely identi-signed to the same per-proportion of potential
fied? son. duplicates
accuracy Do the data reflect the For some customers,manually check the ac-
truth, or are they at thenameoraddressare curacy of the data (in
odds with reality? incorrect. a sample), for exam-
ple by telephone sur-
vey; proportion of cus-
tomers with incorrect
information
timeli- Do the data reflect the Some customers have proportion of cus-
ness currentstatusofthein-moved but their ad-tomers whose address
formation, or are they dresses have not been data have not been
outdated? updated. updated for some time
Table 1.6. Data quality dimensions


================================================================================
PAGE 51
================================================================================

References 33
References
[1] “Interim Report: ANSI/X3/SPARC Study Group on Data Base Manage-
mentSystems75-02-08”.In: Bulletin of ACM SIGMOD 7.2(1975).Ed.by
Thomas B. Steel, Jr.
[2] Peter Pin-Shan Chen. “The entity-relationship model—toward a unified
viewofdata”.In:ACMTransactionsonDatabaseSystems1.1(Mar.1976),
pp. 9–36. doi: 10.1145/320434.320440.
[3] Michael Widenius, Davis Axmark, and Paul DuBois. MySQL Reference
Manual. 1st ed. Sebastopol, USA: O’Reilly & Associates, 2002.
[4] MariaDB Corporation. MariaDB Server Documentation. Accessed Aug.
29, 2021. url: https://mariadb.com/kb/en/documentation/.
[5] PostgreSQL Development Team. PostgreSQL Documentation. Accessed
July 10, 2020. url: https://www.postgresql.org/docs/.
[6] Ian Robinson, Jim Webber, and Emil Eifrem. Graph Databases. 2nd ed.
Sebastopol, USA: O’Reilly, 2015.
[7] Neo4j Team. The Neo4j Operations Manual v4.1. Accessed July 11, 2020.
url: https://neo4j.com/docs/pdf/neo4j-operations-manual-4.1.pdf.
[8] RSS feed from Towards Data Science. Accessed Sep. 18, 2020. url: https:
//towardsdatascience.com/feed.
[9] Nicola Askham et al. The Six Primary Dimensions for Data Quality
Assessment. Tech. rep. Data Management Association UK, Oct. 2013.
[10] Mark Litwin. How to Measure Survey Reliability and Validity. SAGE
Publications, Inc., 1995. doi: 10.4135/9781483348957.
[11] JeffreyE.F.Friedl. Reguläre Ausdrücke.3rded.O’Reilly,Oct.2012. isbn:
978-3-897-21720-1.
[12] CDC Population Health Surveillance Branch. Behavioral Risk Factor
Surveillance System (BRFSS) Survey Data 2018. Accessed Feb. 1, 2020.
url: https://www.cdc.gov/brfss/.
[13] LorenzoBerettaandAlessandroSantaniello.“Nearestneighborimputation
algorithms: a critical evaluation”. In: BMC Med Inform Decis Mak 74.16
(2016). doi: 10.1186/s12911-016-0318-z.
[14] Agnieszka Mikołajczyk and Michał Grochowski. “Data augmentation
for improving deep learning in image classification problem”. In: 2018
International Interdisciplinary PhD Workshop (IIPhDW). IEEE, May
2018. doi: 10.1109/iiphdw.2018.8388338.
[15] Steven Y. Feng et al. A Survey of Data Augmentation Approaches for
NLP. Dec. 2021. arXiv:2105.03075v5.
[16] Xiang Zhang, Junbo Zhao, and Yann LeCun. “Character-Level Convolu-
tionalNetworksforTextClassification”.In: 28th International Conference
on Neural Information Processing Systems, Montreal, Canada. Vol. 1.
NIPS’15. MIT Press, 2015, pp. 649–657.
[17] Rico Sennrich, Barry Haddow, and Alexandra Birch. “Improving Neural
Machine Translation Models with Monolingual Data”. In: 54th Annual
Meeting of the Association for Computational Linguistics. Vol. 1. Berlin,


================================================================================
PAGE 52
================================================================================

34 Elements of data organization
Germany: Association for Computational Linguistics, Aug. 2016, pp. 86–
96. doi: 10.18653/v1/P16-1009.
[18] GaétandeRassenfosse,HélèneDernis,andGeertBoedt.“AnIntroduction
to the Patstat Database with Example Queries”. In: Australian Economic
Review 47.3 (Sept. 2014), pp. 395–408. doi: 10.1111/1467-8462.12073.
[19] EuropeanPatentOffice.PATSTATGlobal-2018AutumnEdition(sample
data). Accessed Sep. 20, 2020. url: https://www.epo.org/searching-for-
patents/business/patstat.html.
[20] Bonnie Berger, Michael S. Waterman, and Yun William Yu. “Levenshtein
Distance, Sequence Comparison and Biological Database Search”. In:
IEEE Transactions on Information Theory (2020). Early Access. doi:
10.1109/tit.2020.2996543.
[21] Robert A. Wagner and Michael J. Fischer. “The String-to-String Correc-
tionProblem”.In: Journal of the ACM21.1(Jan.1974),pp.168–173. doi:
10.1145/321796.321811.
[22] WilliamE.Winkler.OverviewofRecordLinkageandCurrentResearchDi-
rections. Tech. rep. Washington: U.S. Census Bureau, Statistical Research
Division, 2006.
[23] H. B. Newcombe et al. “Automatic Linkage of Vital Records: Computers
canbeusedtoextract’follow-up’statisticsoffamiliesfromfilesofroutine
records”. In: Science 130.3381 (Oct. 1959), pp. 954–959. doi: 10.1126/
science.130.3381.954.
[24] Ivan P. Fellegi and Alan B. Sunter. “A Theory for Record Linkage”. In:
Journal of the American Statistical Association 64.328 (1969), pp. 1183–
1210. doi: 10.1080/01621459.1969.10501049.
[25] D. Randall Wilson. “Beyond probabilistic record linkage: Using neural
networks and complex features to improve genealogical record linkage”.
In: 2011 International Joint Conference on Neural Networks, San Diego,
USA. IEEE, July 2011. doi: 10.1109/ijcnn.2011.6033192.


================================================================================
PAGE 53
================================================================================

2
Descriptive statistics
Through our everyday experience, we have an intuitive understanding of what a
typical body height is for people in the population. In much of the world, adult
humans are typically between 1.60 m and 1.80 m tall, while people taller than
two meters are rare to meet.
By providing a frequency distribution of body height, this intuited fact can
be backed up with numerical evidence:
body height l number of people/ relative
absolute frequency frequency
l<1.60m 81,199 19%
1.60m≤l<1.80m 260,433 62%
1.80m≤l<2.00m 77,462 18%
2.00m≤l 770 <1%
Table 2.1. Frequency of human body height
These figures are based on a dataset collected by the U.S. Centers for Disease
Control and Prevention (CDC) that lists, among other attributes, the height of
more than 340,000 individuals [1].
An inspection of this frequency table shows that, in fact, more than half
of the people interviewed for the survey reported their height to be between
1.60mand1.80m.Highlightingkeycharacteristicsoffrequencydistributionsvia
numericmeasuresandgraphicalrepresentationisaprimarygoalof descriptive
statistics.
2.1 Samples
When a dataset is the subject of a statistical study, it is also referred to as a
sample. Here is a small excerpt from the CDC sample:
© Springer-Verlag GmbH Germany, part of Springer Nature 2023 35
M. Plaue, Data Science, https://doi.org/10.1007/978-3-662-67882-4_2


================================================================================
PAGE 54
================================================================================

36 Descriptive statistics
sex income body height body weight
category in m in kg
female 6 1.62 59
female 4 1.66 91
female 3 1.47 64
male 3 1.79 86
. . . .
. . . .
. . . .
Table 2.2. CDC sample
The income category takes discrete values from 1 to 8 and denotes a specific
intervalofannualhouseholdincomeinascendingorder.Forexample,category3
represents an income of $15,000 or more but less than $20,000 (income in USD).
In the last chapter, we already identified the columns of such a data table as
attributes.Inthecontextofstatistics,theyarealsocalled variables.Inmachine
learning, we will often call them features, especially when the variables’ values
areusedtoinformthealgorithmaboutessentialcharacteristicsoftheassociated
entities in order to compare them. All possible values that a variable/feature
may take constitute the domain/feature space.
Variables that may take only a finite number of values which have no natural,
meaningful order are called nominal variables. For example, a person’s sex is
a nominal variable.
Variables that can produce a finite number of possible outcomes which can be
ordered in some natural and meaningful way are called ordinal variables. For
example, the income category is an ordinal variable because a person placed in
income category 6 earns more than a person in income category 3.
A variable that is either nominal or ordinal is also known as categorical or
qualitative.
Variables that allow for a meaningful comparison of their values as differences,
ratios, etc. are called numeric or quantitative. For example, height is a
quantitative variable because statements such as “this person is 10 cm taller
than that person” are meaningful.
The rows of the tabulated sample represent statistical units, entities, or
objects. In machine learning, the term instance is commonly used. We can
also refer to them more concretely: in this case, for example, we can speak of
“persons.” The number of statistical units is called the sample size.
A column represents a series of measurements of a single variable, or in other
terms the observations of a feature.
We refer to the set Ω of all existing statistical units as the population—i.e.,
not only those covered by the sample. In the CDC survey, the population is all
U.S. adults and their households. Each subset Ω ⊆Ω of the population (i.e.,
0
including the sample) is a subpopulation. If the subpopulation is specifically


================================================================================
PAGE 55
================================================================================

2.2. Statistical charts 37
a group of people—for example, in the context of a demographic study—it is
also referred to as a cohort.
Each subpopulation uniquely defines a dichotomous or binary variable,
i.e., a variable with domain {0,1}: a statistical unit is assigned the value
one if it belongs to the subpopulation, and a value of zero if it does not
belong to the subpopulation. Conversely, each binary variable uniquely defines
a subpopulation: all those statistical units for which we observe the value 1. In
summary, there is a one-to-one correspondence between subpopulations and
binary variables.
All of the above are examples for univariate variables: each observation
corresponds to only a single value at a time. However, we can also combine
several univariate variables into one multivariate variable to yield a sequence
of data points or feature vectors. For example, the feature vector (height
in m, body weight in kg) can be considered for each person. Such a multivariate
variable or feature with exactly two entries is also referred to as bivariate.
In summary, the variables in the CDC dataset can be categorized as follows:
variable/feature domain/feature space data type
sex {female,male} nominal
income category {1,2,...,8} ordinal
body height ]0,∞[⊂R numeric
(body height, body weight) ]0,∞[×]0,∞[ numeric, bivariate
Table 2.3. Data types
Finally, subpopulations can be defined by imposing conditions on variables.
Examples would be the cohort of males Ω = {ω|sex(ω) = male} or the
male
cohort of individuals with a body mass index (BMI) between 25kg/m2 and
30kg/m2:
(cid:26) (cid:12)
(cid:12)
weight(ω) (cid:27)
Ω
pre-obese
= ω(cid:12)
(cid:12)
25≤
height(ω)2
<30
2.2 Statistical charts
In the introduction, we had already introduced a form of statistical chart, the
line chart, or line graph (Fig. 0.1). It is similar to the scatter plot discussed
in one of the following sections, with successive data points connected by a
(straight) line to highlight an increase or decrease in the ordinate value. This
type of chart is particularly suitable for plotting time series, that is, numeric
observations ordered over time.
The use of statistical charts is well suited for exploratory data analysis. In
this context, they are used to uncover patterns and relationships to formulate
hypotheses that can be tested against the data.


================================================================================
PAGE 56
================================================================================

38 Descriptive statistics
2.2.1 Bar charts and histograms
Inorderto make us—quiteliterally—apictureof agiven frequencydistribution,
we can represent it as a bar chart in the case of a categorical feature, or a
histogram in case of a numeric variable. In Fig. 2.7, a few bar charts and
histograms are shown for features exhibited by the CDC dataset.
For qualitative variables, such as sex or income category, the height of each
rectangle indicates the relative frequency that the respective value occurs with.
The absolute frequency can also be plotted; this simply corresponds to a global
scaling of all column heights by the sample size. The widths of the rectangles
have no particular meaning.
For quantitative variables such as body height or body weight, the domain
must be divided into intervals, called bins or buckets, in order to count
the observations within each bin and thus determine the frequency. The bin
width is represented by the width of each rectangle in the chart. For example,
the bin width for the histogram of the body height in the example charts is
exactly 2.54cm. This value corresponds to one inch, the U.S. customary unit of
length that the body height had been measured in originally. The frequency
is represented by the area of each rectangle, and the height of each rectangle
is given by the frequency divided by the bin width. In general, although not
commonly found, a histogram may have variable bin width.
Example. We notice that the histogram of the body weight reported with
theCDCsurveyshowsgapsatregularintervals.A“zoom” intothehistogram,
given in the original units of measurement provides more detail:
0.05
0.04
0.03
0.02
0.01
0.00
155 160 165 170 175 180 185 190 195 200
body weight in pounds
Fig. 2.1. Frequency distribution of self-reported body weight
The data were collected via a telephone survey among U.S. citizens. Partic-
ipants rarely reported their weight exactly to the pound, but instead they


================================================================================
PAGE 57
================================================================================

2.2. Statistical charts 39
often used rounded values. This behavior gives us an example of response
bias,noticeablebyhowthebodyweightsdivisiblebyfiveareoverrepresented.
The example shows that we can use bar charts and histograms to identify
patterns in the distribution of values. Characteristics that can be inferred are:
• Which values of a categorical variable are the most common, and which
values of a numeric variable can be considered “typical”?
• Do all values occur equally often, i.e., do they show a large variation or
dispersion—or are they concentrated around a “typical” value?
Statistical measures that gauge a central tendency or dispersion in the distribu-
tion of values help us ground such obervations on numeric evidence. These will
be described in the later sections.
2.2.2 Scatter plots
Variables often depend on each other, i.e., there may be functional relation-
ships between them. Such association between two numeric variables can be
represented graphically by scatter plots. These plots may illustrate an al-
ready known association or be used to explore the data for previously unknown
relationships between features.
In a scatter plot, the paired variable values—i.e., values that belong to the same
statistical unit—are plotted against each other as data points in the coordinate
plane.
The following scatter plot shows height and weight for 150 randomly selected
male respondents from the CDC survey.
160
120
80
1.50 1.60 1.70 1.80 1.90 2.00
body height in m
gk
ni
thgiew
ydob
Fig. 2.2. Scatter plot of body height vs. body weight


================================================================================
PAGE 58
================================================================================

40 Descriptive statistics
As expected, there is a general tendency for taller people to also have higher
weight. Nevertheless, even amongst those persons with the same height, there is
a large variation in body weight. Therefore, height is not the only variable that
factors into a person’s weight, a finding that is consistent with our everyday
experience:
Example. Let’s use the CDC dataset to compare the body mass index and
the Broca index. These measures serve as a rough indication of what can
be considered a healthy body weight. BMI is calculated using the following
formula:
body weight
BMI=
(body height)2
Usually, BMI is expressed in units of kilograms per square meter. Adults
with a BMI of more than 30 kg are generally considered obese, according to
m2
the World Health Organization [2, Sect. 2.3].
Normal weight according to Broca is calculated as follows:
normal weight according to Broca in kg=body height in cm−100
TheBrocaindexisthedifferenceoftheactualbodyweightfromthisreference
point,givenasapercentage.Accordingtothismetric,adultswithadeviation
above +20% from the normal weight can be considered obese.
The following chart shows a plot of BMI against Broca’s index for the male
respondents in the CDC survey selected above.
45
40
35
30
25
20
0 30 60
Broca index in percent
2m/gk
ni
IMB
Fig. 2.3. Scatter plot of Broca vs. body mass index
The gray areas mark the “critical” regions BMI>30 kg and Broca index>
m2
20%, respectively. Both metrics are associated strongly: although the Broca
indexhasbecome“outoffashion” comparedtotheBMI,bothmeasurescome


================================================================================
PAGE 59
================================================================================

2.2. Statistical charts 41
to very similar conclusions. The definitions for obesity are also compatible
witheachother:thereareonlyveryfewobservationsinthelightgrayareasat
the top left or bottom right that would indicate an inconsistent assessment.
Inadditiontographicalrepresentation,wecancomputemeasuresofassociation
to gauge whether statistical variables are related. These measures will be
discussed in Sect. 2.5.
Furthermore, associations can be described by statistical models. For example,
the dependence of the Broca index on the body mass index, and vice versa,
appears to be linear: the data points do not lie exactly but are approximately
on a straight line. The optimal position and orientation of such a straight line
can be determined by a regression analysis, see Sect. 4.5.1.
2.2.3 Pie charts, grouped and stacked bar charts, heatmaps
2.2.3.1 Pie chart
One popular method used to represent proportions is the pie chart, or circle
chart.Inapiechart,proportionsarerepresentedassectorsofacircle,similarto
pieorpizzaslices.Althoughitiswidelyusedinpopularpublications,whetheror
not the pie chart is an effective form of visualization is considered controversial
among experts [3]. If possible, a pie chart should only be used if it does not
contain too many pieces. The use of three-dimensional pie charts should always
be refrained from.
A variant of the pie chart is the doughnut chart, which is basically a single
stackedbar(seethenextsection)benttoacircle.Thefollowingdoughnutchart
shows the outcome of the 2021 German federal election [4]:
Free Democratic Party other parties
12% 14%
The Greens Alternative for Germany
15% 10%
24%
26%
Union parties
Social Democratic Party
Fig. 2.4. Doughnut chart


================================================================================
PAGE 60
================================================================================

42 Descriptive statistics
2.2.3.2 Grouped and stacked bar charts
In order to compare distributions across (sub-)populations, we can show their
bar charts in a single figure. The following grouped bar chart shows the
outcome of consecutive German federal elections [4, 5, 6]:
2021 2017 2013
U
Social
D
nion
em
F .
ree
D
A
T he
G
em
.
lt.
for
G
reens
erm
any
T
he
L
eft
0% 5% 10% 20% 30% 40%
Fig. 2.5. Grouped bar chart
Foreachparty,wecanreadilycomparehowtheshareofvoteschangedovertime.
Nevertheless, we are also able to gauge which parties received a larger share in
general. The vertical dashed line indicates the five-percent electoral threshold,
which must be met for a party to hold office in the German parliament.
The following stacked bar chart is an alternative visualization that allows
comparison of the overall outcome for each election:
Union Free Dem. Alt. for Germany
Social Dem. The Greens The Left
2021
2017
2013
0% 25% 50% 75%
Fig. 2.6. Stacked bar chart


================================================================================
PAGE 61
================================================================================

2.3. Measures of central tendency 43
2.2.3.3 Heatmap
A heatmap is used to visualize key figures arranged in a matrix, where each
numeric value corresponds to a color-coded tile. Fig. 2.8 shows on the left a
heatmapdiagrambasedondatafromtheGerman2018ALLBUSsurvey[7].The
chart compares the preference for a political party in Germany with responses
to the following question: “What do you think of the following statement: the
influx of refugees should be stopped.” The color saturation of the tiles indicates
the proportion of people with a given party preference, i.e., each row represents
the distribution of the frequency of responses by people with the given party
preference. Consequently, the distributions in the respective cohorts can be
compared easily.
Another variant of the heatmap is the choropleth map, in which geographic
areas are colored. Such a map is shown in Fig. 2.8 on the right. It shows the
percentage of ALLBUS respondents who tend to agree or disagree that the
influx of refugees should be stopped for each German federal state.
2.3 Measures of central tendency
Measures of central tendency answer the question: which measurements or
observations occurring in a sample can be considered “typical”?
Tab. 2.1 at the beginning of the chapter shows that most people, 62%, have
a height between 160 and 180 cm, which is a larger proportion than in any
other of the given height cohorts. Therefore, the range of values between 160
and 180 cm can be considered typical because people with heights in this range
are most frequently encountered. In other words, the frequency distribution
assumes a maximum number of observations at that range. Such a maximum
is also called a mode of the distribution. In practice, we often speak of the
mode, even though the mode need not be uniquely determined. Firstly, variable
values can occur with exactly the same or nearly the same frequency. Secondly,
it may happen that a histogram has several local maxima, in which case the
distribution is called multimodal, otherwise unimodal. Fig. 2.10 shows the
histogram of a multimodal distribution.
For categorical variables, determining the mode simply requires counting obser-
vations within each category and selecting the one that occurs most frequently.
Fornumericvariables,themodedependsonthedivisionofthevariable’sdomain
into bins that is used to determine the histogram or frequency distribution. The
mode can also be determined via smooth approximations to the histogram, like
kernel density estimation (see Sect. 4.4.3).
2.3.1 Arithmetic mean and sample median
Besides the mode, the following measures of central tendency are among the
most commonly used.


================================================================================
PAGE 62
================================================================================

44 Descriptive statistics
)thgir(
smargotsih
dna
)tfel(
strahc
rab
:yevrus
CDC
eht
morf
selbairav
rof
noitubirtsid
ycneuqerF
.7.2
.giF
%05
30.0
%04
20.0
%03 %02
10.0
%01
00.0
%0
002
571
051
elam
elamef
mc
ni
thgieh
ydob
xes
%03
20.0
%02
10.0
%01
00.0
%0
051
001
05
8
7
6
5
4
3
2
1
gk
ni
thgiew
ydob
yrogetac
emocni


================================================================================
PAGE 63
================================================================================

2.3. Measures of central tendency 45
%01
%12
%12
%33
%51
%9
%71
%71
%53
%22
%1
%4
%11
%83
%64
%8
%41
%61
%33
%03
%46
%81
%11
%4
%3
%21
%42
%91
%42
%02
%92
%41
%7
%34
%7
gree
a
gree
a
o
d
t
te n
ffere
nt
di
n
i
gree
a not
te n d
t o
not
a
gree
do
U
S
n
o
i o
ci
n
a l
p a
D
r
e
t
m
i e
o
s
cr
ati c Party
T
he Gree ns
Alte
T
r n
h
a
e
t i
L
v
e
e
f t
f or
F r
G
e
e
e
r
D
m
e
a
m
n y
ocr
ati c Party ot hers
%57
05 52
0
;deppots
eb
dluohs
seegufer
fo
xuflni
eht
taht
eerga
ro
eerga
ot
dnet
taht
snosrep
fo
egatnecrep
:)thgir(
ynamreG
fo pam
htelporohC
.8.2
.giF
lortnoc
noitargim
fo
ytissecen
eht
no
noinipo
.sv
ecnereferp
ytrap
lacitilop
:)tfel(
pamtaeh


================================================================================
PAGE 64
================================================================================

46 Descriptive statistics
For a sequence of numeric observations x = (x ,x ,...,x ) ∈ RN, the
1 2 N
arithmetic mean, or arithmetic average, is defined as follows:
N
1 1 X
x¯ = (x +x +···+x )= x
arithm N 1 2 N N n
n=1
Now assume that the observations have been sorted in ascending order:
x ≤x ≤···≤x . The sample median of x is defined as the midpoint
1 2 N
of this sorted sequence:

x
N+1
if N is odd
x¯ = 2(cid:16) (cid:17)
median  1 2 · x N +x N+1 if N is even
2 2
The sample median can also be calculated for ordinal variables. However, in
general, there is no longer a meaningful convention with which to enforce a
unique result in the case of an even number of observations. For example, for a
sample x=(1,5,6,8) of income categories, both x¯ =5 and x¯ =6
median median
are valid medians.
In practice, the sample median in this example could still be given as x¯ =
median
5.5, even though no fractional income categories are defined. Even computing
the arithmetic mean for—strictly speaking—ordinal features can be useful in
some cases. For example, in the course of a game of dice, the average die roll
might be given by 3.14—although, of course, a real die has no side that would
correspond to such a fractional number.
For the sample median we also write:
median(x)= median (x )=x¯
n median
n∈{1,...,N}
For the arithmetic mean, we often omit the subscript: x¯ = x¯ . Other
arithm
possible notations include the following:
µ(x)=⟨x⟩=⟨x ⟩ =x¯
n n∈{1,...,N} arithm
The sample median is also called the empirical median, while the arithmetic
mean can also be called the empirical mean, sample mean, or empiri-
cal expected value. The labels “sample” or “empirical” indicate that these
measures are computed from data. Empirical measures have counterparts in
probability theory—discussed later in Chap. 3—that are derived from more
abstract objects called random variables. In inferential statistics, empirical
measures are interpreted as estimates of these “theoretical” values. For the sake
of brevity, we may at times omit the label “sample” or “empirical.”
The terms population mean and population median are commonly used to
refer to the mean/median of the whole population. However, we will not make


================================================================================
PAGE 65
================================================================================

2.3. Measures of central tendency 47
use of those terms in this book and will only refer to the sample mean/median,
which may be computed with respect to a subpopulation of any size.
Example. The arithmetic mean of the values for body height collected in
the CDC survey is 1.70 m. The median is also 1.70 m.
Although the arithmetic mean is a very commonly used measure of central
tendency,themedianhasapropertythatmakesitsuperiorforsomeapplications:
itisarobuststatistic,resistanttooutliers.Thismeansthatitdoesnotchange
its value much, if at all, if some values in the sample differ significantly from
the rest. Outliers can be the result of data defects, so such robustness may be
desired.
Inordertoillustratethisproperty,wecalculatethearithmeticmeanandmedian
for the sequence of observations x=(−1.0,−1.0,0.0,1.0,2.0,100.0):
1
x¯= ·(−1.0−1.0+0.0+1.0+2.0+100.0)≈16.8
6
1 1
x¯ = ·(x +x )= ·(0.0+1.0)=0.5
median 2 3 4 2
The outlier x =100.0 has a significant impact on the arithmetic mean but not
6
the median.
For so-called skewed distributions, the proportion of values smaller or larger
than the arithmetic mean can deviate substantially from 50%. However, the
median splits the sequence of observations right in the middle: half the values
are below the median and half are above.
Example. Income statistics often lead to skewed distributions. For example,
according to the data provided with the ALLBUS survey, the arithmetic
mean of monthly net household income in Germany in 2018 is 3150 Euros
(EUR). However, more than half (60%) of households actually have lower
incomes. Therefore, the median income is the better benchmark: 2800 EUR.
Thereareanumberoftestsandmeasuresthatexistforthepurposeofevaluating
the skewness or asymmetry of a frequency distribution. A rule of thumb (cf. [8])
is the following:
The skewness of a unimodal distribution of values x ,...,x , with mode
1 N
x¯ , median x¯ , and arithmetic mean x¯, can be characterized as
mode median
follows. The distribution is:
symmetric if x¯ ≈x¯ ≈x¯,
mode median
negatively skewed if x¯ >x¯ >x¯,
mode median
positively skewed if x¯ <x¯ <x¯.
mode median


================================================================================
PAGE 66
================================================================================

48 Descriptive statistics
The income distribution derived from the ALLBUS data is positively skewed,
as can be inferred from the following figure:
arithmetic mean
mode
median
2×10−4
1×10−4
0
0 2500 5000 7500
monthly net income of German households in 2018, in EUR
Fig. 2.9. Histogram of a positively skewed distribution
The mode has been determined via the maximum of a so-called kernel density
estimateofthedistribution(givenbythedashedcurve).WeexplaininSect.4.4.3
how to compute such an estimate.
2.3.2 Sample quantiles
Quantiles are another important class of statistical measures.
Let 0 < α < 1, and x = (x ,...,x ) be a sample of numeric or ordinal
1 N
values. A sample quantile of order α or α-quantile is a value Q (x)
α
fromthesamplesuchthatbelowandabovethatvalueacertainproportion
of observations can be found:
1. At least α·N of the observations are less than or equal to Q (x), and
α
2. at least (1−α)·N of the observations are greater than or equal to
Q (x).
α
The α-quantile is only not uniquely determined if α·N is an integer. Otherwise,
the quantile is given by Q (x) = x , where the observations have been
α ⌊αN⌋+1
sorted in ascending order and ⌊αN⌋ is the largest integer less than or equal to
α·N.
In practice, it is common—as with the median—to enforce uniqueness via the
arithmetic mean of the candidates:
(
x if α·N ̸∈N
Q (x)= ⌊αN⌋+1
α 1 ·(x +x ) if α·N ∈N
2 αN αN+1


================================================================================
PAGE 67
================================================================================

2.3. Measures of central tendency 49
With this convention, the sample median is just the 0.5-quantile: x¯ =
median
Q (x).
0.5
Other quantiles that deserve a special name are the lower and upper quartile:
Q and Q , respectively.
0.25 0.75
Example. The lower quartile of the height surveyed in the CDC study is
1.63 m, and the upper quartile is 1.78 m.
2.3.3 Geometric and harmonic mean
The following measures of central tendency have special applications where the
arithmetic mean does not produce a reasonable average value.
For a sequence of positive numeric observations x = (x ,x ,...,x ) ∈
1 2 N
]0,∞[N, we define:
The geometric mean
N ! N 1
1 Y
x¯
geom
=(x
1
·x
2
···x
N
)N = x
n
n=1
and the harmonic mean
N
!−1
N X 1
x¯ = =N · .
harm 1 + 1 +···+ 1 x
x1 x2 xN n=1 n
It can be proven that—for any sample x=(x ,...,x ) of positive values—the
1 N
various measures of central tendency satisfy the inequalities:
0<min{x }≤x¯ ≤x¯ ≤x¯ ≤x¯ ≤max{x }
n harm geom arithm RMS n
n n
Here, x¯ is the root mean square, another measure of central tendency
RMS
that we haven’t mentioned yet:
v
u N
1 uX
x¯ = √ ·t x2
RMS n
N
n=1
The geometric mean is used in particular for averaging rates of exponential
growth or decline, as illustrated by the following calculation. Say that some
monetary investment of 1000 EUR yields variable profits. During the first year,
theinvestmentgrowsbyp =+20.0%.Inthesecondyear,thereisap =−20.0%
1 2
loss.Finally,inthethirdyear,thereisa p =+10.0%profit.Thecorresponding
3
factors by which the investment grows each year are W =(1.200,0.800,1.100).
Therefore, after three years, the investor has the following amount in EUR:


================================================================================
PAGE 68
================================================================================

50 Descriptive statistics
1000·1.200·0.800·1.100≈1000·1.056
Consequently, the total growth rate is +5.6%. However, what is the average
annual growth rate? That growth rate corresponds to the average factor W¯
?
under the assumption of a fixed rate of interest with the same end result:
1000·W¯ ·W¯ ·W¯ =1000·1.200·0.800·1.100
? ? ?
It is not so difficult to see that this average factor is just equal to the geometric
mean of the individual factors:
W¯
?
=W¯
geom
=(1.200·0.800·1.100)3 1 ≈1.018
Therefore,theaverageannualgrowthrateis 1.8%.Anaiveuseofthearithmetic
meanwouldhaveledtoadifferentandthusfactuallyincorrectresult: W¯ =
arithm
1.033, p¯ =3.3%.
arithm
We will encounter the harmonic mean again in the definition of the F -score, a
1
metric for the evaluation of classification algorithms (see Sect. 6.1.3.2). Another
application is in averaging speeds, as the following example will illustrate. Anna
takes a public bus to work in the morning (distance ∆s = 5km) when there
is little traffic and an average speed of v =40km. The average speed on the
1 h
return trip home is only v =10km since the bus has to fight its way through
2 h
traffic.
What is the average speed v¯ by which Anna or the bus cover the total distance
?
2·∆s on the way there and back? This average speed is equal to the distance
traveled divided by the total time taken ∆t: v¯ = 2·∆s. For the outward trip,
? ∆t
the bus needs the time ∆t = ∆s, and for the return trip the time ∆t = ∆s.
Thus, the average speed is
1
given
v1by: 2 v2
2·∆s 2·∆s 2
v¯ = = = =v¯
? ∆t +∆t ∆s + ∆s 1 + 1 harm
1 2 v1 v2 v1 v2
Plugging in the actual numbers gives the result v¯ =16km. The arithmetic
harm h
mean yields a higher value: v¯ =25km. This is because Anna needs much
arithm h
more time for the return trip than for the outward trip. Therefore, she also sits
in the slow-moving bus for a longer time, so overall she moves with a speed that
is lower than the arithmetic mean would imply.
2.4 Measures of variation
Measures of central tendency compute a “typical” value of a distribution. How-
ever, the significance of such a calculation can vary, as the value thus obtained
can be “more or less typical.” For example, approximately 55% of the CDC
surveyrespondentsreportedbeingfemale,while45%reportedbeingmale.Thus,
strictly speaking, “female” is the mode of the variable sex. Nevertheless, this


================================================================================
PAGE 69
================================================================================

2.4. Measures of variation 51
category can hardly be described as typical because the proportion of persons
of male sex is about the same.
On the other hand, the average body height of 1.70 m may well be considered
a typical value because we can infer from experience or from the shape of the
histogram that not many persons deviate from this value to a significant degree.
Measures of variation or dispersion indicate the extent to which values
occur with equal frequency, and they also quantify the extent of dispersion
around a central point.
2.4.1 Deviation around the mean or the median
A simple measure of variation for numeric variables is the range, given by the
difference between the largest and smallest values in the sample. However, even
single outliers can have a significant impact on this value. The interquartile
range is more resistant to outliers than the full range. The interquartile range
is defined as the difference between the upper and lower quartile: Q −Q .
0.75 0.25
Example. The interquartile range of the body height values collected with
the CDC survey is given by 178cm−163cm=15cm.
The following measures of variation are based on the idea of calculating the
average deviation from the average value.
For a sequence of numeric obervations x = (x ,x ,...,x ) ∈ RN, the
1 2 N
sample variance is the mean squared deviation from the arithmetic
mean:
N
1 X
s2(x)= (x −x¯)2
N n
n=1
The sample standard deviation is the square root of the variance:
p 1 X N
!1
2
s(x)= s2(x)= (x −x¯)2
N n
n=1
The above definition describes what should more accurately be called the biased
sample variance. The so-called unbiased sample variance, also called the
Bessel-corrected sample variance, is given by:
N
1 X N
s2 (x)= (x −x¯)2 = ·s2(x)
cor N −1 n N −1
n=1
The use of the unbiased variance is particularly recommended for small samples.
For large samples, however, both formulas give approximately the same results.
WewilllearninSect.4.2.3aboutthemotivationandrationalebehindtheBessel
correction.


================================================================================
PAGE 70
================================================================================

52 Descriptive statistics
Example. The standard deviation of the body height values collected with
the CDC survey is given by 11cm.
Other measures of variation include the following.
The mean absolute deviation around the mean is given by:
N
1 X
MAD(x)= |x −x¯|
N n
n=1
The mean absolute deviation around the median is given by:
N
1 X
MAD (x)= |x −x¯ |
median N n median
n=1
Example. The mean absolute deviation around the mean/median of the
body height values collected with the CDC survey are both given by 9cm.
Example. The following histogram shows the distribution of the length
of the petals of iris plants [9]. The horizontal bars indicate the intervals
[x¯−s(x),x¯+s(x)] and [x¯ ±MAD (x)], respectively. Apparently,
median median
thefrequencydistributionismultimodal,asthehistogramshowstwomaxima.
Infact,thereareeventwoseparatedgroups,eachofwhichbelongtodifferent
species.
median
0.75
0.50 arithmetic mean
0.25
0.00
2.0 4.0 6.0
petal length in cm
Fig. 2.10. Deviation around the mean and the median


================================================================================
PAGE 71
================================================================================

2.4. Measures of variation 53
2.4.2 Shannon index
Foracategoricalfeaturewith K possiblevaluesorcategories,wecanobtainthe
relativefrequencies,f ,...,f ,oftheoccurrenceofeachcategorybydividingthe
1 K
absolutefrequencies,n ,...,n ,bythesamplesizeN.Theabsolutefrequencies
1 K
always sum to N, while the relative frequencies sum to one:
K K K
X f = Xn k = 1 · X n = 1 ·N =1
k N N k N
k=1 k=1 k=1
The category that occurs most frequently, i.e., the maximum value for f or
k
n , is the measure of central tendency that we already know as the mode. In
k
a bar chart, the mode corresponds to the category with the longest bar. The
following metric, on the other hand, is a measure of the extent to which all bars
have a similar length.
LetxbeasequenceofobservationsofacategoricalvariablewithK possible
values. Furthermore, let f ,...,f be the relative frequencies that the K
1 K
categories occur with. The Shannon index is then given as follows:
K
X
H(x)=− f log (f )
k b k
k=1
Here, b denotes the base of the logarithm, and we agree on the convention
0·log 0=0: terms with vanishing relative frequency f are set to zero.
b k
The normalized Shannon index is given as follows:
1
H (x)= ·H(x)
norm log (K)
b
Common values for the base of the logarithm are b=2 (binary logarithm) or
b=e=2.718... (natural logarithm). The Shannon index can be interpreted
as an empirical estimate of the Shannon entropy, see Sect. 3.4.1, an abstract
measure of average information content. In this context, the logarithm base
determines units of measurement: the choice b=2 corresponds to measuring
the Shannon entropy in the unit of information commonly referred to as bit. For
the definition of the normalized Shannon index, the choice of the base does not
matter. In the following paragraphs, we will always use the natural logarithm.
The normalized Shannon index varies between zero and one. It vanishes if only
a single category actually appears in the sample. Without loss of generality, we
mayassumethatitisthethefirstone, f =1andf =0forall k ∈{2,...,K}:
1 k
K
1 X 1
H (x)=− f ln(f )=− ·1·ln(1)=0
norm ln(K) k k ln(K)
k=1


================================================================================
PAGE 72
================================================================================

54 Descriptive statistics
The other extreme is given by the situation when all categories occur with the
same frequency. In this case, they are said to follow a uniform distribution.
For a uniform distribution, f
k
= 1/K holds for all k ∈ {1,...,K} and the
Shannon index is maximized:
K K (cid:18) (cid:19)
1 X 1 X 1 1
H (x)=− f ln(f )=− ln
norm ln(K) k k ln(K) K K
k=1 k=1
1 1
=− ·K· ·(−ln(K))=1
ln(K) K
The inverse statements also apply. For example, a maximum Shannon index
implies uniform distribution. The Shannon index measures the variation within
a categorical frequency distribution. A low Shannon index, approaching zero,
indicates that the majority of observations belong to one category (the mode).
A high Shannon index, approaching its maximum, indicates that every category
occurs with about the same frequency.
Example. The normalized Shannon index for the distribution of sex among
the respondents to the CDC survey is given by:
1
H (sex)=− (0.55·log(0.55)+0.45·log(0.45))≈0.993
norm log(2)
The entropy of the distribution of income categories is lower, since some
categories are more frequent than others:
H (income category)≈0.893
norm
2.5 Measures of association
Variables can be dependent of each other, i.e., there can be functional rela-
tionships between them. For example, let us imagine a company that produces
rectangular shape workpieces and—perhaps for quality assurance—measures
the size of a random sample of these workpieces. Even if the manufactured
parts vary in size, the following is true for each: the area of the workpiece is the
product of its side lengths. The example seems trivial because the relationship
follows immediately from geometric considerations. However, this is not always
thecase;theremayalsobehiddenfunctionalrelationshipsbetweenfeaturesthat
are not immediately apparent. Secondly, even very strong associations do not
reflect a strictly deterministic dependence between observations. For example,
there is an association, demonstrated by many studies, between inhalation of
tobacco smoke and the development of cancer [10]. Nevertheless, not every
smoker develops cancer, and some—albeit few—lung cancer patients turn out
to be non-smokers.


================================================================================
PAGE 73
================================================================================

2.5. Measures of association 55
Measures of association are used to confirm or explore relationships between
variables. To this end, we compare sequences of observations x=(x ,...,x )
1 N
and y = (y ,...,y ) of those variables. For the results to have any practical
1 N
value, these observations need to represent paired data: every data point
(x ,y ) comes from a single statistical unit so that x and y are naturally
n n n n
matched. For example, x and y could be body height and body weight of the
n n
same individual.
2.5.1 Sample covariance and Pearson’s correlation coefficient
The statistical measures defined below can be used to gauge a linear functional
relationship between numeric variables. If such a measure comparing two vari-
ables has a high value in terms of magnitude, then the linear increase in one
variable is associated with the linear increase or decrease of the other.
For two paired sequences of numeric measurements/observations, x =
(x ,...,x ) and y =(y ,...,y ), their sample covariance is given as
1 N 1 N
follows:
N
1 X
s(x,y)= (x −x¯)·(y −y¯)
N n n
n=1
The sample Bravais–Pearson correlation coefficient is given by:
s(x,y)
r(x,y)= ,
s(x)·s(y)
where we need to assume s(x)̸=0 and s(y)̸=0.
The sample variance can be interpreted as the covariance of a single sequence of
observations with itself: namely that s(x,x)=s2(x) holds for all x∈RN. The
Bravais–Pearsoncorrelationcoefficientisalsoknownas Pearson’s correlation
coefficient.
We would now like to clarify how to interpret the covariance and Pearson’s
correlation coefficient. For this purpose, we first claim the following general
properties of the arithmetic mean µ(·) and the sample variance s2(·), which
are not difficult to prove:
µ(mx+c)=mµ(x)+c,
s2(mx+c)=m2s2(x)
for all x ∈ RN and m,c ∈ R. Thus, for the standard deviation, s(mx+c) =
p s2(mx+c)= p m2s2(x)=|m|·s(x).
Let’sassumenowthattheequationy =mx+cholds:whenplottingthey-values
over the x-values in a scatter plot, they would lie exactly on a straight line
with slope m and intercept c. Thus, the variable values are associated through


================================================================================
PAGE 74
================================================================================

56 Descriptive statistics
a perfect linear relationship. In this case, the covariance can be computed as
follows:
N
1 X
s(x,y)=s(x,mx+c)= (x −x¯)·(mx +c−mx¯−c)
N n n
n=1
N
1 X
=m· (x −x¯)·(x −x¯)=m·s(x,x)
N n n
n=1
=m·s2(x)
Consequently, for the correlation coefficient (assuming m̸=0):
s(x,mx+c) ms2(x)
r(x,y)= =
s(x)·s(mx+c) |m|(s(x))2
(
1 if m>0
=sgn(m)=
−1 if m<0
Ifthey valuesincreaselinearlywith x,thenthecorrelationisgivenby r(x,y)=
+1. But if they decrease linearly with x, then we have r(x,y) = −1. Each
situation corresponds to a perfect positive or negative linear correlation of
both features, respectively. We come back to the relationship between Pearson
correlation and linear dependence in more detail at the end of Sect. 4.5.1.
In addition to these extreme values, the following interpretations of the effect
size can be given for certain magnitudes of the Bravais–Pearson coefficient [11,
p. 79]:
|r(x,y)| 0.0 0.1 0.3 0.5
effect none small medium large
Table 2.4. Size of correlation effects
Example. By analyzing N =164,798 answers from male respondents in the
CDC survey, we can determine the Pearson correlation coefficient between
body mass index and the Broca index. In the scatter plot of Fig. 2.3, the
datapointslieonastraightlinewithapositiveslope,togoodapproximation.
Therefore, we can expect that there is a strong positive correlation of r ≈1.
In fact, r = 0.995 holds. Between body weight and BMI, the correlation
coefficient is only r = 0.872—this value still indicates a strong correlation
though. Body height and weight show a moderate correlation with r =0.387.
Body height and BMI show no significant linear correlation: r =−0.094.
2.5.2 Rank correlation coefficients
The measures of association defined in this section can be used to gauge a
monotone functional relationship between numeric or ordinal variables. A high


================================================================================
PAGE 75
================================================================================

2.5. Measures of association 57
value in terms of magnitude indicates that the increase in one variable is
associated with the increase or decrease of the other. This relationship—in
contrast to the scope of the Pearson correlation—need not necessarily be linear.
Let x=(x ,...,x ) be a sequence of observations of a numeric or an ordinal
1 N
variable. We can sort these observations in descending order:
x ≥x ≥···≥x ,
ι(1) ι(2) ι(N)
where ι: {1,...,N}→{1,...,N} is a permutation of indices. The numbers
rg(x)=(ι(1),ι(2),...,ι(N))
are called the ranks of the observations. The observation with the largest value
is given rank 1, and the observation with the smallest value is given rank N.
The convention of putting the smallest value first is also common.
If no value occurs more than once in the sample, each value will have a unique
rank. Otherwise, to ensure uniqueness, the first occurrence of a repeated value
should receive the lower rank.s
However, this convention will lead to identical variable values being assigned a
different rank, which can be undesirable. We may correct the ranking as follows:
identical observations are assigned the arithmetic mean of their ranks, and we
denote the result by rg(x).
Another useful definition is the percentile rank of an observation x :
n
1
%-rg(x )= ·|{m∈{1,...,N}|x ≤x }|
n N m n
Thus, the largest value in the sample always receives the maximum percentile
rank of 100%.
We consider a hypothetical example to illustrate the different definitions of a
rank. Imagine five students receive the following grades at the end of the school
year: x=(B,A,B,A,C).Weinterpretthesegradesasasequenceofvaluesfrom
an ordinal variable with domain E/F < D < C < B < A. The corresponding
ranks are given as follows, where we have re-ordered the sample by the simplest
definition of the rank:
n x rg(x ) rg(x ) %-rg(x )
n n n n
2 A 1 1.5 100%
4 A 2 1.5 100%
1 B 3 3.5 60%
3 B 4 3.5 60%
5 C 5 5 20%
Table 2.5. Rank statistics of school grades


================================================================================
PAGE 76
================================================================================

58 Descriptive statistics
Let x = (x ,...,x ) and y = (y ,...,y ) be two paired sequences of
1 N 1 N
observations of numeric or ordinal values.
Spearman’s rank correlation coefficient is defined as follows:
ρ(x,y)=r(rg(x),rg(y)),
where r(·, ·) is the Bravais–Pearson correlation coefficient.
Kendall’s rank correlation coefficient is the following measure:
1 X
τ(x,y)= sgn(x −x )·sgn(y −y )
N(N −1) l k l k
k,l∈{1,...,N}
In order to compare the above rank correlation coefficients with Pearson’s and
showcase some of their characteristics, we compute them for a collection of four
synthetic datasets called Anscombe’s quartet [12], shown in Fig. 2.11.
A calculation of the individual correlation coefficients for each dataset given by
x(i) and y(i), i=1,2,3,4, yields the following results:
i Pearson Spearman Kendall
1 0.82 0.82 0.63
2 0.82 0.69 0.56
3 0.82 0.99 0.96
4 0.82 0.50 0.18
Table 2.6. Correlation coefficients computed for Anscombe’s quartet
First, we note that for all four datasets—although they are of a very different
shape, as evidenced by their scatter plots—the Bravais–Pearson correlation
coefficientisidentical.Therankcorrelationcoefficientsfortheseconddataset,on
theotherhand,arelowerbecausethe y valuesdonotgroworfallmonotonically
with the x values. In addition, the rank correlation is more robust to individual
outliers, as shown by the third example. However, the fourth example also
reveals a difficulty: the majority of the x values here are identical or nearly
identical. Any small variation in these values leads to arbitrary ranks and,
consequently, to equally arbitrary rank correlation coefficients.
2.5.3 Sample mutual information and Jaccard index
Let x=(x ,...,x ) and y =(y ,...,y ) be paired sequences of observations
1 N 1 N
that take values from a list of K and L categories, respectively.
The association between those categorical variables is characterized by their
joint frequencies 0≤f ≤1 with k ∈{1,...,K} and l∈{1,...,L}. These
kl
are the relative frequencies in which the categories co-occur: f is the relative
kl


================================================================================
PAGE 77
================================================================================

2.5. Measures of association 59
frequency with which x is observed to be the k-th category and y to be the
n n
l-th category, at the same time.
From the joint frequencies, we can calculate the marginal frequencies:
L K
X X
f = f , f = f
k• kj •l il
j=1 i=1
for all k ∈{1,...,K} and l∈{1,...,L}. The marginal frequencies are simply
the frequencies of the individual variables, represented as a sum over joint
frequencies.
All frequencies add up to 100%:
K L K L
X X XX
f = f = f =1
k• •l kl
k=1 l=1 k=1l=1
We can summarize the joint and marginal frequencies in a contingency table:
f f ... f f
11 12 1L 1•
f f ... f f
21 22 2L 2•
. . .
. . .
. . .
f f ... f f
K1 K2 KL K•
f f ... f
•1 •2 •L
Given the above notation, we can define the following measures of association
for categorical variables.
The joint Shannon index is given as follows (as usual we agree on
0·ln0=0):
K L
XX
H(x,y)=− f ·ln(f )
kl kl
k=1l=1
The sample mutual information of the two variables/features is the
following quantity:
K L (cid:18) (cid:19)
MI(x,y)= XX f ·ln f kl
kl f ·f
k• •l
k=1l=1
The normalized sample mutual information is determined as follows:
MI(x,y)
MI (x,y)=
norm H(x,y)
for H(x,y)>0, otherwise we may assume MI (x,y)=1.
norm


================================================================================
PAGE 78
================================================================================

60 Descriptive statistics
The joint Shannon index or mutual information of a sequence of observations
x with respect to itself is just its regular Shannon index, i.e., MI(x,x) =
H(x,x) = H(x) holds. That’s because in this case we have f = 0 for k ̸= l
kl
and f =f =f for k =l. This fact also implies MI (x,x)=1.
kl k• •l norm
Thenormalizedmutualinformationmayrangebetweenzeroandone.Avalueof
one indicates a maximum possible association between the categorical variables.
A vanishing mutual information, on the other hand, corresponds to the condi-
tion that every joint frequency is the product of the corresponding marginal
frequencies:
f =f ·f
kl k• •l
Ifweinterpretthefrequenciesasestimatesforprobabilities,wewillseelater—in
Sect.3.1.1—thatthisconditionisastatementaboutthevariables’ independence.
In other words, the frequency of the k-th category occurring does not provide
information on how often the l-th category occurs, and vice versa.
Example. The following is a contingency table based on the German 2018
ALLBUS survey. The table compares the preference for a political party with
the answer to the following question: “What do you think of the following
statement: the influx of refugees should be stopped.”
The mutual information between the two categorical variables is given by
MI =0.035. This may sound like a small value, so here is a comparison.
norm
The mutual information between party preference and the presence of a door
phone in the respondent’s home is much smaller: MI =0.0026. This is
norm
an expected result, as we can hardly imagine a mechanism or explanation
that would imply a strong enough correlation between those two features.
All figures are in percent:
do not tend to indiffer- tend to agree P
agree not ent agree
agree
Union parties 5.9 13.0 8.0 8.3 3.8 39.0
Social Democratic Party 5.9 9.3 4.6 4.7 2.3 26.9
The Greens 6.4 5.4 1.5 0.5 0.2 13.9
The Left 2.7 3.0 1.4 1.2 0.7 9.0
Alternative for Germany 0.2 0.3 0.6 1.1 3.7 5.8
Free Democratic Party 1.0 1.1 0.9 1.1 0.6 4.7
others 0.1 0.3 0.1 0.1 0.2 0.7
P 22.1 32.3 17.1 17.0 11.5
Table 2.7. Contingency table of party preference vs. opinion on migration control


================================================================================
PAGE 79
================================================================================

2.5. Measures of association 61
Let x = (x ,...,x ) and y = (y ,...,y ) be two paired sequences of
1 N 1 N
binary observations: x ,y ∈{0,1} for all n∈{1,...,N}.
n n
Let f be the frequency of co-occurrence of a positive value, that is, the
11
frequency of x =y =1. Furthermore, let f be the frequency of x =1
n n 1• n
and f be the frequency of y =1.
•1 n
The Jaccard index is then given as:
f
J(x,y)= 11 ,
f +f −f
•1 1• 11
if not exactly x=y =0, in which case the Jaccard index is not defined.
In order to showcase similarities with mutual information, we have defined the
Jaccardindexintermsoffrequencies.Itdoesnotmatterwhethertherelativeor
absolute frequencies are used; the sample size cancels out either way. However,
theJaccardindexcanbedescribedmoreconvenientlyintermsofsubpopulations.
As noted earlier, there is a natural one-to-one correspondence between binary
variables and subpopulations. Comparing with the above formula, we find that
the Jaccard index of two subpopulations S,T ⊆Ω via that correspondence is
given as follows:
|S∩T| |S∩T|
J(S,T)= =
|S|+|T|−|S∩T| |S∪T|
The Jaccard index takes values between zero and one, where J(S,T) = 0
correspondstosubpopulationsthathavenostatisticalunitincommon:S∩T =∅.
Maximum association, J(S,T)=1, is given if and only if both subpopulations
are identical: S =T.
Example. In the 2013 German federal election, 16.89 million voters who
had not moved away or died by 2017 cast their ballots for the alliance of
center-right parties CDU and CSU, also called the Union parties. Excluding
new voters and new citizens, the figure for the following election in 2017
was 14.77 million. 11.09 million voters gave their vote to the Union in both
years [13]. Therefore, the Jaccard index between the subpopulations of Union
voters in 2013 and those in 2017 is given by:
11.09
J(Union 2013,Union 2017)= ≈54%
16.89+14.77−11.09
The table below shows the Jaccard index for selected other parties and the
cohort of non-voters.
We can interpret this value as a measure that gauges voter loyalty or vote
retention. If the value were 0%, this would mean that in 2017 only swing
votes went to that party. In contrast, a value of 100% would mean that the
pool of voters was identical in 2013 and 2017.


================================================================================
PAGE 80
================================================================================

62 Descriptive statistics
political party Jaccard index,
voters 2013 vs.
2017
Union parties 54%
Social Democratic Party 43%
The Greens 34%
The Left 36%
Alternative for Germany 23%
Free Democratic Party 22%
non-voters 48%
Table 2.8. Jaccard index as a measure for vote retention


================================================================================
PAGE 81
================================================================================

2.5. Measures of association 63
0.01 0.5
51
01
5
)1(
x
y
)1(
00.01
00.5
51
01
5
)2(
x
y
(2)
0.01 0.5
51
01
5
)3(
x
y
)3(
0.01
0.5
51
01
5
)4(
x
y
(4)
tneicffieoc
noitalerroc
nosraeP
lacitnedi
htiw
stesatad
tnereffid
ruof
:tetrauq
s’ebmocsnA
.11.2
.giF


================================================================================
PAGE 82
================================================================================

64 Descriptive statistics
References
[1] CDC Population Health Surveillance Branch. Behavioral Risk Factor
Surveillance System (BRFSS) Survey Data 2018. Accessed Feb. 1, 2020.
url: https://www.cdc.gov/brfss/.
[2] WHO Consultation on Obesity (1999: Geneva, Switzerland) and World
HealthOrganization.Obesity:preventingandmanagingtheglobalepidemic.
Tech. rep. 2000.
[3] HarriSiirtola.“TheCostofPieCharts”.In: 23rd International Conference
Information Visualisation (IV). 2019, pp. 151–156. doi: 10.1109/IV.2019.
00034.
[4] The Federal Returning Officer of Germany. 2021 Bundestag Election:
final result. Press release no. 52/21. Wiesbaden, Germany, Oct. 2021.
url: https://www.bundeswahlleiter.de/en/info/presse/mitteilungen/
bundestagswahl-2021/52_21_endgueltiges-ergebnis.html.
[5] The Federal Returning Officer of Germany. 2017 Bundestag Election:
final result. Press release no. 34/17. Wiesbaden, Germany, Oct. 2017.
url: https://www.bundeswahlleiter.de/en/info/presse/mitteilungen/
bundestagswahl-2017/34_17_endgueltiges_ergebnis.html.
[6] The Federal Returning Officer of Germany. Official final result of the
2013 Bundestag Election. Press release no. 34/13. Wiesbaden, Germany,
Oct. 2013. url: https://www.bundeswahlleiter.de/en/info/presse/
mitteilungen/bundestagswahl-2013/2013-10-09-endgueltiges-amtliches-
ergebnis-der-bundestagswahl-2013.html.
[7] GESIS–Leibniz-InstitutfürSozialwissenschaften.AllgemeineBevölkerung-
sumfrage der Sozialwissenschaften ALLBUS 2018. 2019. doi: 10.4232/1.
13250.
[8] Paul T. von Hippel. “Mean, Median, and Skew: Correcting a Textbook
Rule”. In: Journal of Statistics Education 13.2 (Jan. 2005). doi: 10.1080/
10691898.2005.11910556.
[9] Ronald Aylmer Fisher. “The use of multiple measurements in taxonomic
problems”. In: Annals of Eugenics 7.2 (Sept. 1936), pp. 179–188. doi:
10.1111/j.1469-1809.1936.tb02137.x.
[10] Robert N. Proctor. “Tobacco and the global lung cancer epidemic”. In:
Nature Reviews Cancer 1.1(Oct.2001),pp.82–86. doi:10.1038/35094091.
[11] JacobCohen.Statistical power analysis for the behavioral sciences.2nded.
New Jersey, USA: Lawrence Earlbaum Associates, 1988.
[12] Francis John Anscombe. “Graphs in Statistical Analysis”. In: The Ameri-
can Statistician 27.1 (Feb. 1973), pp. 17–21.
[13] infratest dimap Gesellschaft für Trend- und Wahlforschung mbH. Bun-
destagswahl 2017 Deutschland Wählerwanderungen. Accessed June 10,
2020. url: https://wahl.tagesschau.de/wahlen/2017-09-24-BT-
DE/analyse-wanderung.shtml.


================================================================================
PAGE 83
================================================================================

Part II
Stochastics


================================================================================
PAGE 84
================================================================================

3
Probability theory
Descriptive statistics are concerned with the investigation of a sample that is
usually limited in size. A key benefit is that these investigations allow us to
draw conclusions about the population as a whole. For example, based on data
alone, we can conclude with some confidence that a human being cannot grow
to a height of three meters.
A somewhat more practical example is the political election poll. Before the
actual election, a sample of eligible voters is selected, and each person is asked
which political party they plan to vote for. The hope is that the proportion of
votesforaparticularpartyinthatsampleisapproximatelythesameproportion
of all voters on election day.
Furthermore,thisproportioncanbeinterpretedasameasurefortheprobability
of a voter—randomly selected from the population—to have a preference for
the party in question. For this reason, the relative frequency can also be called
the empirical probability.
One important goal of stochastics is to justify such a procedure rigorously,
mathematically. The field can be divided into two subfields:
• Probability theory, which is the subject of this chapter, deals with the
mathematical definition and investigation of the concept of probability. A
central object of such an investigation are variables the values of which are
not specified or known precisely but are subject to uncertainty. In other
words, a probability can only be given that such a random variable takes
values within a certain range.
• Inferential statistics, which will be discussed in the next chapter, builds
on descriptive statistics and probability theory. Its rationale is based on the
assumption that statistical observations and measures, such as frequencies,
means, etc., are values or realizations of random variables. Conversely, the
field investigates the extent to which characteristics of random variables can
be estimated from sampled data. In particular, under certain simplifying
© Springer-Verlag GmbH Germany, part of Springer Nature 2023 67
M. Plaue, Data Science, https://doi.org/10.1007/978-3-662-67882-4_3


================================================================================
PAGE 85
================================================================================

68 Probability theory
assumptions, it is possible to quantify the accuracy or error of such an
estimate.
The field of (statistical) machine learning makes substantial use of stochastic
considerations,suchaswithclassification.Inclassification,probabilitiesquantify
the frequency of occurrence of a class (e.g., “proportion of photographs in the
trainingdatasetshowingacat”)ortheconfidenceinaclassificationresult(“with
high probability, this photograph in the test dataset shows a cat”).
3.1 Probability measures
In the context of probability theory, a process with (possibly) an uncertain
outcomethatcanberepeated—inprinciple,atleast—underidenticalconditions
and as often as desired is called an experiment. Each individual repetition of
an experiment is called a trial and yields a single outcome from a well-defined
set of outcomes. A classic example of such an experiment is the flipping of a
coin. At the end of each trial, either the side with heads shows, or the side with
tails. Another example is that of rolling a six-sided die.
The set of all possible outcomes is also called the sample space. The sample
space for a coin toss or a die roll can be written as Ω = {tails,heads} or
Ω ={ , , , , , }, respectively.
We can interpret the relative frequency with which an outcome occurs in an
experiment after many trials as the probability of that event occurring. This
interpretation is called the frequentist interpretation of probability and
is common in the natural sciences, where repeatable experiments are essential
for gaining empirical knowledge. An example of a frequentist statement could
be the following: “We can observe that about 50% of all atomic nuclei of the
radioactive isotope iodine-131 have decayed after eight days. Therefore, the
probability that a single such atomic nucleus has decayed after this time is
50%.”
In comparison, the Bayesian interpretation of probability sees probability
as a (subjective) measure for the plausibility of an event, without the event
necessarily being the result of a repeatable experiment. For example, according
to the Bayesian interpretation, it would make sense to say: “the probability
that it will rain today is 75%.” Adopting the Bayesian viewpoint is useful for
reasoning and decision-making under uncertainty, with the aim of maximizing
expected utility—“should I, or should I not, take an umbrella with me today?”
There are even more approaches to imbue “probability” with universal meaning
[1]. Whatever the interpretation, probability can be defined rigorously as a
mathematical concept. The key idea is to assign subsets of the sample space a
number between zero and one: the probability that one of the outcomes in that
subset is realized with each trial.


================================================================================
PAGE 86
================================================================================

3.1. Probability measures 69
A probability measure is a map Pr(·) that assigns a nonnegative real
number to certain subsets A ⊆ Ω of a sample space Ω that has the
following properties:
(1)Pr(∅)=0 and Pr(Ω)=1
(2)For every finite or countably infinite family of pairwise disjoint sets
(A ) :
i i∈I
!
[ X
Pr A = Pr(A )
i i
i∈I i∈I
TheaboveconditionsformthebasisfortheKolmogorov axioms of probabil-
ity theory. A more rigorous mathematical analysis shows that it is not always
possible or reasonable to assign a well-defined probability to every arbitrary
subset of Ω. Subsets of the sample space that can be assigned a probability are
called events, or measurable. Events that contain exactly one element are
called elementary events, or atomic events.
We want to construct a meaningful probability measure that describes a game
of dice. When rolling a six-sided die, it should be impossible for the player to
predictwhichsidewillshow.Nevertheless,itispossibletoestimatehowlikelyit
is that a certain side will show, or that a certain number will be rolled. Without
further information, they must assume that each possible outcome is equally
likely:
1
Pr({ω})=
6
for all ω ∈ Ω = { , , , , , }. The probabilities of all other events are
obtained by applying the rules above. For example, the probability of rolling an
even number is given by:
Pr({ω|ω represents an even number})=
Pr({ , , })=
Pr({ }∪{ }∪{ })=
Pr({ })+Pr({ })+Pr({ })=
1 1 1 1
+ + =
6 6 6 2
In the argument above, we have invoked the more general principle of indif-
ference.Accordingtothisprinciple,ifnoadditionalinformationotherthanthe
setofoutcomesisavailable,theneachoutcomeoratomicevent {ω}⊂Ω should
be assigned equal probability, meaning that they are uniformly distributed.
For finite sample spaces with a uniform distribution, we have Pr({ω})= 1 ,
|Ω|
which implies Laplace’s rule:
|A|
Pr(A)=
|Ω|


================================================================================
PAGE 87
================================================================================

70 Probability theory
for all events A⊆Ω. This formula can be used to determine the probability of
rolling an even number as follows:
|{ , , }| 3 1
Pr({ , , })= = =
|{ , , , , , }| 6 2
For another example, imagine a dart player throws at a dartboard with radius
R > 0. A reasonable mathematical model for this situation is given by the
sample space Ω ={(ω ,ω )∈R2|(ω )2+(ω )2 ≤R2}, that is, a circular disk
1 2 1 2
in the plane. Each point in the disk corresponds to a possible location where
the dart can hit.
The goal of the player is to throw the dart so that it lands as close as possible
to the center point (0,0). A perfect player that hits the center every single
time would be described by the following probability measure, which is called a
Dirac measure:
(
1 if (0,0)∈A
Pr (A)=
0 0 otherwise
For atomic events {ω}∈Ω, this means in particular:
(
1 if ω =(0,0)
Pr ({ω})=
0 0 otherwise
A player who is able to hit the dartboard but otherwise has no control over the
dart’s trajectory corresponds to the other extreme, a uniform distribution:
|A| |A|
Pr (A)= =
R |Ω| πR2
Here we have denoted the area of a region B ⊆Ω by |B|. Note that predicting
whether a single point on the dartboard will be hit is no longer meaningful
because Pr ({ω}) = 0 holds for all ω ∈ Ω. Consequently, this probability
R
measurecannotbedefinedbydeterminingitsvalueforelementaryevents,which
would be possible for a finite sample space.
In a more realistic scenario, the player is not perfect but still very good, and
therefore the player hits with 90% probability the bull’s eye B(r)={(ω ,ω )∈
1 2
R2|(ω )2+(ω )2 ≤r2} with radius r, 0<r <R:
1 2
|A∩B(r)| |A∩(Ω\B(r))|
Pr (A)=0.9· +0.1·
r |B(r)| |Ω\B(r)|
Rules for calculating with probabilities. For a fixed probability
measure Pr(·), where A,B ⊆Ω are arbitrary events:
(1)Pr(A∪B)=Pr(A)+Pr(B)−Pr(A∩B)
(2)Pr(A\B)=Pr(A∪B)−Pr(B), in particular Pr(Ω\A)=1−Pr(A)


================================================================================
PAGE 88
================================================================================

3.1. Probability measures 71
The event Ω\A is called the event complementary to A, which we will also
denote as ¬A.
A quick example calculation for rule (1): the probability of rolling an even
number or a number divisible by three with a six-sided die (A={ , , } or
B ={ , }) is given by:
Pr(A∪B)=Pr(A)+Pr(B)−Pr(A∩B)
3 2 3 2 1
= + −Pr({ })= + −
6 6 6 6 6
2
= ≈0.67
3
Of course, in this case we can easily calculate the probability directly:
4 2
Pr(A∪B)=Pr({ , , , })= =
6 3
Regarding (2): the probability of not rolling the number two is given by:
1 5
Pr(¬C)=Pr(Ω\C)=1− = ≈0.83,
6 6
where C ={ }.
Inequalities for probabilities. For any events A,B ⊆Ω, the following
inequalities hold:
(1)Pr(A)≤Pr(B) if A⊆B
(2)Pr(A∪B)≤Pr(A)+Pr(B)
(3)Pr(A∩B)≥Pr(A)+Pr(B)−1
The second inequality is useful only for small probabilities or frequencies (since
otherwise the right-hand side can become larger than one), the third only for
large ones (since otherwise the right-hand side can become smaller than zero).
Example. (1): The proportion of German households with no more than
two cars is at least as large as the proportion of households with no more
than one car.
(2): 19% of all German households are home to a dog, 23% to a cat (in 2018
[2]). These statistics imply that at most 42% of all households own either a
dog, a cat, or both.
(3): In Germany, around 77% of all households own a car, and 97% own a
mobile phone (in 2019 [3]). From these statistics, we can deduce that at least
74% of all German households own a car and also a mobile phone.


================================================================================
PAGE 89
================================================================================

72 Probability theory
Since probability measures behave in many ways like other measures for the
size of a set, the above inequalities and similar facts about probability can be
illustrated using Venn or Euler diagrams such as the following:
Ω Ω
A B A B
Pr(A∪B) Pr(A\B)
Ω Ω
A B A B
Pr(A∩B) Pr(¬A)
Fig. 3.1. Venn diagrams of the probability of events
3.1.1 Conditional probability
Itisimportanttonotethattheestimatedprobabilityofaneventmaydependon
additional information known to the person making the estimate. For example,
if the game master of a game of dice rolls a single die and hides the result from
the player but tells the player that the result is an even number (i.e., two, four,
or six), then, from the player’s perspective, the probability that the number
rolled is three is no longer one-sixth but zero.
What is the probability that the player will assign to the event of rolling a two,
i.e., the event A={ }? The set of possible outcomes has effectively changed
from Ω ={ ,..., } to the smaller set B ={ , , }. Therefore, according to
Laplace’s rule, the conditional probability is the following:
|{ }| 1
Pr(A|B)=Pr({ }|{ , , })= =
|{ , , }| 3
Laplace’s rule applies only to uniform distributions over finite sample spaces.
In general, the conditional probability is defined as follows.


================================================================================
PAGE 90
================================================================================

3.1. Probability measures 73
Let A,B ⊆Ω be events with Pr(B)>0. Then
Pr(A∩B)
Pr(A|B)=
Pr(B)
is called the probability of A under the condition B.
We can easily verify that this definition of conditional probability is consistent
with the intuition we obtained earlier. If Laplace’s rule holds, the conditional
probability is indeed the proportion of atomic events in A with respect to a
restricted set of possible outcomes B:
Pr(A∩B) |A∩B|/|Ω| |A∩B|
Pr(A|B)= = =
Pr(B) |B|/|Ω| |B|
To illustrate the concept of conditional probability, consider the following game.
Anna, the game master, rolls a six-sided die and tells Robert whether the result
is an even or an odd number. Robert must then guess whether the number is a
prime number, or not. Robert wants to develop a strategy that maximizes his
chances of guessing correctly. We define the following events:
B ={ω|ω represents an even number}={ , , },
A={ω|ω represents a prime number}={ , , }
IfAnna statesthatthe numberiseven,then thehypothesis thatitis alsoprime
yields the following probability from Robert’s perspective:
Pr(A∩B) Pr({ }) 1/6 1
Pr(A|B)= = = = ≈0.33
Pr(B) Pr({ , , }) 3/6 3
In this case, the probability that the number is prime is only 33%. Therefore,
Robert should guess that the result is not a prime number, which will result in
a probability of winning of 67%.
If Anna announces that the number is odd, the conditional probability of the
number being prime is given by:
Pr(A∩(Ω\B)) Pr({ , }) 2/6 2
Pr(A|¬B)= = = = ≈0.67
Pr(Ω\B) 1−Pr(B) 1/2 3
In that case, Robert should guess that the result is prime.
Two events A and B are called independent if the following holds:
Pr(A∩B)=Pr(A)·Pr(B)
Assuming that the probabilities of A and B are strictly positive, independence
can also be characterized as follows:


================================================================================
PAGE 91
================================================================================

74 Probability theory
Pr(A|B)=Pr(A) or, equivalently, Pr(B|A)=Pr(B)
Thus, the occurrence of B does not change the probability of A occurring (and
vice versa). Example: Anna rolls the die and tells Robert whether the number
is even or odd. Robert then has to guess whether the number is divisible by
three, or not:
B ={ω|ω represents an even number}={ , , }
A={ω|ω represents a number divisible by three}={ , }
We compute the probability of A conditioned on B:
Pr(A∩B) Pr({ }) 1/6 1
Pr(A|B)= = = = =Pr(A)
Pr(B) Pr({ , , }) 3/6 3
Consequently, Robert has not gained any useful information from Anna’s
statement. Therefore, he should always guess that the number is not divisible
by three because Pr(¬A)= 2 >Pr(A) holds.
3
The following construction can be interpreted as a numeric measure of the
dependence of two events:
The pointwise mutual information of two events A and B is given as
follows:
(cid:18) (cid:19)
Pr(A∩B)
PMI(A,B)=log
Pr(A)·Pr(B)
The choice of the base of the logarithm does not play an important role, and
with suitable normalization (see below) it does not play a role at all. We will
use the natural logarithm. The pointwise mutual information is positive if the
probability of A increases when conditioned on B:
(cid:18) (cid:19)
Pr(A|B)
Pr(A|B)>Pr(A)⇔ln >0
Pr(A)
(cid:18) (cid:19)
Pr(A∩B)
⇔ln >0
Pr(A)·Pr(B)
⇔PMI(A,B)>0
Allprobabilitiesmustbeassumedtobestrictlypositive.Themutualinformation
between two events vanishes if and only if they are independent.
This measure is often normalized in a suitable manner. One possible normaliza-
tion is the following:
(cid:18) (cid:19)
Pr(A∩B)
nPMI(A,B)=ln ·(−ln(Pr(A∩B)))−1
Pr(A)·Pr(B)
ln(Pr(A)·Pr(B))
= −1
ln(Pr(A∩B))


================================================================================
PAGE 92
================================================================================

3.1. Probability measures 75
For all events A and B, we have −1<nPMI(A,B)≤1.
The limit case nPMI(A,B) → (−1) represents the situation where A and B
occur together with vanishing probability: Pr(A∩B)=0.
The case nPMI(A,B)=1 corresponds to a maximum possible dependence of
events: Pr(B) = Pr(A) = Pr(A∩B). In this case, the events A and B are
identical, except, possibly, for a subset with vanishing probability:
Pr(A\B)=Pr(A∪B)−Pr(B)
=Pr(A)+Pr(B)−Pr(A∩B)−Pr(B)=0,
Pr(B\A)=0
Example. Pointwise mutual information is used, for example, in keyword
extraction, an important task in natural language processing. Given a
collection of text documents, the association of a word (or phrase) with one
of the documents can be measured as follows:
PMI(document,word)=
(cid:18) relative frequency with which the word occurs in the document (cid:19)
ln
relative frequency with which the word occurs in the whole corpus
Givenadocument,ifawordoccursmorefrequentlyinthatdocumentthanin
the whole corpus, this measure has a positive value. Words with high values
for PMI may be interpreted as keywords, i.e., the terms that best describe
the subject of the document.
An examination of the twitter feeds of the U.S. Republican Party [4] and
the U.S. Democratic Party [5] (3200 tweets each, retrieved on July 03, 2022)
reveals that the following top 10 words have particularly high (normalized)
pointwise mutual information with respect to each feed:
@TheDemocrats @GOP
keyword # in # in nPMI keyword # in # in nPMI
feed corpus feed corpus
president 966 1081 0.101 joe 756 759 0.175
infrastructure 258 258 0.098 border 328 330 0.149
health 214 218 0.092 biden 1151 1456 0.139
bipartisan 189 192 0.090 failed 217 223 0.135
bidenharris 192 198 0.088 gop 271 293 0.131
act 200 209 0.086 policies 152 159 0.125
rescue 118 118 0.086 prices 273 315 0.120
plan 312 340 0.086 rnc 91 93 0.119
vaccinated 123 124 0.086 primary 124 132 0.118
climate 85 85 0.082 southern 72 72 0.118
Table 3.1. Keyword extraction via pointwise mutual information


================================================================================
PAGE 93
================================================================================

76 Probability theory
3.1.2 Bayes’ theorem
In the previous section, we saw how new information can influence the sub-
jective probability of an event. This process of gaining new information can
be understood as learning under uncertainty, and it may impact the learner’s
decision-making. For example, if a dice player learns that an even number is
very likely to be the outcome, they may choose to bet less money on a roll of
three.
We can describe the process of learning under uncertainty in more detail as
follows. At the outset, the probability for a certain hypothesis H has a certain
prior probability Pr(H). When new evidence in the form of an observation
E becomes available, it leads to a correction of the prior probability, resulting
in the posterior probability Pr(H|E). In the example mentioned above, the
hypothesis H corresponds to the event “the die shows the number three,” and
Pr(E) corresponds to the probability of “the number rolled is even.”
Bayes’ theorem tells us how to compute the posterior probability.
Bayes’ theorem. Let H, E be events with Pr(H)>0, Pr(E)>0. Then:
Pr(E|H)
Pr(H|E)= ·Pr(H)
Pr(E)
Thus, the posterior Pr(H|E) is obtained from the prior Pr(H) by multiplying
with a factor that is proportional to the likelihood Pr(E|H), that is, the
probability of observing the evidence under the hypothesis.
The proof of the theorem is not difficult and follows immediately from the
definition of conditional probability:
Pr(H ∩E) Pr(E|H)·Pr(H)
Pr(H|E)= =
Pr(E) Pr(E)
An alternative version of Bayes’ theorem useful for many calculations is the
following:
Pr(E|H)
Pr(H|E)= ·Pr(H)
Pr(E|H)·Pr(H)+Pr(E|¬H)·Pr(¬H)
Example. Sensitivity and specificity are common measures to evaluate
the quality of diagnostic tests. These tests may detect a particular disease or
an infection with a particular pathogen. Sensitivity is the proportion of sick
or infected patients who indeed test positive. Specificity is the proportion of
healthypatientsforwhomthetestisnegative,asexpected.Theseproportions
can be interpreted as empirical probabilities. Thus:


================================================================================
PAGE 94
================================================================================

3.1. Probability measures 77
sensitivity=Pr(E|H)
specificity=Pr(¬E|¬H)=1−Pr(E|¬H)
Here we abbreviated the hypothesis “patient is sick/infected” as H, and the
evidence “test turns out positive” as E.
Suppose a patient tests positive for a particular pathogen. What is the
probability Pr(H|E) that the patient is actually infected with the pathogen
in question? This probability depends on the prevalence of the pathogen
among the population being tested. Prevalence refers to the spread of the
pathogen among the test subjects and determines the prior probability.
Let us compute an example. Rapid antigen tests for detecting an infection
with the pathogen SARS-CoV-2, the causative agent of the disease COVID-
19, have a typical sensitivity of around 50% and a specificity of 99% [6].
Among patients randomly screened at a general practitioner, we might want
to assume a prevalence of around Pr(H) = 3%. The above numbers imply
the following posterior probability for an actual infection with SARS-CoV-2
given a positive test:
Pr(E|H)
Pr(H|E)= ·Pr(H)
Pr(E|H)·Pr(H)+Pr(E|¬H)·Pr(¬H)
0.5
= ·0.03
0.5·0.03+(1−0.99)·(1−0.03)
≈61%
Conversely, we can ask for the probability for a patient to test negative and
actually not be infected:
Pr(¬E|¬H)
Pr(¬H|¬E)= ·Pr(¬H)
Pr(¬E|¬H)·Pr(¬H)+Pr(¬E|H)·Pr(H)
0.99
= ·(1−0.03)
0.99·(1−0.03)+(1−0.5)·0.03
≈98%
Theprevalenceofadiseaseorinfectioncansignificantlyimpacttheprobability
thatapatientisactuallyinfectedbasedonapositivetestresult.Forexample,
if a patient exhibits typical symptoms of COVID-19 during a period of high
transmission, we might assume a prior probability of 30%. This assumption
would lead to a probability of 96% that a positive rapid test indicates the
patient is infected and a probability of 82% that a negative test correctly
indicates the patient is not infected.
Bayes’ theorem forms the foundation for many machine learning methods. In
this context, the theorem is interpreted to mean that the initial belief of a


================================================================================
PAGE 95
================================================================================

78 Probability theory
learning algorithm about the probability of a hypothesis H is given by Pr(H).
ThisbeliefisthenupdatedbasedonnewlycollecteddataE,tobecomePr(H|E)
after the learning process. If new data is repeatedly presented to the algorithm,
further adjustments are made.
Wewanttosketchthefunctionofasimpleemailspamfilterinordertoillustrate
how a machine learning algorithm based on Bayesian inference may work. This
algorithm could be fed the following data:
• In general, 45% of all email messages can be considered as spam. Thus,
the prior probability for the hypothesis “this message is spam” is given by
Pr(H)=0.45.
• Among all these spam messages, 5% have the word “Viagra” in the subject
line, so the likelihood for this piece of evidence is Pr(E|H)=0.05.
• Amongall theremainingmessages, onlya vanishinglysmall percentagehave
the word “Viagra” in the subject line: Pr(E|¬H)=0.001.
Overall, this results in the following posterior probability:
Pr(E|H)
Pr(H|E)= ·Pr(H)
Pr(E|H)·Pr(H)+Pr(E|¬H)·Pr(¬H)
0.05
= ·0.45
0.05·0.45+0.001·(1−0.45)
≈98%
This means that if the word “Viagra” is included in the email subject, the
algorithm is convinced that this message is most likely spam.
Now let the evidence E be given by the fact that the email message was
sent from an address that is included in the recipient’s address book. Only a
vanishingly small proportion of spam messages originate from known senders:
Pr(E|H) = 0.001. In contrast, a significantly higher proportion of non-spam
messages originate from known senders: Pr(E|¬H)=0.2. From these statistics
we get:
Pr(E|H)
Pr(H|E)= ·Pr(H)
Pr(E|H)·Pr(H)+Pr(E|¬H)·Pr(¬H)
0.001
= ·0.45
0.001·0.45+0.2·(1−0.45)
≈0.4%
Consequently, the algorithm concludes that an email from a known sender is
not spam with a very high probability.
A note on hypotheses with a prior probability of one or zero: If Pr(H) = 1
holds, then Pr(H|E)=1 always holds regardless of the evidence E. This means
that a hypothesis assumed to be true a priori is incontrovertible. Similarly, if
Pr(H)=0 is assumed, the Bayesian method cannot learn from the evidence.


================================================================================
PAGE 96
================================================================================

3.2. Random variables 79
Evidence that is observed with a probability of one is also problematic: If
Pr(E)=1, it always follows that Pr(H|E)=Pr(H), meaning that the evidence
provides no additional information. Therefore, it is generally best to avoid
extreme probabilities in model building, a principle known as Cromwell’s rule
[7, Sect. 6.7].
3.2 Random variables
Whenrollingadie,ithasaspecificpositionandorientationinspaceatanygiven
time during the experiment. However, the process of rolling a die is complex
and the randomness comes from our lack of knowledge of the exact trajectory.
From this perspective, the sample space Ω consists of many more states than
just the six sides of the die that can be rolled. It would be impractical and
unnecessarily complicated to determine a probability measure for all possible
trajectories and initial conditions. Ultimately, we are only interested in the final
number. We can model this situation formally by introducing a map, called
a random variable, X, which assigns one of the six possible outcomes to each
history of the die roll: X: Ω →{1,2,...,6}.
In inferential statistics, the distribution of values of the random variables
studied is essential, and precise knowledge of the underlying sample space is
not necessary.
3.2.1 Discrete and continuous random variables
A random variable is a quantity that takes on values in a given, limited range
only with a certain probability. Formally, a random variable can be defined as
follows.
A (real-valued) random variable X is a function on the sample space
X: Ω →R such that for any value u∈R the set X−1(]−∞,u]) is measur-
able.
When a random variable assumes a particular value u = X(ω), that value is
called a realization or an observed value of that random variable. The set
of all possible realizations is given by the range or image, range(X) = X(Ω).
Inferential statistics is based on the assumption that the observations in a
sample are realizations of random variables.
The quantity Pr(X−1(]−∞,u])) is the probability that the random variable X
takes on a value less than or equal to u. Thus, we may write more succinctly:
Pr(X ≤u):=Pr(X−1(]−∞,u]))
Similarly, Pr(X = u) stands for Pr(X−1({u})). We can introduce such ab-
breviations for other sets and types of intervals. For example, we can write


================================================================================
PAGE 97
================================================================================

80 Probability theory
Pr(X ∈[a,b])orPr(a≤X ≤b)foraninterval [a,b]⊂Rinsteadoftheclunkier
Pr(X−1([a,b])).
ThecumulativedistributionfunctionofarandomvariableX isdefined
as follows:
F : R→[0,1], F (u)=Pr(X ≤u)
X X
The cumulative distribution function thus indicates the probability with which
a random variable takes on values up to a given threshold. Furthermore, if the
cumulative distribution function is known, it is also possible to calculate the
probability with which the random variable takes on values in a given interval:
Pr(a<X ≤b)=F (b)−F (a) for all a,b∈R with a≤b.
X X
It can be shown that cumulative distribution functions always satisfy the
following properties.
Properties of the cumulative distribution function. Let X be a
random variable and F (·) be its cumulative distribution function. Then,
X
the following statements always hold:
1. F is monotonically increasing.
X
2. F is right-continuous, i.e.: lim F (ξ)=u for all u∈R.
X ξ↘u X
3. We have lim F (ξ)=0 and lim F (ξ)=1.
ξ→−∞ X ξ→∞ X
Statistical variables can be characterized as qualitative/categorical or quan-
titative/numeric. Similarly, random variables can be distinguished accord-
ing to whether they take on a discrete number of values (e.g., from the set
{0,1,2,3,...}) or an entire continuum of values (e.g., from the interval [0,1]).
A random variable is called discrete if its range is given by a finite or a
countably infinite set of values.
A random variable is called continuous if its cumulative distribution
function is continuous.
Arandomvariableisabsolutelycontinuousifitscumulativedistribution
function is continuous and, moreover, continuously differentiable with the
possible exception of at most finitely many points.
A few notes on the mathematical foundations: The conditions on absolute
continuity mentioned above can be relaxed, but the characterization provided is
usually sufficient for data analysis. A more in-depth mathematical analysis also
shows that every “sufficiently regular” random variable can be represented as
the sum of a discrete and an absolutely continuous random variable (Lebesgue
decomposition, cf. [8, Proposition 4.5.1]). In that sense, with the exception of
“pathological cases,” the types of random variables mentioned above cover all
possibilities that are relevant in practice.


================================================================================
PAGE 98
================================================================================

3.2. Random variables 81
In what follows, instead of saying “absolutely continuous,” we will simply say
“continuous,” since we will only be dealing with this type of continuous random
variable. For a discrete random variable X, we define its support as follows:
supp(X)={u∈R|Pr(X =u)>0}
The cumulative distribution function of a discrete random variable must be a
piecewise constant function, with points of discontinuity given by the elements
of the random variable’s support.
Wearenowabletosketchtheshapeoftypicalcumulativedistributionfunctions
of discrete (on the left) or continuous random variables (on the right):
Wins and losses in games of chance are examples of quantities that can be
modeled by random variables. Let’s consider an example. Robert wins 5.00
of some currency (say, Euro) when rolling the number 6. Otherwise, he loses
1.00 EUR. The payoff is a random variable X with
(
−1.00 if ω ∈{ , , , , }
X(ω)=
5.00 if ω =
This random variable yields only the two possible values t = −1.00 or t =
1 2
5.00. Therefore, it is a discrete random variable. The associated cumulative
distribution function is the following piecewise constant function:

0 if u<−1.00

F (u)= 5 if −1.00≤u<5.00
X 6
1 if 5.00≤u
We return to the example of the dart player. As a random variable, we consider
the distance of the thrown dart to the center of the dartboard: X: Ω →
R, X(ω ,ω ) = p (ω )2+(ω )2. The cumulative distribution function of a
1 2 1 2
random variable also depends on the underlying probability measure. For the
perfect dart player (corresponding to the Dirac measure), X is discrete with
the following cumulative distribution function:
(
0 if u<0
F(0)(u)=
X 1 if 0≤u


================================================================================
PAGE 99
================================================================================

82 Probability theory
Ifanytwoareasofequalsizearehitwithequalprobability,therandomvariable
is continuous and distributed as follows:

0 if u<0

F(R)(u)= (cid:0)u(cid:1)2 if 0≤u<R
X R
1 if R≤u
For the last probability measure given in the example (the bull’s eye u≤r is
hit in 90% of all cases), we also have a continuous distribution:
 0 if u<0
0.9·
(cid:0)u(cid:1)2 if 0≤u<r
F(r)(u)= r
X  0
1
.9+0.1· R u2 2 − − r r 2 2 i
i
f
f
r
R
≤
≤
u
u
<R
3.2.2 Probability mass and density functions
Frequency distributions are a central focus of descriptive statistics and can
be represented visually using bar charts or histograms. Bar charts show the
frequency with which a category occurs, and histograms show how often a
numeric variable takes on values in a certain interval. In probability theory,
probability mass functions show the probability of a discrete random variable
taking on certain values, while the probability of a continuous random variable
takingonvalueswithincertainintervalsisgivenbytheareaunderitsprobability
density function.
3.2.2.1 Probability mass functions of discrete random variables
A discrete random variable is characterized by the probabilities with which it
yields each value in its support.
The probability mass function of a discrete random variable X is given
as follows:
p : supp(X)→[0,1], p (u)=Pr(X =u)
X X
The cumulative distribution function can be reconstructed from the probability
mass function as follows:
X
F (u)= p (κ)
X X
κ≤u,
κ∈supp(X)
Conversely, consider any map p: T → [0,1] with at most countably infinite
domain T ={t ,t ...}⊂R that satisfies the condition:
1 2
X
p(κ)=1
κ∈T


================================================================================
PAGE 100
================================================================================

3.2. Random variables 83
We want to call any such function a probability mass function as well.
As an example, consider again the piecewise constant cumulative distribution
function:

0 if u<−1.00

F(u)= 5 if −1.00≤u<5.00
6
1 if 5.00≤u
The graph of this function is a step function that looks like this:
1.0
0.8
0.5
0.2
0.0
-2.5 0.0 2.5 5.0 7.5
u
)u(F
Fig. 3.2. Cumulative distribution function of a discrete random variable
Thelocationofeachstepisdeterminedbythepointsofdiscontinuity t =−1.00
1
and t = 5.00. The associated probability mass function simply reflects the
2
height of each step:
(
5 if u=−1.00
p: {−1.00,5.00}→[0,1], p(u)= 6
1 if u=5.00
6
3.2.2.2 Probability density functions of continuous random variables
The cumulative distribution function of a discrete random variable can be
represented as a sum of the probability mass function. For continuous random
variables, a similar construction is possible using an integral instead of a sum.
Aprobability density functionp : R→[0,∞[ofacontinuousrandom
X
variable X satisfies the following condition:
Z u
F (u)= p (ξ)dξ
X X
−∞
Instead of referring to it as a probability density function, we can also use
the shorter terms probability density, density function, or simply just


================================================================================
PAGE 101
================================================================================

84 Probability theory
“density” to refer to this concept. For continuous random variables X—that is,
“continuous” in the less rigorous, or stronger, sense that we use the term—the
cumulative distribution function F is piecewise continuously differentiable.
X
Hence, a density always exists. Furthermore, at each point u ∈ R where F
X
is differentiable, this density is uniquely determined by the derivative of the
cumulative distribution function: p (u)= d F (u).
X du X
Once we know its density function, we can quite conveniently calculate the
probability with which a continuous random variable takes on values in a given
interval:
Z b
Pr(a≤X ≤b)=F (b)−F (a)= p (ξ)dξ
X X X
a
Conversely, we can call any piecewise continuous function p: R→[0,∞[ that
satisfies the condition
Z ∞
p(ξ)dξ =1
−∞
a density function. The improper integral over the whole real number line R is
defined as follows:
Z ∞ Z 0 Z ∞
p(ξ)dξ = p(ξ)dξ+ p(ξ)dx
−∞ −∞ 0
Z 0 Z u
= lim p(ξ)dξ+ lim p(ξ)dξ
u→−∞ u→∞
u 0
Consequently, both partial integrals must exist. Unlike a probability mass
function, it is quite possible for a density function to have p(u) > 1 at some
point. A typical probability mass function (on the left) and density function
can be sketched as follows:
If a continuous/discrete random variable X is distributed according to a proba-
bility density/mass function p(·), we will write X ∼p(·).
An important example of a probability density function is the following.
The standard normal distribution is given by this density function:
1
p: R→[0,∞[, p(u)= √ e−1 2 u2
2π


================================================================================
PAGE 102
================================================================================

3.2. Random variables 85
The following figure shows the graph of that function and the corresponding
cumulative distribution function F(·):
1.0
0.8
p(u)
0.5
F(u)
0.2
0.0
-2 0 2
u
Fig. 3.3. Standard normal probability density and cumulative distribution function
For this function to actually represent a density, its integral must be equal
to one. This fact is implied by the value of the Gaussian integral—see, for
example, [9], or Sect. B.3.4 in the appendix of this book:
Z ∞ √
e−ξ2
dξ = π
−∞
The probability that a standard normally distributed random variable X yields
avalue,forexample,between−1.96and+1.96isgivenbythefollowingintegral:
Z 1.96 1
Pr(−1.96≤X ≤1.96)= √ e−1 2 ξ2 dξ
2π
−1.96
In contrast to the integral over the entire number line, this value cannot be
calculated analytically and given in a closed form. However, the value can be
approximated by means of numerical integration: Pr(−1.96≤X ≤1.96)≈0.95.
3.2.3 Transformations of random variables
We want to investigate functions of a random variable X: Ω → R. More
precisely, suppose we have a sufficiently regular (e.g., piecewise continuous)
functiondefinedwithintherangeofX,i.e.:f: I →Rwithrange(X)⊆I.Then,
we can consider the transformed random variable f(X):
f(X): Ω →R, f(X)(ω):=(f ◦X)(ω)
The values of the transformed random variable Y = f(X) follow a different
distribution than the values of the original variable:
F (u)=Pr(Y ≤u)=Pr(f(X)≤u)=Pr(X ∈f−1(]−∞,u]))
Y


================================================================================
PAGE 103
================================================================================

86 Probability theory
3.2.3.1 Transformations of discrete random variables
In the discrete case, the question of how the values of the transformed random
variables are distributed can be answered in a straightforward manner.
Transformed probability mass function. If X is a discrete random
variable, then f(X) is also a discrete random variable with the following
probability mass function:
X
p : f(supp(X))→[0,1], p (v)= p (κ)
f(X) f(X) X
κ∈f−1(v)
This can be seen from the following short calculation:
X
p (v)=Pr(f(X)=v)=Pr(X ∈f−1(v))= Pr(X =κ)
f(X)
κ∈f−1(v)
X
= p (κ)
X
κ∈f−1(v)
for all v ∈supp(f(X))=f(supp(X)).
We illustrate with an example. Let X be a random variable that is distributed
as follows:
 0.1 if u=−3
0.2
if u=0
Pr(X =u)=
 0
0
.7 i
o
f
th
u
e
=
rw
3
ise
Now let f: R→R, f(u)=u2 be the standard quadratic function. The values
of the random variable f(X)=X2 are then distributed as follows:

Pr(X =0) if v =0

Pr(X2 =v)= Pr(X =−3)+Pr(X =3) if v =9
0 otherwise

0.2 if v =0

= 0.8 if v =9
0 otherwise
3.2.3.2 Transformations of continuous random variables
Wewillnowdiscussthecalculationofthedensityfunctionfortransformationsof
a continuous random variable. It is worth noting that the transformed random
variable does not necessarily have to be continuous again. For example, the zero
function, f(u)=0 for all u, results in the discrete random variable f(X)=0.
However, if f: R→R represents a continuously differentiable, monotonically
increasing function with positive derivative, then:


================================================================================
PAGE 104
================================================================================

3.2. Random variables 87
Pr(f(X)≤u)=Pr(X ≤f−1(u))
Z f−1(u)
= p (ξ)dξ
X
−∞
for all u∈R. We continue the calculation with the substitution ξ(t)=f−1(t):
Z u d Z u p (f−1(t))
Pr(f(X)≤u)= p (f−1(t))· (f−1(t))dt= X dt
X dt f′(f−1(t))
−∞ −∞
Iff ismonotonicallydecreasing,thenwehavethesamecalculationwiththesigns
reversed. Thus, if the transformation is monotonically increasing or decreasing,
we have the following handy formula(s) for the density function of f(X):
p f(X) : R→[0,∞[, p f(X) (v)=p X (f−1(v))· (cid:12) (cid:12) (cid:12) (cid:12)d d v f−1(v) (cid:12) (cid:12) (cid:12) (cid:12) = | p f X ′( ( f f − − 1 1 ( ( v v ) ) ) ) |
Linearfunctionsprovidesimplebutimportantexamplesforsuchtransformations.
According to the above formula, the density function of Y = m·X +c with
constants m∈R,c∈R, m̸=0 is given by:
(cid:18) (cid:19)
1 v−c
p (v)= ·p
Y |m| X m
Iff isnotmonotonic,thetransformationformulaneedstobeappliedtointervals
where it is. These considerations lead to the following formula.
Transformed probability density function. Let X be a continuous
random variable and f: I → R with range(X) ⊆ I be a continuously
differentiable function with nonvanishing derivative.
The probability density function of the transformed random variable f(X)
is then given as follows:
K
X
p : R→[0,∞[, p (v)= |g′(v)|·p (g (v))
f(X) f(X) k X k
k=1
where g (·),...,g (·) are all the solutions of the equation f(g(v))=v.
1 K
Asanexample,weconsideroncemorethestandardquadraticfunctionf(u)=u2.
First, we have to exclude the point u=0 because f′(0)=0. However, since this
point is merely an isolated point, we can simply specify a suitable value there
later. We want to transform a random variable X that is normally distributed:
1
p X : R→[0,∞[, p X (u)= √ ·e−1 2 u2
2π
The equation f(g(v)) = v ⇔ (g(v))2 = v has two solutions if v > 0, namely
√ √
g (v)=− v andg (v)= v.Consequently,thedensityfunctionof X2 isgiven
1 2
as follows:


================================================================================
PAGE 105
================================================================================

88 Probability theory
p (v)=|g′(v)|·p (g (v))+|g′(v)|·p (g (v))
X2 1 X 1 2 X 2
1 √ √ 1 √
= √ ·(p (− v)+p ( v))= √ ·p ( v)=
2 v X X v X
1
= √ ·e−1 2 v
2πv
Thereisnorealsolutionto (g(v))2 =v forv <0,inwhichcasewegetanempty
sum that is simply zero. Putting it all together yields:
(
0 if v ≤0
p : R→[0,∞[, p (v)=
X2 X2 √1 ·e−1 2 v if v >0
2πv
This distribution is called the chi-squared distribution with one degree of
freedom. We explain in Sect. 3.5.1 what a chi-squared distribution with an
arbitrary number of degrees of freedom looks like.
3.3 Joint distribution of random variables
Random variables can often have functional dependencies. One important task
in inferential statistics is modeling and describing these relationships based on
empiricaldata.Thisisthesubjectofregressionanalysis,whichwillbediscussed
further in Sect. 4.5.
3.3.1 Joint probability mass and density functions
For two random variables X,Y (and mutatis mutandis for more than two
random variables or other types of intervals), we write:
Pr(X ≤u, Y ≤v):=Pr(X−1(]−∞,u])∩Y−1(]−∞,v]))
This is the probability with which the random variables do not exceed certain
threshold values at the same time.
Given the random variables X ,...,X , their joint cumulative distri-
1 D
bution function is the following:
F : RD →R, F (u ,...,u )=Pr(X ≤u ,...,X ≤u )
X1,...,XD X1,...,XD 1 D 1 1 D D
If X ,...,X are all discrete random variables, their joint probability
1 D
mass function is given by:
p (u ,...,u )=Pr(X =u ,...,X =u )
X1,...,XD 1 D 1 1 D D
for all u ∈supp(X ),...,u ∈supp(X ).
1 1 D D
If X ,...,X are all continuous random variables, the multiple integral
1 D
over a joint probability density function yields the joint cumulative


================================================================================
PAGE 106
================================================================================

3.3. Joint distribution of random variables 89
distribution function:
Z u1 Z uD
F (u ,...,u )= ··· p (ξ ,...,ξ )dξ ···dξ
X1,...,XD 1 D X1,...,XD 1 D 1 D
−∞ −∞
for all u ,...,u ∈R. This fact implies that at every point where those
1 D
partial derivatives exist:
∂DF
p (u ,...,u )= X (u ,...,u )
X 1 D ∂u ···∂u 1 D
1 D
For discrete random variables, the individual probability mass functions can be
reconstructed from the joint probability mass function by summing over the
remaining variables. For example, for two variables X,Y:
X
p (u)= p (u,κ)
X X,Y
κ∈supp(Y)
X
p (v)= p (κ,v)
Y X,Y
κ∈supp(X)
Similarly, the densities of continuous random variables can be “integrated out”
from their joint density function, yielding a marginal probability density
for each:
Z ∞
p (u)= p (u,ξ)dξ
X X,Y
−∞
Z ∞
p (v)= p (ξ,v)dξ
Y X,Y
−∞
Finally,wecanalsoconsiderthejointdistributionofadiscreteandacontinuous
random variable.
Themixedjointprobabilitydensityfunctionforacontinuousrandom
variable X and a discrete random variable Y is a function p : R×
X,Y
supp(Y)→[0,∞[ with the following property:
Z u
X
F (u,v)=Pr(X ≤u,Y ≤v)= p (ξ,κ)dξ
X,Y X,Y
κ≤v, −∞
κ∈supp(Y)
for all u∈R, v ∈supp(Y).
In this case, the marginal distributions can be determined by summation or
integration with respect to the other variable:


================================================================================
PAGE 107
================================================================================

90 Probability theory
X
p (u)= p (u,κ)
X X,Y
κ∈supp(Y)
Z ∞
p (v)= p (ξ,v)dξ
Y X,Y
−∞
This concept can be generalized, mutatis mutandis, to any (finite) number of
discrete and continuous random variables.
3.3.2 Conditional probability mass and density functions
The concept of conditional probability can also be applied to probability mass
and density functions. A conditional probability mass or density function de-
scribes the dependence of a random variable Y on another random variable
X. Estimating joint conditional distributions from data is a goal of regression
analysis, as discussed in Section 4.5.
For two discrete random variables X,Y and a realization u∈supp(X) of
X, the probability mass function of Y under the condition X =u
is given as follows:
p (u,v)
p : supp(Y)→[0,1], v 7→p (v|u)= X,Y
Y|X Y|X p (u)
X
The conditional probability mass function simply describes the probability of Y
taking on the values in its support under the condition that X obtains a certain
value u:
p (u,v) Pr(X =u,Y =v)
p (v|u)= X,Y = =Pr(Y =v|X =u)
Y|X p (u) Pr(X =u)
X
For continuous random variables, we have the difficulty that Pr(X = u) = 0
always holds, so the conditional probability is not defined. Nevertheless, we can
apply a similar rationale.
For two continuous random variables X,Y and a realization u∈R of X
with p (u) > 0, the probability density function of Y under the
X
condition X =u is given as follows:
p (u,v)
p : R→[0,∞[, v 7→p (v|u)= X,Y
Y|X Y|X p (u)
X
The conditional density function indeed satisfies the defining properties of a
density function: p (v|u)≥0 holds for all v ∈R, and also:
Y|X
Z ∞ 1 Z ∞ 1
p (ξ|u)dξ = · p (u,ξ)dξ = ·p (u)=1
Y|X p (u) X,Y p (u) X
−∞ X −∞ X


================================================================================
PAGE 108
================================================================================

3.3. Joint distribution of random variables 91
Similarly, we can construct conditional probability mass and density functions
for other combinations of discrete and continuous random variables. If Y is a
discrete random variable and X a continuous random variable, the probability
mass function of Y under the condition X =u is the following:
p (u,v)
p (·|u): supp(Y)→[0,∞[, p (v|u)= X,Y
Y|X Y|X p (u)
X
As before, we cannot directly interpret this conditional mass function as a
conditional probability. We will nevertheless notate it as such. That is, Pr(Y =
v|X =u):=p (v|u) because in the limit of small intervals X ∈[u,u+h] we
Y|X
have:
Pr(Y =v,u≤X ≤u+h)
lim Pr(Y =v|u≤X ≤u+h)= lim
h↘0 h↘0 Pr(u≤X ≤u+h)
F (u+h,v)−F (u,v)
= lim X,Y X,Y
h↘0 F X (u+h)−F X (u)
h−1·(F (u+h,v)−F (u,v))
= lim X,Y X,Y
h↘0 h−1·(F X (u+h)−F X (u))
p (u,v)
= X,Y
p (u)
X
whenever p (·) and p (·,v) are continuous at u.
X X,Y
3.3.3 Independent random variables
Weconsidertworandomvariables X andY tobeindependentifforallintervals
[a,b] and [c,d] the events X−1([a,b]) and Y−1([c,d]) are independent:
Pr(a≤X ≤b,c≤Y ≤d)=Pr(a≤X ≤b)·Pr(c≤Y ≤d)
Any “reasonable” sets A,B can be written as a countable union of intervals.
Accordingly, for independent random variables, we may assume more generally:
Pr(X ∈A,Y ∈B)=Pr(X ∈A)·Pr(Y ∈B)
Since the distribution of values of a random variable is determined by its cumu-
lative distribution function, the condition of independence can be characterized
as follows.
The random variables X ,...,X are called (mutually) independent
1 D
if for all u ,...,u ∈R:
1 D
D
Y
F (u ,...,u )=F (u )·F (u )···F (u )= F (u )
X1,...,XD 1 D X1 1 X2 2 XD D Xd d
d=1
Independence of random variables can also be inferred from their probability
mass and density functions:


================================================================================
PAGE 109
================================================================================

92 Probability theory
Independence of discrete or continuous random variables. The
discrete random variables X ,...,X are independent if and only if
1 D
D
Y
p (u ,...,u )= p (u )
X1,...,XD 1 D Xd d
d=1
holds for all u ∈supp(X ),...,u ∈supp(X ).
1 1 D D
The continuous random variables X ,...,X are mutually independent if
1 D
and only if
D
Y
p (u ,...,u )= p (u )
X1,...,XD 1 D Xd d
d=1
holds for all points of continuity u ,...,u ∈R.
1 D
Another proposition is the following:
Transformations of independent random variables. If two random
variables X and Y are independent, then the transformed variables f(X)
and g(Y) are also independent.
This result follows from the following calculation:
F (u,v)=Pr(X ∈f−1(]−∞,u]),Y ∈g−1(]−∞,v]))
f(X),f(Y)
=Pr(X ∈f−1(]−∞,u]))·Pr(Y ∈g−1(]−∞,v]))
=Pr(f(X)∈]−∞,u])·Pr(g(Y)∈]−∞,v])
=F (u)·F (v)
f(X) g(Y)
3.4 Characteristic measures of random variables
Discrete random variables correspond to categorical variables in descriptive
statistics, while continuous random variables correspond to numeric variables.
If we draw a sufficiently large sample from a distribution of a discrete ran-
dom variable, the resulting bar chart should approximate the underlying mass
function. Similarly, if we draw a sample from the distribution of a continuous
random variable, the histogram of the observations should approximate the
density function.
In this way, probability mass and density functions are analogous to frequency
distributions in descriptive statistics. Probability theory also has counterparts
to statistical measures of central tendency, variation, and association.
3.4.1 Median, expected value, and variance
Inthissection,wedefinemeasuresofcentraltendencyandvariationforrandom
variables.


================================================================================
PAGE 110
================================================================================

3.4. Characteristic measures of random variables 93
Let X be a random variable with cumulative distribution function
F : R→[0,1]. The quantile function of X is given as follows:
X
Q[X]: R→[0,1], Q[X](r)=inf{u∈R|F (u)≥r}
X
Let 0<α<1. An α-quantile of X is any number q with
α
Pr(X ≤q )≥α and Pr(X ≥q )≥1−α
α α
In particular, Q[X](α) is an α-quantile. A median of X is an α-quantile
with α=1/2 .
Similar to descriptive statistics, these definitions imply the subtle technicality
that a random variable can have multiple medians or α-quantiles, even for a
fixed value of α. However, we can enforce uniqueness by casually speaking of
the quantile q
α
[X]:=Q[X](α) and the median m[X]:=Q[X](1/2).
For a continuous random variable, the α-quantile can be expressed most conve-
niently via its probability density function p (·):
X
Z qα[X]
p (ξ)dξ =α
X
−∞
Especially for the median:
Z m[X] 1
p (ξ)dξ =
X 2
−∞
Let X be a discrete or continuous random variable with probability mass
function p : supp(X) → [0,1] or density function p : R → [0,∞[, re-
X X
spectively.
The expected value, or expectation, E[X] is defined as follows:
X
E[X]= κ·p (κ)
X
κ∈supp(X)
or
Z ∞
E[X]= ξ·p (ξ)dξ
X
−∞
The expected value and the median of random variables are closely related
to the arithmetic mean and the sample median of descriptive statistics: they
represent a “typical” observed value. Consequently, the expected value can also
be called the random variable’s mean or average.
Let us compute an example for the expected value of a random variable. For a
game of dice with winnings of t =5EUR when a six is rolled, and t =1EUR
1 2
loss otherwise, the expected winnings are:


================================================================================
PAGE 111
================================================================================

94 Probability theory
5 1
E[X]=t ·Pr(X =t )+t ·Pr(X =t )=(−1)· +5· =0
1 1 2 2 6 6
On average, the player would neither lose money nor win money in the long run.
However, it should be noted that if he plays only once, his risk of losing is much
greater than his probability of winning: 5/6 versus 1/6 , i.e., five times higher.
This circumstance is compensated by the much higher payout when winning.
Unlike the arithmetic mean, the expected value need not always exist or be
finite. For example, the St. Petersburg paradox leads to a random variable
for which the expected value is not finite. In this scenario, game master Anna
flips a coin multiple times until heads appears. If heads appears after k coin
tosses, Robert receives 2k−1 euros. For example, if heads appears on the first
toss, he receives 1.00EUR, while if heads appears on the second toss he receives
2.00EUR. The potential payout doubles with each toss of tails. If heads and
tails are equally probable and independent events with each flip, the winnings
can be modeled by a discrete random variable X with the following probability
mass function:
p
(cid:0) 2k−1(cid:1)
=
(cid:18)
1
(cid:19)k
, k ∈{1,2,...}
X 2
The expected profit from participating in the game is therefore:
X
∞ (cid:18)
1
(cid:19)k
X
∞
1
E[X]= 2k−1· = =∞
2 2
k=1 k=1
The paradox lies in the observation that if Robert were to base his decision-
making solely on his expected profits then he would accept any entry fee for
participating in the game, no matter how high.
An example of a continuous random variable with no well-defined expected
value is given by the probability density function
1 1
p(u)= ·
π u2+1
since the improper integral
Z ∞ 1 ξ
· dξ
π ξ2+1
−∞
cannot be assigned a finite value.
After transformation, the values of a random variable usually follow a different
distribution. There is a simple rule for calculating the expected value of the
transformed variable.
Expectation of transformed random variables. Let X be a discrete
or continuous random variable, and f: I → R with range(X) ⊆ I a
(sufficiently regular, nonconstant) function.


================================================================================
PAGE 112
================================================================================

3.4. Characteristic measures of random variables 95
The expected value of the transformed random variable f(X) can be
calculated as follows:
X
E[f(X)]= f(κ)·p (κ) if X is discrete, or
X
κ∈supp(X)
Z ∞
E[f(X)]= f(ξ)·p (ξ)dξ if X is continuous.
X
−∞
The summand/integrand can be assumed to vanish where f(·) is undefined
(the probability mass/density function vanishes at those points so they do not
contribute).
Sometimes, these formulas are used to define the expected value. However,
they should rather be viewed as theorems that follow from the transformation
formulas for probability mass and density functions. We show this by the
example of a continuous random variable X and a monotonically increasing
transformation f: R→R with positive derivative:
Z ∞ Z ∞ (cid:18) d (cid:19)
E[f(X)]= ξ·p (ξ)dξ = ξ·p (f−1(ξ))· f−1(ξ) dξ
f(X) X dξ
−∞ −∞
Z ∞
= f(t)·p (t)dt
X
−∞
In the above calculation, the substitution ξ(t)=f(t) has been applied.
The formulas for calculating expected values also apply to functions of random
variables over the joint distribution:
Expectation of jointly transformed random variables. Let X and
Y be two discrete or two continuous random variables. Let f: I ×J →
R be a (sufficiently regular, nonconstant) function with range(X) ⊆ I,
range(Y)⊆J.
The expected value of the random variable f(X,Y) can be calculated as
follows:
X X
E[f(X,Y)]= f(κ ,κ )·p (κ ,κ )
1 2 X,Y 1 2
κ1∈supp(X)κ2∈supp(Y)
if X and Y are discrete, or
Z ∞ Z ∞
E[f(X,Y)]= f(ξ ,ξ )·p (ξ ,ξ )dξ dξ
1 2 X,Y 1 2 1 2
−∞ −∞
if X and Y are continuous.
The following important properties of expected values can be derived from the
formulas which have been presented so far.


================================================================================
PAGE 113
================================================================================

96 Probability theory
Linearity and monotonicity of the expected value. The expected
value is a linear map:
E[a·X +b·Y +c]=a·E[X]+b·E[Y]+c
for all random variables X,Y and numbers a,b,c∈R.
In addition, the following monotonicity property holds. If Y is almost
surely at least as large as X, i.e., if Pr(Y −X ≥ 0) = 1 holds, then the
analogous inequality holds for the expected values:
E[Y]≥E[X]
TheconditionPr(Y −X ≥0)=1issatisfied,forexample,ifY isalwaysatleast
aslargeasX,i.e.,Y(ω)≥X(ω)holdsforall ω ∈Ω.Inparticular,theexpected
value of a nonnegative random variable is also nonnegative: Y ≥0⇒E[Y]≥0.
The following measures are analogues to the corresponding empirical measures
of variation.
The variance of a random variable X is given by the expected squared
deviation from the mean:
σ2[X]=E[(X −E[X])2]
The standard deviation of X is given by σ[X]= p σ2[X].
An alternative notation is var[X] = σ2[X]. Unlike the expected value, the
variance is not a linear function, but the following rule applies. For all constants
m,c∈R:
σ2[m·X +c]=m2·σ2[X]
We determine the expectation and variance of a standard normally distributed
random variable X as an example. The expected value is zero since it is an
integral over an odd function with f(−ξ)=−f(ξ):
E[X]=
Z ∞
ξ·p X (ξ)dξ =
Z ∞
√
ξ ·e−ξ
2
2
dξ =0
2π
−∞ −∞
We use integration by parts to compute the variance:
var[X]=E[(X−E[X])2]=E[X2]
= Z ∞ ξ2·p X (ξ)dξ = √ 1 Z ∞ ξ· (cid:18) ξ·e−ξ 2 2 (cid:19) dξ
2π
−∞ −∞
= −√
ξ ·e−ξ
2
2 (cid:12) (cid:12)
(cid:12)
∞
+ √
1 Z ∞ e−ξ
2
2
dξ
2π (cid:12) 2π
ξ=−∞ −∞
=1


================================================================================
PAGE 114
================================================================================

3.4. Characteristic measures of random variables 97
Furthermore, we want to consider linear functions of the standard normally
distributedrandomvariable: Y =σ·X+µ where µ,σ ∈R, σ >0.Accordingto
the transformation formulas for the probability density function, for all u∈R:
p Y (u)= √
1 e−(u
2
−
σ
µ
2
)2
2πσ
To determine the expected value and variance of Y, we can use the behavior of
the expected value and variance under transformations:
E[Y]=E[σ·X +µ]=σ·E[X]+µ=µ,
var[Y]=var[σ·X +µ]=σ2·var[X]=σ2
We call a random variable distributed like Y normally distributed with
mean µ and variance σ2. For the probability density function, we use the
following notation:
Y ∼p (·)=N(·|µ,σ2)
Y
For µ=0 and different values of σ, the normal distribution is shown in Fig. 4.2
on the top left. With smaller values for σ, the function graph, also called
a Gaussian bell curve, becomes narrower: values sampled from a normally
distributed random variable with smaller variance will (usually) show a smaller
dispersion.Fromthisperspective,thestandardnormaldistributionisthenormal
distribution with zero mean and unit variance: X ∼N(·|0,1).
The following general inequalities can be useful to produce bounds on the
expectation or variance of a random variable if the proper value may be diffi-
cult to compute. Despite the expectation being a linear operation, in general,
transformations and taking the mean do not commute: E[f(X)] ̸= f(E[X]).
However, the following is true.
Jensen’s inequality.LetX bearandomvariableand f: I →Raconvex
function where I ⊆ R is an interval with range(X) ⊆ I. Given these
conditions, the following inequality holds:
E[f(X)]≥f(E[X])
For concave transformations, the opposite inequality holds. Examples: E[X2]≥
√
(E[X])2 or E[ X]≤ p E[X].
For a continuous random variable X and a differentiable convex function
f: I → R, we may sketch a proof. For convenience, we write µ = E[X]. A
differentiable function is convex if and only if the graph of the function lies
above any tangent. In particular, for all ξ ∈R:
f(ξ)≥f(µ)+f′(µ)·(ξ−µ)
We can multiply this inequality by the probability density of X because it is
nonnegative, and we can integrate on both sides because of the monotonicity of
the integral:


================================================================================
PAGE 115
================================================================================

98 Probability theory
Z ∞ Z ∞ Z ∞
f(ξ)·p (ξ)dξ ≥f(µ)· p (ξ)dξ+f′(µ)· (ξ−µ)·p (ξ)dξ
X X X
−∞ −∞ −∞
| {z } | {z }
=1 =0
which simplifies to E[f(X)]≥f(µ), as desired.
We can also show that bounded random variables have bounded variance.
Popoviciu’s inequality. Suppose that X is a random variable such that
Pr(a≤X ≤b)=1. Then, the following inequality holds:
1
σ2[X]≤ ·(b−a)2
4
To show the result, we examine the rescaled variable:
X−a
Y =
b−a
Forconvenience,wewriteµ=E[Y].WenotethatY (almostsurely)takesvalues
withintheunitinterval, [0,1].Thus,thequantityE[(1−Y)·Y]=E[Y]−E[Y2]
is nonnegative, which means that E[Y2]≤E[Y]=µ. We can use this fact to
put a bound on the variance:
σ2[Y]=E[(Y −µ)2]=E[Y2]−2µ·E[Y]+E[Y]2
1
=E[Y2]−µ2 ≤µ−µ2 =µ·(1−µ)≤
4
The last inequality follows from the fact that E[Y]=µ is also bounded by zero
and one. The general inequality follows from scaling Y back to X.
Finally,wecanalsodefinethefollowingmeasuresthatcorrespondtotheShannon
index.
The Shannon entropy of a discrete random variable X is given by:
X
H[X]=− p (κ)·ln(p (κ))
X X
κ∈supp(X)
The differential entropy of a continuous random variable X:
Z ∞
H[X]=− p (ξ)·ln(p (ξ))dξ
X X
−∞
As usual, we agree on 0·ln0=0 to hold.
3.4.2 Covariance and correlation
The following measures correspond to the measures of association of the same
name in descriptive statistics.


================================================================================
PAGE 116
================================================================================

3.4. Characteristic measures of random variables 99
The covariance of two random variables X,Y is given as follows:
σ[X,Y]=E[(X −E[X])·(Y −E[Y])]
The correlation between the two variables:
σ[X,Y]
ρ[X,Y]= ,
σ[X]·σ[Y]
if σ[X]>0 and σ[Y]>0.
The random variables X and Y are called uncorrelated if σ[X,Y]=0
holds.
An alternative notation is cov[X,Y] = σ[X,Y]. The covariance of a random
variable with itself is its variance: σ[X,X]=σ2[X].
An alternative calculation rule that is often used can be derived from the
linearity of the expected value:
σ[X,Y]=E[X ·Y]−E[E[X]·Y]−E[E[Y]·X]+E[X]·E[Y]
=E[X ·Y]−E[X]·E[Y]
In particular, the following applies to the variance:
σ2[X]=E[X2]−(E[X])2
As an example, we consider two continuous random variables X and Y with
the following joint density function:
1
(cid:18) u2−2ρ·u·v+v2(cid:19)
p (u,v)= exp −
X,Y 2π p 1−ρ2 2(1−ρ2)
where ρ ∈ R, 0 ≤ ρ < 1 is an additional parameter. This is a member of the
family of multivariate normal distributions, which we will discuss in Sect. 5.4.2.
WewanttocalculatethecovarianceofX andY,σ[X,Y]=E[X·Y]−E[X]·E[Y].
In order to do so, we will use the formula for computing the general Gaussian
integral:
Z ∞ e−aξ2+bξ+cdξ = r π ·e4 b2 a +c
a
−∞
for all a,b,c∈R with a>0. The marginal density of Y is given as follows:
Z ∞
p (v)= p (ξ,v)dξ
Y X,Y
−∞
1 Z ∞ (cid:18) ξ2 ρv v2 (cid:19)
= exp − + ·ξ− dξ
2π p 1−ρ2 2(1−ρ2) (1−ρ2) 2(1−ρ2)
−∞
= √ 1 e−v 2 2 =N(v|0,1)
2π


================================================================================
PAGE 117
================================================================================

100 Probability theory
This is the density of a standard normal distribution. For reasons of symmetry,
X followsastandardnormaldistributionaswell.Inparticular,wehave E[X]=
E[Y]=0.
Now, we just need to calculate the expected value of the product.
σ[X,Y]=E[X·Y]−E[X]·E[Y]=E[X·Y]
Z ∞ Z ∞
= ξ ·ξ ·p (ξ ,ξ )dξ dξ
1 2 X,Y 1 2 1 2
−∞ −∞
Z ∞ Z ∞ ξ ·ξ (cid:18) (ξ )2−2ρ·ξ ·ξ +(ξ )2(cid:19)
= 1 2 ·exp − 1 1 2 2 dξ dξ
2π p 1−ρ2 2(1−ρ2) 1 2
−∞ −∞
The following linear transformation with determinant det(Dξ(s,t))= p 1−ρ2
leads to a decoupling of the variables:
√ √
(cid:18) (cid:19) (cid:18) (cid:19) (cid:18) (cid:19)
ξ (s,t) 1 1+ρ− 1−ρ s
ξ(s,t)= 1 = √ √ √ ·
ξ 2 (s,t)) 2 1+ρ 1−ρ t
The integral is then transformed via a few algebraic transformations to the
following:
Z ∞ Z ∞
σ[X,Y]= ξ (s,t)·ξ (s,t)·p (ψ(s,t))·det(Dξ(s,t)) dsdt
1 2 X,Y
−∞ −∞
= 1 · Z ∞ Z ∞ (cid:0) (1+ρ)·s2−(1−ρ)t2(cid:1) ·e−1 2 (s2+t2)· dsdt
4π
−∞ −∞
Thisresultcannowbeintegratedstepbystep—firstwithrespecttoonevariable,
then the other—until, finally:
σ[X,Y]=ρ
Tounderstandtheinterpretationofcovariance,considerahypotheticalcompany
thatinspectssquare-shapedworkpieceswithanaveragesidelengthofx¯=1.00m.
After the production process, quality control measures the side length of the
workpieces again with high precision and finds that they vary with a standard
deviation of s(x)=0.05m.
We assume that the side length can be modeled as a random variable X, with
expected value E[X] = x¯, and variance σ2[X] = s2(x). We will learn later in
Section 4.2 under which circumstances this assumption may be justified.
The average area of a workpiece is not as one might expect, (E[X])2 =1.00m2
butisactuallyalittlehigherevenifthesidelengthsaresymmetricallydistributed
around the mean:
E[X2]=σ2[X]+(E[X])2 =1.0025m2
However, this is only true if the manufacturing process led to variations in the
sidelength,butbothsidelengthswerealwaysexactlyidentical.Amorerealistic


================================================================================
PAGE 118
================================================================================

3.4. Characteristic measures of random variables 101
model might assume that the side lengths are realizations of different random
variables,X andY,thathavethesameexpectedvaluebutareuncorrelated,i.e.,
E[X·Y]=E[X]·E[Y] holds. In this case, the average area of the workpieces
is in fact given by E[X ·Y]=1.00m2.
Furthermore, the following relationship between independence and correlation
of random variables is important.
Correlation of independent random variables. Independent random
variables are always pairwise uncorrelated.
For two continuous random variables X,Y this can be shown as follows:
Z ∞ Z ∞
E[X·Y]= ξ ·ξ ·p (ξ ,ξ )dξ dξ
1 2 X,Y 1 2 1 2
−∞ −∞
Z ∞ Z ∞
= ξ ·ξ ·p (ξ )·p (ξ )dξ dξ
1 2 X 1 Y 2 1 2
−∞ −∞
(cid:18)Z ∞ (cid:19) (cid:18)Z ∞ (cid:19)
= ξ ·p (ξ )dξ · ξ ·p (ξ )dξ
1 X 1 1 2 Y 2 2
−∞ −∞
=E[X]·E[Y]
The converse is not true in general: uncorrelated random variables need not be
independent. For a counterexample, consider a continuous variable X with the
following density function, a uniform distribution on the interval [−2,2]:
(
1 if −2≤u≤2
p (u)= 4
X 0 otherwise
The random variables X and Y =X2 are not independent, because on the one
hand the following holds:
F (1,1)=Pr(X ≤1,X2 ≤1)=Pr(X ≤1,−1≤X ≤1)
X,Y
1
=Pr(−1≤X ≤1)=
2
On the other hand:
3 1
F (1)·F (1)=Pr(X ≤1)·Pr(−1≤X ≤1)= ·
X Y 4 2
̸=F (1,1)
X,Y
Nevertheless, the variables are uncorrelated because their covariance vanishes:
σ[X,Y]=E[X·Y]−E[X]·E[Y]=E[X3]−E[X]·E[X2]
1Z 2 (cid:18) 1Z 2 (cid:19) (cid:18) 1Z 2 (cid:19)
= ξ3dξ− ξdξ · ξ2dξ
4 4 4
−2 −2 −2
=0


================================================================================
PAGE 119
================================================================================

102 Probability theory
3.4.3 Chebyshev’s inequality
Our work so far is rewarded by the following result, which has far-reaching
consequences.
Chebyshev’s inequality. For any random variable X for which expected
value E[X] and variance σ2[X] exist and are finite, the following holds for
any r ∈R, r >0:
σ2[X]
Pr(|X −E[X]|≥r)≤
r2
In other words, the smaller the variance, the less likely it is that the random
variable will take on values that are far from the mean. This result aligns with
our intuitive understanding of a measure of dispersion.
Analternativeformoftheinequalitycanbeobtainedbysubstituting r =zσ[X]:
1
Pr(|X −E[X]|≥z·σ[X])≤
z2
for all z ∈R, z >1.
For example, the probability that a random variable takes on a value that
deviatesfromthemeanbymorethansixstandarddeviationsislessthan3%.In
other words, the probability of finding an observed value of the random variable
within six standard deviations of its expected value is very high, at least 97%.
This result holds for distributions of any shape as long as the expected value
and variance are finite values.
Chebyshev’s inequality can be proved as follows. First, for the sake of clarity of
the formulas, we set µ=E[X] and σ =σ[X].
Furthermore, we introduce the concept of an indicator function. For each
event A⊆Ω, we can define it as follows:
(
1 if ω ∈A
I : Ω →R, I (ω)=
A A 0 otherwise
The indicator function is a discrete random variable with the following cumula-
tive distribution function:
(
0 if u<1
F (u)=
IA Pr(A) if 1≤u
We can express the probability of any event as the expectation of its indicator
function: E[I ]=Pr(A).
A
Let us apply this fact to the event A := {ω ∈ Ω||X(ω)−µ| ≥ r} and set
Y :=I , which implies:
A
E[Y]=Pr(A)=Pr(|X(ω)−µ|≥r)


================================================================================
PAGE 120
================================================================================

3.5. Sums and products of random variables 103
On the other hand, for all ω ∈Ω, |X(ω)−µ|2 ≥r2·Y(ω) holds. We can use
the monotonicity and the linearity of the expected value to conclude:
σ2 =E[|X−µ|2]≥E[r2Y]=r2E[Y]=r2·Pr(|X(ω)−µ|≥r)
Dividing both sides of the inequality by r2 gives the desired result.
Another useful form of Chebyshev’s inequality is given by:
σ2
Pr(|X−µ|<ε)≥1−
ε2
for all ε∈R, ε>0.
3.5 Sums and products of random variables
For discrete random variables X,Y, we can compute the probability mass
function of their sum Z =X +Y.
Probabilitymassfunctionofthesumofdiscreterandomvariables.
For discrete random variables X,Y, the following holds:
X
p (u)= p (κ,u−κ)
X+Y X,Y
κ∈supp(X)
for all u∈supp(X +Y).
Moreover, if X and Y are independent random variables, we have:
X
p (u)= p (κ)·p (u−κ)
X+Y X Y
κ∈supp(X)
WenowwanttocalculatetheprobabilitydensityfunctionofthesumZ =X+Y
of two continuous random variables X and Y. First, we express the distribution
of Z in terms of the joint distribution of X and Y as follows:
F (u)=Pr(X +Y ≤u)= p (ξ ,ξ )dξ dξ
Z x X,Y 1 2 1 2
B(u)
Here, B(u) is the domain of integration {(ξ ,ξ ) ∈ R2|ξ +ξ ≤ u}. Written
1 2 1 2
as a multiple integral, substitution of ξ (t)=t−ξ and swapping the order of
2 1
integration yields:
!
Z ∞ Z u−ξ1
F (u)= p (ξ ,ξ )dξ dξ
Z X,Y 1 2 2 1
−∞ −∞
Z ∞ (cid:18)Z u (cid:19)
= p (ξ ,t−ξ )dt dξ
X,Y 1 1 1
−∞ −∞


================================================================================
PAGE 121
================================================================================

104 Probability theory
Z u (cid:18)Z ∞ (cid:19)
= p (ξ ,t−ξ )dξ dt
X,Y 1 1 1
−∞ −∞
Finally, we observe that the density function is the derivative of the cumulative
distribution function p (u)= d F (u), that is, the inner integrand.
Z du Z
Density function of the sum of continuous random variables. For
continuous random variables X,Y, the density function of their sum is
given as follows:
Z ∞
p : R→[0,∞[, p (u)= p (ξ,u−ξ)dξ
X+Y X+Y X,Y
−∞
An interesting special case occurs when X and Y are independent random
variables:
Z ∞
p (u)= p (ξ)·p (u−ξ)dξ
X+Y X Y
−∞
Generally, the operation
Z ∞
(f ∗g)(u):= f(ξ)·g(u−ξ)dξ
−∞
for integrable functions f,g: R→R is called a convolution. Thus, using this
terminology, the density function of the sum of two independent continuous
random variables is given by the convolution of their density functions: p =
X+Y
p ∗p .
X Y
Asanexample,let’scalculatethedensityfunctionofthesumoftwoindependent
random variables X and Y, each normally distributed with zero mean. We
denote the variance with σ2 and τ2, respectively:
p X (u)=N(u|0,σ2)= √ 1 ·e− 2 u σ 2 2, p Y (u)=N(u|0,τ2)= √ 1 ·e− 2 u τ 2 2
2πσ 2πτ
Computing the convolution of these two functions leads to a general Gaussian
integral:
p X+Y (u)= 2π 1 στ Z ∞ e− 2 ξ σ 2 2 ·e−(u 2 − τ ξ 2 )2 dξ
−∞
1 Z ∞ (cid:18) σ2+τ2 u u2 (cid:19)
= exp − ξ2+ ξ− dξ
2πστ 2σ2τ2 τ2 2τ2
−∞
= √ √ 1 ·e − 2(σ2 u + 2 τ2) =N(u|0,σ2+τ2)
2π· σ2+τ2
Thus, the sum of two normally distributed random variables with zero mean is
again normally distributed with zero mean. The new variance is given by the
sum of variances. In general, the expected values also simply add up:


================================================================================
PAGE 122
================================================================================

3.5. Sums and products of random variables 105
p =N(·|µ ,σ2), p =N(·|µ ,σ2)⇒
X1 1 1 X2 2 2
p =N(·|µ +µ ,σ2+σ2)
X1+X2 1 2 1 2
For another application of the convolution formula, we want to calculate the
density function of the sum of two independent random variables X and Y that
both follow a chi-squared distribution with one degree of freedom:
(
0 if v ≤0
χ2: R→[0,∞[, χ2(v)=
1 1 √1 ·e−1 2 v if v >0
2πv
The convolution of this function with itself is calculated as follows:
Z ∞
p (u)= χ2(ξ)·χ2(u−ξ)dξ
X+Y 1 1
−∞
We have p (u) = 0 for u ≤ 0, so we can assume u > 0 in the following.
X+Y
The integrand vanishes if ξ ≤0 or u≤ξ. Consequently, with the substitution
ξ(t)= u ·(t+1), for u>0:
2
e−1 2 u Z u 1 e−1 2 u Z 1 1
p (u)= dξ = √ dt
X+Y 2π p ξ·(u−ξ) 2π 1−t2
0 −1
(cid:12)1
= e− 2π 1 2 u ·arcsint (cid:12) (cid:12) (cid:12) = 1 2 ·e−1 2 u
(cid:12)
t=−1
We recall that the chi-squared distribution is identical to the distribution of the
squareofastandardnormallydistributedvariable.Thus,theabovedistribution
corresponds to the sum of two such squares: this is the chi-squared distribution
with two degrees of freedom.
Forproductsofindependentcontinuousrandomvariables,wehavethefollowing
formula.
Density function of the product of continuous random variables.
For two continuous random variables X and Y, the following formula
holds:
Z ∞ 1 (cid:18) u (cid:19)
p (u)= ·p ξ, dξ
X·Y |ξ| X,Y ξ
−∞
The proof works similarly to the sum of random variables. First, the following
applies to the cumulative distribution function:
F (u)=Pr(X ·Y ≤u)= p (ξ ,ξ )dξ dξ
X·Y x X,Y 1 2 1 2
B(u)
withB(u)={(ξ ,ξ )∈R2|ξ ·ξ ≤u}.Wedecomposethedomainofintegration
1 2 1 2
into two sub-domains:


================================================================================
PAGE 123
================================================================================

106 Probability theory
(cid:26) (cid:12) (cid:27)
B + (u)= (ξ 1 ,ξ 2
)∈R2(cid:12)
(cid:12) (cid:12) ξ 2 ≤ ξ
u
, ξ 1 >0 ,
1
(cid:26) (cid:12) (cid:27)
B − (u)= (ξ 1 ,ξ 2
)∈R2(cid:12)
(cid:12) (cid:12) ξ 2 ≥ ξ
u
, ξ 1 <0
1
Furthermore, with the substitution ξ (t)= t :
2 ξ1
!
Z ∞ Z u/ξ1
p (ξ ,ξ )dξ dξ = p (ξ ,ξ ) dξ dξ
x X,Y 1 2 1 2 X,Y 1 2 2 1
0 −∞
B+(u)
Z u (cid:18)Z ∞ 1 (cid:18) t (cid:19) (cid:19)
= ·p ξ , dξ dt
ξ X,Y 1 ξ 1
−∞ 0 1 1
In a similar way, we achieve the result:
Z ∞(cid:18)Z 0 1 (cid:18) t (cid:19) (cid:19)
p (ξ ,ξ )dξ dξ = ·p ξ , dξ dt
x X,Y 1 2 1 2 ξ X,Y 1 ξ 1
u −∞ 1 1
B−(u)
Therefore, we can conclude the desired result:
d
p (u)= F (u)
X·Y du X·Y
Z ∞ 1 (cid:18) u (cid:19) Z 0 1 (cid:18) u (cid:19)
= ·p ξ, dξ− ·p ξ, dξ
ξ X,Y ξ ξ X,Y ξ
0 −∞
Z ∞ 1 (cid:18) u (cid:19)
= ·p ξ, dξ
|ξ| X,Y ξ
−∞
As an application of the product formula, we consider a standard normally
distributed random variable Z as well as a random variable Y that follows a
chi-squared distribution with two degrees of freedom, that is:
(
0 if u≤0
p (u)=
Y 1/2·e−u/2 if u>0
Let’s assume that Z and Y are independent. We want to determine the distri-
bution of the following random variable:
√
2·Z √
T = √ = 2·Z·Y−1 2
Y
First, with f(u)=u−1/2:
p (f−1(v))
p (v)=p (v)= Y
Y−1/2 f(Y) |f′(f−1(v))|
(
0 if v ≤0
=
v 1 3 ·e− 2v 1 2 if v >0


================================================================================
PAGE 124
================================================================================

3.5. Sums and products of random variables 107
From the product formula, assuming independence, and substituting ξ(t) =
√
1+u2·t−1:
p
Z·Y−1/2
(u)=
Z ∞
|
1
ξ|
·p
Y
(ξ)·p
Z
(cid:18) u
ξ
(cid:19)
dξ = √
1
2π
Z ∞
ξ
1
4
·e
−1+
ξ2
u2
dξ
−∞ 0
= √ 1 · (cid:0) 1+u2(cid:1)−3 2 · Z ∞ t2·e−1 2 t2 dt= 1 · (cid:0) 1+u2(cid:1)−3 2
2π 2
0
And finally via the transformation formula for linear functions:
1
(cid:18)
u
(cid:19)
1
(cid:18) u2(cid:19)−3
2
p√ (u)= √ ·p √ = √ · 1+
2·Z·Y−1/2
2
Z·Y−1/2
2 2 2 2
This distribution is called Student’s t-distribution1 with two degrees of freedom.
3.5.1 Chi-squared and Student’s t-distribution
In the examples of the previous sections, we calculated the density functions
of Y =(X )2 and Y =(X )2+(X )2 for standard normally distributed and
1 1 2 1 2
independent random variables X ,X . Generalizing these results yields the
1 2
following family of distributions.
The sum Y =(X )2+···+(X )2 of squares of independent standard
N 1 N
normally distributed random variables X ,...,X follows a chi-squared
1 N
distribution with N degrees of freedom:
p (·)=χ2 (·): R→[0,∞[,
YN N
(
0 if u≤0
χ2 (u)=
N 2−N 2 · (cid:0) Γ (cid:0)N(cid:1)(cid:1)−1 ·uN 2 −1·e−u 2 if u>0
2
Here, we have introduced the gamma function:
Z ∞
Γ: ]0,∞[→R, Γ(z)= ξz−1·e−ξdξ
0
For each nonnegative integer n∈N, we have
Γ(n+1)=n!
where n!=n·(n−1)···2·1 is the factorial of n≥1, and by definition 0!=1.
The gamma function thus extends the domain of the factorial beyond integer
values. Specifically, for half-integer values, we have:
√
(cid:18) (cid:19)
1 (2n)!· π
Γ n+ =
2 n!·4n
1 actually William Sealy Gosset (*1876 – †1937), Student is a pseudonym


================================================================================
PAGE 125
================================================================================

108 Probability theory
At the top of Fig. 3.4, there is a function graph of the chi-squared distribution
for a few selected values for the number of degrees of freedom.
For N =1 and N =2, we have already calculated the chi-squared distribution.
By inserting these values for N, we can convince ourselves that the above
formula is correct for these cases. The other cases can be proven by induction.
The nonconstant part is important; the constant factor in front is implied by
the normalization condition R∞ χ2 (ξ)dξ =1. Assuming that the formula is
−∞ N
correct for χ2 (u) with u > 0, the substitution ξ(t) = u ·(t+1) implies the
N 2
formula for N +1 in a way that is very similar to the already calculated base
case χ2 =χ2∗χ2:
2 1 1
Z u
(χ2 N+1 )(u)=(χ2 N ∗χ2 1 )(u)∝ ξN 2 −1·e−ξ 2 ·(u−ξ)−1 2 ·e−u− 2 ξ dξ
0
=
(cid:16)u(cid:17)N
2
+1−1
·e−u 2 ·
Z 1
(1+t) N 2 −1·(1−t)−1 2 dt
2
−1
(cid:16)u(cid:17)N+1−1
∝ 2 ·e−u 2
2
For two degrees of freedom, we have already introduced the Student’s t-
distribution. When there is an arbitrary number of degrees of freedom, then
the Student’s t-distribution is given as follows.
Let Z be a standard normally distributed random variable, and Y a chi-
N
squared distributed random variable with N degrees of freedom. Suppose
thatZ andY areindependent,andconsiderthefollowingrandomvariable:
N
√
N ·Z
T = √
N
Y
N
Then, T follows the Student’s t-distribution with N degrees of
N
freedom:
Γ (cid:0)N+1(cid:1) (cid:18) u2(cid:19)−N 2 +1
p (·)=t (·): R→[0,∞[, t (u)= √ 2 · 1+
TN N N Nπ·Γ (cid:0)N(cid:1) N
2
We will do without a more detailed derivation. The distribution is of special
importance in statistical test theory; more about its application in Sect. 4.3.3.
At the bottom, Fig. 3.4 shows a Student’s t-distribution for N =5 degrees of
freedom.Thet-distributionisverysimilartothestandardnormaldistribution—
in fact, in the limit of a large number of degrees of freedom, for all u∈R:
1
lim t N (u)= √ e−1 2 u2
N→∞ 2π
ForsufficientlylargevaluesofN,thetwodistributionsarehardlydistinguishable
in practice; a common rule of thumb is N >30.


================================================================================
PAGE 126
================================================================================

3.5. Sums and products of random variables 109
0.5
N = 2
0.4
0.3
N = 3
0.2
0.1 N = 4
0.0
0 1 2 3 4
u
)u(
2χ N
0.4
normal distribution
0.3
0.2
0.1
0.0
-2 0 2
u
)u(
t
5
Fig. 3.4. Chi-squared distribution (top) and Student’s t-distribution (bottom)


================================================================================
PAGE 127
================================================================================

110 Probability theory
References
[1] Alan Hájek. “Interpretations of Probability”. In: The Stanford Encyclo-
pedia of Philosophy. Ed. by Edward N. Zalta. Herbst 2019. Metaphysics
Research Lab, Stanford University. url: https://plato.stanford.edu/
archives/fall2019/entries/probability-interpret/.
[2] SKOPOS Institut für Markt- und Kommunikationsforschung GmbH &
Co. KG. Der deutsche Heimtiermarkt 2018 – Struktur und Umsatzdaten.
Accessed July 10, 2020. url: https://www.zzf.de/fileadmin/files/ZZF/
Marktdaten/ZZF_IVH_Folder_2018_Deutscher_Heimtiermarkt_
und_Heimtierpopulation_UPDATE.pdf.
[3] Federal Statistical Office of Germany. “Laufende Wirtschaftsrechnungen
Ausstattungen privater Haushalte mit ausgewählten Gebrauchsgütern”.
In: Fachserie 15.2 (Dec. 2019), p. 12.
[4] GOP [@GOP]. Twitter timeline. Accessed July 3, 2022, 17:03 CET. url:
https://twitter.com/gop.
[5] TheDemocrats[@TheDemocrats].Twittertimeline.AccessedJuly3,2022,
17:03 CET. url: https://twitter.com/TheDemocrats.
[6] Chandima Jeewandara et al. “Sensitivity and specificity of two WHO
approved SARS-CoV2 antigen assays in detecting patients with SARS-
CoV2 infection”. In: BMC Infectious Diseases 22.1 (Mar. 2022). doi:
10.1186/s12879-022-07240-6.
[7] Dennis V. Lindley. Making Decisions. 2nd ed. Nashville, TN: John Wiley
& Sons, Oct. 1985.
[8] Krishna B. Athreya and Soumendra N. Lahiri. Measure Theory and
Probability Theory. Springer New York, 2006. doi: 10.1007/978-0-387-
35434-7.
[9] C. P. Nicholas and R. C. Yates. “The Probability Integral”. In: The
American Mathematical Monthly 57.6 (1950), pp. 412–413. doi: 10.2307/
2307644.


================================================================================
PAGE 128
================================================================================

4
Inferential statistics
Inferential statistics is based on the assumption that data are realizations
of random variables. For example, we may assume that the outcome of tossing
a fair coin is determined by a discrete random variable X that takes the
1
values zero (corresponding to tails) or one (heads) with equal probability:
Pr(X
1
=0)=Pr(X
1
=1)=1/2 . If we flip the coin again, we may assume that
the outcome can be described by a random variable X that is independent of
2
X
1
but follows the same distribution: Pr(X
2
=0)=Pr(X
2
=1)=1/2 .
If we perform the experiment repeatedly, the sequence of observations of heads
or tails becomes the subject of investigation of descriptive statistics: a sample
of a binary variable. Given the nature of the data generating process, we
expect that both possible values occur with approximately the same frequency:
f ≈1−f ≈0.5.
1 0
Conversely, the data allow us to draw conclusions about the underlying true
distribution. For example, if we observe very different frequencies for heads and
tails, such as a 70% frequency for heads compared to 30% for tails, then—if the
sample size is sufficiently large—we would be convinced that we need to correct
our original assumption of equal probability. In other words, we may need to
abandon our assumption that the coin is fair.
In the above example, the relative frequency serves as an estimator of the
probability. Other important estimators include the arithmetic mean as an
estimator of the expected value and the sample variance as an estimator of the
“true” variance.
Intuitively, our confidence in such estimates grows with the sample size. For
example, if the imbalance described above were found among only ten coin
tosses—that is, seven tosses of heads and three of tails—we may not yet be
convinced that we have a biased trick coin at hand. There is still the realistic
possibility that the so-called null hypothesis of a fair coin is true. Colloquially
speaking,theoutcomeoftheexperimentcouldalsohavebeentheresultof“pure
chance.” On the other hand, seventy occurrences of heads among one hundred
© Springer-Verlag GmbH Germany, part of Springer Nature 2023 111
M. Plaue, Data Science, https://doi.org/10.1007/978-3-662-67882-4_4


================================================================================
PAGE 129
================================================================================

112 Inferential statistics
coin tosses would be much stronger evidence for the alternative hypothesis that
the coin is biased!
Inferential statistics allows us to mathematically justify this intuition of a law
of large numbers. From these insights, statistical procedures can be derived that
not only estimate measures such as probability, expected value, and variance
but also gauge our confidence in the correctness of the estimate.
In addition, in this chapter, we will cover the topic of statistical modeling: a
processforestimatingtheparametersoffamiliesofprobabilitymassanddensity
functions from a sample in a way that the distribution represents the best fit to
the observed data.
4.1 Statistical models
For the purpose of statistical inference, we are particularly interested in families
of distributions. That is, the probability mass or density function p not only
depends on the argument u but also on a number of parameters θ ,...,θ .
1 K
We express this dependency via the notation p(u|θ ,...,θ ). We also call such
1 K
a family a (parametric) statistical model. A statistical model is usually
required to satisfy the condition that the model parameters uniquely determine
each probability mass or density function within the family: it is impossible for
two different parameter assignments to lead to the same distribution.
4.1.1 Models of discrete random variables
The following statistical models represent families of probability mass functions
over the natural numbers. For each parameter assignment, it is a nonnegative
function p: N→R, k 7→p(k), the values of which sum to one. Bar graphs for a
selection of parameters are shown in Fig. 4.1.
Given the number of possible outcomes L ∈ N, L > 0, the discrete
uniform distribution is characterized by the following probability mass
function:
(
1 if k ∈{1,...,L}
U(k|L)= L
0 otherwise
More generally, uniformly distributed random variables are characterized by the
factthateverypossibleoutcomewithnonzeroprobabilityisequallyprobable.For
auniformlydistributeddiscreterandomvariableX withsupp(X)={t ,...,t },
1 L
the expectation can be calculated as follows:
L
X 1 1 X
E[X]= κ· = t
L L k
κ∈supp(X) k=1


================================================================================
PAGE 130
================================================================================

4.1. Statistical models 113
Thus, for a uniformly distributed variable, the expected value is formally given
by the arithmetic mean of all the values in its support.
The variance can also be determined using the formula known from descriptive
statistics:
L L
!2
1 X 1 X
σ2[X]=E[(X−E[X])]2 = t − t
L l L k
l=1 k=1
The principle of indifference mentioned at the beginning of Chap. 3 states
that—in the absence of further information—all possible outcomes should be
assumed equally likely; i.e., the outcomes follow a uniform distribution.
Among all discrete distributions over some fixed, finite support, the uniform
distribution is the unique distribution that has maximum Shannon entropy.
The following distribution describes a type of experiment called a Bernoulli
trial, which only has two possible outcomes: success (denoted by k = 1) or
failure (denoted by k =0).
For the probability of success p ∈ [0,1], the Bernoulli distribution is
given by the following probability mass function:

1−p if k =0

B(k|p,1)= p if k =1
0 otherwise
An example of a Bernoulli trial is a coin toss, where either heads or tails can
appear. Typically, both outcomes are equally likely, meaning p is approximately
1. However, it is possible to have a biased coin where heads is more likely, or
2
less likely, to occur than tails, resulting in a value of p that is different from 1.
2
Connecting this topic back to descriptive statistics, the observations of a
Bernoulli experiment produce the values of a binary variable.
The expectation and variance of a Bernoulli-distributed random variable X can
be calculated as follows:
E[X]=0·(1−p)+1·p=p,
σ2[X]=(0−p)2·(1−p)+(1−p)2·p=p(1−p)
The following distribution describes the probability of finding heads exactly k
timesamongaseriesof N cointosses.ItwillplayasignificantroleinSect.4.2.1
when we establish the connection between the frequency of an observation and
the probability of its occurrence.


================================================================================
PAGE 131
================================================================================

114 Inferential statistics
For N trials with probability of success p∈[0,1], the binomial distribu-
tion is given by the following probability mass function:
((cid:0)N(cid:1)
pk(1−p)N−k if k ∈{0,...,N}
B(k|p,N)= k
0 otherwise
For the case that p=0 or p=1, the convention 00 =1 shall apply. The term
(cid:0)N(cid:1) is not a vector but denotes the binomial coefficient. When repeating
k
a Bernoulli trial N times, the binomial coefficient (cid:0)N(cid:1) denotes the number of
k
possible outcomes that produce exactly k successful trials:
(cid:18) (cid:19)
N N!
=
k k!(N −k)!
In the above formula, the exclamation marks denote the factorial: for every
natural number n≥1, n!=n·(n−1)···2·1. By definition, 0!=1.
The Bernoulli distribution is identical to the binomial distribution for the case
N =1.
The expectation and variance of a binomially distributed random variable
X ∼B(·|p,N) are given as follows:
E[X]=Np, σ2[X]=Np(1−p)
Thegeometric distributionwithprobabilityofsuccessp∈R,0<p≤1,
is given by the following probability mass function, k ∈N:
Geom(k|p)=p(1−p)k
The probability that in a sequence of coin flips the first occurrence of heads
happens after exactly k times of tossing tails is given by Geom(k|p).
The expected value and the variance of a geometrically distributed random
variable X ∼Geom(·|p) can be computed as follows:
1−p 1−p
E[X]= , σ2[X]=
p p2
For λ ∈ R, λ > 0, the Poisson distribution is given by the following
probability mass function, k ∈N:
λk
Pois(k|λ)= e−λ
k!
This formula is for the expected value and variance of a Poisson-distributed
random variable X ∼Pois(·|λ):


================================================================================
PAGE 132
================================================================================

4.1. Statistical models 115
E[X]=σ2[X]=λ
The Poisson distribution results from the binomial distribution in the limit of
a large number of Bernoulli trials with probability of success p= λ. We can
N
show this by the following calculation:
(cid:18) (cid:12)
(cid:12)λ
(cid:19) "
N!
(cid:18)
λ
(cid:19)k (cid:18)
λ
(cid:19)N−k #
lim B k(cid:12) ,N = lim · · 1−
N→∞ (cid:12)N N→∞ k!(N −k)! N N
λk " N(N −1)···(N −k+1) (cid:18) λ (cid:19)N−k #
= · lim · 1−
k! N→∞ Nk N
λk "(cid:18) λ (cid:19)−k(cid:18) λ (cid:19)N #
= · lim 1− 1−
k! N→∞ N N
λk (cid:18) λ (cid:19)N λk
= · lim 1− = e−λ =Pois(k|λ)
k! N→∞ N k!
In the last step, we have used the identity ex =lim (cid:0) 1+ x(cid:1)N. The rate
N→∞ N
parameter λ can then be interpreted as the average frequency of a successful
trial.
4.1.2 Models of continuous random variables
Models for continuous random variables are listed in this section. For each
assignment of parameters, the model represents a nonnegative function p: R→
R, u 7→ p(u), the integral of which is equal to one. Fig. 4.2 shows graphs of
those density functions for selected parameters.
For a,b∈R, a<b, the continuous uniform distribution is given by
the following probability density function, u∈R:
(
1 if u∈[a,b]
U(u|a,b)= b−a
0 otherwise
The expected value and variance of a uniformly distributed continuous random
variable X ∼U(·|a,b) are given as follows:
1 1
E[X]= (b+a), σ2[X]= (b−a)2
2 12
The normal distribution with location parameter µ ∈ R and scale
parameter σ ∈ R, σ > 0, is given by the following probability density
function, u∈R:
N(u|µ,σ2)= √ 1 e−1 2 (u− σ µ)2
σ 2π


================================================================================
PAGE 133
================================================================================

116 Inferential statistics
The expected value and the variance of a normally distributed random vari-
able X ∼N(·|µ,σ2) are determined by the location parameter and the scale
parameter, respectively:
E[X]=µ, σ2[X]=σ2
The normal distribution with an expected value µ=0 and variance σ2 =1 is
called the standard normal distribution.
Linear combinations of normally distributed random variables are normally
distributed:IfX ,...,X arenormallydistributed,sois Y = PN a X with
1 N n=1 n n
arbitrary numbers a ,...,a ∈R (unless all those coefficients are zero).
1 N
If, additionally, the random variables X ,...,X are independent, then:
1 N
N N N
X X X
Y = a X ∼N(·|µ ,σ2) with µ = a µ and σ2 = (a σ )2,
n n Y Y Y n n Y n n
n=1 n=1 n=1
where µ ,...,µ are the expected values and σ2,...,σ2 are the variances of
1 N 1 N
X ,...,X .
1 N
IfX ,...,X areindependentvariablesthatfollowthesamenormaldistribution
1 N
with an identical mean µ and variance σ2, then this formula implies:
N
X
X =X +···+X ∼N(·|N ·µ,N ·σ2)
n 1 N
n=1
Later on, the following random variable will be of special interest:
√ 1 PN X −µ −Nµ+ PN X
Z = N · N n=1 n = √ n=1 n
σ Nσ
Under the conditions imposed on X ,...,X , the random variable Z is always
1 N
a standard normally distributed variable:
√ (cid:16)√ (cid:12) (cid:17)
p (u)= Nσ·N Nσ·u+N ·µ(cid:12)N ·µ,N ·σ2
Z (cid:12)
 √ !2 
√ 1 1 Nσu+Nµ−Nµ
= Nσ· √ √ exp− √ 
2π Nσ 2 Nσ
= √ 1 e−u 2 2 =N(u|0,1)
2π
The central limit theorem, discussed in Sect. 4.2.4, makes the surprising state-
ment that under fairly general circumstances, and for a large N, the variable
Z is approximately normally distributed even when X ,...,X are not. In
1 N
other words, even if we know very little about the distribution of the variables
X ,...,X , we know very well how the derived statistic Z is distributed. This
1 N
resultexplainsthesignificanceofthenormaldistributionininferentialstatistics.


================================================================================
PAGE 134
================================================================================

4.1. Statistical models 117
Another useful way to understand the special role of the normal distribution in
statisticsistonotethat,amongalldistributionsofcontinuousrandomvariables
withafixedmeanandvariance,itisthedistributionwithmaximum1 differential
entropy. The principle of indifference states that when there is a complete lack
of information then a uniform distribution of all possible observations should
be assumed. The principle of maximum entropy is a generalization of the
principle of indifference: it advises choosing the distribution with maximum
entropy among those that are consistent with the data. Therefore, the normal
distribution is obtained from this principle when only the mean and variance of
a continuous variable are known.
The Cauchy–Lorentz distribution with location parameter x ∈R and
0
scale parameter γ ∈R, γ >0, is given by the following probability density
function, u∈R:
1 1
L(u|x ,γ)= ·
0 πγ (cid:16) (cid:17)2
1+ u−x0
γ
The Cauchy–Lorentz distribution (also known as the Cauchy distribution) is an
example for a class of continuous distributions for which neither the expected
value nor the variance exist. For all parameter assignments, the normalization
condition that characterizes a probability density is satisfied:
Z ∞ Z ∞ 1 1 1 Z ∞ 1
L(ξ|x ,γ)dξ = · dξ = · dt
0 πγ (cid:16) (cid:17)2 π 1+t2
−∞ −∞ 1+ ξ−x0 −∞
γ
1 (cid:18)Z 0 1 Z ∞ 1 (cid:19)
= · dt+ dt
π 1+t2 1+t2
−∞ 0
(cid:18)
1
= · lim (arctan(0)−arctan(t))+
π t→−∞
(cid:17)
lim(arctan(t)−arctan(0))
t→∞
1 (cid:16) (cid:16) π(cid:17) π (cid:17)
= · 0− − + −0 =1
π 2 2
However, the corresponding improper integrals for the expected value and
variance do not converge. The median and mode of the Cauchy distribution do
exist though. Both are given by the location parameter x .
0
Although the graph of the Cauchy density looks similar to that of the normal
distribution (a bell curve, see Fig. 4.2 on the left), unlike the latter, it is a
fat-tailed probability density: values far from the median x (i.e., outliers)
0
of a Cauchy-distributed random variable are more likely to occur.
1 This property of the normal distribution can be proved using the calculus of
variations: maximize the functional H[p]=− R∞ p(ξ)·ln(p(ξ))dξ, subject to the
−∞
constraints R∞ p(ξ)dξ=1, R∞ ξ·p(ξ)dξ=µ and R∞ (ξ−µ)2·p(ξ)dξ=σ2.
−∞ −∞ −∞


================================================================================
PAGE 135
================================================================================

118 Inferential statistics
For the parameters x ,α∈]0,∞[, the Pareto distribution is given by
min
the following probability density function:
(
αxα ·u−(α+1) if u≥x
Par(u|x ,α)= min min
min 0 otherwise
A Pareto-distributed random variable X ∼ Par(·|x ,α) has the following
min
expected value:
(
∞ if 0<α≤1
E[X]=
αxmin if 1<α
α−1
The variance is given as follows:
(
∞ if 0<α≤2
σ2[X]=
α(xmin)2 if 2<α
(α−1)(α−2)
4.2 Laws of large numbers
Our intuition tells us that the relative frequency of a value occurring in a large
enough sample should be a good estimate for the probability of that occurrence.
For example, when we roll a six-sided die, we can imagine that each outcome
is a realization of a discrete random variable X with supp(X) = {1,...,6}.
If we continue to roll the die, we will usually find that each number appears
roughly one-sixth of the time. Therefore, we conclude that X follows a uniform
distribution.
The same holds true for other characteristics of random variables and their
distributions, such as the mean or variance. Our goal is to estimate these
characteristics from observations of the data. We expect that these estimates
become more accurate as we have more observations or a larger sample size. In
this section, we will provide mathematical arguments to support this intuition,
known as the laws of large numbers.
4.2.1 Bernoulli’s law of large numbers
The relative frequency with which an event occurs upon repeated observation is
also known as the empirical probability of that event. In the following example,
we want to show Bernoulli’s law of large numbers: the true probability can
be well estimated through the empirical probability. More importantly, we can
also determine the accuracy of this estimate as a function of the sample size.
To formalize this concept, we consider a discrete random variable X that takes
1
the value one with probability p (where 0≤p≤1) and zero with probability
1−p. In other words, the variable follows a Bernoulli distribution. For example,


================================================================================
PAGE 136
================================================================================

4.2. Laws of large numbers 119
snoitcnuf
ssam
ytilibaborp
fo
seilimaf
cirtemaraP
.1.4
.giF
%03 %02 %01 %0
21
11
01
9
8
7
6
5
4
3
2
1
0
01 = N ,laimonib
p
%08
05.0
%06
08.0
%04 %02
%0
01
9
8
7
6
5
4
3
2
1
0
geometric distribution
p
05.0 08.0
%51 %01 %5 %0
21
11
01
9
8
7
6
5
4
3
2
1
0
noitubirtsid nossioP
λ
%03
0.5 0.8
%02 %01
%0
01
9
8
7
6
5
4
3
2
1
0
uniform distribution
L
3 7


================================================================================
PAGE 137
================================================================================

120 Inferential statistics
snoitcnuf
ytisned
ytilibaborp
fo
seilimaf
cirtemaraP
.2.4
.giF
5.0=σ
08.0 06.0
1=σ
04.0
2=σ
02.0 00.0
2
0
2-
0 = μ ,noitubirtsid lamron
52.1
5.0
=
b
00.1 57.0
1
=
b
05.0
2
=
b
52.0 00.0
2
1
0
1-
2-
uniform distribution, a = −b
5.0 =
γ
06.0 04.0
1 =
γ
2 =
γ
02.0 00.0
2
0
2-
0 = 0x ,noitubirtsid yhcuaC
05.2
5.2
=
α
00.2 05.1
5.1
=
α
00.1 05.0
5.0
=
α
00.0
3
2
1
Pareto distribution, x = 1
min


================================================================================
PAGE 138
================================================================================

4.2. Laws of large numbers 121
we can imagine tossing a coin that may not be fair, i.e., p ̸= 1/2 . The events
(X )−1(1) and (X )−1(0) correspond to the possible outcomes of heads and
1 1
tails, respectively, which we also call success or failure.
Furthermore, we can assume that if we toss the same coin again under the same
conditions then heads and tails will occur with the same probabilities as before,
and these events are independent of the outcome of the first coin toss. If we
considerthesecondcoinflipasasecondrandomvariable X ,thenthefollowing
2
formulas can be used to determine the joint distribution of X and X :
1 2
Pr(X =1)=Pr(X =1)=p,
1 2
Pr(X =1,X =1)=Pr(X =1)·Pr(X =1)=p2
1 2 1 2
Pr(X =1,X =0)=p·(1−p)
1 2
Pr(X =0,X =1)=(1−p)·p
1 2
Pr(X =0,X =0)=(1−p)·(1−p)
1 2
AfteratotalofN cointosses,describedbyindependentandBernoulli-distributed
random variables X ,...,X , the absolute frequency of occurrence of heads
1 N
is given by the random variable n(N):= PN X . We want to determine the
l=1 l
distributionofn(N).Amongallsequencesofcoinflipswith k headsand(N−k)
tails, the probability that a specific sequence occurs is given by:
Pr(X =1,...,X =1,X =0,...X =0)=pk(1−p)N−k
1 k k+1 N
There are a total of (cid:0)N(cid:1) = N! possible combinations with exactly k
k k!(N−k)!
occurrences of heads. Therefore, the probability that k out of N Bernoulli trials
are successful, regardless of the order of the outcomes, is given by:
(cid:18) (cid:19)
N
Pr(n(N)=k)= ·pk(1−p)N−k
k
Therefore, n(N) is a binomially distributed random variable. The expected
value of the relative frequency f(N)=N−1·n(N) of the occurrence of heads
among N coin flips is thus determined as follows:
(cid:20) (cid:21)
n(N) 1 1
E[f(N)]=E = ·E[n(N)]= ·Np=p
N N N
Thismeansthattheexpectedvaluefortherelativefrequencyf(N)ofasuccessful
trial does indeed correspond to the probability of success. Accordingly, we say
that f(N) is an unbiased estimator of the parameter p.
To determine the accuracy of the empirical probability, we need to compute the
variance:
1 1 p(1−p)
σ2[f(N)]= ·σ2[n(N)]= ·Np(1−p)=
N2 N2 N


================================================================================
PAGE 139
================================================================================

122 Inferential statistics
We can now apply Chebyshev’s inequality:
σ2[f(N)]
Pr(|f(N)−E[f(N)]|≥r)≤ ,
r2
consequently
p(1−p) 1
Pr(|f(N)−p|≥r)≤ ≤ .
Nr2 4Nr2
We can illustrate the practical consequences of this inequality through an
example. Suppose we want to estimate the probability p for the occurrence of
heads such that the result is at most r =0.05 away from the true probability.
Since we are observing a random process, we can never be completely sure that
this error bound will be met. For instance, we might be very unlucky and have
heads fall a hundred times in a row, even though the coin is fair. However, we
can estimate the probability of being this unlucky. Additionally, we can require
thattheprobabilitythattheestimateexceedsthegivenerrorboundbeatmost,
say, α=1%. From these parameters, we can compute a minimum sample size:
N ≥ 1 . Plugging in the example values gives: N ≥10,000.
4αr2
Tosummarize,ifthecoinisflipped10,000times,theobservedrelativefrequency
andtheactualprobabilityofanoccurrenceofheadswilldifferbyatmost ±0.05
with a probability of at least 99%. Thus, with this sample size, we can be very
confident that the estimate is sufficiently accurate.
Moreover, Chebyshev’s inequality implies that for all ε>0:
lim Pr(|f(N)−p|<ε)=1
N→∞
Thatis,foranygivenerrorbound,anestimatethatviolatesthatboundbecomes
increasinglyunlikelywithalargersamplesize.Intheupperlimitofanarbitrarily
largesample,apreciseestimatebecomesalmostcertain,astherelativefrequency
f(N) is a consistent estimator of the parameter p.
In summary, the following result holds:
Bernoulli’s law of large numbers. The relative frequency of success
of a series of independent Bernoulli trials is an unbiased and consistent
estimator for the probability of success.
Example. A total of N =436,323 individuals that participated in the CDC
survey [1] specified their sex. Of these individuals, 238,911 reported being
female. This corresponds to a relative frequency of f = 238,911 =54.8%.
436,323
It would only be possible to determine the actual proportion of female adults
among U.S. citizens with complete accuracy by surveying approximately all
300 million people living in the U.S.


================================================================================
PAGE 140
================================================================================

4.2. Laws of large numbers 123
From a statistical estimation perspective, the probability that our figure of
f =54.8% differs from the actual proportion by more than ∆f =1.0% is at
most α = 1 = 0.57%. It is worth noting that the probability of the
4N(∆f)2
estimate being off by more than ∆f = 0.1% could be as high as α = 57%.
Therefore, it is not appropriate to present the result with three significant
digits. Instead, it should be written as f =55%.
Other independent statistics lead to different results for the proportion of
persons of female sex in the U.S. population with variations that cannot be
explained by the estimation error alone. For example, a study by the United
Nations concludes that the proportion of female adults in the U.S. is given
by f =50.5% (as of 2018 [2]). While estimates of statistical errors are useful,
it is important to keep in mind that systematic factors, such as study design
or data quality, can also be significant.
4.2.2 Chebyshev’s law of large numbers
Justastherelativefrequency(undercertainconditions,suchasindependence)is
a good estimator for the probability of an event or outcome of a binary variable,
we might expect the arithmetic mean to be a good estimator for the expected
value of the random variable that produces the numeric data we observe.
It is important to note that this estimate itself is again a random variable.
If we roll a die 50 times and record the average number, and then we repeat
the experiment, we will likely get slightly different values. If we repeat the
experiment many times, the arithmetic means we recorded will follow some
distribution. For large samples, however, we expect them to show only a small
dispersion and to be centered around the true expected value. This is the key
message of Chebyshev’s law of large numbers, which we will detail below.
Suppose that we observe numeric values x ,...,x in a sample that are the
1 N
realizations of random variables X , n = 1,...,N. We assume that these
n
random variables are mutually independent and follow the same distribution,
a property commonly known as independent and identically distributed,
or i.i.d. for short. This assumption is reasonable when the observations are
the result of independently set up and identically prepared trials or when they
represent a random selection from a population. However, it is important to
note that this assumption may not always be justified.
In addition, we assume that the expected value E[X ] and variance σ2[X ]
n n
of each variable X exist and are finite. Since the variables have the same
n
distribution, these values are the same for each, and we can use the notation
µ=E[X ] and σ2 =σ2[X ].
n n
Next, we consider the following random variable that produces the arithmetic
mean:
N
X¯ =X¯(N)= 1 X X
N n
n=1


================================================================================
PAGE 141
================================================================================

124 Inferential statistics
We want to determine the expected value and variance of this variable in order
to confirm that it is an unbiased and consistent estimator of the expectation µ.
By virtue of the linearity of the expected value, the arithmetic mean is an
unbiased estimator of µ:
" N # N
E[X¯(N)]=E 1 X X = 1 X E[X ]=µ
N n N n
n=1 n=1
Furthermore, since the X are assumed to be mutually independent, they are
n
pairwise uncorrelated:
E[X ·X ]=E[X ]·E[X ]
k l k l
for all k,l=1,...,N with k ̸=l.
It is not difficult to check that for pairwise uncorrelated random variables, the
variance can be represented as follows since all cross terms vanish:
σ2(X +···+X )=σ2(X )+···+σ2(X )
1 N 1 N
Therefore, the variance of the arithmetic mean estimator is given as follows:
σ2[X¯(N)]=σ2 " 1 X N X # = 1 X N σ2[X ]= σ2
N n N2 n N
n=1 n=1
Once more, we can apply Chebyshev’s inequality:
σ[X¯(N)]2
Pr(|X¯(N)−E[X¯(N)]|<ε)≥1− ⇒
ε2
σ2
Pr(|X¯(N)−µ|<ε)≥1− ⇒
ε2N
lim Pr(|X¯(N)−µ|<ε)=1
N→∞
This shows that the arithmetic mean is a consistent estimator of the expected
value. For large samples, the expected value µ of the underlying distribution
and the arithmetic mean of the sample are unlikely to differ significantly.
Let us summarize:
Chebyshev’s law of large numbers. Let X ,...,X be independent
1 N
and identically distributed random variables with finite expected value µ
and finite variance.
Under these assumptions, the arithmetic mean X¯ = 1(X +···+X ) is
N 1 N
an unbiased and consistent estimator of the expected value µ.


================================================================================
PAGE 142
================================================================================

4.2. Laws of large numbers 125
4.2.3 Variance estimation and Bessel correction
Wenowexaminetherelationshipbetweentheempiricalvarianceandthevariance
of the true underlying distribution. The sample variance is estimated from a
set of independent and identically distributed random variables X ,...,X as
1 N
follows:
N
S2(N)= 1 X (X −X¯(N))2
N n
n=1
Its expected value can be calculated as follows:
N
E[S2(N)]= 1 X E[(X −X¯)2]
N n
n=1
N
= 1 X (E[X2]−2·E[X ·X¯])+E[X¯2])
N n n
n=1
N N " N #  N !2
= N 1 X (µ2+σ2)− N 2 X E X N n X X k +E N 1 X X k 
n=1 n=1 k=1 k=1
N
2 X
=µ2+σ2− (µ2+σ2+(N −1)µ2)+
N2
n=1
+
1 (cid:0) N(µ2+σ2)+(N2−N)µ2(cid:1)
N2
(cid:18) (cid:19)
1
= 1− ·σ2
N
Here, we have used the following relation which follows from the X being
n
pairwise uncorrelated:
(
E[X2]=µ2+σ2 if k =n
E[X ·X ]= n
k n E[X ]·E[X ]=µ2 if k ̸=n
n k
Thus, the expected value of the sample variance is not exactly equal to the
variance:S2(N)isabiased estimator.InsteadofS2(N),wecanuseanunbiased
estimator for the variance, which is given as follows:
N
S2 (N)= 1 X (X −X¯(N))2 = N S2(N)
cor N −1 n N −1
n=1
The factor N/(N−1) is also called Bessel correction. The Bessel-corrected
variance is an unbiased estimator: E[S2 (N)]=σ2.
cor
However, both estimators yield similar values for large samples and are thus
both asymptotically unbiased:
E[S2 (N)]= lim E[S2(N)]=σ2
cor
N→∞


================================================================================
PAGE 143
================================================================================

126 Inferential statistics
Just like the arithmetic mean and the empirical probability, both estimators
are consistent:
lim Pr(|S2(N)−σ2|<ε)= lim Pr(|S2 (N)−σ2|<ε)=1
cor
N→∞ N→∞
Werecallthatthestandarddeviationisgivenbythesquarerootofthevariance.
Estimation of the standard deviation is consistent as well. This is not a trivial
resultbutaconsequenceoftheso-calledcontinuousmappingtheorem,which
essentially states that continuous functions preserve limits even for random
variables[3,Theorem3.2.10].Ingeneral,theestimatorforthestandarddeviation
is biased.
Let us summarize the results.
Variance estimation. Let X ,...,X be independent and identically
1 N
distributedrandomvariableswithafiniteexpectedvalueandfinitevariance
σ2.
The sample variance S2 = 1 PN (X −X¯)2 is an asymptotically un-
N n=1 n
biased and consistent estimator. The Bessel-corrected sample variance
S2 = 1 PN (X −X¯)2 is an unbiased and consistent estimator of
cor N−1 n=1 n
the variance σ2.
√
The sample standard deviation, S2, is a consistent estimator of the
standard deviation σ.
4.2.4 Lindeberg–Lévy central limit theorem
Chebyshev’s law of large numbers states that, under fairly general conditions,
the arithmetic mean of a large sample is very likely to be found close to the
true mean of the underlying distribution. Perhaps surprisingly, we can be
quite specific on how the averages of large samples distribute around the true
expectation:
Lindeberg–Lévy central limit theorem. Let X ,...,X be indepen-
1 N
dent and identically distributed random variables with finite expected
value µ and finite variance σ2 >0.
Then, for large samples, the mean X¯(N)= 1(X +···+X ) is approxi-
N 1 N
mately normally distributed:
(cid:18) √ X¯(N)−µ (cid:19) Z b
lim Pr a≤ N · ≤b = N(ξ|0,1)dξ
N→∞ σ a
In general, a sequence of random variables Z ,Z ,... is said to converge in
1 2
distribution against the random variable Z if their cumulative distribution
functions converge pointwise against the distribution of Z: lim F (u)=
N→∞ ZN


================================================================================
PAGE 144
================================================================================

4.2. Laws of large numbers 127
F (u) for all u∈R—in abbreviated notation: Z − D →Z. Mathematically, the
Z N
central limit theorem states that the sequence of random variables
√
Z := Nσ−1(X¯(N)−µ)
N
always converges in distribution to a standard normally distributed random
variable Z:
Z − D →Z with Z ∼N(·|0,1)
N
Statistically, the central limit theorem states that if we repeatedly collect a
sufficiently large sample from the same population, the mean values of those
samples will be normally distributed. This theorem has practical significance
becauseitallowsustomakeprecisestatementsabouttheaccuracyofstatistical
estimations. A common misconception is that this theorem is the reason why
many empirical distributions can supposedly be approximated by a normal
distribution in practice. However, this is not the case.
Although the proof of the theorem requires advanced analytical tools that we
willnotdiscussinthisbook(see,e.g.,[3,Theorem3.4.1]),wecanunderstandits
practicalimplicationsthroughanumericalexample.Imaginethatwerepeatedly
draw samples of size N from some probability density p(·). We can represent
these samples as follows:
(cid:16) (cid:17)
x(1) = x(1),...,x(1) ,
1 N
(cid:16) (cid:17)
x(2) = x(2),...,x(2) ,...
1 N
Even if we know nothing about the distribution p(·), except that it has a finite
expected value and variance, we can be confident that the associated arithmetic
means x¯(1),x¯(2),... follow a normal distribution.
In the upper left of Figure 4.3, a density function p(·) is shown with expected
value µ ≈ 0.64 and standard deviation σ ≈ 1.80. To emphasize that the
0 0
theorem holds for any shape of the underlying distribution, notice how the
density function does not resemble a bell curve.
The other figures show histograms of a large number of means x¯(1),x¯(2),...
computed from samples of size N drawn from the distribution p(·) through
numeric simulation. The limiting distribution, a normal distribution with lo-
cation parameter µ=µ
0
and dispersion parameter σ = √σ0 , is also shown for
N
comparison.
For the small sample size N =1, we cannot expect the limit theorem to apply,
and we simply reproduce the underlying distribution p(·). However, even for
the relatively small sample size N =5, the distribution of the arithmetic means
x¯(k) shows the typical bell shape of the normal distribution. For N =20, this
bell curve is much narrower, once more illustrating Chebyshev’s law of large
numbers—for large samples, it is very likely that the arithmetic mean is close
to the true mean.


================================================================================
PAGE 145
================================================================================

128 Inferential statistics
ezis
elpmas
gniworg
htiw
snaem
citemhtira
fo
noitubirtsid
:meroeht
timil
lartnec
yvéL–grebedniL
.3.4
.giF
52.0 02.0 51.0 01.0 50.0 00.0
6
3
0
3-
u
)u(p
6
3
0
3-
x
N = 1
00.1 57.0 05.0 52.0 00.0
6
3
0
3-
)x(μ
5 = N
6
3
0
3-
)x(μ
N = 20


================================================================================
PAGE 146
================================================================================

4.3. Interval estimation and hypothesis testing 129
4.3 Interval estimation and hypothesis testing
In the derivation of the laws of large numbers, we saw that if we view the
collection of a sample as the outcome of a trial with an uncertain result, we can
make statements about the distribution of sample statistics, like the arithmetic
mean, with repeated collection. This allows us to explore:
• Given a maximum probability of error, what is the minimum accuracy of
our estimation of a distribution’s parameter?
• What statistical effects, such as deviations of an estimated parameter from
some default value, are unlikely to be the result of pure chance and can be
considered statistically significant?
4.3.1 Interval estimation
The central limit theorem is important because it allows us to specify a confi-
dence interval rather than just a point estimate. This means that instead
of a single estimated value, we specify an interval that we can be reasonably
sure contains the true parameter.
Forexample,supposewewanttoensurethatourestimateofthemeaniscorrect
with95%confidenceforsufficientlylargesamples.Wecanachievethisbysetting
the confidence interval [x¯]γ =[x¯ ,x¯ ] with a confidence level of γ =0.95:
min max
lim Pr(X¯(N)∈[x¯ ,x¯ ])=γ
min max
N→∞
We make the following ansatz with the number z ∈R, z >0, which is yet to be
determined:
(cid:18) (cid:20) (cid:21)(cid:19)
σ σ
γ = lim Pr X¯(N)∈ µ−z· √ ,µ+z· √
N→∞ N N
The central limit theorem allows us to conclude:
(cid:18) √ X¯(N)−µ (cid:19)
γ = lim Pr −z ≤ N · ≤z
N→∞ σ
Z z
= N(ξ|0,1)dξ
−z
Thus, z =z(γ) is determined by the integral limits that produce an area of γ
under the standard normal bell curve. Consequently,
(cid:18) (cid:19)
1+γ
z(γ)=Φ−1 ,
2
where Φ(·) is the standard normal cumulative distribution function:
Φ(u)=
Z u
N(ξ|0,1)dξ = √
1 Z u e−ξ
2
2
dξ
2π
−∞ −∞


================================================================================
PAGE 147
================================================================================

130 Inferential statistics
forallu∈R.Valuesofz(γ)canbedeterminednumerically,andsomefrequently
used ones are tabulated below. The table also lists the one-sided critical value
z∗(γ)=Φ−1(γ), the application of which we will explain later:
γ 90.0% 95.0% 99.0% 99.9%
z(γ) 1.64 1.96 2.58 3.29
z∗(γ) 1.28 1.64 2.33 3.09
Table 4.1. Critical values as a function of confidence level
The interval estimate of the mean at confidence level γ based on a
sufficiently large sample x=(x ,...,x ) is given as follows:
1 N
(cid:20) (cid:21)
s(x) s(x)
[x¯] = x¯−z(γ)· √ ,x¯+z(γ)· √
γ N N
In order to arrive at the above formula, we have replaced the mean µ and
the standard deviation σ with their empirical estimates. This is a reasonable
approximation for sufficiently large samples and can be justified by Slutsky’s
theorem: If A − D → a and B − D → b with constants a,b ∈ R, then A ·Z +
N N N N
B − D →aZ+b holds if Z − D →Z. Thus, for sufficiently large samples, we can
N N
replace constant summands and factors, such as µ and σ, with their consistent
estimators. Common rules of thumb for the sample to be sufficiently large in
order to apply these approximations are N >30 or N >50.
Instead of the confidence level γ, the significance level, or probability of
error, α=1−γ can be specified.
Example. The99.9%confidenceintervalfortheaveragebodyheightofmale
respondents in the CDC survey is given as follows:
[µ(body height)] =[177.98cm;178.10cm]
0.999
This high statistical accuracy is due to the large sample size N with more
than 190,000 male persons who were interviewed.
We want to demonstrate how interval estimation works for a smaller sample
size. To this end, we randomly sample a set of N =50 body height values
one hundred times and compute the corresponding 95% confidence interval.
The result can be seen in Fig. 4.4 above. Notice that most of the confidence
intervals, shown as vertical error bars, also contain the true value of 178 cm,
shownasahorizontaldashedline.However,fiveoftheintervalsdonotcontain
it—this is expected by construction and is consistent with the specified error
probability of α = 5%. There is always the possibility that the interval
estimatewillmissthetruemeanofthepopulation,especiallyatlowconfidence
levels.


================================================================================
PAGE 148
================================================================================

4.3. Interval estimation and hypothesis testing 131
The sample of male respondents’ height examined in the example above has
an empirical standard deviation of s(x)=7.85cm. By Chebyshev’s inequality,
we can expect that at least δ =95% of the data points lie within the following
interval around the expected value:
(cid:20) (cid:21) (cid:20) (cid:21)
1 1 1
x¯− √ ·s(x),x¯+ √ ·s(x) = 178cm± √ ·7.85cm
1−δ 1−δ 0.05
=[143cm,213cm]
A more accurate estimate can be obtained using quantiles:
[Q (x),Q (x)]=[163cm,193cm]
0.025 0.975
Intervals of this type are called prediction intervals. It is important to
distinguishpredictionintervalsfromconfidenceintervals.Weexpectmostvalues
produced by some distribution to remain within the prediction interval. The
confidence interval, on the other hand, represents a range that is very likely to
contain some key characteristic of the distribution, such as the expected value
or a model parameter.
Example.BasedondatafromtheALLBUSsurvey2018[4],wecancompute
the 95% confidence interval for the average monthly net household income in
Germany:
[µ(income)] =[3066EUR,3236EUR]
0.95
In this case, the statistical inaccuracies are no longer negligible. Notice that
the sample size is relatively small (N =2530 individuals), and the standard
deviation with which the income disperses around the mean is relatively high:
2179EUR.
4.3.2 Z-test
One important application of the central limit theorem is in hypothesis testing.
Suppose that we have reason to believe that the expected value E[X] of a
random variable X is not equal to zero. In that case, we want to disprove the
null hypothesis E[X]=0 in favor of the alternative hypothesis E[X]̸=0.
At a confidence level of γ, we can reject the null hypothesis E[X] = 0 if the
arithmetic mean x¯ of the sequence of observed values is not contained in the
following interval:
(cid:20) (cid:21)
s(x) s(x)
−z(γ)· √ ,z(γ)· √
N N
As usual, we assume that the sample x=(x ,...,x ) is sufficiently large and
1 N
represents a sequence of realizations of independent random variables with the
same distribution as the model variable X. If the null hypothesis states that
the expected value is some specific value µ that is not necessarily zero, then the
interval becomes:


================================================================================
PAGE 149
================================================================================

132 Inferential statistics
(cid:20) (cid:21)
s(x) s(x)
µ−z(γ)· √ ,µ+z(γ)· √
N N
Let us consider the example of a possibly biased coin. We record the result of
each coin flip, which yields a sequence of binary values, where x =1 represents
n
heads and x = 0 represents tails. The arithmetic mean of that sequence is
n
equal to the relative frequency f of heads:
N
1 X
x¯= x =f
N n
n=1
The probability of success p is equal to the expected value of the underlying
Bernoulli-distributed random variable: E[X]=p≈f.
Suppose we have reason to believe that the coin is not fair. The null hypothesis
claimsthatthecoinisfair,i.e.,E[X]=1/2 .Inafirstexperiment,weobservethat
after ten tosses, the coin lands with heads on top seven times. At a confidence
level of γ =0.95, the confidence interval for this experiment is the following:
(cid:20) (cid:21)
0.42 0.42
0.5−1.96· √ ,0.5+1.96· √ =[0.24,0.76]
10 10
The observed proportion of 0.7 is still within this interval. Therefore, the
null hypothesis of a fair coin cannot be rejected at the given confidence level.
The sample size is relatively small, so it is actually recommended to use the
Student’s t-test, which we discuss in the next section. A t-test would correct
the score z(0.95) ≈ 1.96 to z (0.95) ≈ 2.26, and thus result in an even wider
9
confidence interval.
If, on the other hand, we observed seventy out of one hundred coin tosses with
the outcome of heads, the following confidence interval would be the result:
(cid:20) (cid:21)
0.46 0.46
0.5−1.96· √ ,0.5+1.96· √ =[0.41,0.59]
100 100
In this case, the observed proportion of 0.7 is not contained in the confidence
interval. Thus, the null hypothesis should be rejected, and we may conclude—at
the given confidence level—that the coin is biased.
The procedure outlined above is the so-called one-sample Z-test, where we
compare the mean of a single population to a fixed value. Another important
test is concerned with whether the difference of the means of two populations
vanishes, or whether one mean is larger or smaller than the other. Fortunately,
the difference of two normally distributed and independent random variables
X ∼N(·|µ ,σ2 ) and Y ∼N(·|µ ,σ2) is also normally distributed:
X X Y Y
Y −X ∼N(·|µ −µ ,σ2 +σ2)
Y X X Y
The following test criteria can be formulated as a result.


================================================================================
PAGE 150
================================================================================

4.3. Interval estimation and hypothesis testing 133
Two-sample Z-test. Let x=(x ,...,x ) and y =(y ,...,y ) be se-
1 Nx 1 Ny
quencesofobservationsthatwemayassumetoberealizationsofidentically
distributed random variables X ,...,X and Y ,...,Y , respectively.
1 Nx 1 Ny
We further assume that X ,...,X ,Y ,...,Y are mutually indepen-
1 Nx 1 Ny
dent in addition to having a finite mean and variance.
Two-sided Z-test. At a confidence level of 0<γ <1, we reject the null
hypothesis E[X]=E[Y] if the following holds:
s
s2(x) s2(y)
|y¯−x¯|>z(γ)· +
N N
x y
where z(γ)=Φ−1(cid:0)1+γ(cid:1) is the critical value.
2
One-sided Z-test. At a confidence level of 0<γ <1, we reject the null
hypothesis E[X]≤E[Y] if the following holds:
s
s2(x) s2(y)
y¯−x¯>z∗(γ)· +
N N
x y
where z∗(γ)=Φ−1(γ). For example, if γ =0.95, then z∗(γ)=1.645.
Example.AccordingtotheALLBUSsurvey,theaveragemonthlynetincome
of one-person households in Germany is 1668 EUR. However, the difference
between the income of female and male respondents appears significant:
1535 EUR versus 1788 EUR.
We may therefore conjecture that women in Germany have lower income
compared to men, and we want to test if the data are consistent with
this hypothesis. A total of N = 269 men and N = 267 women provided
y x
information on their income. The respective standard deviations are s(y)=
1083EUR and s(x)=827EUR. At a confidence level of 95%, the one-sided
Z-test requires rejecting the null hypothesis “women in Germany earn at
least as much as men” if the observed income difference is greater than the
following value:
s s
s2(x) s2(y) (827EUR)2 (1083EUR)2
1.645· + =1.645· +
N N 169 267
x y
≈137EUR
The value is below the observed income difference of 253 EUR. The data
thus provides sufficient reason to reject the null hypothesis in favor of the
alternative hypothesis “women in Germany earn less than men.” The gender
pay gap is in fact a global and well-documented phenomenon [5].


================================================================================
PAGE 151
================================================================================

134 Inferential statistics
4.3.3 Student’s t-test
So far, we have always assumed that the sample size is “sufficiently large” in
order to apply limit theorems appropriately. We now present a method that
may also apply to small samples.
Letusrecallthecentrallimittheorem,whichdeterminesthelimitingdistribution
ofthetestscorethatisthedeviationfromthemeaninmultiplesofthestandard
deviation:
(cid:18) √ X¯(N)−µ (cid:19) Z z
lim Pr −z ≤ N · ≤z = N(ξ|0,1)dξ
N→∞ σ −z
The standard deviation σ is assumed to be known. In practical applications, the
standard deviation is usually not known and must be estimated from the data.
Fortunately, the above formula remains true if we replace the true standard
deviation by its consistent estimator:
!
√ X¯(N)−µ Z z
lim Pr −z ≤ N · ≤z = N(ξ|0,1)dξ
p
N→∞ S c 2 or (N) −z
The above formula holds exactly only in the limit, and we may assume that it
holds well enough for large samples. Without further assumptions, it appears
difficult to make more accurate statements about the distribution of the test
score that could be applied to small samples. It turns out that if we assume
the random variables X¯(N) and S2 (N) to be independent, then we know the
cor
distribution of both the data and the test score exactly for any sample size N.
Conditions on a t-distributed test score. Let X ,...,X , N > 1,
1 N
be independent and identically distributed random variables with finite
expected value µ and finite variance σ2.
If the estimators for the expected value X¯(N) and the variance S2 (N)
cor
are independent random variables, then the following holds:
1. X ,...,X are normally distributed,
1 N
2. the test variable
√ X¯(N)−µ
T(N)= N ·
p
S2 (N)
cor
follows a t-distribution with N −1 degrees of freedom.
We briefly outline a proof. Geary’s theorem and its extension by Lukacs
[6, 7] state that the usual unbiased estimators for expectation and variance
are independent random variables if and only if X ,...,X follow a normal
1 N
distribution.
The random variable that determines the distribution of the test score can be
written as follows:


================================================================================
PAGE 152
================================================================================

4.3. Interval estimation and hypothesis testing 135
√ Z
T(N)= N −1·
p
Y
N−1
with
√ X¯(N)−µ (N −1)·S2 (N)
Z = N · and Y = cor .
σ N−1 σ2
Since the random variables that produce the observed data follow exactly a
normaldistribution,Z isstandardnormallydistributed,afactwhichwealready
established in Sect. 4.1.2.
We define the following new random variable:
n !
X˜ := 1 · −n·X + X X
n p n+1 k
n·(n+1)σ
k=1
for all n ∈ {1,...,N −1}. It is not difficult to check that X˜ ,...,X˜ are
1 N
standard normally distributed. Moreover, their independence can be proved,
and the following holds:
N−1
Y = X (cid:16) X˜ (cid:17)2
N−1 n
n=1
Therefore, Y is distributed according to a chi-squared distribution with
N−1
N −1 degrees of freedom, and thus T(N) follows a t-distribution also with
N −1 degrees of freedom.
Let us use Φ (·) to denote the corresponding distribution function:
N−1
Z u
Φ (u)= t (ξ)dξ
N−1 N−1
−∞
for u∈R. The confidence intervals that we had used for interval estimates and
hypothesis tests in previous sections can be easily modified by replacing the
normal distribution with a t-distribution. At a confidence level of γ and for
samples of size N, the critical values are given as follows:
(cid:18) (cid:19)
1+γ
z (γ)=Φ−1 and z∗ (γ)=Φ−1 (γ)
N−1 N−1 2 N−1 N−1
For sufficiently large samples, these critical values lead to the same confidence
intervals as those used in the Z-test since the t-distribution is identical to the
normal distribution in the limit of a large number of degrees of freedom:
lim z (γ)=z(γ), lim z∗ (γ)=z∗(γ)
N−1 N−1
N→∞ N→∞
At a 95% confidence level, the following critical values arise as a function of
sample size:
N 5 15 30 50 100 1000 ∞
z (0.95) 2.78 2.14 2.05 2.01 1.98 1.96 1.96
N−1
z∗ (0.95) 2.13 1.76 1.70 1.68 1.66 1.65 1.64
N−1
Table 4.2. Critical values as a function of sample size


================================================================================
PAGE 153
================================================================================

136 Inferential statistics
Example. We can assume that the height of male participants in the CDC
survey is approximately normally distributed, see Fig. 4.6. The large sample
size of more than 190,000 individuals allows for a very accurate estimate of
the average height: 178 cm. We want to demonstrate how this value can be
estimated with a t-test on the basis of much smaller samples. To do this, we
randomly select a set of five values x ,...,x for height and compute the
1 5
associated 95% confidence interval:
(cid:20) (cid:21)
s(x)
x¯±z (0.95)· √ ≈[x¯±1.24·s(x)]
4
5
We do this one hundred times, each time producing a different sample of
size N = 5. Most of the confidence intervals also contain the true value of
178cm,seeFig.4.4below.Wecanalsoclearlyseethatthestandarddeviation
estimatedfromaverysmallsampleisitselfsubjecttolargestatisticalvariation.
Fourofthehundredintervalestimatesdonot containthetruevalue,reflecting
the chosen error probability of α=5%.
4.3.4 Effect size
Especially for very large samples, it can be quite common to detect statistically
significant differences in the mean or other types of effects that are considered
significant according to statistical tests. However, those effects might still be
small in magnitude.
Example. The CDC dataset allows for comparisons between different U.S.
states. For example, we can compare the average height of male respondents
in Rhode Island x¯ with those in New York y¯. We obtain the following test
score for the two-sided Z-test at a confidence level of 95%:
s s
s2(x) s2(y) (7.68cm)2 (8.23cm)2
1.96· + =1.96· +
N N 2391 15843
x y
≈0.33cm
Thisvalueisbelowtheobserveddifferenceof|y¯−x¯|=0.44cm.Therefore,the
difference is statistically significant. However, it is very small in magnitude,
and therefore we can expect it to be of little practical relevance.
In many cases, the effect size can be gauged well by specifying the effect in
natural units. In the above example, we chose metric units of length. Another
possibility is to specify it in units corresponding to a multiple of the standard
deviation.
For two samples x=(x ,...,x ) and y =(y ,...,y ), Cohen’s d is a
1 Nx 1 Ny
measure of the practical relevance of a statistical effect, defined as follows:


================================================================================
PAGE 154
================================================================================

4.4. Parameter and density estimation 137
y¯−x¯
d(y,x)=
s (x,y)
pool
with the pooled variance [8, p. 67]:
N s2(x)+N s2(y)
s2 (x,y)= x y
pool N +N −2
x y
Example. The difference |y¯−x¯|=0.44cm observed in the example above
corresponds to a value of d(y,x)=0.05 for Cohen’s d. When we compare the
averageheightofrespondentsinPuertoRicoz¯withthoseinNewYork,weget
d(y,z)=0.50, corresponding to a difference in metric units of y¯−z¯=4.1cm.
Rules of thumb for interpreting values of Cohen’s d are noted in the following
table [9]:
|d(y,x)| 0.01 0.2 0.5 0.8 1.2 2.0
effect size negligible small medium large very large huge
Table 4.3. Effect size according to Cohen’s d
4.4 Parameter and density estimation
For a sequence of numerical observations x = (x ,...,x ), the empirical
1 N
cumulative distribution function is given by the proportion of data points
below a certain value:
1
Fˆ: R→[0,1], Fˆ(u)= ·|{m∈{1,...,N}|x ≤u}|
N m
The concept is closely related to the percentage rank (see Sect. 2.5.2): Fˆ(x )=
n
%-rg(x ) holds for all n∈{1,...,N}.
n
The histogram, which is based on a division of the real number line into
intervals]u ,u ]⊂R,k ∈Z,canbeexpressedusingtheempiricalcumulative
k k+1
distribution function:
Fˆ(u )−Fˆ(u )
pˆ: R→[0,∞[, pˆ(u)= k+1 k for all u∈]u ,u ]
u −u k k+1
k+1 k
The Glivenko–Cantelli theorem is another important law of large numbers
(see[10,Theorem8.2.4]fordetails).Forasequenceofindependentandidentically
distributed random variables, the empirical cumulative distribution function
converges uniformly against the true distribution function.
Under certain conditions, with the bin width as a function of the sample size,
the histogram is a consistent estimator of the underlying probability density


================================================================================
PAGE 155
================================================================================

138 Inferential statistics
002 081 061 041
08
77
44
04
51
mc ni thgieh ydob
002 081 061 041
39
44
6
4
)mottob(
5=
N
dna
)pot(
05=
N
ezis
elpmas
rof
slavretni
ecnedfinoc
%59
.4.4
.giF


================================================================================
PAGE 156
================================================================================

4.4. Parameter and density estimation 139
function (see [11, Sect. 6.2]). We can therefore regard the histogram to be an
empirical density function. In what follows, we will present other methods of
density estimation. When these methods are based on the assumption that
the observations are produced by a particular statistical model, the task of
density estimation becomes one of determining the optimal parameters from
the observed data.
4.4.1 Maximum likelihood estimation
Suppose we have good reason to believe that a statistical variable is distributed
according to some specific parametric model. We want to determine the param-
eters of the model in such a way that it matches the observed distribution as
closely as possible.
In order to accomplish this, for a sequence of observed values x=(x ,...,x )
1 N
and a statistical model p(·|θ ,...,θ ), we consider the likelihood function:
1 K
L(θ ,...,θ |x ,...,x )=p(x |θ ,...,θ )···p(x |θ ,...,θ )
1 K 1 N 1 1 K N 1 K
N
Y
= p(x |θ ,...,θ )
n 1 K
n=1
As usual, we assume that each observation is produced by a random variable.
We also assume that the random variables have equal distribution and are
mutually independent. Under these assumptions, the likelihood function is the
jointprobabilityfunctionoftherandomvariables,evaluatedatthepointrealized
by the sample.
A useful criterion for selecting optimal parameters θˆ ,...,θˆ is to maximize
1 K
the likelihood function, which are the parameters that make the observations
most likely under the model assumption.
Formanycommonmodels,thecalculationsimplifiesifweusethelog-likelihood
function instead of the likelihood function, which assumes its maximum at the
same point:
ℓ(θ ,...,θ |x ,...,x )=ln(L(θ ,...,θ |x ,...,x ))
1 K 1 N 1 K 1 N
N !
Y
=ln p(x |θ ,...,θ )
n 1 K
n=1
N
X
= ln(p(x |θ ,...,θ ))
n 1 K
n=1
Tosimplifythenotation,wewillfrequentlyomitthedependenceontheobserva-
tionsandassumethosevaluesasfixed: ℓ(θ ,...,θ )=ℓ(θ ,...,θ |x ,...,x ).
1 K 1 K 1 N
In summary, the procedure can be described as follows.


================================================================================
PAGE 157
================================================================================

140 Inferential statistics
Suppose p(·|θ ,...,θ ) is a statistical model and x = (x ,...,x ) is a
1 K 1 N
sample.Themaximumlikelihoodestimateθˆ ,...,θˆ oftheparameters
1 K
is given by the maximum point of the log-likelihood function:
N
X
ℓ(θ ,...,θ )= ln(p(x |θ ,...,θ ))
1 K n 1 K
n=1
Consequently,theestimateddensityisthefunction pˆ(·)=p(·|θˆ ,...,θˆ ).
1 K
If the likelihood of an observation vanishes, i.e., p(x |θ ,...,θ ) = 0 for at
n 1 K
least one n∈{1,...,N}, we may formally set ℓ(θ ,...,θ )=−∞.
1 K
As an example, let us calculate the log-likelihood for the Pareto distribution.
We can assume that all observed values are at least as large as the parameter
x because the likelihood vanishes otherwise:
min
X N X N (cid:18) αxα (cid:19)
ℓ(x ,α)= ln(Par(x |x ,α))= ln min
min n min xα+1
n=1 n=1 n
N
X
=Nlnα+Nαlnx −(α+1) lnx
min n
n=1
Thelog-likelihoodgrowswith x .Therefore,wewanttochoosetheparameter
min
that is just large enough to agree with what we learn from the sample:
xˆ = min {x }
min n
n∈{1,...,N}
The partial derivative with respect to the second parameter α can be calculated
as follows:
N
∂ℓ N X
(xˆ ,α)= +Nlnxˆ − lnx
∂α min α min n
n=1
The derivative is monotonically decreasing with α. Therefore, the maximum
point of the log-likelihood function is given by the zero of the derivative:
N
(cid:18)(cid:28)
x
(cid:29)(cid:19)−1
αˆ = = ln
PN n=1 lnx n −Nlnxˆ min xˆ min
where ⟨·⟩ denotes the arithmetic mean.
Example. We believe that all higher incomes (more than 2700 EUR) of
German households according to the ALLBUS survey can be modeled by a
Paretodistribution.Afterpluggingthesurveyedincomevaluesintotheabove
formula, we get x =2750EUR and α=2.36 for the optimal parameters.
min


================================================================================
PAGE 158
================================================================================

4.4. Parameter and density estimation 141
The following figure shows a histogram of the data compared to the Pareto
density.
8×10−4
6×10−4
4×10−4
2×10−4
0
4000 8000 12000 16000
monthly net household income in EUR
Fig. 4.5. Fit of a Pareto distribution to higher incomes in Germany
Now, given a sequence of numeric observations x=(x ,...,x ), suppose that
1 N
we want to fit a normal distribution. The log-likelihood as a function of the
location parameter µ and the scale parameter σ computes as follows:
N N (cid:18) (cid:19)
ℓ(µ,σ)= X ln(N(x n |µ,σ2))= X ln √ 1 ·e−1 2 ·(xn σ − 2 µ)2
σ 2π
n=1 n=1
N
1 X N
=− (x −µ)2−Nln(σ)− ln(2π)
2σ2 n 2
n=1
The gradient of this function:
(cid:18)∂ℓ(µ,σ) (cid:19) 1 PN (x −µ) !
gradℓ(µ,σ)= ∂µ = σ2 n=1 n
∂ℓ(µ,σ) 1 PN (x −µ)2− N
∂σ σ3 n=1 n σ
Anymaximum(µˆ,σˆ)mustbeastationarypoint,i.e.,apointwherethegradient
vanishes:
N N
1 X 1 X
µˆ = x =x¯, σˆ2 = (x −µˆ)2 =s2(x)
N n N n
n=1 n=1
By examining the Hessian matrix of second derivatives (see Sect. B.3.3 in the
appendixofthisbookor[12,Sect.7.6]),wemayconfirmthattheseparametersdo
indeed represent a maximum point. Thus, according to the maximum likelihood
paradigm, we simply need to compute the empirical mean and the variance of
the data, and then we plug these values into the model as parameters.


================================================================================
PAGE 159
================================================================================

142 Inferential statistics
Example.Webelievethatthebodyheightoffemaleandmalerespondentsin
the CDC survey are normally distributed. The mean and standard deviation
can be estimated from the data:
µˆ(body height|female)=163cm, σˆ(body height|female)=7.3cm
µˆ(body height|male)=178cm, σˆ(body height|male)=7.8cm
The following figure shows histograms for each subpopulation compared to
the normal distributions with the above parameters:
0.06
0.04
sex
female
male
0.02
0.00
150 175 200
body height in cm
Fig. 4.6. Normal fit to distribution of body height
Theverticaldashedlinedenotesabodyheightof 170cm.Thispointservesas
anoptimaldivisionofthesubpopulationsbasedonbodyheight.InSect.6.3.3,
we will explain how to compute this so-called decision boundary.
The maximum likelihood method can also be applied to models of discrete/cate-
goricalvariables,aswewillillustratewiththefollowingexample.Weparticipate
in a lottery in which colored balls are drawn randomly from an opaque urn
with replacement. The number of balls is unknown, as is the number of colors.
However, we have reason to believe that each color appears with equal proba-
bility. If we number the colors from 1 to K, this assumption translates to the
following uniform distribution:
(
1 if k ∈{1,...,K}
Pr({color no. k drawn})=U(k|K)= K
0 otherwise
Suppose we observe N lottery draws and note down the outcomes k ,...,k ∈
1 N
{1,2,...}. Each previously unobserved color k is denoted by the next con-
n+1
secutive number max {k }+1. For example:
n n


================================================================================
PAGE 160
================================================================================

4.4. Parameter and density estimation 143
n 1 2 3 4 5 6 7 8 ···
color red red yellow blue red yellow green green ···
k 1 1 2 3 1 2 4 4 ···
n
Table 4.4. Outcomes of a lottery
The log-likelihood function is given as follows:
N
X
ℓ(K)= ln(U(k |K))
n
n=1
(
−∞ if k >K for at least one n∈{1,...,N}
= n
−NlnK otherwise
The case max {k } > K corresponds to the situation where more than K
n n
different colors would be drawn. Such a model would not be consistent with the
observed data, so we can assume k ≤K right away.
n
The term ℓ(K)=−NlnK decreases strictly monotonically with K. Therefore,
we must choose a K value as small as possible without contradicting the
condition k ≤ K. This leaves only one choice as the maximum likelihood
n
estimate for K:
Kˆ = max {k }
n
n∈{1,...,N}
At the same time, Kˆ is also an estimator for the number of different colors
present in the urn. If we observe that Kˆ different colors were drawn, then the
optimal assumption according to the maximum likelihood paradigm is that
there are a total of Kˆ different colors in the urn.
However, note that this estimator is biased. Let Kˆ =Kˆ(N) be a function in the
random variables X ,...,X that produce the lottery’s outcomes. We assume
1 N
that these variables are mutually independent and have a uniform distribution
U(·|K ), where K denotes the true number of different colors in the urn. The
0 0
probability that the k-th color appears in a sample of size N is given by:
N
Y
1−Pr(X ̸=k,...,X ̸=k)=1− Pr(X ̸=k)
1 N n
n=1
Y
N (cid:18)
1
(cid:19)N
=1− (1−Pr(X =k))=1− 1−
n K
0
n=1
The expected value of the number of colors drawn is therefore:
E[Kˆ(N)]= X
K0
1−
(cid:18)
1− 1
(cid:19)N !
=K −K ·
(cid:18)
1− 1
(cid:19)N
K 0 0 K
0 0
k=1
Our estimator is asymptotically unbiased, lim E[Kˆ(N)] = K . Still, Kˆ
N→∞ 0
always yields a result that is smaller than the true value K . However, since
0


================================================================================
PAGE 161
================================================================================

144 Inferential statistics
the difference depends on the unknown value K , in practice, we cannot simply
0
add it to the estimate in order to correct it.
4.4.1.1 Power transforms
Suppose that we apply a strictly monotonically increasing function f: I →R,
I ⊆ R to a sequence of numeric observations x ,...,x ∈ I, and then we
1 N
study the transformed data f(x ),...,f(x ) instead. For many applications,
1 N
such a transformation does not change essential characteristics of the data. For
example, the rank statistics stay the same. Furthermore, we can invert the
transformation to retrieve the original observations so that no information is
lost.
However, the distribution of the data will change. We can use this fact to
our advantage and transform the data to fit some desired distribution. Two
popularchoicesoftransformationsforthispurposearethefamiliesof Box–Cox
transforms [13] g (·) and Yeo–Johnson transforms [14] h (·) :
λ λ
(
λ−1·(uλ−1) if λ̸=0
g : ]0,∞[→R, g (u)=
λ λ ln(u) if λ=0
 λ−1·((1+u)λ−1) if λ̸=0 and u≥0
ln(1+u)
if λ=0 and u≥0
h : R→R, h (u)=
λ λ  −
−
(
l
2
n(
−
1
λ
−
)−
u)
1·((1−u)2−λ−1) i
i
f
f
λ
λ
̸=
=
2
2
a
a
n
n
d
d
u
u
<
<
0
0
The following figure shows the graph of the Yeo–Johnson transform for dif-
ferent values of the power parameter λ. Box–Cox transforms show similar
characteristics, but their domain is restricted to positive values.
1.0
0.5
0.0
-0.5
-1.0
-2 -1 0 1 2
u
)u(
h
λ
λ = -1
λ = 0
λ = +1
λ = +2
Fig. 4.7. Yeo–Johnson transforms


================================================================================
PAGE 162
================================================================================

4.4. Parameter and density estimation 145
Given a family of transformations f (·) like the above, and assuming that the
λ
transformeddatafollowtheparametricmodelp(·|θ ,...,θ ),thelog-likelihood
1 K
in terms of the original data is given by:
N N
X X
ℓ(λ,θ ,...,θ )= ln(p(f (x )|θ ,...,θ ))+ ln(f′(x ))
1 K λ n 1 K λ n
n=1 n=1
Maximizing this function with respect to the parameters, including λ, selects
the optimal data transformation.
Example.Accordingtothe2018ALLBUSsurvey,themonthlynetincomein
Germanhouseholdsfollowsaskeweddistribution,seeFig.2.9.Afterapplying
a Box–Cox transform with power parameter λ = 0.277, the distribution
resembles a normal distribution, as seen in the following figure.
0.08
0.06
0.04
0.02
0.00
100 3000 6000 9000
monthly net household income in EUR
Fig. 4.8. DataresemblinganormaldistributionafterapplyingaBox–Coxtransform
4.4.2 Bayesian parameter estimation
The maximum likelihood method assumes that the distribution of observed
values is determined by a statistical model with a specific set of parameters.
Conversely,wecanreconstructthosemodelparametersfromtheobservations(by
maximizing the likelihood function). Due to limited data, the model parameters
may only be estimated with some finite accuracy: given different samples,
estimations may vary. Still, the method assumes that there exists an underlying
true set of parameters, the values of which may be unknown to the statistician
but nevertheless are fixed.
Thus, in maximum likelihood estimation, the model parameters are not random
variables. Conceptually, we cannot speak of a probability with which the param-
eters take on particular values. This is a view common in frequentist statistics.


================================================================================
PAGE 163
================================================================================

146 Inferential statistics
On the other hand, Bayesian statistics present us with a different philosophy:
we assume that the models and model parameters themselves follow some prob-
ability distribution which gauges our incomplete knowledge about their value.
These distributions may in turn depend on so-called hyperparameters.
In order to apply this idea in a meaningful way, we modify the likelihood
function as follows.
Theposteriorprobabilitydistributionoftheparametersofastatistical
model p(·|θ ,...,θ ) is proportional to the product of the likelihood
1 K
function and the prior probability distribution p (·|α ,...,α ):
prior 1 L
p (θ ,...,θ |x ,...,x ;α ,...,α )
post 1 K 1 N 1 L
N !
Y
∝ p(x |θ ,...,θ ) ·p (θ ,...,θ |α ,...,α )
n 1 K prior 1 K 1 L
n=1
where x=(x ,...,x ) is a sequence of observations and α ,...,α are
1 N 1 L
hyperparameters.
Theprior/posteriorprobabilitydistributionsareoftensimplycalledtheprior/the
posterior. The right-hand side of the above formula must be multiplied by a
suitable constant so that the integral (or sum) over the parameters is equal to
one, thus satisfying the usual normalization condition for a probability density
(or mass) function. The prior distribution does not necessarily have to be
normalized. In fact, the integral (or sum) does not even need to exist—as long
as the right-hand side can be normalized to yield a proper posterior probability
distribution. If the prior cannot be normalized, it is called an improper prior.
Thefinalresultoftheprocedureisnotapointestimateθˆ ,...,θˆ oftheoptimal
1 K
model parameters. Rather, the final result is a joint distribution over possible
values θ ,...,θ .
1 K
The prior distribution models information that may already be available about
theparametersevenbeforethedataarecollected.Forexample,aplayerbetting
on coin tosses might be convinced that the coin has a high probability of
being fair even before the game starts. In mathematical terms, it is assumed a
priori that with high probability the parameter of a Bernoulli distribution that
produces the sequence of coin tosses will differ little from p=50%. Accordingly,
foraBayesiananalysisoftheirchancesofwinning,theplayerwouldapplyaprior
with expectation ⟨p⟩=50% and a variance reflecting their initial uncertainty
about this information. Maybe the person that tosses the coin is particularly
trustworthy and the coin does not look or feel unusual or loaded in any way.
In that case, the player is quite convinced that the coin is fair, implying a
small variance of potential parameter values. By multiplying the initial prior
distribution by the likelihood function that depends on the actual data (i.e., the
observed sequence of coin tosses), the player may then update their belief about
the value for p. That updated belief is modeled by the posterior distribution.


================================================================================
PAGE 164
================================================================================

4.4. Parameter and density estimation 147
This example illustrates why Bayesian approaches are of particular importance
to the field of machine learning. These methods provide a framework that can
be interpreted and implemented as a learning process, continuously updating
the machine’s model of the world by observation and processing of new data.
Analogously to the maximum likelihood procedure, we can determine the mode
of the posterior distribution (i.e., its maximum point) in order to obtain a point
estimate for the model parameters, the maximum a posteriori estimate
(MAP).
If there is no a priori information available about the parameters to be esti-
mated, we choose a constant function as the (improper) prior. Before data are
collected, all parameter values are equally likely. Such a prior is also called
a noninformative prior. In that case, the posterior is proportional to the
likelihood, and the results of maximum a posteriori and maximum likelihood
estimation coincide.
Let us illustrate the Bayesian method of parameter estimation by computing
an example (see also [15, Sect. 3.4.1]). Let x=(x ,...,x ) be a sequence of
1 N
numeric observations that we have reason to believe are distributed normally.
In order to keep this example simple, we further assume that we already know
the value of the scale parameter of that normal distribution: σ =σ .
0
Thus, we only need to estimate the location parameter µ, which determines the
likelihood of a single observation x as follows:
n
p(x |µ)=N(x |µ,σ2)
n n 0
Weassumethatpriortocollectingthedata,themodelparameterµisdistributed
according to a normal distribution with mean µ and standard deviation ∆ :
0 0
p (µ|µ ,∆ )=N(µ|µ ,∆ )
prior 0 0 0 0
Therefore, the posterior distribution computes as follows:
N !
Y
p (µ|x;µ ,∆ )∝ p(x |µ) ·p (µ|µ ,∆ )
post 0 0 n prior 0 0
n=1
N !
Y
= N(x |µ,σ2) ·N(µ|µ ,∆2)
n 0 0 0
n=1
−(µ−µ0)2 Y N −(xn−µ)2
∝e 2(∆0)2 · e 2(σ0)2
n=1
Wecanseefromthefunctionalformthatthismustalsobeanormaldistribution:
1 −(µ−µˆN)
p post (µ|x;µ 0 ,∆ 0 )= √ ·e 2∆2 N
2π∆
N
A somewhat longer calculation that we omit here yields the location and scale
parameters of this distribution:


================================================================================
PAGE 165
================================================================================

148 Inferential statistics
N∆2·x¯+σ2·µ ∆ σ
µˆ = 0 0 0, ∆ = 0 0 .
N N∆2+σ2 N p N∆2+σ2
0 0 0 0
The maximum a posteriori estimate of µ is given by µˆ . In addition to this
N
point estimate, we can also provide the following interval estimate:
[x¯] =[µˆ −z(γ)·∆ ,µˆ +z(γ)·∆ ]
MAP,γ N N N N
with 0 < γ < 1 and, for example, z(0.95) = 1.96. With probability γ, the
parameter is contained in this interval. In Bayesian statistics, such an interval
is called a credibility interval in order to distinguish the term from the
confidence interval of frequentist statistics. The interpretation of the latter is
that estimates may vary within the interval with each sample or experiment,
but the true parameter has a fixed, deterministic value.
Notwithstandingthevariousinterpretations,forlargesamples,Bayesianinterval
estimates are consistent with the frequentist estimation described in Sect. 4.3.1.
This follows, firstly, from the fact that the maximum likelihood estimate (=
arithmetic mean x¯) and the maximum a posteriori estimate µˆ coincide for
N
large samples:
lim µˆ =x¯
N
N→∞
Secondly, for large samples, credibility and confidence intervals coincide as well:
√
σ0/ N
lim =1
N→∞ ∆ N
Example.WeassumethattheheightofmalesurveyparticipantsintheCDC
study is normally distributed with known standard deviation σ = 7.8cm,
0
but unknown mean µ.
190
180
170
160
150
0 20 40 60 80
N
mc
ni
thgieh
ydob
Fig. 4.9. Maximumaposterioriestimateofbodyheightwithincreasingsamplesize


================================================================================
PAGE 166
================================================================================

4.4. Parameter and density estimation 149
The above figure illustrates how an a priori estimate of µ =175cm can be
0
improved by observing new data, with increasing sample size N. The grey
area indicates the 95% credibility interval based on ∆ =5.0cm. The dashed
0
line indicates the “true” value of 178 cm, determined from the entire sample.
4.4.3 Kernel density estimation
Anotherestimatorfortheshapeofaprobabilitydensityfunctionisthefollowing.
Letx ,...,x beasequenceofnumericobservations.Thekernel density
1 N
estimate with bandwidths h ,...,h ∈ ]0,∞[ is given as follows, for
1 N
all u∈R:
N (cid:18) (cid:19)
p (u)= X 1 K u−x n
h1,...,hN Nh h
n n
n=1
The kernel K: R → [0,∞[ is a nonnegative function that satisfies the
following conditions:
1. it is even, i.e., K(u)=K(−u) for all u∈R, and
2. R∞ K(ξ)dξ =1.
−∞
A popular choice for the kernel is a Gaussian function:
1
K(u)= √ e−1 2 u2
2π
We can think of the procedure as placing a small Gaussian bell curve at each
location of a data point. The total density will then be the sum of all those
small heaps of probability mass. In regions with high density, where the data
points tend to cluster, this sum will be large:
0.5
0.4
0.3
0.2
0.1
0.0
-2 0 2
u
)u(p
Fig. 4.10. Principle behind kernel density estimation


================================================================================
PAGE 167
================================================================================

150 Inferential statistics
By construction, p (u)≥0 holds for all u∈R, and moreover:
h1,...,hN
Z ∞ p (ξ)dξ = 1 X N 1 Z ∞ K (cid:18) ξ−x n (cid:19) dξ
h1,...,hN N h h
−∞ n=1 n −∞ n
1 X N 1 Z ∞
= h ·K(y ) dy
N h n n n
n=1 n −∞
1 X N Z ∞
= K(y ) dy =1
N n n
n=1 −∞
Here, the substitution y = ξ−xn was made in the integral for each summand.
Therefore, p (·) i n s inde h end a probability density.
h1,...,hN
Since we also assume that the kernel is an even function, R∞ ξ·K(ξ)dξ =0
−∞
holds and a similar calculation shows:
Z ∞
ξ·p (ξ)dξ =x¯
h1,...,hN
−∞
Thus, the estimated density function reproduces the arithmetic mean: E[X ∼
p (·)] = x¯. However, the variance obtained from the kernel density
h1,...,hN
estimate always differs from the empirical variance:
Z ∞ 1 X N
σ2[X ∼p (·)]=s2(x)+ ξ2·K(ξ)dξ· h2
h1,...,hN N n
−∞ n=1
The parameters h ,...,h are hyperparameters in the sense that they cannot
1 N
be readily determined by maximizing the likelihood function. As a result, this
approach would lead to vanishing bandwidths.
Given a smooth differentiable kernel function, the kernel density estimation can
be considered as a smooth approximation to the histogram, a discontinuous
step function. Consequently, the method is sometimes referred to as kernel
smoothing. Kernel density estimates that have small values for the bandwidth
yield large local variations in density, similar to histograms that have a small
bin width. On the other hand, higher values for the bandwidth imply a need to
average across wider intervals, and consequently the need for a higher amount
of smoothing.
Example. The following figure shows two kernel density estimates based on
the frequency distribution of body weight in the CDC dataset. The estimates
use a Gaussian kernel with a constant bandwidth of h = 5.0kg = h =
1
h = ··· = h (solid line) and h = 1.2kg (dashed line), respectively. For
2 N
comparison, the figure also shows the histogram with bin width 2.27kg.


================================================================================
PAGE 168
================================================================================

4.5. Regression analysis 151
0.02
0.01
0.00
50 100 150
body weight in kg
Fig. 4.11. Kernel density estimates of different bandwidth
4.5 Regression analysis
In the previous section, we studied individual statistical/random variables
and modeled their distribution through parameterized families of probability
mass and density functions. Now, we will use regression analysis to study such
variables and their functional dependencies. Consequently, we want to model
their joint and/or conditional distribution so that we can understand these
relationships.
4.5.1 Simple linear regression
Letusconsiderasequenceofpairedobservations(x ,y ),...,(x ,y ).Asusual,
1 1 N N
we think of these as realizations of independent and identically distributed
random variables X ,X ,...,X and Y ,Y ,...,Y , respectively.
1 2 N 1 2 N
An unseen future observation may be thought of as being produced by random
variables X = X and Y = Y . Our goal is to make a prediction
∗ N+1 ∗ N+1
yˆ =fˆ(x ) for y given the information that X =x .
∗ ∗ ∗ ∗ ∗
To make this prediction, we must assume that essential characteristics of the
distribution of Y are determined upon conditioning on the corresponding
n
observation X =x for any trial, n∈{1,...,N,∗,...}. More specifically, in
n n
simple linear regression2, we assume that there exist constants m,c∈R and
normally distributed, mutually independent random variables ε ∼N(·|0,σ2)
n
such that:
2 The term “simple” refers to the fact that only a single independent variable X
is used to make predictions. Therefore, we may also speak of univariate linear
regression.


================================================================================
PAGE 169
================================================================================

152 Inferential statistics
Y =mx +c+ε
n n n
In other words, we assume the following scenario:
• The values y of Y are normally distributed around some mean values,
∗ ∗
• and these mean values lie on a straight line f(x )=mx +c, depending on
∗ ∗
the observations x of X .
∗ ∗
In regression models, the variable Y is called the dependent variable, re-
∗
sponse variable, or target variable. The variable X is the independent
∗
variable, explanatory variable, or predictor variable. In machine learning,
we may call X a feature. The random variable ε is called the error term,
∗ ∗
or disturbance.
This model leads to the following conditional probability density to explain the
observations:
p(y |x ;m,c,σ)=N(y |mx +c,σ2)
n n n n
for all n∈{1,...,N,∗,...}.
The log-likelihood function derived from this model is the following:
N
X
ℓ(m,c,σ)= ln(N(y |mx +c,σ2))
n n
n=1
N
1 X N
=− (y −mx −c)2−Nln(σ)− ln(2π)
2σ2 n n 2
n=1
A calculation of the maximum point (mˆ,cˆ,σˆ) yields the optimal model parame-
ters in a procedure summarized as follows.
Simple linear regression. The slope and intercept of a regression line
fˆ: R→R, fˆ(x )=mˆx +cˆ
∗ ∗
fittingasequenceofdatapoints(x ,y ),...,(x ,y )∈R2 aredetermined
1 1 N N
as follows:
PN
(x −x¯)·(y −y¯) s(x,y)
mˆ = n=1 n n = ,
PN (x −x¯)2 s2(x)
n=1 n
N
1 X
cˆ= (y −mˆx )=y¯−mˆx¯
N n n
n=1
The mean squared error (MSE)
N
1 X
σˆ2 = (y −yˆ )2
N n n
n=1


================================================================================
PAGE 170
================================================================================

4.5. Regression analysis 153
√
with yˆ =fˆ(x ) and the root mean squared error (RMSE) σˆ = σˆ2 can be
n n
interpreted as measures of accuracy for the predictions from a regression model.
In simple linear regression, the (root) mean squared error indicates how widely
the data points are dispersed around the regression line. If σˆ =0 were to hold,
the data points would lie exactly on a straight line, indicating a perfect fit. The
very similar quantity, shown by the below formula,
N N
X X
Nσˆ2 = (y −yˆ )2 = (y −mˆx −cˆ)2
n n n n
n=1 n=1
is called the residual sum of squares (RSS). If we omit the estimation of σ,
then maximizing the likelihood is equivalent to minimizing the residual sum of
squares. Here, we show it written as a function of the model parameters:
N
X
R(m,c)= (y −mx −c)2
n n
n=1
This view on linear regression is called the method of least squares. In fact,
many statistical methods and machine learning techniques rely on solving some
optimization problem, minimizing or maximizing some objective function.
Another measure for goodness of fit is the coefficient of determination,
which equals one if the regression line fits the data perfectly:
PN (y −yˆ )2 σˆ2
r2 =1− n=1 n n =1−
PN (y −y¯)2 s2(y)
n=1 n
Thecoefficientofdeterminationisequaltozeroiftheregressionisnotabetterfit
than the horizontal line passing through the mean y¯. Even though the measure
is written as “R squared,” in settings more general than simple linear regression,
it may be negative.
Example. The Berkeley Earth Surface Temperature project provides mea-
surement data to quantify global warming [16]. The figure below shows the
time series of average global air temperatures since 1850 along with a line
fitted to the data points through linear regression.
The slope of the regression line is given by mˆ =0.006K/a , which corresponds
to a warming of 0.6 Kelvin per century. In general, the difference between the
actual observation and the prediction is called the residual. Geometrically,
the residual is the distance of the data point from the regression line along
the y-axis. In this figure, the residual for each observation is indicated by the
size of the data point, which visually highlights any outliers. The root mean
squared error is given by σˆ =0.17K and the coefficient of determination is
given by r2 =0.77.
The analysis also shows that measurement data from the 20th century lie
below the regression line, while most data points from before 1900 or after


================================================================================
PAGE 171
================================================================================

154 Inferential statistics
2000 lie above the line. This association indicates that the true functional
relationship is a convex function, i.e., the increase in temperature is not
uniform but accelerated. To account for this, we will later fit a second-order
polynomial instead of a regression line (see Fig. 6.3).
15.5
15.0
14.5
14.0
13.5
13.0
1850 1900 1950 2000
year
C°
ni
erutarepmet
ria
labolg
Fig. 4.12. Time series of average global air temperature with regression line
Alternatively, the equation for the regression line can be written as follows:
fˆ: R→R, fˆ(x )=βˆ(x −x¯)+αˆ
∗ ∗
with βˆ = mˆ and αˆ = y¯. In particular, we recognize that the regression line
always passes through the centroid (x¯,y¯) of the data.
Statisticalestimationtheoryallowsustocomputeaγ confidenceintervalinstead
of just a point estimate fˆ(x ). We omit the derivation. Given some predictor
∗
value x ∈R, for sufficiently large samples, we get the following:
∗
" s #
σˆ (x −x¯)2
[fˆ(x )] = fˆ(x )±z(γ)· √ · 1+ ∗
∗ γ ∗ N s2(x)
with, e.g., z(0.95) = 1.96. With a varying x , the above formula defines a
∗
confidence band around the regression line. The confidence band reflects our
uncertainty about the position and orientation of the regression line that is a
result of having limited data. The width of the confidence band increases with
the distance from the centroid (x¯,y¯).
Theconfidencebandisnottobeconfusedwithapredictionband.Aprediction
band denotes a region where a certain proportion 0<δ ≤1 of the data points
canbeexpected.Forsufficientlylargesamples,a δ-predictionbandcanbegiven
as follows:
" s
1
(cid:18)
(x
−x¯)2(cid:19)#
fˆ(x )±z(δ)·σˆ· 1+ · 1+ ∗
∗ N s2(x)


================================================================================
PAGE 172
================================================================================

4.5. Regression analysis 155
For x-values that are not too far away from the mean x¯, the prediction band is
approximately [fˆ(x )±z(δ)·σˆ].
∗
The following figure once more shows measurement data on global air tempera-
tures with a regression line fitted to the data points. The 95% confidence band
is shown as a narrow gray ribbon around the regression line, and the dashed
curves indicate the borders of the 95% prediction band.
15.0
14.5
14.0
13.5
1850 1900 1950 2000 2050
year
C°
ni
erutarepmet
ria
labolg
Fig. 4.13. Confidence and prediction bands for linear regression
Finally, armed with what we have just learned, we want to take another look at
the Bravais–Pearson correlation coefficient. The slope of the regression line is
given by
s(x,y)
mˆ(y,x)=
s2(x)
where x = (x ,...,x ) is the sequence of independent values and y =
1 N
(y ,...,y ) is the sequence of dependent values. If we swap the roles of depen-
1 N
dent and independent values, we get:
s(y,x) s(x,y)
mˆ(x,y)= =
s2(y) s2(y)
First, we note that sgn(mˆ(y,x)) = sgn(mˆ(x,y)) holds: the slopes of both
regression lines have the same sign. Consequently, we can derive the following
formula for the correlation coefficient:
s(x,y) p
r(x,y)= =sgn(mˆ(y,x))· mˆ(y,x)·mˆ(x,y)
s(x)·s(y)
In magnitude, the Pearson coefficient is the geometric mean of the slopes
of the regression lines through the data points. This further emphasizes the
interpretation of this measure as one of linear correlation.


================================================================================
PAGE 173
================================================================================

156 Inferential statistics
4.5.2 Theil–Sen regression
The following procedure presents an alternative to simple linear regression.
Let (x ,y ),...,(x ,y ) ∈ R2 be a sequence of data points/paired nu-
1 1 N N
meric obervations. The Theil–Sen estimator determines the slope and
intercept of a regression line:
(cid:18) (cid:19)
y −y
mˆ = median l k ,
TS k,l∈{1,...,N} x l −x k
xk̸=xl
cˆ = median (y −mˆ ·x )
TS k TS k
k∈{1,...,N}
The Theil–Sen method is more robust than linear regression, as it uses the
median so that outliers have less of an influence on the line of best fit. In
contrast, with linear regression, even a few outliers in the data can lead to
completely different results.
Example. In addition to monthly net income, the ALLBUS survey also
records respondents’ total daily television viewing time. We want to find out
if there is a relationship between those two variables. The figure below plots
television viewing time against income for the cohort of male respondents
who live alone and work full time.
400
300
200
100
0
1000 2000 3000 4000
monthly net household income in EUR
.nim
ni
noitpmusnoc
noisivelet
yliad
linear regression
Theil–Sen estimator
Fig. 4.14. Theil–Sen regression vs. simple linear regression
The regression line, determined by linear regression, has a slightly negative
slope. This negative slope might suggest that, in the selected cohort, the
people with higher income watch less television than the people not of higher


================================================================================
PAGE 174
================================================================================

4.5. Regression analysis 157
income. More precisely, mˆ = −0.012 min., i.e., a reduction in television
EUR
viewing time of 12 minutes per 1000 EUR of additional income.
However, σˆ = 68min, which makes the predictive power of this statement
questionable. Furthermore, the regression line obtained through the more
robust Theil–Sen estimation has a vanishing slope: mˆ = 0. As a result,
TS
this analysis reaches a different conclusion—on average, each person watches
120 minutes of television daily, regardless of income.
4.5.3 Simple logistic regression
In linear regression, the target variable Y is a continuous random variable,
∗
potentially assuming arbitrary values. In logistic regression, the target variable
is Bernoulli distributed: only the values Y =0 and Y =1 are possible.
∗ ∗
The logistic regression model makes the following assumption, where the x
n
represent realizations of the explanatory variable:
(
1 if mx +c+ε >0
Y = n n
n 0 otherwise
Furthermore, it is assumed that the error terms ε follow a logistic distribu-
n
tion: ε ∼Logist(·|0,1). The logistic distribution is defined as follows:
n
(cid:18) (cid:19)
1 u−µ
Logist(u|µ,s)= sech2
4s 2s
with the hyperbolic secant
2
sech(u)= .
eu+e−u
We can think of the approach as follows. To explain the observations produced
by the discrete random variables Y , we introduce the auxiliary continuous
n
random variable Y∗ =mx +c+ε , which causes observation Y =1 whenever
n n n n
the condition Y∗ >0 is met. In this context, Y∗ is called a latent variable;
n n
its realizations do not correspond to any actual observation.
This approach yields the following probabilities for the two possible values of
the response variable Y conditioned on the observed values for the explanatory
n
variable X :
n
Pr(Y =1|X =x )=Pr(Y∗ >0|X =x )
n n n n n n
Z ∞
= Logist(ξ|mx +c,1)dξ
n
0
1
=
1+e−mxn−c


================================================================================
PAGE 175
================================================================================

158 Inferential statistics
or
Pr(Y =0|X =x )=1−Pr(Y =1|X =x )
n n n n n n
1
=1−
1+e−mxn−c
1
=
1+emxn+c
In summary, we can describe the situation by the following statistical model:
1
p(y |x ;m,c)=
n n 1+exp((−1)yn ·(mx
n
+c))
for all n∈{1,...,N,...}.
Thefollowingformulashowsthecorrespondinglog-likelihoodfunctionforsimple
logistic regression:
N
X
ℓ(m,c)=− ln(1+exp((−1)yn ·(mx +c)))
n
n=1
The maximum point (mˆ,cˆ) of this function cannot be calculated in closed form.
Instead, numerical methods need to be used.
Theestimatedparametersdeterminethe decision boundary xˆ,wherewehave
mˆxˆ+cˆ=0. For observed values x with mˆx +cˆ>0, according to the logistic
∗ ∗
model, it is more likely to find Y =1: Pr(Y =1|X =x )>Pr(Y =0|X =
∗ ∗ ∗ ∗ ∗ ∗
x ). On the other side of the decision boundary, we expect that the occurrence
∗
of Y =0 is more likely.
∗
For simple (i.e., univariate) logistic regression, the decision boundary consists of
only a single point, since we consider only one independent variable. In practice,
univariate logistic regression is of little importance. However, building on these
ideas, we introduce multivariate logistic regression in Sect. 6.3.1.


================================================================================
PAGE 176
================================================================================

References 159
References
[1] CDC Population Health Surveillance Branch. Behavioral Risk Factor
Surveillance System (BRFSS) Survey Data 2018. Accessed Feb. 1, 2020.
url: https://www.cdc.gov/brfss/.
[2] UN Department of Economic and Social Affairs. World Population
Prospects 2019. Accessed July 10, 2020. url: https://population.un.
org/wpp/.
[3] Rick Durrett. Probability: Theory and Examples. 5th ed. Cambridge Uni-
versity Press, May 2019.
[4] GESIS–Leibniz-InstitutfürSozialwissenschaften.AllgemeineBevölkerung-
sumfrage der Sozialwissenschaften ALLBUS 2018. 2019. doi: 10.4232/1.
13250.
[5] AndrewM.Penneretal.“Within-jobgenderpayinequalityin15countries”.
In:NatureHumanBehaviour(Nov.2022).doi:10.1038/s41562-022-01470-
z.
[6] EugeneLukacs.“A Characterizationof theNormalDistribution”.In: Ann.
Math.Statist.13.1(Mar.1942),pp.91–93.doi:10.1214/aoms/1177731647.
[7] Radha G. Laha. “On an extension of Geary’s theorem”. In: Biometrika
40.1-2 (1953), pp. 228–229. doi: 10.1093/biomet/40.1-2.228.
[8] JacobCohen.Statistical power analysis for the behavioral sciences.2nded.
New Jersey, USA: Lawrence Earlbaum Associates, 1988.
[9] Shlomo S. Sawilowsky. “New Effect Size Rules of Thumb”. In: Journal
of Modern Applied Statistical Methods 8.2 (Nov. 2009), pp. 597–599. doi:
10.22237/jmasm/1257035100.
[10] Krishna B. Athreya and Soumendra N. Lahiri. Measure Theory and
Probability Theory. Springer New York, 2006. doi: 10.1007/978-0-387-
35434-7.
[11] Larry Wasserman. All of Nonparametric Statistics. Springer New York,
2006. doi: 10.1007/0-387-30623-4.
[12] JanR.Magnus.MatrixDifferentialCalculuswithApplicationsinStatistics
and Econometrics. 3rd ed. Wiley, Feb. 2019. doi: 10.1002/9781119541219.
[13] George E. P. Box and David R. Cox. “An Analysis of Transformations”.
In: Journal of the Royal Statistical Society: Series B (Methodological) 26.2
(July 1964), pp. 211–243. doi: 10.1111/j.2517-6161.1964.tb00553.x.
[14] In-Kwon Yeo and Richard A. Johnson. “A new family of power transfor-
mations to improve normality or symmetry”. In: Biometrika 87.4 (Dec.
2000), pp. 954–959. doi: 10.1093/biomet/87.4.954.
[15] Richard O. Duda, Peter E. Hart, and David G. Stork. Pattern Classifica-
tion. 2nd ed. Wiley, 2000.
[16] Berkeley Earth. Time Series Data – Monthly Global Average Temperature
(Annual Summary). Accessed Feb. 1, 2020. url: http://berkeleyearth.
org/data/.


================================================================================
PAGE 177
================================================================================

5
Multivariate statistics
When we learned about association measures and regression methods in the
previous chapters, we gained a first glimpse into multivariate statistics. Mul-
tivariate methods allow for the joint study of statistical variables and their
relationships between each other with the goal of capturing a complete picture
of the data. In machine learning, this approach is essential, as predictions are
based on a large number of features and their statistical characteristics.
5.1 Data matrices
Let us consider a sample of size N where each observation collects the values
for a total of D statistical variables/features. To simplify the discussion, we
will assume that the data are quantitative/numeric, unless stated otherwise.
Thus, each of the N observations is a D-dimensional data point/feature vector
x ∈RD, n∈{1,...,N}. In order to work with tools from linear algebra, such
n
as matrix multiplication, we need to agree on conventions for the format of
the vectors and matrices involved. One option is to write the feature vectors
x ,...,x as the columns of a matrix, like so: x = (x ,...,x ). In general,
1 N 1 N
this matrix has the format D×N, consisting of D rows and N columns. For
example, four observations of both body height (in meters) and body weight
(in kilograms) can be summarized as a matrix as follows:
(cid:18) (cid:19)
1.63 1.66 1.47 1.79
x=
59 91 64 86
This convention is especially helpful when we want to use tools of multivariate
calculus. Otherwise, we would have to break with common conventions, so that,
e.g.,thegradientbecomesarowvector.Instatistics,however,itisalsocommon
to write the feature vectors as rows in a way that each column contains a
sequence of observed values, resulting in a matrix with N rows and D columns:
© Springer-Verlag GmbH Germany, part of Springer Nature 2023 161
M. Plaue, Data Science, https://doi.org/10.1007/978-3-662-67882-4_5


================================================================================
PAGE 178
================================================================================

162 Multivariate statistics
 
1.63 59
xT =   1.66 91 
1.47 64
1.79 86
Wesimplycallamatrixconstructedinthiswaya data matrix.Ithasthesame
format as the data tables that we already encountered in previous chapters.
We give the data matrix its own notation: X = xT. Despite this convention,
we always write data points/feature vectors as column vectors. Similarly, when
we refer to a random vector, i.e., a tuple of random variables, we always mean
column vectors. We may also write column vectors as transposed rows, e.g.,
u=(u ,u ,u )T.
1 2 3
Sequences of observed values, on the other hand, are usually to be understood
as row vectors. If a different convention is used, we may indicate it in bold print
for the sake of clear notation: y =yT =(y ,...,y )T.
1 N
We will also combine, for example, model parameters to vectors and matrices.
We then explicitly point out the format if necessary.
In general, a data matrix with N rows/observations and D columns/features
has the following form:
 
x x ··· x
11 12 1D
x 21 x 22 ··· x 2D
X = . . . =(x )
 . . . . . .  nd n∈{1,...,N}
  d∈{1,...,D}
x x ··· x
N1 N2 ND
The dimensionality of the data is given by D. The rows X ,...,X of a
1• N•
data matrix X are the transposed feature vectors:
X =xT, X =xT, ..., X =xT
1• 1 2• 2 N• N
We can denote the columns—i.e., the sequences of observed univariate values
for each feature—by X ,...,X . If we subtract the respective arithmetic
•1 •D
mean, we get the mean-centered data matrix:
X 7→X −X
•d •d •d
for all d ∈ {1,...,D}; the minus sign here means that the mean is to be
subtracted from each observation in the sequence.
If,inadditiontomean-centering,wedividebytherespectivestandarddeviation,
we get the standardized data matrix that consists of the so-called standard
scores, or z-scores:
X −X
X 7→Z = •d •d
•d •d s(X )
•d


================================================================================
PAGE 179
================================================================================

5.2. Distance and similarity measures 163
If the variable has a vanishing variance, i.e., s(X )=0 holds, we may assume
•d
Z = 0. By construction, arithmetic means of variables/features in mean-
•d
centered or standardized data are always zero. Moreover, the sample variance
of a z-score is always equal to one (unless it vanishes).
Standardization is particularly advisable when the variables have different units
(e.g., meters vs. kilograms) or operate on a different scale (e.g., body height
vs. daily walking distance). For example, the above data matrix of height and
weight (using unbiased sample variance) becomes:
 
−0.05 −1.00
 0.17 1.00 
Z = 
−1.27 −0.69
1.16 0.69
Another popular form of normalization is min–max scaling:
X −X
X 7→ •d min,d
•d X −X
max,d min,d
where
X = min {x } and X = max {x }.
min,d nd max,d nd
n∈{1,...,N} n∈{1,...,N}
Min–max scaled variables take values between zero and one.
For some applications, it is convenient to add a zeroth column to the data
matrix, the entries of which are all equal to one:
 
1
.

X
•0
= 

. .

N times
1

This extended data matrix is especially useful in the discussion of (multivariate)
regression, where we will call it the regressor matrix. Other common names
are the design matrix or the model matrix.
5.2 Distance and similarity measures
Inordertocomparetwoobservationsu,v ∈Rofaunivariate,numericstatistical
variable,wecancomputetheirdistanceviatheabsolutevalueoftheirdifference:
δ(u,v)=|u−v|. For ordinal variables, we may use the difference in rank. For
a categorical variable with domain {m ,...,m }, the discrete metric is the
1 K
standard choice to compare values:
(
0 if k =l
δ(m ,m )=
k l 1 if k ̸=l
For multivariate variables, when we want to numerically compare two obser-
vations, there are a number of useful measures that can be interpreted as a
distance or similarity.


================================================================================
PAGE 180
================================================================================

164 Multivariate statistics
5.2.1 Distance and similarity measures for numeric variables
First, we define various measures for the length of a single feature vector. In
mathematical parlance, such a measure is generally called a norm.
For a numeric vector u=(u ,...,u )T ∈RD and fixed p∈N, p≥1, we
1 D
define its Minkowski norm of order p (or p-norm for short):
D ! p 1
X
∥u∥ = |u |p
p d
d=1
The maximum norm is the following:
∥u∥ = max {|u |}
∞ d
d∈{1,...,D}
The maximum norm can be interpreted as the limit of the p-norm for large
values of p, since for all u∈RD we have the following:
lim ∥u∥ =∥u∥
p ∞
p→∞
The2-normistheordinaryEuclideannorm,whichwefallbacktoifnoparticular
pisspecified:∥u∥=∥u∥ .TheEuclideannormisinturnrelatedtothestandard
2
Euclidean inner product
D
X
⟨u,v⟩=u•v = u ·v
d d
d=1
as follows:
p
∥u∥= ⟨u,u⟩
For two column vectors u,v ∈RD, the inner product can be written as a matrix
multiplication as follows:
⟨u,v⟩=uT ·v
The distance between two data points can be computed via the length of the
vector that connects them:
Fortwonumericdatapointsu,v ∈RD,wedefinetheEuclidean distance
δ (u,v)=∥u−v∥ ,
2 2
the Manhattan distance
δ (u,v)=∥u−v∥ ,
1 1
and the Chebyshev distance, or maximum distance,
δ (u,v)=∥u−v∥ .
∞ ∞


================================================================================
PAGE 181
================================================================================

5.2. Distance and similarity measures 165
The above list represents the Minkowski distances most commonly used
in data analysis. These distance measures can be defined in that way for any
Minkowski norm. Unless specified otherwise, we will use the Euclidean distance.
Let’s calculate an example:
(cid:18) (cid:19) (cid:18) (cid:19)
−0.5 1.0
u= ,v =
0.5 1.0
The following values result from the various distance measures:
δ (u,v)=|−0.5−1.0|+|0.5−1.0|=2.0
1
p
δ (u,v)= (−0.5−1.0)2+(0.5−1.0)2 ≈1.6
2
δ (u,v)=max{|−0.5−1.0|,|0.5−1.0|}=1.5
∞
Example. We consider three plants of the genus Iris, which were selected
from a larger dataset of 150 specimens [1]:
n type sepal length sepal width petal length petal width
1 Iris setosa 5.1 cm 3.5 cm 1.4 cm 0.2 cm
2 Iris setosa 4.9 cm 3.0 cm 1.4 cm 0.2 cm
101 Iris virginica 6.3 cm 3.3 cm 6.0 cm 2.5 cm
Table 5.1. Measurements of sepal and petal of iris flowers
Wecancombinethelengthsofsepalandpetaltodatapointsx ,x ,x ∈R4.
1 2 101
The Chebyshev distance between specimens of the species Iris setosa is
δ (x ,x ) = 0.5cm. The distance of these specimens to the Iris virginica
∞ 1 2
specimen is much larger due to the significantly longer petal: δ (x ,x )=
∞ 1 101
δ (x ,x )=4.6cm.
∞ 2 101
If the data come with units of measurement, those units must be identical in
order to compare them in a meaningful way. For example, in the calculation
above, we chose centimeters to measure and compare lengths. In many cases, a
prior standardization of the data (i.e., computing the z-scores) is recommended
so that the variables are unitless and have an equal variance.
The concept dual to distance is similarity: when two information objects or
observations are associated with feature vectors that have a small distance, we
can think of them as being similar.
For two numeric feature vectors with non-negative components u,v ∈
[0,∞[D, we define their cosine similarity:
⟨u,v⟩
σ (u,v)= =cos∢(u,v)
cos ∥u∥·∥v∥


================================================================================
PAGE 182
================================================================================

166 Multivariate statistics
unless u = 0 or v = 0, in which case one may either leave the measure
undefined or set σ (u,v)=0.
cos
The Tanimoto similarity is given as follows:
⟨u,v⟩
σ (u,v)=
Tanim ∥u∥2+∥v∥2−⟨u,v⟩
unless u=v =0, in which case the Tanimoto similarity is undefined.
Conventions that fill the gaps in the above similarity measures’ domains are
not set in stone. For example, some may want to argue for σ (0,0)=0.
Tanim
If the compared vectors are orthogonal, both the cosine and the Tanimoto
similarity vanish. If they are colinear, the cosine similarity takes its maximum
possible value of one: It holds σ (u,v) = 1 precisely when v = λu for some
cos
λ>0. On the other hand, the maximum Tanimoto similarity σ (u,v)=1
Tanim
is given if and only if u=v.
Example. We can also compare the dimensions of the sepal and petal of
irises from the above example using similarity measures. The Tanimoto
similarity of the two Iris setosa specimens in the above example is given
by σ (x ,x ) ≈ 0.99. The similarity with the specimen of the species
Tanim 1 2
Iris virginica is much lower and given by σ (x ,x ) ≈ 0.65 and
Tanim 1 101
σ (x ,x )≈0.64, respectively.
Tanim 2 101
5.2.2 Distance and similarity measures for categorical variables
Suppose we are given two ordered lists of equal length that contain symbols or
other objects where we can discern (in-)equality. An obvious idea to determine
a measure of their distance/similarity is to compare each position in the list
and count instances of different/identical symbols or objects. For example, the
two strings ABCDE and ABXDY would have a distance of two, since two characters
do not match (or a similarity of three, since three characters do match). See
also the edit distances that we introduced in Sect. 1.4.5.1 for the purpose of
data deduplication.
This idea gives rise to the following formal definition.
For two data tuples u,v of length D that contain values for the same
categorical variables, we define their Hamming distance:
δ (u,v)=|{d∈{1,...,D}|u ̸=v }|
Hamm d d
The normalized Hamming distance is given by: 1/D·δ
Hamm
(u,v)
The Hamming distance simply counts the number of features that have a
different value. An everyday example would be plant identification. Two plants


================================================================================
PAGE 183
================================================================================

5.2. Distance and similarity measures 167
with identical characteristics (e.g. growth habit, leaf shape, leaf arrangement,
etc.)haveaHammingdistanceofzero,andthustheycanbepresumedtobelong
to the same species.
For binary variables, the Hamming distance is the number of distinct bits. Let
x =(1,1,0,1)T and x =(0,1,0,1)T be two binary feature vectors. For easier
1 2
comparison, we can also write them on top of each other as a data matrix:
(cid:18) (cid:19)
1101
X =
0101
Only the first entries are different, so δ (x ,x )=1 holds. The normalized
Hamm 1 2
Hamming distance is given by 0.25 since there are four entries in total.
The following similarity measures are specifically designed to compare lists of
binary variable values.
Fortwodatatuplesu,v ∈{0,1}D ofbinaryvalues,wedefinetheirJaccard
similarity as follows:
|{d|u =1 and v =1}
σ (u,v)= d d
Jacc |{d|u =1 or v =1}|
d d
If u=v =0 holds, this measure is not defined.
The Szymkiewicz–Simpson similarity, or overlap coefficient, is
defined as follows:
|{d|u =1 and v =1}|
σ (u,v)= d d
overlap min{|{d|u =1}|,|{d|v =1}|}
d d
If u=0 or v =0 hold, this measure is not defined.
In Sect. 2.5.3, we introduced the Jaccard index as a measure of association
between two binary variables as a method to compare sequences of observations.
Here, we apply the same formula to measure the similarity between two obser-
vations of multiple categorical variables. Instead of the binary vectors u and v,
we can consider the sets U and V for the variables which have been assigned a
value of one. The Jaccard similarity and overlap coefficient prove to be useful
measures for the size of those sets’ intersection:
|U ∩V| |U ∩V|
σ (U,V)= and σ (U,V)=
Jacc |U ∪V| overlap min{|U|,|V|}
Both measures take values between zero and one, where σ (U,V) =
Jacc
σ (U,V)=0correspondstoavanishingoverlap:U∩V =∅.Themaximum
overlap
values are characterized as follows:
σ (U,V)=1⇔U =V,
Jacc
σ (U,V)=1⇔U ⊆V or U ⊇V
overlap


================================================================================
PAGE 184
================================================================================

168 Multivariate statistics
An alternative formula for the Jaccard similarity that is often convenient is the
following:
|U ∩V|
σ (U,V)=
Jacc |U|+|V|−|U ∩V|
Letuscomputeanexampleandconsiderthetwobinaryvectors u=(1,1,0,1)T
and v = (0,1,0,1)T. If the features associated with each entry of u and v
are named by letters from a to d, these binary vectors correspond to the sets
U ={a,b,d} and V ={b,d}, thus U ∩V ={b,d}. The similarity measures are
calculated as follows:
2
σ (u,v)=σ (U,V)= ≈0.67,
Jacc Jacc 3+2−2
2
σ (u,v)=σ (U,V)= =1.00
overlap overlap min{3,2}
5.2.3 Distance and similarity matrices
In the last sections, we learned about examples of distance and similarity
measures. We now approach a general definition.
Let Ω be any set, e.g., some feature space like Ω ⊆ RD or Ω = {0,1}D.
Let δ: Ω ×Ω → [0,∞[ be a map for which we consider the following
conditions, for all u,v,w ∈Ω:
(1) δ(u,u)=0
(2) δ(u,v)=0⇒u=v
symmetry: δ(u,v)=δ(v,u)
triangle inequality: δ(u,w)≤δ(u,v)+δ(v,w)
If at least condition (1) is satisfied, we call δ(·, ·) a premetric1. If all of
the conditions above are satisfied, the map is called a metric.
All distance measures induced by the Minkowski norms ∥ · ∥ are metrics, as is
p
the Hamming distance.
We can construct the Jaccard distance from the Jaccard similarity as follows:
δ (u,v):=1−σ (u,v)
Jacc Jacc
for all u,v ∈{0,1}D. One can prove that this distance measure is a metric.
The following is an example of a symmetric premetric that is not a metric
(neither the triangle inequality nor condition (2) are satisfied):
1 Thedefinitiongivenisnotastandarddefinition.Someauthorsmaymeansomething
different when they talk about a “premetric.”


================================================================================
PAGE 185
================================================================================

5.2. Distance and similarity measures 169
δ (u,v):=1−σ (u,v)
overlap overlap
for all u,v ∈{0,1}D.
Many distance measures commonly used in data science are at least symmetric
premetrics, and similarity measures can often be constructed from those. This
observation gives rise to the following conditions, all or some of which can be
reasonably imposed on similarity measures:
(1) σ(u,u)=σ(v,v)
(2) σ(u,v)<σ(v,v)⇐u̸=v
symmetry: σ(u,v)=σ(v,u)
for all u,v ∈ Ω. In particular, if δ(·, ·) is some metric, then all of the above
properties are satisfied by the following similarity measure:
σ(u,v):=a2·e−1
2
(δ(u
h
,v))q
with real numbers a,h,q >0; q =1 or q =2 are common choices.
In some cases, the following multiplicative triangle inequality is also a desirable
property:
σ(u,w)≥σ(u,v)·σ(v,w)
Let x ,...,x be a sequence of observations that take values in some
1 N
domain Ω with distance measure δ(·, ·). We can define the distance
matrix as follows:
 
δ(x ,x ) δ(x ,x ) ··· δ(x ,x )
1 1 1 2 1 N
δ(x
2
,x
1
) δ(x
2
,x
2
) ··· δ(x
2
,x
N
)
∆(x)= . . . 
 . . . . . . 
 
δ(x ,x )δ(x ,x )··· δ(x ,x )
N 1 N 2 N N
For a similarity measure σ(·, ·), the similarity matrix Σ(x) is defined
analogously.
The distance/similarity matrix consists of all pairwise distances/similarities
between observations. Given N observations, it is a square matrix of format
N ×N. If the distance measure is a symmetric premetric, the distance matrix
is symmetric and has vanishing diagonal entries.
Letuscalculateareal-lifeexampleandconsiderthepairwisegeographicdistances
(measuredinkilometers)oftheGermancitiesBerlin,Hamburg,Munich,Cologne,
and Frankfurt. These can be summarized in a distance matrix as follows:
 
0 282508534459
282 0 615377396
∆((Berlin,Hamburg,Munich,Cologne,Frankfurt))=  508615 0 470312  
 
534377470 0 163
459396312163 0


================================================================================
PAGE 186
================================================================================

170 Multivariate statistics
As another example, let us consider the standardized data matrix of height and
weight from Sect. 5.1, which is composed of four data points:
(cid:18) (cid:19) (cid:18) (cid:19) (cid:18) (cid:19) (cid:18) (cid:19)
−0.05 0.17 −1.27 1.16
z = , z = , z = , z =
1 −1.00 2 1.00 3 −0.69 4 0.69
The Euclidean distance matrix is given as follows:
 
0 2.011.262.08
2.01 0 2.221.04
∆(z)= 
1.262.22 0 2.79
2.081.042.79 0
Finally, we can use similarity measures to characterize, for example, cooking
recipes by ingredients. Each ingredient defines a binary variable: for each dish,
the ingredient is either needed or not needed. Examples:
U =spaghetti aglio e olio={chili, garlic, olive oil, spaghetti},
1
U =curry={broccoli, chili, coconut milk, curry powder, garlic, tofu},
2
U =spaghetti al pomodoro={basil, olive oil, onions, spaghetti, tomatoes},
3
U =ratatouille={aubergines, basil, bell pepper, garlic, olive oil,
4
onions, rosemary, tomatoes, zucchini}
The pairwise computation of the Jaccard similarity and overlap coefficient for
these sets of ingredients leads to the following similarity matrices:
 
1 0.250.290.18
0.25 1 0 0.07
Σ Jacc (U)= 0.29 0 1 0.40   ,
0.180.070.40 1
 
1 0.5 0.5 0.5
0.5 1 0 0.17
Σ overlap (U)= 0.5 0 1 0.8  
0.50.170.8 1
5.3 Multivariate measures of central tendency and
variation
Suppose that we are given a sequence of univariate observations x ,...,x ∈R.
1 N
We want to find the location uˆ∈R on the number line that minimizes the sum
of squared distances to those observations. That is, uˆ is the minimum point of
the following function:
N
X
ℓ : R→[0,∞[, ℓ (u)= (u−x )2
2 2 n
n=1


================================================================================
PAGE 187
================================================================================

5.3. Multivariate measures of central tendency and variation 171
The derivative of this function is given as follows:
N N
d X X
ℓ (u)= 2(u−x )=2N ·u−2 x
du 2 n n
n=1 n=1
The second derivative is positive, so the uniquely determined minimum point
is at the zero of the derivative: uˆ= 1 PN x . We recognize this number to
N n=1 n
be the arithmetic mean of the observations. Similarly, it can be shown that
the sample median is a minimum point of the sum of the distances without
squaring them, i.e., a minimum point of the following function:
N
X
ℓ : R→[0,∞[, ℓ (u)= |u−x |
1 1 n
n=1
Themeanandthemediancanbegeneralizedtomultivariatemeasuresofcentral
tendency by applying the above idea to more general distance measures, such
as the Euclidean distance instead of the distance along the number line.
We also want to describe how multidimensional data points disperse, in which
case it is important to note that this dispersion may vary when computed along
different directions in feature space.
5.3.1 Centroid and geometric median, medoid
The centroid is the multivariate analogue of the arithmetic mean.
Given a sequence of data points/feature vectors x ,...,x with x ∈RD
1 N n
for all n∈{1,...,N}, the sample mean vector, or centroid, is defined
as follows:
N
1 X
x¯ = x
centroid N n
n=1
It is not difficult to show that the centroid is characterized by minimizing the
sum of squared Euclidean distances to the data points; i.e., it is the uniquely
determined minimum point of the following function:
N
X
ℓ : RD →[0,∞[, ℓ (u)= ∥u−x ∥2
2 2 n
n=1
Furthermore, the centroid can be characterized as the column-wise arithmetic
mean of the data matrix:
 
X
•1
X •2
x¯ = . 
centroid  . . 
 
X
•D


================================================================================
PAGE 188
================================================================================

172 Multivariate statistics
In other words, the centroid is the vector composed of the arithmetic means of
the individual univariate variables. In particular, we see that mean-centering is
equivalent to the operation of subtracting the centroid from each data point.
Therefore, the centroid of a set of mean-centered data points is always the
coordinate origin.
We may use the alternative notations µ(x), x¯ for the centroid, which coincide
with the arithmetic mean.
Given a sequence of data points x ,...,x with x ∈ RD for all n ∈
1 N n
{1,...,N}, a geometric median is any point x¯ ∈ RD that is a
median
minimum point of the following function:
N
X
ℓ : RD →[0,∞[, ℓ (u)= ∥u−x ∥
1 1 n
n=1
Thus,ageometricmedianminimizesthesumofthedistancestothedatapoints
in the sample. If the data points x ,...,x do not happen to all lie on a single
1 N
line, their geometric median is uniquely determined.
In contrast to the centroid, there is no closed formula for the calculation of
the geometric median. In particular, the geometric median is not given by
the sample median vector, i.e., the vector comprised of the univariate medians
for each variable. The geometric median can be calculated numerically using
Weiszfeld’s algorithm [2, 3]. This algorithm applies the following iteration:
N
!−1
N
y = X 1 · X x n
k+1 ∥x −y ∥ ∥x −y ∥
n k n k
n=1 n=1
with a suitable starting value y , for example y = x¯ . If the geometric
0 0 centroid
median is unique, and if one of the intermediate results y does not happen to
k
lie exactly on one of the data points x , then the sequence y ,y ,... converges
n 0 1
to x¯ .
median
Example.Fig.5.2showsthescatterplotofthewidthandlengthofthepetal
leaf of iris flower plants, along with the geometric median and the centroid of
the data points.
The geometric median and the centroid minimize the sum of the Euclidean
distancesandsquaredEuclideandistancestothedatapoints x ,...,x ,respec-
1 N
tively. We can generalize this idea to metrics δ(·, ·) defined on some space Ω:
thegeneralized geometric medianandtheFréchet meanaretheminimum
points of the function
N
X
ℓ : Ω →[0,∞[, ℓ(u)= (δ(u,x ))α
α n
n=1


================================================================================
PAGE 189
================================================================================

5.3. Multivariate measures of central tendency and variation 173
with α=1 or α=2, respectively [4, 5].
Computing these minima is in general a hard task. The following measure of
central tendency is more relevant in practice, as it is easier to calculate.
Let x ,...,x be data points that can be compared by some symmetric
1 N
premetric δ(·, ·). A medoid is a data point x¯ ∈{x ,...,x } that
medoid 1 N
minimizes the sum of the distances to the other data points. Thus, it is a
minimum point of the following function:
N
X
f: {x ,...,x }→[0,∞[, f(u)= δ(u,x )
1 N n
n=1
Unlike the geometric median, the medoid is selected from the set of observed
data points.
Giventhedistancematrix∆,amedoidx correspondstoanindexi∈{1,...,N}
i
with minimum row or column sum:
N N
X X
∆ = ∆ = ∆ =∆
•i ni in i•
n=1 n=1
5.3.2 Sample covariance and correlation matrix
We can calculate pairwise measures of association between a collection of
statistical variables and write them into a matrix.
Let x ,...,x ∈ RD be data points and X be the corresponding data
1 N
matrix. The sample covariance matrix is given by the pairwise sample
covariances of its columns:
 
s(X ,X ) s(X ,X ) ··· s(X ,X )
•1 •1 •1 •2 •1 •D
s(X
•2
,X
•1
) s(X
•2
,X
•2
) ··· s(X
•2
,X
•D
)
S(x)= . . . 
 . . . . . . 
 
s(X ,X )s(X ,X )··· s(X ,X )
•D •1 •D •2 •D •D
Similarly, the sample correlation matrix R(x) is the matrix of Bravais–
Pearson correlation coefficients.
The covariance matrix and the correlation matrix are both symmetric matrices.
If the data matrix X is mean-centered, the covariance matrix can be expressed
succinctly as a matrix product:
1
S(x)= XT ·X,
N
or S (x)= 1 XT ·X if a Bessel-corrected estimation is to be used. If the
cor N−1
data matrix has been standardized, then the covariance matrix and correlation
matrix are identical.


================================================================================
PAGE 190
================================================================================

174 Multivariate statistics
Example. We refer once more to the Iris flower dataset and analyze the
length and width of the petal leaves. First, we standardize the data—the
resulting z-scores have unit variance. The covariance/correlation matrix of
those data computes to the following:
(cid:18) (cid:19)
1 0.96
R(x)=
0.96 1
Length and width are thus strongly correlated; the bottom chart in Fig. 5.2
shows the scatter plot of z-scores. The figure also shows the covariance
error ellipse. This ellipse is centered around the centroid of the data points
and its semi-axes point in the directions of the smallest and largest variances,
respectively. The lengths of the semi-axes scale with the respective standard
deviation. The directions of the semi-axes are given by the eigenvectors of
the covariance matrix: further details can be found in Sect. 7.2.1 on principal
component analysis.
5.4 Random vectors and matrices
Now that we have generalized the basic notions from descriptive statistics to
the multivariate case, let us do the same for probability theory and inferential
statistics.
Just as we can think of univariate observations as realizations of a random
variable, data points/feature vectors can be thought of as realizations of a
random vector. Most conveniently, we may view a random vector X as a
(column) vector, the entries of which are random variables, that is:
 
X
1
.
X = . . 
 
X
D
where X ,...,X are random variables.
1 D
Similarly, random matrices are matrices, the entries of which are given by
random variables.
5.4.1 Expectation vector and covariance matrix
Wecangeneralizethenotionofexpectedvaluesforrandomvectorsbycomputing
the expectation of each of the components and then writing those as a vector
again.
In a similar fashion, we can compute the covariances of the random vector’s
components and then summarize them as a matrix.


================================================================================
PAGE 191
================================================================================

5.4. Random vectors and matrices 175
Let X =(X ,...,X )T be a random vector. The expectation vector
1 D
or mean vector of X is given as follows:
 
E[X ]
1
.
E[X]= . . 
 
E[X ]
D
The covariance matrix is the symmetric matrix of pairwise covariances:
 
σ[X ,X ] σ[X ,X ] ··· σ[X ,X ]
1 1 1 2 1 D
σ[X
2
,X
1
] σ[X
2
,X
2
] ··· σ[X
2
,X
D
]
Σ[X]= . . 
 . . . . 
 
σ[X ,X ]σ[X ,X ]··· σ[X ,X ]
D 1 D 2 D D
We may omit the word “vector” and simply talk about the expectation, mean,
or expected value of a random vector. The expected value of a random matrix
is defined analogously.
The linearity of the univariate expected value carries over:
E[A·X+B·Y +C]=A·E[X]+B·E[Y]+C
whereX,Y arearbitraryrandomvectorswithDentries,whileA,B arematrices
of format K×D, and C is a column vector of length K.
We recall that the following relationship exists between the covariance and
variance: σ[X ,X ]=σ2[X ]. Therefore, the diagonal of the covariance matrix
i i i
contains the variances of the components of the random vector.
Thecovariancematrixcanalsobewrittenmoresuccinctlyastheexpectedvalue
of a random matrix. Remember that we write X as a column vector:
Σ[X]=E[(X−E[X])·(X−E[X])T]
Asquarematrix Aofformat D×D ispositive semidefinite ifitdoesnotreverse
the direction of vectors. Accordingly, for all vectors v ∈ RD with v ̸= 0 and
scalars λ∈R, the following holds:
A·v =λv ⇒λ≥0
In other words, the matrix has no negative eigenvalues (see also Sect. B.2.4 in
theappendix).Anotherequivalentcharacterizationisthefollowing[6,Sect.1.6]:
⟨v,A·v⟩≥0
for all v ∈RD.
The covariance matrix is always positive semidefinite. This is not difficult to
show, setting Y =X−E[X]:


================================================================================
PAGE 192
================================================================================

176 Multivariate statistics
⟨v,Σ[X]·v⟩=vT ·Σ[X]·v =vT ·E[Y ·YT]·v
=E[vT ·Y ·YT ·v]=E[(vT ·Y)2]≥0
where we used the linearity and monotonicity of the expected value.
5.4.2 Multivariate normal distributions
The probability density function of a random vector X =(X ,...,X )T,
1 D
thecomponentsofwhicharecontinuousrandomvariables,isthejointprobability
density function of these components:
p : RD →[0,∞[, p (u)=p (u ,...,u )
X X X1,...,XD 1 D
One of the most important families of multivariate density functions is given by
the generalization of the univariate normal distribution.
TheD-dimensional normal distribution isthefollowing(multivariate)
probability density function:
N(u|µ,Σ)=N(u ,...,u |µ,Σ)
1 D
1
= p ·e−1 2 (u−µ)T·Σ−1·(u−µ)
(2π)D·det(Σ)
whereµ∈RD,andΣ isasquarematrixofformatD×Dthatissymmetric
and positive definite.
The expectation and covariance matrix of a normally distributed random vector
X ∼N(·|µ,Σ) are given by E[X]=µ and Σ[X]=Σ, respectively.
2
1
0
-1
-2
-2 -1 0 1 2
x
1
x 2
density
(0.00, 0.02]
(0.02, 0.04]
(0.04, 0.06]
(0.06, 0.08]
(0.08, 0.10]
(0.10, 0.12]
(0.12, 0.14]
(0.14, 0.16]
(0.16, 0.18]
(0.18, 0.20]
Fig. 5.1. Probability density function of a bivariate normal distribution


================================================================================
PAGE 193
================================================================================

5.4. Random vectors and matrices 177
The figure above shows the density of a bivariate normal distribution with a
mean vector and covariance matrix given by:
(cid:18)
0
(cid:19) (cid:18)
1
1(cid:19)
µ= , Σ = 2 .
0 1 1
2
The squared Euclidean norm of a D-dimensional normally distributed random
vector X centered at the origin, the covariance matrix of which is given by the
identity matrix Σ =diag(1,...,1), follows a chi-squared distribution with D
degrees of freedom (see Sect. 3.5.1):
∥X∥2 ∼χ2
D
The following theorems can be shown by way of cumbersome calculations, see
for example [7, Chap. VIII, Sect. 9]. In what follows, let X =(X ,...,X )T
1 D
be a normally distributed random vector: X ∼N(·|µ,Σ).
Linear transformations of a normally distributed random vector.
LetAbeamatrixofformat K×D,K ≤D,ofrankK.Then,therandom
vector Y := A · X is also normally distributed, with mean A · µ and
covariance A·Σ·AT:
Y ∼N(·|A·µ,A·Σ·AT)
As a special case of the above theorem, we can derive the formula for a linear
combination Y = PN a X of independent univariate normally distributed
n=1 n n
random variables X ,...,X with expected values µ ,...,µ and variances
1 N 1 N
σ2,...,σ2 . Plugging in the values
1 N
Σ =diag(σ2,...,σ2 ) and A=(a ,...,a ),
1 N 1 N
we then get this formula:
N N
X X
Y ∼N(·|µ ,σ2) with µ = a µ and σ2 = (a σ )2
Y Y Y n n Y n n
n=1 n=1
We now want to provide formulas for computing the marginal densities. For
this purpose, we imagine X divided into two random vectors of lengths K and
D−K, respectively, where 1≤K <D:
   
X X
1 K+1
. .
X(0) = . .  and X(1) = . . 
   
X X
K D
We divide the mean vector the same way:
   
µ µ
1 K+1
. .
µ(0) = . .  and µ(1) = . . 
   
µ µ
K D


================================================================================
PAGE 194
================================================================================

178 Multivariate statistics
Finally, we write the covariance matrix into the following block form:
(cid:18) Σ(00) Σ(01)(cid:19)
Σ =
Σ(10) Σ(11)
Deleting the last D−K columns and rows from Σ yields the K ×K-matrix
Σ(00), and deleting the first K columns and rows yields Σ(11), etc.
Marginal distributions of a normally distributed random vector.
The random vector X(0) is also normally distributed:
X(0) ∼N(·|µ(0),Σ(00))
For reasons of symmetry, this theorem can be applied to X(1) or to any other
selection of components. In particular, each individual component X , d ∈
d
{1,...,D} of a normally distributed random vector follows a one-dimensional
normal distribution with mean µ and variance Σ .
d dd
Conditionaldistributionsofcomponentsofanormallydistributed
random vector. Let x(0) ∈ RK. The conditional distribution of X(1)
under the condition X(0) =x(0) is a normal distribution:
(cid:16) (cid:12) (cid:17) (cid:16) (cid:12) (cid:17)
p ·(cid:12)x(0) =N ·(cid:12)µ(1|0),Σ(1|0)
X(1)|X(0) (cid:12) (cid:12)
with
(cid:16) (cid:17)−1 (cid:16) (cid:17)
µ(1|0) =µ(1)+Σ(10)· Σ(00) · x(0)−µ(0) ,
(cid:16) (cid:17)−1
Σ(1|0) =Σ(11)−Σ(10)· Σ(00) ·Σ(01)
As an example, let us consider a normally distributed random vector X =
(X ,X )T with the following mean vector and covariance matrix:
1 2
(cid:18)
0
(cid:19) (cid:18)
1
1(cid:19)
µ= , Σ = 2 .
0 1 1
2
The marginal densities are standard normal distributions: X ,X ∼N(·|0,1).
1 2
The distribution of X under the condition X =−1 is a normal distribution
2 1
with mean µ =−1 and variance σ2 = 3.
2|1 2 2|1 4
We can interpret this result as follows. The random variables X and X are
1 2
positively correlated: σ[X ,X ]=Σ = 1. Upon learning that X =−1, we
1 2 12 2 1
also know more about X . Since there is a positive correlation, we no longer
2
expect the value to be close to the prior mean µ = 0, as we will find that
2
the value is more likely to be found near µ =−1. After including this new
2|1 2
information of what we know about the value of X , we are less uncertain of it:
2
σ ≈0.87<1=σ .
2|1 2


================================================================================
PAGE 195
================================================================================

5.4. Random vectors and matrices 179
5.4.3 Multinomial distributions
The multivariate probability mass function of a random vector X =
(X ,...,X )T, the components of which are all discrete random variables,
1 D
is given by the joint probability mass function of these components:
p : supp(X )×···×supp(X )→[0,∞[, p (u)=p (u ,...,u )
X 1 D X X1,...,XD 1 D
The following distribution can be considered a multivariate generalization of
the binomial distribution (Sect. 4.1.1).
The multinomial distribution is given by the following (multivariate)
probability mass function:
M(·|p,N): N→[0,1],
M(k|p,N)=M(k ,...,k |p ,...,p ,N)
1 D 1 D
( N! · QD pkd if PD k =N
= QD d=1 kd! d=1 d d=1 d
0 otherwise
where p ,...,p ∈[0,1] with PD p =1, and N ∈N.
1 D d=1 d
Theexpectationvectorandthecovariancematrixofamultinomiallydistributed
random vector X ∼M(·|p,N) are given as follows:
E[X]=N ·p, Σ[X]=N ·(Σ −p·pT)
p
wherep=(p ,...,p )T,andΣ =diag(p ,...,p )isthematrixwithdiagonal
1 D p 1 D
entries p ,...,p and otherwise vanishing entries.
1 D


================================================================================
PAGE 196
================================================================================

180 Multivariate statistics
2.5
2.0
geometric median
1.5
1.0
centroid
0.5
0.0
2.0 4.0 6.0
petal length in cm
mc
ni
htdiw
latep
1.00
0.00
-1.00
-1.00 0.00 1.00
petal length, z-score
erocs-z
,htdiw
latep
Fig. 5.2. Centroid and geometric median (top); covariance error ellipse (bottom)


================================================================================
PAGE 197
================================================================================

References 181
References
[1] Ronald Aylmer Fisher. “The use of multiple measurements in taxonomic
problems”. In: Annals of Eugenics 7.2 (Sept. 1936), pp. 179–188. doi:
10.1111/j.1469-1809.1936.tb02137.x.
[2] Endre Weiszfeld. “Sur le point pour lequel la somme des distances de n
points donnés est minimum”. In: Tohoku Mathematical Journal 43 (1937),
pp. 355–386.
[3] Amir Beck and Shoham Sabach. “Weiszfeld’s Method: Old and New
Results”.In: Journal of Optimization Theory and Applications 164.1(May
2014), pp. 1–40. doi: 10.1007/s10957-014-0586-7.
[4] MauriceRenéFréchet.“Lesélémentsaléatoiresdenaturequelconquedans
un espace distancié”. In: Annales de l’Institut Henri Poincaré 10.4 (1948),
pp. 215–310.
[5] Miroslav Bacák. “Computing Medians and Means in Hadamard Spaces”.
In: SIAM J. Optim. 24 (2014), pp. 1542–1566. arXiv:1210.2145.
[6] JanR.Magnus.MatrixDifferentialCalculuswithApplicationsinStatistics
and Econometrics. 3rd ed. Wiley, Feb. 2019. doi: 10.1002/9781119541219.
[7] Richard von Mises. Mathematical Theory of Probability and Statistics.
Ed. by Hilda Geiringer. 1st ed. Academic Press, 1964.


================================================================================
PAGE 198
================================================================================

Part III
Machine learning


================================================================================
PAGE 199
================================================================================

6
Supervised machine learning
According to the International Organization for Standardization (ISO), an
algorithm [1] is a “finite ordered set of well-defined rules for the solution of a
problem.”
For example, an algorithm can sort a list of arbitrary strings—such as a list of
words or names—in alphabetical order. If such an algorithm was presented with
the tuple (David, Robert, Anna, Carl), the correct output would be the tuple
(Anna, Carl, David, Robert). A simple algorithm for sorting lists is bubble
sort. Bubble sort steps through the input list and puts adjacent entries into
the correct order. This process is repeated until no more swaps are necessary
and the list has become fully sorted:
N := length of the input tuple x
swapped := true
while swapped = true do
swapped := false
for i = 1 to N −1 do
if x >x then
i i+1
swap x with x
i i+1
swapped := true
end
end
end
Output: x
Here, x >x stands for “x comes after x in alphabetical order.”
i i+1 i i+1
Algorithms are powerful tools because they can produce correct results for any
given input. The bubble sort algorithm defines instructions according to a set of
rulesexplicitlyspecifiedbytheprogrammer.Anymoderncomputercanexecute
these instructions in a very short amount of time.
However, a purely rule-based approach is not always practical or even feasible.
For example, it would be very difficult to define explicit rules that were to
© Springer-Verlag GmbH Germany, part of Springer Nature 2023 185
M. Plaue, Data Science, https://doi.org/10.1007/978-3-662-67882-4_6


================================================================================
PAGE 200
================================================================================

186 Supervised machine learning
instructanalgorithmtoperformthefollowingimageclassificationtask:“arrange
photos into categories depending on whether the photo shows a landscape, a
portrait,orsomethingotherthanalandscapeoraportrait.” Machinelearning
provides a set of tools that are able to solve such problems.
In this chapter, we will deal with supervised machine learning. Supervised
methods are based on the statistical evaluation of a sample where each observa-
tion comes with an already known assignment of a label that the algorithm is
ultimately supposed to predict for yet unseen data. That sample is called the
training dataset. Keeping with the image classification example, a training
datasetwouldconsistofa(large)numberofphotographs,eachofwhichhasbeen
(manually) annotated with one of the labels: landscape, portrait, etc. Ideally,
the learning algorithm is then able to recognize patterns that characterize and
distinguish between landscape and portrait photographs. More concretely, these
patterns are statistical variations of features. For digital photographs, the
raw features are given by the color values of each pixel. From these statistical
patterns, rules are generated that are able to categorize new, yet to be seen
photos that were not contained in the training dataset. These rules are not
explicitly specified by the programmer but are “learned” by the machine on the
basis of the training dataset.
Some typical characteristics of machine learning tasks and problems are the
following:
• How to extract useful features is not always obvious; typically, some form
of feature engineering is required. For example, unstructured text data
cannot be used in their raw form but must be represented numerically in
order to make them accessible to computational and statistical analysis.
• Datasets are often high-dimensional, i.e., there are a great number of
features that need to be processed. For example, digital photographs with a
typicalresolutionof1280×720pixelsandthreecolorchannelsarerepresented
byD =1280·720·3=2.764.800colorvaluesperimage.Therefore,itmaybe
useful or even necessary to apply feature selection and other procedures
to reduce the dimensionality of the data.
• It is not uncommon for datasets used for machine learning tasks to also
consist of a large number of records. ImageNet, for example, is a publicly
availabledatasetthatconsistsofmorethan14milliondigitalimagesassigned
toatotalof1000differentcategories[2].JFT-300Misanexampleofadataset
used for machine learning that consists of 300 million images [3]. Datasets
in natural language processing may consist of millions of sentences or
paragraphs as well. Machine learning engineering—applying machine
learning algorithms to massive datasets at scale—is an important topic that
we will, however, not address in this book (see, for example, [4] instead).
• Machine learning is primarily used for the prediction of features associated
withinstancesthathaveyettobeseenbythealgorithm,instancesthatwere
not included in the training dataset. The classification algorithm should be


================================================================================
PAGE 201
================================================================================

6.1. Elements of supervised learning 187
able to recognize a large variety of landscapes, portraits, etc., given any
new input image. Consequently, the purpose of such an algorithm is not
necessarily or primarily to produce a statistical model that describes the
training dataset well: it should adapt and generalize well to new situations.
• For some tasks that humans master quite effortlessly, computers have only
been able to perform through machine learning. These tasks include, for
example: image recognition—especially face recognition—speech recogni-
tion, natural language translation [5], or playing the Japanese board game
Go above amateur level [6]. Consequently, machine learning provides an
important set of tools in the field of artificial intelligence (AI).
6.1 Elements of supervised learning
An important task of intelligent computer systems is to predict the value of a
statistical variable. If this prediction is made from patterns and correlations
previously observed in a so-called training dataset, then it is referred to as
supervised learning.
Classification algorithms are used to predict the values of a categorical
variable. If the target variable is a numeric variable, we speak of a regres-
sion algorithm1. For example, predicting stock prices based on historical
trends would fall into the realm of regression. The automatic assignment of
digital photographs to categories (e.g., landscapes, portraits, etc.) belongs to
the field of classification. Another example of a classification algorithm is an
automated email filter that assigns each email to one of the categories spam or
not spam/ham.
Formally,thesituationcanbedescribedasfollows.Wearegivenafeaturespace
X that represents the range of values for the explanatory variables that the
prediction is based on. For example, X =RD, so D numeric features would be
used for prediction. These could be, for example, the color values of a digital
photograph.
The target variable, the values of which we want to predict, has some
range Y. For regression algorithms, Y = R. For classification algorithms,
Y consists of a finite number of categories, classes, or labels: for example,
Y ={landscape,portrait,other}. We can always assume Y ⊂N by appropriate
numbering of the categories.
Binary classification, Y = {0,1}, is especially useful for illustration and vi-
sualization. Moreover, binary classification can be used to solve multi-label
classificationtasks,i.e.,whenaninstancecanbeassignedmultipleofK nonex-
clusive labels l ,...,l . A multi-label classification task can be transformed
1 K
1 Instatisticallearningtheory, both classificationandregressionalgorithmsarebased
on the idea of regression analysis. Consequently, the terminology may appear
somewhat inconsistent.


================================================================================
PAGE 202
================================================================================

188 Supervised machine learning
into a series of binary classification tasks, each aimed at making a prediction of
the form “does belong to class l ” versus “does not belong to class l .”
k k
In Sections 6.2 and 6.3, we present a number of regression and classification
procedures.Theresultofsuchaprocedureisamap fˆ: X →Y learnedfromthe
training data that is called a decision rule, or hypothesis. Such a decision
rule assigns, for example, a photo to an image category based on the color
values of the pixels.
In classification, decision rules are also called classification rules, or classifiers.
Decision rules in regression come in the form of regression functions. Any
classifier or regression function is selected from some hypothesis space F ⊂
{f: X →Y}. In many cases, the hypothesis space is a parameterized family of
functions:
F ={f(·;θ): X →Y|θ ∈P}
where P is the space of model parameters to be determined during training,
typicallyP ⊆RK.Theoptimalhypothesis2 isselectedbyestimatingtheoptimal
model parameters θˆ∈P from the training dataset.
Often,weconsidernotjustasinglehypothesisspacebutafamilyofsuchspaces
where a member is identified by a set of hyperparameters.
Formally, we can summarize this concept as follows:
Let X be the feature space and Y the range of possible predictions. Fur-
thermore, let S =(X ×Y)N denote all possible training datasets of size
N
N.
A family of methods of supervised learning parameterized by hyper-
parameters α∈H consists, firstly, of a family of hypothesis spaces:
F ={f (·;θ): X →Y|θ ∈P }
α α α α∈H
Secondly,itisdefinedbyaprocedurethatselectsasetofmodelparameters
given a training dataset (of arbitrary size N):
θˆ : S →P
α N α
A supervised algorithm processes a training dataset (x,y) ∼ = ((x ,y ), ...,
1 1
(x ,y )) with the goal of learning a decision rule:
N N
fˆ(·)=f (·;θˆ (x,y))
α α
Given yet unseen data x , this decision rule can be used to make a prediction
∗
yˆ =fˆ(x ).
∗ ∗
2 We skip a few mathematical details. For example, decision rules f: X →Y should
at least be measurable maps so that, for example, expected values like E[f(X)] are
well-defined, given a random variable X: Ω →X.


================================================================================
PAGE 203
================================================================================

6.1. Elements of supervised learning 189
The hyperparameters α are determined from a priori assumptions, or alterna-
tively they may be calculated through a validation procedure—a concept we
discuss in more detail in Sect. 6.1.3.
A binary classification rule f: X →{0,1} is equivalent to dividing the feature
space into two disjoint regions:
X =f−1({0})∪f−1({1}) with f−1({0})∩f−1({1})=∅
Thesetworegionsareseparatedbya decision boundary.Insomesense,along
this boundary, the classifier is actually “undecided.” The linear classifiers are
an important family of decision rules with domain X =RD. Linear classifiers
are characterized by their decision boundary being an (affine) hyperplane:
( ( 1 if PD w u <w (cid:12) (cid:12) )
F = f(u;w)= d=1 d d 0 (cid:12)w =(w ,...,w )∈RD+1
0 otherwise (cid:12) (cid:12) 0 D
The logistic regression described in Sect. 6.3.1 is an example of a procedure
that learns a linear classifier.
Let us illustrate how a procedure that we already know fits into the above
characterization. Simple linear regression (Sect. 4.5.1) can be interpreted as a
regression algorithm with X =R and Y =R. The hypothesis space is given by
the space of regression lines:
F ={f: R→R, f(u;m,c)=mu+c|m,c∈R}
1
The space of model parameters consists of all possible values for the slope and
the intercept of the regression line: P ={(m,c)|m,c∈R}=R2. There are no
hyperparameters.
The training consists of computing the minimum point of the residual sum
of squares. Given a training dataset (x,y)∼ =((x ,y ),...,(x ,y )), we recall
1 1 N N
that this minimum point is given as follows:
(cid:18) (cid:19)
s(x,y) s(x,y)
θˆ(x,y)= ,y¯− ·x¯ =(mˆ,cˆ)
s2(x) s2(x)
Thedecisionrulefˆ: R→Rthuslearnedisthefunctionfˆ(x )=mˆx +cˆ,which
∗ ∗
makes a prediction for any x ∈R.
∗
In Sect. 6.2.1, we will see how we can fit polynomials of higher degree to a
sample of data points, and contrary to the previous methods shown it will not
just be a straight line. For each degree of a polynomial K, which we interpret
as a hyperparameter, we can associate the following hypothesis space:
( X K (cid:12) (cid:12) )
F = f (u;w)= w uk(cid:12)w =(w ,...,w )∈RK+1
K K k (cid:12) 0 K
(cid:12)
k=0 K∈N


================================================================================
PAGE 204
================================================================================

190 Supervised machine learning
6.1.1 Loss functions and empirical risk minimization
We can numerically evaluate the goodness of a prediction by introducing a loss
function:
λ: Y ×Y →[0,∞[, (y,yˆ)7→λ(y,yˆ)
The loss function measures the cost or damage caused by predicting yˆ when
the true value of the target variable is in fact y.
A popular loss function for regression algorithms is the quadratic loss, or L
2
loss:
λ (y,yˆ)=(y−yˆ)2
2
for all y,yˆ∈R. Another possible choice is the L loss: λ (y,yˆ)=|y−yˆ|. More
1 1
generally, we may consider the family of L loss functions λ (y,yˆ)=|y−yˆ|p
p p
with p≥1.
For classification tasks, the zero–one loss function is a particularly simple
choice. When using a zero–one loss, if the predicted category is correct, the loss
is given by λ=0. If the prediction is incorrect, the loss is given by λ=1. In
general, the loss function for a classification task can be described by a cost
matrix, which tabulates the loss for each possible combination of true and
predicted values.
The cost matrix for identifying spam emails might look like this (a,b∈R with
a,b>0):
prediction
no spam spam
true class
no spam 0 a
spam b 0
Table 6.1. Cost matrix of a spam filter
If the message is classified correctly, the loss is always zero. If the message is
incorrectly classified as spam, the cost incurred by the misclassification is given
by λ(not spam,spam)=a. If the spam filter lets an unwanted message through,
the cost incurred is λ(spam,no spam)=b.
Thus, if the user of the email software were to consider it a greater harm for a
relevantmessagetoaccidentallyendupinthespamfolderthanforanunwanted
message to remain in the inbox, then a>b should be chosen when designing
the algorithm.
The empirical risk or training error of a decision rule f: X →Y with
respect to a training dataset ((x ,y ), ..., (x ,y )) ∈ (X ×Y)N and
1 1 N N
a loss function λ: Y ×Y → [0,∞[ is given by the average loss over the
training examples:


================================================================================
PAGE 205
================================================================================

6.1. Elements of supervised learning 191
N
Rˆ[f]= 1 X λ(y ,f(x ))
N n n
n=1
If the decision rule is selected from a hypothesis space F = {f (·;θ)},
α α
the training error can be interpreted as a function R (·) in the model
α
parameters:
N
R (θ)=Rˆ[f (·;θ)]= 1 X λ(y ,f (x ;θ))
α α N n α n
n=1
The empirical risk minimization (ERM) paradigm is a simple and popular
approach to supervised machine leaning:
• Choose a hypothesis space and hyperparameters, i.e., a set of classifiers/re-
gression functions to select from,
• choose a loss function that evaluates goodness of fit,
• given the training dataset, minimize the training error to determine the
optimal classifier/regression function.
For example, simple linear regression corresponds to minimizing the following
empirical risk with respect to the quadratic loss function, with m,c∈R:
N
1 X
R(m,c)= (y −mx −c)2
N n n
n=1
If we ignore the constant factor 1/N , then this formula is just the residual sum
of squares.
However, minimizing empirical risk alone is not sufficient to ensure the gen-
eralizability of the learned decision rule: the quality of predictions for new
data may be severely limited even if the classifier or regression function is very
well adapted to the training data. This fact can be illustrated by the following
extreme example. Given a training dataset ((x ,y ), ..., (x ,y ))∈(R×R)N,
1 1 N N
we define the following decision rule:
(
y if x =x for some i∈{1,...,N}
fˆ(x )= i ∗ i
∗ 1042 otherwise
Here, we assume that the x are pairwise distinct, or they at least uniquely
i
determine the corresponding y . In other words, the procedure looks up the
i
input in the training dataset and then assigns the corresponding response. If
it can’t find the input, the prediction is just the arbitrary value yˆ=1042. For
any reasonable loss function, e.g., the quadratic loss function, the empirical risk
vanishes for this procedure: the decision rule is always an optimal fit to the
training data—all pairs of values are reproduced perfectly. Nevertheless, the


================================================================================
PAGE 206
================================================================================

192 Supervised machine learning
algorithm is no better than random guessing, since for almost all input values
the prediction can produce an arbitrarily high loss.
The example shows that minimizing the empirical risk/training error Rˆ[f]
does not imply minimization of the true expected risk R[f], also called the
test error or generalization error. At first glance, this may seem like a
contradiction, since for some fixed decision rule f: X → Y and all ε > 0 the
arithmetic mean is a consistent estimator after all:
(cid:16)(cid:12) (cid:12) (cid:17)
lim Pr (cid:12)Rˆ [f]−R[f](cid:12)<ε =1
(cid:12) N (cid:12)
N→∞
with
N
Rˆ [f]= 1 X λ(Y ,f(X )), R[f]=E[λ(Y ,f(X ))]
N N n n ∗ ∗
n=1
where X ,...,X ,X and Y ,...,Y ,Y are independent and identically dis-
1 N ∗ 1 N ∗
tributed random variables with range X and Y, respectively. However, when
applying a machine learning procedure, the decision rule is not fixed but varies
over the hypothesis space F, depending on the training data. In order to guar-
antee that the expected risk is always minimized, we would have to make sure
that uniform convergence holds, for all ε>0:
!
(cid:12) (cid:12)
lim Pr sup(cid:12)Rˆ [f]−R[f](cid:12)<ε =1
(cid:12) N (cid:12)
N→∞ f∈F
In that case, the empirical risk cannot arbitrarily deviate from the expected
risk. An essential task of the theory of statistical learning is to investigate in
which cases and to what extent such requirements on the generalizability of the
procedures can be guaranteed.
6.1.2 Overfitting and underfitting
The figure below shows polynomials of varying degree, fitted to the time series
of measurements of the global average temperature of the Earth [7]. The higher
the degree of the polynomial, the better it fits the sample/training data. In
other words, the empirical risk—the average squared deviation between the
regression curve and the data points—is minimized.
This observation points to a more general phenomenon: the more parameters a
model has (in this case, the coefficients of the polynomial), the more “wiggle
room” there is to fit it to the training data.
At first glance, it seems to make sense to use models that are as complex as
possible, because then the empirical risk is minimized. Within the interval
wherethereis sufficient trainingdata,the20thdegreepolynomial isthebestfit,
accounting also for small variations in temperature. However, we also clearly
see that this model is poorly suited for predictions. For instance, for the early
and late times that are beyond what was included in the training data, the


================================================================================
PAGE 207
================================================================================

6.1. Elements of supervised learning 193
regression curve drops off very quickly. The decision rule predicts a “sudden ice
age” for Earth’s past and future.
15.0
14.5
14.0
13.5
13.0
1850 1900 1950 2000 2050
year
C°
ni
erutarepmet
ria
labolg
regression polynomial
1st degree
2nd degree
20th degree
Fig. 6.1. Average global air temperature and regression polynomials of varying degree
In order to investigate in more detail the impact of model complexity on the
generalization error, we consider regression algorithms that operate under the
following assumptions:
• The target variable is distributed according to Y =f(x )+ε , where the
n n n
independent and identically distributed error terms ε have a vanishing
n
expected value and finite variance σ2 >0.
• The training dataset ((x ,y ),...,(x ,y )) and a point in the test dataset
1 1 N N
(x ,y ) are realizations of independent and identically distributed random
∗ ∗
variables (X ,...,X ,X ) and (Y ,...,Y ,Y ), respectively.
1 N ∗ 1 N ∗
• The loss function is the quadratic loss function λ(y,yˆ) = (y−yˆ)2 for all
y,yˆ∈R.
Let x ∈ X be a value of the predictor variable observed in the test dataset.
∗
Then, the test error (subject to the condition X =x ) is given as follows:
∗ ∗
h (cid:12) i (cid:20)(cid:16) (cid:17)2 (cid:21)
R fˆ (cid:12)X =x =E f(x )+ε −fˆ (x )
α(cid:12) ∗ ∗ ∗ ∗ α ∗
withtheprediction fˆ (x )=f (x ;θˆ ).Indoingso,weinterprettheprediction
α ∗ α ∗ α
as a statistical estimator, i.e., a function in the random variables that produce
the distribution of the training data:
θˆ =θˆ ((X ,Y ),...,(X ,Y ))
α α 1 1 N N
For clarity, we introduce short notation: fˆ= fˆ (x ), f = f(x ) and ε = ε .
α ∗ ∗ ∗
The disturbance ε with E[ε]=0 and E[ε2]=σ2 generates variations in the test


================================================================================
PAGE 208
================================================================================

194 Supervised machine learning
dataset that cannot be explained by any observation in the training dataset.
Since the estimator fˆwas learned using the training dataset, it is uncorrelated
with that disturbance. Given x , the quantity f is a deterministic constant.
∗
Therefore, we get the following formula:
h i h i h i
E ε·fˆ =E[ε·f]=0, E f ·fˆ =E[f]·E fˆ
The expected risk can therefore be transformed as follows:
E (cid:20)(cid:16) f −fˆ+ε (cid:17)2 (cid:21) =E (cid:20)(cid:16) f −fˆ (cid:17)2 (cid:21) +E h 2ε· (cid:16) f −fˆ (cid:17)i +E (cid:2) ε2(cid:3)
(cid:20)(cid:16) (cid:17)2 (cid:21)
=E f −fˆ +σ2
=E (cid:2) f2(cid:3) −2E h f ·fˆ i +E h fˆ2 i +σ2
= (cid:18)(cid:16) E h fˆ i(cid:17)2 −2E[f]·E h fˆ i +E (cid:2) f2(cid:3) (cid:19)
(cid:18) h i (cid:16) h i(cid:17)2 (cid:19)
+ E fˆ2 − E fˆ +σ2
(cid:16) h i(cid:17)2 (cid:20)(cid:16) (cid:17)2 (cid:21)
= E fˆ−f +E fˆ−E[fˆ] +σ2
Bias–variance decomposition. The expected risk of a regression algo-
rithm with quadratic loss can be decomposed as follows:
h (cid:12) i
R fˆ (cid:12)X =x
α(cid:12) ∗ ∗
(cid:16) h i(cid:17)2 (cid:20)(cid:16) h i(cid:17)2 (cid:21)
= E fˆ (x )−f(x ) +E fˆ (x )−E fˆ (x ) +σ2
α ∗ ∗ α ∗ α ∗
(cid:16) h (cid:12) i(cid:17)2 h (cid:12) i
= bias fˆ (cid:12)X =x +variance fˆ (cid:12)X =x +σ2
α(cid:12) ∗ ∗ α(cid:12) ∗ ∗
The generalization error is comprised of the following components:
• Due to the random fluctuations of the target quantity Y around the true
∗
value f(x ), a prediction with vanishing error based on observation of data
∗
is not possible: at least the irreducible error σ2 is to be expected.
• The bias E[fˆ (x )−f(x )] is the expected deviation of the estimate from
α ∗ ∗
the true value.
• The variance E[(fˆ (x )−E[fˆ (x )])2] indicates the variation that occurs
α ∗ α ∗
when the procedure is repeatedly applied to different training datasets, even
if those are drawn from the same distribution.
Model selection—i.e., the optimal choice of hyperparameters α—implies a
suitable bias–variance tradeoff such that the model minimizes the expected
risk. A complex model that can be fitted to training data, and therefore has low


================================================================================
PAGE 209
================================================================================

6.1. Elements of supervised learning 195
empiricalriskandbias,oftencomesatthepriceofahighvariance.Forinstance,
such a model may be too sensitive to random fluctuations in the training data.
Inthiscase,wesaythatthemodelisoverfitting(thedata).Ontheotherhand,
models that are too simple and exhibit a high bias are said to be underfitting.
The following decomposition of expected risk is independent of a specific loss
function and applies to classification methods as well.
Approximation and estimation error. The expected risk of a super-
vised machine learning procedure can be decomposed as follows:
(cid:18) (cid:19) (cid:18) (cid:19)
R[fˆ ]= inf {R[f]}−R[f ] + R[fˆ ]− inf {R[f]} +R[f ]
α Bayes α Bayes
f∈Fα f∈Fα
=approximation error+estimation error+Bayes error
Here, R[f ] is the minimum expected risk under all decision rules that
Bayes
are allowed in principle without restriction to the hypothesis space.
In more detail, the terms have the following meaning:
• The Bayes error is the irreducible error that corresponds to the minimum
expected risk, produced by an optimal decision rule f .
Bayes
• The approximation error inf{R[f]}−R[f ] is analogous to the bias
Bayes
and indicates the excess risk generated byselectingthe optimal decision rule
from a limited hypothesis space.
• The estimation error R[fˆ ]−inf{R[f]} results from estimating the model
α
parameters from a limited training dataset: Even if the algorithm minimizes
empiricalrisk,fˆ doesnotnecessarilyminimizeexpectedrisk.Itisanalogous
α
to the variance.
A classification model with a large estimation error is overfitting, and a model
with high approximation error is underfitting the data.
6.1.2.1 Regularization
One approach to avoid overfitting is the method of regularization, where a
regularizer term R[f] is added to the empirical risk to be minimized:
N
Rˆ[f]= 1 X λ(y ,f(x ))+R[f]
N n n
n=1
The regularizer does not depend on the data, yet it measures the complexity
of the classifier/regression function f. The idea is to minimize not only the
training error but also to put a penalty on decision rules that represent more
complex models, such as a “wigglier” polynomial. The hope is to reduce the
estimationerror/varianceand,consequently,thegeneralizationerror.Writtenas


================================================================================
PAGE 210
================================================================================

196 Supervised machine learning
a function of model parameters and hyperparameters, the regularized objective
function becomes:
N
1 X
R (θ)= λ(y ,f (x ;θ))+R (θ)
α,β N n α n β
n=1
where we introduced regularization parameters β that gauge the strength of
the regularization. Let us consider the case where we wish to learn a function
of the form f(u;b,w)=φ(wT ·u+b), u∈RD, where the model parameters are
given by b∈R and a row vector of coefficients w =(w ,...,w ). The function
1 D
φ: R→R can be assumed to be monotone. Linear regression (Sect. 6.2.1) and
logistic regression (Sect. 6.3.1) are both examples of models that can be written
in such a way. Thus, we have the following model:
N
1 X
R (b,w)= λ(y ,φ(wT ·u+b))+R (w)
β N n β
n=1
Thereisnoparticularmotivationtoputapenaltyonthesizeofb,soweremoved
it from the regularizer’s argument. In fact, we argue that f(u)=const. is the
simplest hypothesis that we may assume a priori, and we want to put a penalty
on the size of the coefficients w ,...,w . This rationale motivates the use of
1 D
one of the following regularizers:
R(1)(w)=β·∥w∥ , R(2)(w)=β·∥w∥2, R(1,2) (w)=β ·∥w∥ +β ·∥w∥2
β 1 β β1,β2 1 1 2
where ∥ · ∥ is the Minkowski 1-norm and ∥ · ∥ the usual Euclidean 2-norm.
1
These are called L regularization, L regularization, and elastic net
1 2
regularization, respectively.
Inamoregeneralsense,regularizationinmachinelearningreferstoanytechnique
that aims at reducing the test error but not the training error in order to avoid
overfitting. Another example for a regularization technique in that sense is
dropout in neural networks, presented later in Sect. 6.4.2.1.
6.1.3 Training, model validation, and testing
A model that minimizes empirical risk does not necessarily perform well on
unseen data, and the true expected risk cannot be estimated from a single
training dataset. One solution to this problem is to compare the model’s
predictions with the true labels of a second, separate dataset, which is called
a validation dataset. The idea is to test the generalizability of the model by
applying it to data that has not been used to train it. In this way, overfitting in
particular can be detected and avoided.
Training dataset. Sample of annotated/labeled training examples, based
on which a machine learning procedure determines the parameters of a
model (by minimizing the training error).


================================================================================
PAGE 211
================================================================================

6.1. Elements of supervised learning 197
Validation dataset. Sample of annotated examples used for hyperpa-
rametertuningandmodelselection.Thegeneralizationerrorisestimated
from this dataset to determine the optimal hyperparameters.
Testdataset.Annotatedexamplesalsousedtoestimatethegeneralization
error,toevaluatetheperformanceofthefinalclassifierorregressionmodel.
A typical workflow for training, validating, and testing a supervised learning
algorithm is the following:
1. Theoriginalrawannotateddataispartitioned—usuallybyrandomselection—
to produce a training dataset, a validation dataset, and a test dataset. A
typical partition could be 70% of training data in addition to 15% each of
validation and test data.
2. The model parameters are determined from the training dataset for a
selectionofhyperparameters.Forexample,theselectionofhyperparameters
can be done manually (grid search) or (partially) at random (random
search).
3. For each selection of hyperparameters, the average loss is determined from
thevalidationdataset,servingasanestimatoroftheexpectedrisk/testerror.
Other performance measures can be used for the evaluation as well, some
of which we explain in the following sections. For example, the efficiency,
in terms of data processing speed or required computational resources, may
also play an important role in selecting a model in practice.
4. The model/hyperparameters that are considered optimal according to the
validation step are finally evaluated using the test dataset.
There is some terminological confusion, as some practitioners may not make a
strict distinction between validation and test dataset. In any event, it is crucial
that the training dataset does not overlap with the validation/test dataset!
The simple validation technique described above is called holdout validation.
Another technique is K-fold cross-validation: the initial dataset (after with-
holding a test dataset) is divided into a total of K non-overlapping validation
datasets of equal size. Each of these validation datasets is assigned a training
dataset, which is simply the remaining observations that are not included in the
respective validation dataset. Training and validation is performed using this
sequence of datasets a total of K times, and the model performance scores are
averaged over those trials. This procedure is aimed at improving the chances of
selecting optimal hyperparameters, compared to using only a single validation
dataset.
6.1.3.1 Performance measures for regression
Inordertoevaluatethepredictivepoweroftheresultofasimplelinearregression
(Sect. 4.5.1), we computed the mean squared error (MSE), root mean squared


================================================================================
PAGE 212
================================================================================

198 Supervised machine learning
error (RMSE), and coefficient of determination (r2) from the whole dataset
at our disposal, with confidence that our model was a good description of the
relation between predictor and target variable.
In multivariate statistics and machine learning, such confidence can rarely be
gained from first principles. In fact, these measures gauge what we now know
as the training error. However, we can use those measures to gauge the size of
the generalization error by applying them to a withheld test dataset.
Supposewearegivenaregressionfunctionfˆ: X →Rthataregressionalgorithm
learned from some training dataset. We would like to validate or test the model
based on test examples (x ,y ),...,(x ,y ). Writing yˆ = fˆ(x ) for the
1 1 M M ∗ ∗
model’s prediction, we may compute the following measures for goodness of fit,
including the mean absolute error (MAE):
1 X M 1 X M
!1
2
MSE= (y −yˆ )2, RMSE= (y −yˆ )2 ,
M m m M m m
m=1 m=1
M
1 X
MAE= |y −yˆ |
M m m
m=1
We recognize that the mean squared error is the average quadratic loss, and the
mean absolute error is the average L loss. In order to optimize performance,
1
those measures need to be minimized. On the other hand, the coefficient of
determination needs to be maximized:
PM (y −yˆ )2
r2 =1− m=1 m m
PM (y −y¯)2
m=1 m
wherey¯isthearithmeticmeanofthetargetvariable’svaluesinthetestdataset.
A useful baseline to compare a given regression function with is the decision
rule that assigns the arithmetic mean to every test example: yˆ =y¯. Assuming
∗
that y¯is accurately estimated, the mean squared error of this baseline predictor
is equal to the variance of the test dataset, the root mean squared error is equal
to the standard deviation, and the mean absolute error is equal to the mean
absolute deviation from the mean. A regression function with r2 <0 performs
worse than this baseline, while r2 =1 indicates a perfect prediction for every
test example.
6.1.3.2 Performance measures for binary classification
Suppose that we are given a binary decision rule fˆ: X → {0,1} and a single
test example (x ,y ). Writing yˆ =fˆ(x ) for the prediction, we note that any
∗ ∗ ∗ ∗
one of the following cases may occur:


================================================================================
PAGE 213
================================================================================

6.1. Elements of supervised learning 199
yˆ =0 yˆ =1
∗ ∗
y =0 true negative false positive
∗
y =1 false negative true positive
∗
Table 6.2. True/false positive/negative results
In the literature, the convention y ∈{−1,+1} for binary classification problems
is also quite common. That convention is more consistent with the manner
preferred when speaking about negative and positive results.
Given M test examples and noting down the absolute frequencies of correct
and incorrect classification, we obtain a contingency table which is called the
confusion matrix:
P
yˆ=0 yˆ=1
y =0 TN FP N
y =1 FN TP P
P N b P b M
In general, the rates of misclassification FP and FN should be kept as low as
possible. Given a cost matrix of the form
λ(·, ·) yˆ=0 yˆ=1
y =0 0 a
y =1 b 0
the empirical test error can be computed as follows: Rˆ[f]=a· FP +b· FN.
M M
Instead of the test error, the following measures are also common to assess
the learned classification rule. Unlike the test error, these metrics should be
maximized.
Forabinaryclassifier,thefollowingperformancemeasurescanbecomputed
from the entries of the confusion matrix:
TN+TP
accuracy= ,
M
TN
specificity= ,
N
TP
recall, sensitivity= ,
P
TP
precision=
P
b
Precision refers to the fraction of correct positive labels out of all examples that
the classifier labeled as positive. Recall refers to the fraction of examples that
the classifier labeled as positive among all examples that are truly positive.


================================================================================
PAGE 214
================================================================================

200 Supervised machine learning
When viewed alone, precision and recall are not sufficient for assessing a classi-
fier’s goodness of fit. For example, a classifier that would assign a positive class
label to every observation would yield a recall of 100%, but overall it would
perform poorly. For many algorithms, we can increase precision at the cost of
lowering recall, or vice versa. However, to help balance this trade-off, we can
use the following combination of precision and recall.
Given a fixed weighting parameter β > 0, the F -score is defined as
β
follows:
(1+β2)·TP
F =
β (1+β2)·TP+β2·FN+FP
precision·recall
=(1+β2)·
β2·precision+recall
The F -score for β =1 is just the harmonic mean of precision and recall. If the
β
value for β is small, more importance is attributed to precision. A large value
for β corresponds to a higher weighting of recall.
Accuracy refers to the fraction of correct labels among all test examples. Using
a zero–one loss function, accuracy equals one minus the empirical test error. If
the data are highly imbalanced, the accuracy may be a misleading measure for
goodness of fit. For example, if 95% of the test examples have a true positive
classassignment,adecisionrulethatwouldassignapositiveclasslabeltoevery
observation would achieve an accuracy of 95%.
The following measures are considered to be suitable for imbalanced data as
well as when positive and negative class labels are to be treated on an equal
footing.
The balanced accuracy is given by the arithmetic mean of specificity
and sensitivity:
1
(cid:18)TN TP(cid:19)
balanced accuracy= · +
2 N P
Matthews’ correlation coefficient (MCC) is defined as follows [8]:
TN·TP−FN·FP
MCC=
p
P b·P·N
b
·N
Youden’s index is a simple rescaling of the balanced accuracy [9]:
TN TP
Youden’s index=2×balanced accuracy−1= + −1
N P
TN·TP−FN·FP
=
P·N


================================================================================
PAGE 215
================================================================================

6.1. Elements of supervised learning 201
If Matthews’ correlation coefficient or Youden’s index are equal to one, the
classifier only makes correct predictions. A classifier with MCC or Youden’s
index equal to minus one produces a false prediction every time.
As an example, imagine that we want to automatically detect and filter spam
email. First, we train a classifier, and then we run it on a test dataset of size
M =1620, yielding the following confusion matrix:
prediction
P
not spam spam
true class
not spam 400 20 420
spam 200 1000 1200
P 600 1020 1620
Table 6.3. Confusion matrix for spam detection
Theaccuracyofthisclassifierisgivenby 400+1000 ≈86%,thebalancedaccuracy
is 1 · (cid:0)400 + 1000(cid:1) ≈ 89%. The Matthews 1 c 6 o 20 rrelation coefficient computes to
2 420 1200
MCC=0.71.
Moreover, we get the following results:
1000
precision for detecting spam= ≈98%
1020
1000
recall for detecting spam= ≈83%
1200
In reference to the error rates: 2% of the emails moved to the spam folder
should not have been; while 17% of unwanted emails slipped through the spam
filter.
Instead of detecting spam emails, we could have just as well declared the
identification of relevant, non-spam messages as the positive class assignment.
In that case, we would get the following results:
400
precision for identifying relevant email= ≈67%
600
400
recall for identifying relevant email= ≈95%
420
In terms of the error rates, 33% of emails in the inbox are in fact spam, and 5%
of actually relevant emails have been moved to the spam folder.
In terms of F -scores, the classifier for identifying relevant emails performs as
β
follows:
F ≈70%, F ≈78%, F ≈88%
0.5 1 2
Precision and recall are also used for the evaluation of information retrieval
systems like search engines. A search engine takes a user query as input and
then outputs those data records from a dataset that are a relevant match to


================================================================================
PAGE 216
================================================================================

202 Supervised machine learning
the query. For this use case, the performance measures are to be interpreted as
follows:
nb. of relevant results
precision= ,
total nb. of results
nb. of relevant results
recall=
total nb. of relevant data records
Precisionindicatesthequalityofresultspresentedtotheuser:howmanyrecords
in the result set are a relevant match to the query? Recall, on the other hand,
canbeinterpretedasameasureforresultcoverage:howmanyoutofallrelevant
records did the system match and retrieve successfully?
6.1.4 Numerical optimization
Given a training dataset and fixed hyperparameters, the empirical risk is a
real-valued function in the model parameters θ ,...,θ . Training via empiricial
1 K
risk minimization means determining the minimum point of that function. As
a rule, this minimum point cannot be given by a closed formula—it must be
calculated by means of numerical analysis.
In fact, many statistical learning procedures, including unsupervised learning,
lead to the numerical computation of extrema of some objective function
R: RK → R. The prototypical algorithm for solving this problem is called
gradient descent, also called steepest descent.
Let us sketch the rationale behind gradient descent. The derivative of R in the
direction h∈RK, ∥h∥=1 can be expressed via the gradient of R as follows:
R(θ+αh)−R(θ)
D R(θ)= lim =⟨h,gradR(θ)⟩
h α→0 α
If θ does not happen to be a stationary point (i.e., a point with vanishing
gradient),andifhpointsintheoppositedirectionofthegradient,thisdirectional
derivative is negative:
D R(θ)=−∥gradR(θ)∥−1·⟨gradR(θ),gradR(θ)⟩<0
h
if h=−∥gradR(θ)∥−1·gradR(θ) and gradR(θ)̸=0. If we choose some α>0
that is not too large, we can approximate the directional derivative by the
difference quotient:
R(θ+αh)−R(θ)
D R(θ)≈
h α
Sufficiently far away from a stationary point, this approximation will also have
a negative value. Thus, given all those conditions, we have R(θ)>R(θ+αh).
We can take advantage of this fact and define an iterative method
θ(j+1) =θ(j)+αh(j)
that produces descending function values:


================================================================================
PAGE 217
================================================================================

6.1. Elements of supervised learning 203
(cid:16) (cid:17) (cid:16) (cid:17)
R θ(0) >R θ(1) >...
Once the norm of the gradient ∥gradR(θ(j))∥ reaches some small enough
threshold, the argument θ(j) is near a local minimum and the iteration can be
terminated.
Let R: RK → R, θ 7→ R(θ) be a (continuously differentiable) function.
Simple gradient descent computes a local minimum point θˆof R(·) by
running the following iteration:
initialize θ ∈RK,
converged := false, j :=0
while converged = false and j <j do
max
update j ←j+1
update θ ←θ+α·h, where h:=−∥gradR(θ)∥−1·gradR(θ)
if ∥gradR(θ)∥≤τ then
converged := true
end
end
output: converged, θˆ=θ
Here, α > 0 and τ > 0 represent step size and the tolerance parameter,
respectively, which are chosen to have small values. The number j
max
specifies the maximum number of iteration steps to be performed.
In order to find a maximum point of R instead of a minimum, we can simply
apply the algorithm to −R. In the context of machine learning, the step size α
is also called the learning rate.
A common variant of the above algorithm is given by using the non-normalized
gradient: “h = −gradR(θ).” If we insist on the convention ∥h∥ = 1, such a
procedure can also be interpreted as a continuously adjusted step size:
α(j) =α(0)·∥gradR(θ(j))∥
Such a control of the step size/learning rate is quite reasonable: that way, we
avoid overshooting the target. A more sophisticated method for adjusting the
step size is the Barzilai–Borwein method [10], which we will just state here
without further comment:
(cid:13) (cid:13)g(j) (cid:13) (cid:13) (cid:10) g(j−1),g(j)−g(j−1)(cid:11)
α(j) =α(j−1)· (cid:13) (cid:13)g(j−1) (cid:13) (cid:13) · (cid:13) (cid:13)g(j)−g(j−1) (cid:13) (cid:13) 2
with g(j) :=gradR (cid:0) θ(j)(cid:1).
Fig. 6.2 (top) illustrates a gradient descent for an objective function with two
arguments, R(θ)=R(θ ,θ ). The non-normalized gradient was used, and the
1 2
arrows indicate the difference of successive pairs of values:


================================================================================
PAGE 218
================================================================================

204 Supervised machine learning
(cid:16) (cid:17)
α(j)h(j) =−α(0)·gradR θ(j) =θ(j+1)−θ(j)
These vectors are perpendicular to the contour lines of the objective function
and point in the direction of its minimum point.
In statistical learning, objective functions are often of the following form:
N
1 X
R(θ)= R (θ)
N n
n=1
For example, the empirical risk is of this form, in which case the loss is summed
over the observations in the training dataset. In order to minimize that risk, we
need to compute the direction of steepest descent many times:
N
1 X
h∝−gradR(θ)=− gradR (θ)
N n
n=1
Often, there are also a very large number of observations/summands, since
trainingdatasetscanbequitelarge.Thus,ordinarygradientdescentcanbecome
expensive and possibly hog computational resources that are not available.
Instead, we can use stochastic gradient descent: with each iteration step,
only a single summand with index n is selected, and only for this training
1
example we determine the gradient:
h ∝−gradR (θ)
stoch n1
The index n ∈ {1,...,N} is usually selected at random. Another variant of
1
gradient descent is mini-batch gradient descent, where we randomly select
up to 1<M ≪N training examples, the mini-batch:
M
1 X
h ∝− gradR (θ)
batch M nk
k=1
The random selection is performed without replacement: after a total of ⌈N/M⌉
iteration steps, which make up a so-called epoch, all training data have been
processed. For the subsequent epoch, all training examples are made available
again and processed in mini-batches.
In this context, ordinary gradient descent is also called full-batch gradient
descent, or just batch gradient descent.
Fig. 6.2 (bottom) shows a stochastic gradient descent. Notice that the direction
of descent is no longer the steepest and may not be orthogonal to the contour
lines of the function to be minimized. Nevertheless, the general direction of
descent—averaged over many iteration steps—remains the correct one with
high probability.
Another numerical optimization algorithm is the Broyden–Fletcher–Goldfarb–
Shannomethod(BFGSmethodforshort)[11,12,13,14].Anumberofexamples


================================================================================
PAGE 219
================================================================================

6.1. Elements of supervised learning 205
in this book have been calculated through this method, so we briefly present it
here.
The method’s rationale is similar to that of gradient descent except that it
considers the second-order Taylor polynomial instead of just a linear approxi-
mation:
α2
R(θ+αh)≈R(θ)+α·⟨h,gradR(θ)⟩+ ⟨h,HessR(θ)·h⟩
2
The search direction h should, once again, be chosen in such a way that the
function values become smaller with each iteration step: i.e., the algorithm
moves in the direction of a minimum. Assuming that the Hessian matrix is
positive definite, the minimum of the Taylor polynomial lies in the following
direction:
h∝−(HessR(θ))−1·gradR(θ)
The step size α is adaptively controlled by approximately minimizing the one-
dimensional function g(α)=R(θ+αh) by means of a so-called backtracking
line search:
set parameters c ∈]0,1[, c ∈]0,1[,
1 2
intialize α>0,
compute m:=⟨gradR(θ),h⟩
while R(θ+αh)≥R(θ)+c mα do
1
update α←c α
2
end
output: α
The termination condition is also called Armijo rule [15]; usually a very small
value is chosen for c .
1
Finally, an essential component of the BFGS algorithm is that the Hessian
matrix is not computed exactly, rather an approximation H is used. This
approximation arises from the following quasi-Newton condition in the j-th
iterationstep[16,Sect.3.2].Forthesakeofclarity,theiterationindexisnotated
as a subscript:
gradR(θ +α h )−gradR(θ ) v
H ·h = j j j j =: j
j+1 j α α
j j
If H is any symmetric and positive definite matrix, then H by the following
j j+1
definition is also symmetric and positive definite, and it also satisfies the above
condition:
H =H +(α ·⟨v ,h ⟩)−1·v ·vT −(⟨h ,H ·h ⟩)−1·(H ·h )·(H ·h )T
j+1 j j j j j j j j j j j j j
Finally, the final formula for the inverse of H used in the following pseudocode
follows from the so-called Sherman–Morrison formula [16, Exercise 3.13].


================================================================================
PAGE 220
================================================================================

206 Supervised machine learning
Let R: RK →R, θ 7→R(θ) be a (twice continuously differentiable) func-
tion. The BFGS method computes a local minimum point θˆ of R(·)
by running the following iteration where τ >0 and j are a tolerance
max
parameter and the maximum number of iteration steps, respectively. All
vectors are to be interpreted as column vectors.
initialize: converged := false,
j :=0, θ =(θ ,...,θ )T ∈RK,
1 K
H−1 := identity matrix of format K×K
while converged = false and j <j do
max
update j ←j+1
# Determine step size and search direction:
determine (approximately) a minimum α∈R of the function
g(α):=R(θ+α·h) where h:=−H−1gradR(θ)
# Update approximation for function value and Hessian matrix:
θ ←θ+α·h,
(cid:18) vTH−1v (cid:19) hhT hvTH−1+H−1vhT
H−1 ←H−1+ 1+α · −
hTv hTv hTv
where v =gradR(θ+α·h)−gradR(θ)
if ∥gradR(θ)∥≤τ then
converged := true
end
end
output: converged, θˆ=θ
6.2 Regression algorithms
Inthefollowingsections,wepresentregressionalgorithmsthatprocessatraining
dataset (x,y) ∼ = ((x ,y ),...,(x ,y )) where x ,...,x ∈ RD are feature
1 1 N N 1 N
vectors, and y ,...,y ∈R are realizations of the target variable. The goal is
1 N
to learn a regression function:
fˆ: RD →R
Thisregressionfunctioncanthenbeusedtomakeaprediction yˆ =fˆ(x )given
∗ ∗
some new, yet unseen feature vector x ∈RD.
∗
6.2.1 Linear regression
InSect.4.5.1,welearnedaboutsimplelinearregression,whichexaminesalinear
relationship between a univariate predictor variable and some response variable.


================================================================================
PAGE 221
================================================================================

6.2. Regression algorithms 207
1.5
1.2 θ
(0)
1.0
θ
(5)
0.8
0.5
0.0 0.3 0.6
θ
1
θ 2
1.5
1.2 θ
(0)
1.0 θ (5)
0.8
0.5
0.0 0.3 0.6
θ
1
θ 2
Fig. 6.2. Ordinary, full-batch gradient descent (top) and stochastic gradient descent
(bottom)


================================================================================
PAGE 222
================================================================================

208 Supervised machine learning
The result can be visually presented as a regression line that runs through the
data points and minimizes the residual sum of squares.
We want to generalize to the multivariate case. If the predictor is a random
vector, its realizations are feature vectors x ,...,x ∈RD. We can write these
1 N
featurevectorsastherowsofadatamatrixwiththeentriesx ,n∈{1,...,N},
nd
d∈{1,...,D}. Hence, each feature vector x has coordinates x ,...,x . In
n n1 nD
multivariate linear regression, the target variable then takes the following form:
D
X
Y =w + w ·x +ε
n 0 d nd n
d=1
with constants w ,w ,...,w and normally distributed, independent error
0 1 D
terms ε ∼N(·|0,σ2), σ >0.
n
The least squares method—that is, minimizing the empirical risk with respect
to the squared loss function—can be summarized as follows.
We are given data points/feature vectors x ,...,x ∈RD and the obser-
1 N
vations of the target variable y ,...,y ∈R paired with those data points.
1 N
Theobjectivefunctionof linear regression istheresidualsumofsquares
R: RD+1 →[0,∞[:
N D
!2
X X
R(w ,...,w )= y −w − w x
0 D n 0 d nd
n=1 d=1
The model parameters are determined by the minimum point wˆ = (wˆ ,
0
..., wˆ ) of R(·), and the learned regression function is given by:
D
D
fˆ(x )=wˆ + X wˆ x
∗ 0 d ∗d
d=1
for all x ∈RD with coordinates x ,...,x .
∗ ∗1 ∗D
It is possible to give a closed-form expression for the minimum point, which we
present in more detail in the next section.
L regularization can be applied to linear regression, in which case the method
2
is called ridge regression. When including an L penalty, the technique is
1
known as LASSO3.
Simple linear regression leads to a regression line fitting the data points in
the 2-dimensional plane (x ,y ) ∈ R×R = R2. More generally, the linear
n n
regression algorithm computes a regression hyperplane that fits the data points
(x ,y )∈RD×R∼ =RD+1 in (D+1)-dimensional space.
n n
3 LASSO stands for Least Absolute Shrinkage and Selection Operator.


================================================================================
PAGE 223
================================================================================

6.2. Regression algorithms 209
Animportantapplicationofthemultivariatemodelis,ofcourse,toincludemore
thanjustasinglefeaturetomakeaprediction.Anotherimportantapplicationof
multivariatelinearregression,however,isthemodelingofnonlinearrelationships.
For example, we can include quadratic terms of a single predictor variable as
follows:
N
R(w ,w ,w )=
X(cid:0)
y −w −w ·x −w
·x2(cid:1)2
0 1 2 n 0 1 n 2 n
n=1
For this model, the learned parameters are the coefficients of a quadratic
polynomial that we want to fit through the data points. Despite the regression
function being nonlinear, we still speak of linear regression: we have merely
added a new feature.
Example. In Sect. 4.5.1, we determined a regression line to model the time
series of global air temperatures on Earth [7] (see Fig. 4.12). If we add a
quadratic term to the model, then we get a regression polynomial instead:
15.5
15.0
14.5
14.0
13.5
13.0
1850 1900 1950 2000
year
C°
ni
erutarepmet
ria
labolg
Fig. 6.3. Time series of average global air temperature with quadratic regression
polynomial
The regression curve is given by the following equation:
K
fˆ(x )=13.8◦C+5.39·10−5 ·(x −1875a)2
∗ a2 ∗
Thus, according to this model, the average global air temperature on Earth
shows an accelerated increase since 1875. The root mean squared error is
givenbyσˆ =0.13Kandthecoefficientofdeterminationisgivenby r2 =0.88.
6.2.1.1 Moore–Penrose inverse
Inordertoapplylinearregressiontoourdata,weneedtocomputetheminimum
pointoftheresidualsumofsquares.Inthissection,weshowthatthisminimum


================================================================================
PAGE 224
================================================================================

210 Supervised machine learning
can be given in a closed form via the so-called Moore–Penrose inverse of a
matrix. First, we recall the definition of the regressor matrix, where the feature
vectors are augmented by a one in the zeroth entry:
 
1 x x ··· x
11 12 1D
1 x 21 x 22 ··· x 2D
X =. . . =(x )
. . . . . .  nd n∈{1,...,N}
  d∈{0,1,...,D}
1x x ··· x
N1 N2 ND
Furthermore, we combine the model parameters and the observations of the
target variable into column vectors of length D+1 and N, respectively:
   
w y
0 1
w 1 y 2
w = .  and y = . 
 . .   . . 
   
w y
D N
Withthesedefinitions,wecanwritetheresidualsumofsquaresR(w ,...,w )=
0 D
R(w) much more compactly:
N D
!2
N D
!2
X X X X
R(w)= y −w − w x = y − x w
n 0 d nd n nd d
n=1 d=1 n=1 d=0
=∥y−X·w∥2
If there were a solution wˆ of the linear system of equations X ·w = y, then
R(wˆ)=0 would hold and the residual sum of squares would be minimized by
that solution. Formally, we could then write wˆ =X−1·y. However, in practice,
suchasolutionwillnotexist:thesystemofequationsconsistsof N equationsin
D+1 unknowns. Usually, the number of model parameters D+1 will be much
smallerthanthesamplesizeN.Thus,thesystemofequationsisoverdetermined.
In the context of simple linear regression, this circumstance arises from the fact
that there are usually many more than just two data points that determine the
slope and intercept of the regression line.
Nevertheless,therealwaysexistsaminimumpointoftheresidualsumofsquares.
Thisminimumpointcanbewrittenaswˆ =X†·y,whereX† isthegeneralized
inverse, pseudoinverse, or Moore–Penrose inverse of the regressor matrix
X.
To determine X†, we first calculate the gradient of the objective function R(·):
d
gradR(w)=(DR(w))T = ∥y−X·w∥2
dw
= (cid:0) 2(y−X·w)T ·(−X) (cid:1)T = (cid:0) −2yTX+2wTXTX (cid:1)T
=−2XT ·y+2XT ·X·w


================================================================================
PAGE 225
================================================================================

6.2. Regression algorithms 211
Here, we used the chain rule (see [17, Sect. 5.12] or Section B.3.3) as well as
these basic differentiation rules:
d d
(∥z∥2)=2zT, (X·z)=X
dz dz
Moreover, we recall the matrix calculation rules (A · B)T = BT · AT and
(AT)T =A.
Therefore, the gradient vanishes for wˆ ∈RD+1 with
XT ·X·wˆ =XT ·y.
Provided that XT ·X is invertible, this equation can be solved directly for wˆ:
wˆ =(XT ·X)−1·XT ·y
This stationary point is the uniquely determined minimum point of R(·),
since that function is nonnegative and thus bounded from below. In this case,
X† =(XT ·X)−1·XT is the Moore–Penrose inverse of X.
If XT ·X is not invertible, we can proceed as follows. First, we notice that
the matrix Σ := XT ·X has only nonnegative eigenvalues. Moreover, Σ is a
symmetric matrix, which implies (see Sect. B.2.4 in the appendix) that there
exists an orthogonal matrix V and a diagonal matrix Λ such that:
Σ =V ·Λ·VT
The columns of V are the normalized and pairwise orthogonal eigenvectors
v ,...,v ∈ RD+1 of Σ. The diagonal entries of Λ are the corresponding
0 D
eigenvalues λ ,...,λ . Alternatively, we can write the diagonal decomposition
0 D
as follows:
D
X
Σ = λ v ·vT
d d d
d=0
We can see that this representation is correct from the fact that Σ acts on the
eigenvector basis as desired:
D D
X X
Σ·v = λ v ·vT ·v = λ ⟨v ,v ⟩v =λ v
i d d d i d d i d i i
d=0 d=0
for all i∈{0,...,D}.
We then determine the Moore–Penrose inverse via the following formula:
X† = X D λ† d v d ·v d T ·XT with λ† d = ( 0 λ 1 d i i f f λ λ d > =0 0
d=0 d
This definition solves our problem, because, as we will show below, it satisfies
the above condition of a vanishing gradient: XTXwˆ =ΣX†y =XTy.


================================================================================
PAGE 226
================================================================================

212 Supervised machine learning
First,wenotethatforanyeigenvectorvwitheigenvaluezero,thevectorvTXTy
must vanish:
Σv =0⇒XTXv =0⇒vTXTXv =0
⇒⟨Xv,Xv⟩=0⇒Xv =0⇒vTXTy =0
Furthermore,PD v vTv =v holdsforanyeigenvectorv and—vialinearity—
d=0 d d i i i
for any vector. Thus, PD v ·vT is the identity matrix.
d=0 d d
Finally, we note the following formula:
D ! D
X X
ΣX†y =Σ· λ†v vTXT ·y = λ†Σv vTXTy
d d d d d d
d=0 d=0
D D
X X
= λ†λ v vTXTy = v vTXTy =XTy
d d d d d d
d=0 d=0
Let us summarize.
The residual sum of squares
R(w)=∥yT −X·w∥2
with regressor matrix X of format N ×(D+1) and observations of the
target variable y =(y ,...,y ) has the minimum point
1 N
wˆ =X†·yT
where X† is the Moore–Penrose inverse of X described above.
6.2.2 Gaussian process regression
To derive another regression procedure, let us once again consider a training
dataset (x,y)∼ =((x ,y ),...,(x ,y )) with feature vectors x ,...,x ∈RD
1 1 N N 1 N
and observed target values y ,...,y ∈R. We assume that y¯=0 holds: this
1 N
circumstance can always be achieved by mean-centering, i.e., subtracting the
arithmetic mean from the target variable. Instead of a linear relationship, we
write down a more general model assumption:
Y =f(x )+ε
n n n
with normally distributed and independent error terms ε ∼N(·|0,δ2) for all
n n
n∈{1,...,N}. We want to allow for the variance δ >0 of the error terms to
n
vary in general and allow for heteroskedasticity, i.e., we do not necessarily
assume δ =δ =···=δ .
1 2 N
Next,letusconsiderthepairsofobservedpredictorvaluesandthecorresponding
(unknown, not directly observable) value of the regression function:


================================================================================
PAGE 227
================================================================================

6.2. Regression algorithms 213
((x ,f ),...,(x ,f ))=((x ,f(x )),...,(x ,f(x )))
1 1 N N 1 1 N N
GaussianprocessregressionisaBayesianmethod:Itisbasedontheassumption
that our ignorance of the values f ,...,f can be modeled by a multivariate
1 N
normal distribution, with location parameter m = m(x ,...,x ) ∈ RN and
1 N
N ×N-covariance matrix Σ˜ =Σ˜(x ,...,x ):
1 N
p(f ,...,f |x ,...,x )=p(f|x)=N(f|m(x),Σ˜(x))
1 N 1 N
We make this assumption for any finite selection of pairs of predictor/predicted
values, not just those in the training dataset. A family x 7→ f of random
∗ ∗
variables distributed as such is called a Gaussian process. Since y¯=0 holds,
wemaketheadditionalassumptionm(x)=0.Thecovariancematrixisassumed
to be of the following form:
 
σ(x ,x ) ··· σ(x ,x )
1 1 1 N
. .
Σ˜(x)= . . . . 
 
σ(x ,x )··· σ(x ,x )
N 1 N N
where σ: RD×RD →R is some suitable similarity measure.
Thebasicrationaleisthefollowing:Iftwofeaturevectors x andx arecloseto
m n
each other, the corresponding values of the target variable should be similar as
well. On the other hand, if the feature vectors are separated by a large distance,
we may assume that only few common influences determine the corresponding
values of the target variable—over large distances in feature space, the target
variable becomes decorrelated. Like all model assumptions, this one should also
be scrutinized in terms of the use case and the data generation process. For
example, a naive application of the method to a time series would not take into
account periodic influences that could cause correlations over long time spans.
We further assume that the entries of the covariance matrix are of a Gaussian
form:
(cid:18) (cid:19)
1
σ(u,v)=a2exp − uT ·Σ−1·v
2 h
for all column vectors u,v ∈RD. The numbers h ,...,h ,a>0 are additional
1 D
parameters, and Σ−1 is the diagonal matrix with diagonal entries h−2,...,h−2
h 1 D
(all other entries being zero).
In order to obtain the distribution of the actual target observations y ,...,y ,
1 N
we still need to take into account the error terms:
p(y ,...,y |x ,...,x )=p(y|x)=N(y|0,K(x))
1 N 1 N
where K(x)=Σ˜(x)+Σ . Here, Σ =diag(δ2,...,δ2 ) is the diagonal matrix
δ δ 1 N
with diagonal entries δ2,...,δ2 .
1 N
If we were to explicitly write out all of the parameters, we would have
σ(·, ·) = σ (·, ·), Σ˜(x) = Σ˜ (x) and K(x) = K (x;h,a). For clarity,
h,a h,a δ
we will notationally suppress those parameters.


================================================================================
PAGE 228
================================================================================

214 Supervised machine learning
Given a new, yet unseen data point x , we want to make the prediction f =
∗ ∗
f(x ). For this purpose, we determine the posterior distribution that describes
∗
our knowledge of this value given the data. The joint density function of the
observed feature values and the prediction is also a normal distribution:
p(y ,...,y ,f |x ,...,x ,x )=p(y,f |x,x )=N((y,f )|0,K )
1 N ∗ 1 N ∗ ∗ ∗ ∗ ∗
The covariance matrix K is given by the following block matrix of the format
∗
(N +1)×(N +1):
(cid:18) (cid:19)
K(x) K(x ,x)
K = ∗
∗ K(x ,x)T a2
∗
withthecolumnvectorK(x ,x):=(σ(x ,x ),...,σ(x ,x ))T.Wecannowuse
∗ ∗ 1 ∗ N
the formula for the conditional probability density of components of a normally
distributed random vector (see Sect. 5.4.2) to derive the posterior distribution
that we are after:
p(f |x,x ,y)=N(f |K(x ,x)TK(x)−1y,a2−K(x ,x)TK(x)−1K(x ,x))
∗ ∗ ∗ ∗ ∗ ∗
with the column vector of target values y =(y ,...,y )T.
1 N
Overall, the model has the following parameters: the variances of the error
terms δ2,...,δ2 , the correlation ranges h ,...,h , and the scale parameter
1 N 1 D
a. The correlation ranges and the scale parameter should be treated as model
parametersandbeestimatedfromthedata.Ifallerrortermswerealsoestimated
from the data, overfitting can easily occur. Alternatively, there are the following
possibilities:
• The variance of the disturbance is assumed to be constant. This assumption
of homoskedasticity drastically reduces the number of model parameters:
δ =···=δ .
1 N
• The standard deviations δ ,...,δ are treated as hyperparameters and are
1 N
inferred from other sources. For example, they can represent the uncertainty
of a physical measurement, as determined by an experimental uncertainty
assessment.
In any case, a maximum-a-posteriori estimator and a credibility interval can be
obtained from the posterior distribution. We summarize our reasoning, treating
δ ,...,δ as hyperparameters.
1 N
The log-likelihood function of Gaussian process regression given fea-
ture vectors x ,...,x ∈ RD and mean-centered target values y =
1 N
(y ,...,y )T is the following:
1 N
ℓ (h,a)=ln(p(y|x))=ln(N(y|0,K (x;h,a)))
δ δ
1 1 N
=− yT(K (x;h,a))−1y− ln(det(K (x;h,a)))− ln(2π)
2 δ 2 δ 2
where K (x;h,a)=Σ˜ (x)+Σ is given in the above derivation.
δ h,a δ


================================================================================
PAGE 229
================================================================================

6.2. Regression algorithms 215
A maximum point (hˆ ,...,hˆ ,aˆ) of the log-likelihood function leads to
1 D
the following regression function:
fˆ: RD →R, fˆ(x )=Kˆ(x ,x)TKˆ(x)−1y
∗ ∗
with
Kˆ(x)=K (x;hˆ,aˆ), Kˆ(x ,x)=(σ (x ,x ),...,σ (x ,x ))T.
δ ∗ hˆ,aˆ ∗ 1 hˆ,aˆ ∗ N
A γ-credibility band for the estimate is given by
(cid:20) q (cid:21)
fˆ(x )±z(γ)· a2−Kˆ(x ,x)TKˆ(x)−1Kˆ(x ,x)
∗ ∗ ∗
with, for example, z(0.95)=1.96.
For a univariate predictor (D =1), the regression curve consists of the pairs of
values (x ,f ). In the multivariate case (D >1), these describe a hypersurface
∗ ∗
in (D+1)-dimensional space.
Example. We apply Gaussian process regression to the time series of mea-
surements of the average global air temperature on Earth. The gray band
around the regression curve marks the 95%-credibility interval:
15.5
15.0
14.5
14.0
13.5
13.0
1850 1900 1950 2000
year
C°
ni
erutarepmet
ria
labolg
Fig. 6.4. Time series of average global air temperature with Gaussian process
regression curve
Berkley Earth provides uncertainties for the measurements (between 0.03K
and 0.21K, depending on the year), and those have been incorporated into
the model directly as the standard deviations of the disturbance δ ,...,δ .
1 N


================================================================================
PAGE 230
================================================================================

216 Supervised machine learning
With the help of the BFGS procedure, a maximum point of the likelihood
function, and thus the remaining parameters, can be determined:
y¯=14.10◦C, h=30y, a=0.52K
6.3 Classification algorithms
In the following sections, we present classification algorithms. These algorithms
process a training dataset (x,y)∼ =((x ,y ),...,(x ,y )) where x ,...,x ∈
1 1 N N 1 N
RD are feature vectors and y ,...,y ∈{0,1,...,K−1} are the labels. Binary
1 N
classification corresponds to the case K =2. The goal is to learn a classification
rule:
fˆ: RD →{0,1,...,K−1}.
This classification rule can then be used to make a prediction yˆ =fˆ(x ) given
∗ ∗
some new, yet unseen feature vector x ∈RD.
∗
6.3.1 Logistic regression
The simple logistic regression model can be generalized to the multivariate case
in a way that is similar to simple linear regression. The training dataset can be
writtenasaregressormatrix X =(x )withN rowsandD+1columns,where
nd
each observation/row is paired with a binary class label y ,...,y ∈{0,1}.
1 N
The log-likelihood function of logistic regression is given as follows:
N D !!
X X
ℓ(w ,...,w )=− ln 1+exp (−1)yn · w x
0 D d nd
n=1 d=0
A maximum point wˆ =(wˆ ,...,wˆ ) of ℓ(·) corresponds to the following
0 D
learned classifier:
( 1 if PD wˆ x >0
fˆ: RD+1 →{0,1}, fˆ(x )= d=0 d ∗d
∗ 0 otherwise
The maximum point of the log-likelihood function can be determined by means
of numerical optimization, such as the BFGS algorithm.
To get a first impression of the algorithm’s behavior, we apply it to a synthetic
training dataset of low dimensionality. The figure below shows the scatter plot
of two classes of data points generated using bivariate Gaussian distributions
(N =1000). In general, logistic regression learns a linear classifier: the decision
boundary is a (D − 1)-dimensional hyperplane with normal vector w⊥ =
(wˆ
1
,...,wˆ
D
)T and the distance wˆ0/∥w⊥∥ from the origin. In this example, the
decisionboundaryisone-dimensionalandindicatedbythesolidlinedividingthe


================================================================================
PAGE 231
================================================================================

6.3. Classification algorithms 217
two-dimensional feature space into regions that correspond to the predictions
yˆ=0 (light region) and yˆ=1 (dark region).
2
0
-2
-2 0 2 4
x
1
x 2
Fig. 6.5. Decision boundary of logistic regression
Let us use this example to illustrate once more the concepts of empirical and
expected risk. The empirical risk—even though it has been minimized by the
algorithm—doesnotvanish,assomeofthetrainingdatawouldnotbeclassified
correctly by the learned decision rule: they are on the wrong side of the decision
boundary.
The dashed line in the above figure indicates the optimal decision boundary
correspondingtothebestpossibleclassifier,alsocalledthe Bayes classifier.In
practice, this boundary is unknown: here we can only determine it because the
dataset is synthetic. For the Bayes classifier, the expected risk is equal to the
irreducible Bayes error. Note that even for the optimal classifier, the empirical
risk does not vanish, either: some training data is misclassified.
The optimal classifier is linear (again: in practice, we would not know this).
Thus, it is contained in the hypothesis space of the applied method. Therefore,
the approximation error vanishes: For larger and larger training datasets, it
becomes more and more likely that the learned classifier comes very close to the
optimal one; the dashed and solid lines coincide. Thus, the deviation between
the learned and optimal decision boundaries shown in the figure is due to the
estimation error alone.


================================================================================
PAGE 232
================================================================================

218 Supervised machine learning
Fig. 6.6 shows a dataset where logistic regression would suffer from (severe)
underfittingifitweretobeappliednaively:thespiral-shapedregionscorrespond-
ing to negative/positive class assignment cannot be separated by a decision
boundary that is a single straight line. In this case, we say that the classes are
not linearly separable.
One way to separate those regions using a linear classifier after all is to add
higher powers of the predictor variables. This procedure is very similar to using
linearregressiontofitapolynomialinsteadofaregressionline.Forexample,we
canaddtermsuptothirdpowers.Insteadofastraightlinew +w x +w x =0,
0 1 1 2 2
the decision boundary is now an algebraic curve of degree three:
w +w x +w x +w x2+w x x +w x2
0 1 1 2 2 11 1 12 1 2 22 2
+w x2x +w x x2+w x3+w x3 =0
112 1 2 122 1 2 111 1 222 2
The result can be seen in Fig. 6.6 above. Note that this model is able to capture
the shape of the data.
Another way of looking at the procedure is as follows. The data points are not
linearly separated in the original two-dimensional feature space. Thus, we map
them to a higher-dimensional space as follows:
 
x
1
 x 2 
 
 x2 
 1 
Φ: R2 →R9, (cid:18) x 1 (cid:19) 7→    x x 1 x 2 2  
x 2    x2 1 x 2 2   
  x 1 x2 2  

x3
1 
x3
2
In this higher-dimensional feature space, the classes are now linearly separated,
and we can apply logistic regression successfully. This idea is also at the core of
the so-called kernel trick, which we describe in the next section.
6.3.1.1 Kernel logistic regression
Once again, we are given a training dataset consisting of feature vectors
x ,...,x ∈ RD and (binary) class labels y ,...,y ∈ {0,1}. Furthermore,
1 N 1 N
we are given a symmetric similarity measure σ: RD×RD →R, which in this
context is called the kernel. A popular choice is once more the Gaussian kernel:
σ h
(u,v)=e−∥u
2
−
h
v
2
∥2
for all u,v ∈ RD with bandwidth h > 0. Another possibility is a polynomial
kernel:
σ (u,v)=(⟨u,v⟩+b)k
k,b
where k ∈N, k ≥1 and b∈R, b≥0.


================================================================================
PAGE 233
================================================================================

6.3. Classification algorithms 219
The objective function for kernel logistic regression is the following:
N N !!
X X
ℓ(α ,...,α )=− ln 1+exp (−1)yn+1· α σ(x ,x )
1 N m m n
n=1 m=1
A maximum point αˆ =(αˆ ,...,αˆ ) of ℓ(·) leads to the following classifi-
1 N
cation rule:
( 1 if PN αˆ σ(x ,x )>0
fˆ: RD →{0,1}, fˆ(x )= m=1 m m ∗
∗ 0 otherwise
Fig. 6.6 below shows the result of applying the procedure with Gaussian kernel
(bandwidth:h=0.05)tothesyntheticdatasetofspiraldistributions.Thismodel
isabletocapturetheshapeofthedataverywell.Itisimportanttonotethat,in
ordertoapplythelearnedclassifier,wemustcomputethesimilaritybetweenthe
featurevectorx tobeclassifiedandeverydatapoint x ,...,x inthetraining
∗ 1 N
dataset. Procedures of this type are referred to as instance-based learning.
For instance-based learners, the complexity of the hypothesis increases with the
size of the training dataset, which can take up many computational resources.
Reducing this complexity may therefore be necessary—for an overview, see [18].
Arationaleforhowtheprocedureworkscanbegivenasfollows.Weassumethat
the kernel has the property that the matrix with entries σ(x ,x ) is symmetric
m n
and positive semidefinite for any finite choice of data points x ,x ,.... For
1 2
example, a Gaussian or polynomial kernel satisfies this condition [19, Sect. 2.2].
Suppose we are given a test dataset with M feature vectors x ,...,x ∈
N+1 N+M
RD. We may consider the full similarity matrix, including both training and
test data:
Σ =(σ(x ,x )) .
m n m,n∈{1,...,N+M}
First, we take the square root of Σ: we are looking for a square matrix Φ with
Σ =Φ·ΦT. One way to construct such a matrix is as follows.
Sincethekernelisassumedtobesymmetric,Σ isasymmetricmatrix.Therefore,
there exists an orthogonal matrix V and a diagonal matrix Λ such that the
following holds (see Sect. B.2.4 in the appendix):
Σ =V ·Λ·VT
ThediagonalofΛcontainstheeigenvaluesλ ,...,λ ofΣ.AsΣ isalsopositive
1 D
semidefinite, the entries of Λ are nonnegative. Therefore, we can take their
√ √
square root, and we write Λ for the resulting matrix. If we define Φ=V · Λ,
that matrix has the desired property:
√ (cid:16) √ (cid:17)T √ √ T
Φ·ΦT =V · Λ· V · Λ =V · Λ· Λ ·VT =V ·Λ·VT =Σ
We note the following:


================================================================================
PAGE 234
================================================================================

220 Supervised machine learning
⟨φ ,φ ⟩=φ ·φT =Σ =σ(x ,x )
m n m n mn m n
for all m,n∈{1...,N,...,N +M}, where φ and φ are the m-th and n-th
m n
row of Φ, respectively. Thus, we can write the decision rule of kernel logistic
regression as follows, where x is taken from the test dataset:
∗
N N
X X
αˆ σ(x ,x )= αˆ ⟨φ ,φ ⟩=⟨w⊥,φ ⟩>0
m m ∗ m m ∗ ∗
m=1 m=1
with w⊥ = PN αˆ φ . We conclude that the decision boundary is a hyper-
m=1 m m
plane with normal vector w⊥.
In other words, kernel logistic regression is a linear classifier—but in a (usually
higher-dimensional) space defined by the feature map
Φ: {x ,...,x }→RN+M, x 7→φ =Φ(x )
1 M+N n n n
that maps the kernel onto scalar products: σ(x ,x )=⟨φ ,φ ⟩.
m n m n
Our construction of a feature map depends explicitly on the test dataset even
though that dataset can be of arbitrary size. For a solid theoretical foundation,
it would be nice if this restriction did not exist and the feature map were
universal:
Φ: RD →H, u7→Φ(u)
where H is some vector space with scalar product ⟨·, ·⟩. Such a map would
provide a complete representation of the kernel in the target feature space:
σ(u,v)=⟨Φ(u),Φ(v)⟩
for all u,v ∈RD. We do not provide all of the details here, but note that such
a construction is possible under fairly general circumstances—see [20, Theorem
6.8]. The target space H is called a reproducing kernel Hilbert space, and it is
infinite-dimensional in general.
6.3.2 K-nearest neighbors classification
Logistic regression produces a linear classifier that allows for a simple geometric
interpretation: entities with positive (yˆ= 1) and negative (yˆ= 0) prediction
are separated by a hyperplane in feature space. If we transform the features in
a nonlinear fashion—for example using the kernel trick—the method is able to
learn more general classifiers.
So-called K-nearest neighbors classification is also best illustrated and under-
stood by imagining feature space as a geometric space. This method makes
predictions based on the labeled data points that have the smallest distance to
the input.


================================================================================
PAGE 235
================================================================================

6.3. Classification algorithms 221
We are given a training dataset (x,y) where x=(x ,...,x )∈XN are
1 N
data points with class labels y =(y ,...,y ). We assume that X comes
1 N
equipped with a distance or similarity measure.
Fix the hyperparameter K ∈ N, K ≥ 1. The K nearest neighbors of a
data point x ∈X are those observations x ,...,x which have the
∗ ι(1) ι(K)
least distance/greatest similarity to x .
∗
The K-nearest neighbors classifier (KNN classifier) commits to a
plurality vote among the neighbors of x : it predicts that x is assigned to
∗ ∗
the mode of y ,...,y .
ι(1) ι(K)
We have implicitly assumed that the K nearest neighbors and the mode of their
labels are uniquely determined; that there is no need to break ties. There are
several sensible ways to handle situations where this is not the case:
• AfterselectingK observationsx ,...,x withminimumdistance/great-
ι(1) ι(K)
est similarity to x , we consider all labeled data points within a distance of
∗
no more than
δ = max {δ(x ,x )}
max ∗ ι(k)
k∈{1,...,K}
to x —even if those may be more than K data points. Here, δ(·, ·) denotes
∗
a distance measure. When a similarity measure σ(·, ·) is used, the plurality
vote is conducted among all data points with a similarity measure of at least
σ = min {σ(x ,x )}.
min ∗ ι(k)
k∈{1,...,K}
• If there is a tie among the K nearest neighbors, i.e., if there are two
candidates that appear with the same maximum frequency, the K − 1
nearest neighbors are considered instead. Repeat this process of reducing
the number of neighbors until a plurality vote is reached.
KNN is an instance-based learner. In its most basic form, the KNN classifier
computes the distances/similarities of the tested data point to all the data
points in the training dataset.
In the case of K = 1, KNN just finds the closest/most similar point in the
training dataset and assigns its label. However, such a small value for K can
easily lead to overfitting. The hyperparameter K can be determined through
√
validation techniques, but in practice rules of thumb such as K ≈ N are also
used [21]. In Fig. 6.7, the procedure is demonstrated for two values of K using
a synthetic dataset. Note that the ordinary Euclidean metric is used as the
distance measure.
6.3.3 Bayesian classification algorithms
The Bayes classifier is the optimal decision rule given complete knowledge of
the probability distributions underlying the observations.


================================================================================
PAGE 236
================================================================================

222 Supervised machine learning
1.0
0.5
0.0
-0.5
-1.0
-1.0 -0.5 0.0 0.5 1.0
x
1
x
2
0,5
0,0
-0,5
-1,0 -0,5 0,0 0,5 1,0
x
1
x
2
Fig. 6.6. Nonlinearclassificationvialogisticregression:includinghigherpowers(top),
and the kernel trick (bottom)


================================================================================
PAGE 237
================================================================================

6.3. Classification algorithms 223
1.0
K=1
0.5
0.0
-0.5
-1.0
-1.0 -0.5 0.0 0.5 1.0
x
1
x
2
1.0
K=21
0.5
0.0
-0.5
-1.0
-1.0 -0.5 0.0 0.5 1.0
x
1
x
2
Fig. 6.7. K-nearest neighbor classification


================================================================================
PAGE 238
================================================================================

224 Supervised machine learning
Let X be the feature space, e.g., X ⊆ RD, and Y = {0,1,...,K −1}
the set of possible class labels. Based on the zero–one loss function, the
Bayes classifier assigns a test example x ∈X to the class y ∈Y that
∗ ∗
maximizes the posterior probability
Pr(Y =y |X =x )
∗ ∗
Toavoidclutterednotation,weomitthe∗indexthatindicatesrandomvariables
that produce the test data: Y = Y , X = X . To simplify the discussion, we
∗ ∗
only consider the binary classification problem where Y ={0,1}. We can thus
write the Bayes classifier like so:
(
1 if Pr(Y =1|X =x )>Pr(Y =0|X =x )
f: X →Y, f (x )= ∗ ∗
Bayes ∗ 0 otherwise
If the features used for prediction are categorical—i.e., produced by discrete
random variables—we can rewrite the condition for a positive class assignment
using Bayes’ theorem, for any test example x with Pr(X =x )>0:
∗ ∗
Pr(X =x |Y =1) Pr(X =x |Y =0)
∗ ·Pr(Y =1)> ∗ ·Pr(Y =0)
Pr(X =x ) Pr(X =x )
∗ ∗
We can note an equivalent formula:
Pr(X =x |Y =1)·Pr(Y =1)>Pr(X =x |Y =0)·Pr(Y =0)
∗ ∗
For continuous predictor variables, we use the conditional probability density
function:
p (x |1)·p (1)>p (x |0)·p (0)
X|Y ∗ Y X|Y ∗ Y
In other words, the Bayesian decision rule assigns the class for which the
likelihood multiplied by the prior probability has the larger value. So far, we
have not derived anything practical because the distributions are unknown.
However, we can now leverage known methods for parameter and density
estimation (Sect. 4.4). Let us assume that likelihood and prior probability can
be described by suitable statistical models:
p(x |θ )·p (1|α)>p(x |θ )·p (0|α)
∗ 1 prior ∗ 0 prior
In summary, we make the following assumptions:
• The joint probability mass/density function of the predictor variables X
under the condition Y =0 resp. Y =1—i.e. the likelihood function—can
be represented by some statistical model p(·|θ ) resp. p(·|θ ). If this model
0 1
is a (multivariate) normal distribution, the technique is also known as
quadratic discriminant analysis (QDA). If both normal distributions
areassumedtohaveanequalcovariancematrix,thenweusetheterm linear
discriminant analysis (LDA).


================================================================================
PAGE 239
================================================================================

6.3. Classification algorithms 225
• A priori—before the algorithm sees any data—class labels are distributed
according to p (·|α).
prior
We recognize the above rationale as a maximum-a-posteriori estimation (see
Sect. 4.4.2). The model parameters θ ,θ are estimated from the training data.
0 1
If we were to strictly adhere to the Bayesian paradigm presented thus far,
the prior probabilities depended only on the hyperparameters α and would
not be inferred from the data. However, it is very common to estimate the
prior probabilities from the training data as well. This approach is called the
empirical Bayes method.
Example. We present an example that is of little practical importance, but
illustrative.Wewanttopredictthesexofapersonbasedontheirbodyheight
using the CDC dataset [22] as a training dataset. In Sect. 4.4.1, we already
established that for a given sex, the distribution of body height x can be
modeled well by a normal distribution:
p(x|µˆ ,σˆ )=N(x|µˆ ,σˆ2), p(x|µˆ ,σˆ )=N(x|µˆ ,σˆ2)
0 0 0 0 1 1 1 1
where the parameters estimated from the data are µˆ =178cm, σˆ =7.8cm
0 0
for male respondents, and µˆ =163cm, σˆ =7.3cm for female respondents.
1 1
These probability density functions will serve us as likelihood functions.
The prior distribution is a Bernoulli distribution, which we can determine by
one of the following methods:
• Assign a noninformative prior, i.e., p (0)=p (1)= 1.
prior prior 2
• Assign an empirical prior inferred from the proportion of respondents
of male/female sex, irrespective of body height: p (0) = 0.45 and
prior
p (1)=0.55.
prior
Inthisparticularcase,bothmethodsyieldverysimilarpriors.Inthefollowing
model, we assume a noninformative prior. Under these model assumptions,
theBayesiandecisionruleforclassifyingapersonofsize xasfemale becomes:
p(x|µˆ ,σˆ )·p (1)>p(x|µˆ ,σˆ )·p (0)⇔
1 1 prior 0 0 prior
(cid:18) (cid:19) (cid:18) (cid:19)
1 (x−µˆ ) 1 1 (x−µˆ ) 1
√ ·exp − 1 · > √ ·exp − 0 · ⇔
2πσˆ 2σˆ2 2 2πσˆ 2σˆ2 2
1 1 0 0
σˆ |x−µˆ |<σˆ |x−µˆ |
0 1 1 0
The decision boundary is given by the following value:
σˆ µˆ +σˆ µˆ
x= 0 1 1 0 ≈170cm
σˆ +σˆ
0 1
A person with a body height below this value would be classified as female.
This decision boundary is the vertical line drawn in Fig. 4.6.


================================================================================
PAGE 240
================================================================================

226 Supervised machine learning
6.3.3.1 Naive Bayes classification
Given the Bayesian paradigm, a highly simplifying (“naive”) assumption is
that—conditioned on class membership—the predictor variables are mutually
independent. Under that assumption, the likelihood decomposes into a product
over the features.
The (binary) naive Bayes classifier, based on K features and the zero–
one loss function, predicts a positive label for a training example x =
∗
(x ,...,x ) if the following condition holds:
∗1 ∗K
K K
Y Y
Pr(Y =1)· Pr(X =x |Y =1)>Pr(Y =0)· Pr(X =x |Y =0)
k ∗k k ∗k
k=1 k=1
Animportantusecaseistheclassificationofsequences t=(t ,...,t ),where
x1 xK
the t are taken from an inventory of D symbols or strings {t ,...,t }, the
xk 1 D
vocabulary. A more concrete example is the classification of natural language
texts. Through the preprocessing step of tokenization, the text is broken
down into lexical units, the tokens. Often, these tokens are the individual words
that make up the text. The vocabulary then represents the collection of these
tokens.
For example, text case normalization and a simple, punctuation-based tokeniza-
tion would transform the sentence “The vocabulary represents the collection of
tokens.” into the following sequence of strings:
(the, vocabulary, represents, the, collection, of, tokens, .)
An additional simplifying assumption is that class membership is independent
of the order of the tokens: In this case, we speak of the bag-of-tokens model
or, more commonly, the bag-of-words model. The above sentence would then
not be distinguished from the following alphabetical sequence, for example:
(., collection, of, represents, the, the, tokens, vocabulary)
6.3.3.2 Multinomial event model
Under the bag-of-tokens/bag-of-words assumption, there are two principal ways
of statistically modelling the sequence/text. The first considers each sequence of
tokens as a list of categorical variables x=(x ,...,x ) with D possible values,
1 K
where D is the size of the vocabulary: x ∈{1,...,D}.
k
The naive Bayesian decision rule for a test sequence x is then of the following
∗
form:
K K
Y Y
Pr(Y =1)· Pr(X =x |Y =1)>Pr(Y =0)· Pr(X =x |Y =0)
k ∗k k ∗k
k=1 k=1


================================================================================
PAGE 241
================================================================================

6.3. Classification algorithms 227
with x ∈{1,...,D}. The bag-of-tokens assumption implies that a token can
∗k
occuratanypositioninthesequencewiththesameprobability: Pr(X =d|Y =
k
y)=Pr(X =d|Y =y) for all k,l∈{1,...,K}, d∈{1,...,D}, y ∈{0,1}. We
l
introduce the abbreviations q = Pr(Y = 1), p = Pr(X = d|Y = 1), and
d|1 k
p =Pr(X =d|Y =0). Consequently, the decision rule becomes:
d|0 k
q
·
Y K p x∗k|1
>1
1−q p
k=1
x∗k|0
An even clearer formula is the following:
q Y
D (cid:18)p
d|1
(cid:19)n∗d
· >1
1−q p
d|0
d=1
where n is the absolute frequency with which the token t occurs in the
∗d d
sequence t(∗) to be classified. This is the multinomial event model, which
assumes that the occurrence of tokens within a class follows a multinomial
distribution. Taking the logarithm on both sides of the inequality yields the
following decision rule:
D
X (cid:0) (cid:1)
logitq+ n · lnp −lnp >0
∗d d|1 d|0
d=1
where
(cid:18) (cid:19)
q
logit: ]0,1[→R, logit(q)=ln
1−q
is the so-called logit function.
The probabilities occuring in the above formula are estimated from the training
dataset (cid:0)(cid:0) t(1),y (cid:1) ,..., (cid:0) t(N),y (cid:1)(cid:1). The prior probability q can be determined
1 N
via the empirical Bayes method:
N
qˆ= +
N
where N = PN y , the number of sequences with a positive class label.
+ n=1 n
To estimate the likelihood, we construct a data matrix N =(n ), the entries
nd
of which are the absolute frequency of the d-th token in the n-th sequence.
The relative frequency of occurrence of the d-th token in each class gives the
following estimates:
PN+ n(+) PN− n(−)
pˆ = n=1 nd , pˆ = n=1 nd
d|1 PD PN+ n(+) d|0 PD PN− n(−)
d=1 n=1 nd d=1 n=1 nd
Here, n(+) and n(−) are those rows of the data matrix N that are paired with
positive and negative class labels, respectively.


================================================================================
PAGE 242
================================================================================

228 Supervised machine learning
In practice, rare tokens may not occur at all within a certain class, implying an
ill-defined decision rule because of pˆ =0. This challenge can be addressed by
d|1
additive smoothing, which corrects the estimates as follows:
PN+ n(+)+s PN− n(−)+s
pˆ = n=1 nd , pˆ = n=1 nd
d|1,s PD PN+ n(+)+s·D d|0,s PD PN− n(−)+s·D
d=1 n=1 nd d=1 n=1 nd
where s ≥ 0 is the smoothing parameter. The smoothing parameter is a hy-
perparameter, the optimal value of which can be determined, for example, by
cross-validation.Otherwise, s=1isacommonlyusedvalue,whichisalsocalled
Laplace smoothing; s<1 is called Lidstone smoothing [23, Sect. 2.6.3].
6.3.3.3 Bernoulli event model
Alternatively, we can assign a list of binary variables x ,...,x to each
n1 nD
sequence t(n): x =1 if the token t occurs in the sequence, otherwise x =0.
nd d nd
That way, we can write the training sequences into a data matrix X =(x )
nd
with binary entries of format N ×D. This type of representation is called
one-hot encoding and leads to the Bernoulli event model.
Assuming the Bernoulli event model, the naive Bayesian decision rule becomes
the following:
D D
Y Y
Pr(Y =1)· Pr(X =x |Y =1)>Pr(Y =0)· Pr(X =x |Y =0)
d ∗d d ∗d
d=1 d=1
with x ∈{0,1}.
∗d
Using the abbreviations q = Pr(Y = 1), p = Pr(X = 1|Y = 1), and
d|1 d
p = Pr(X = 1|Y = 0), respectively, this decision rule can be written as
d|0 d
follows:
D ( pd|1 if x =1 )
logitq+
X
ln
pd|0 ∗d
=
1−pd|1 if x =0
d=1 1−pd|0 ∗d
X D (cid:18)1−p d|1 +x ∗d ·(2p d|1 −1)(cid:19)
logitq+ ln >0
1−p +x ·(2p −1)
d|0 ∗d d|0
d=1
The likelihood can be estimated from the training dataset by counting tokens/-
words in addition to making use of additive smoothing:
PN+ x(+)+s PN− x(−)+s
pˆ = n=1 nd , pˆ = n=1 nd
d|1,s N +sD d|0,s N +sD
+ −
Here, x(+) and x(−) are those rows of the data matrix X that have positive
and negative class assignments, respectively.


================================================================================
PAGE 243
================================================================================

6.4. Artificial neural networks 229
6.4 Artificial neural networks
Artificial neural networks are machine learning systems used for both
regression and classification tasks. As the name implies, these methods are
inspired by biological nervous systems. In Fig. 6.10, the neural network of the
nematode worm Caenorhabditis elegans is shown for illustration [24, 25]: each
node corresponds to a neuron, each edge to an interneuronal synapse (cf. [26]).
Possibly the first implementation of an artificial neural network, the Mark I
Perceptronwasdevelopedasearlyas1960bypsychologistandcomputerscientist
Frank Rosenblatt [27, 28, 29]. Since about 2010, neural networks have gained
immense importance in the field of machine learning and are used for numerous
tasks for which large or enormous amounts of training data are available. So-
called deep neural networks can have a large or immensely large number of
model parameters, in orders of 104–1011, to learn highly customized classifiers
and regression functions from these training data, yet with an equally high
degree of generalizability.
The simplest form of an artificial neural network can be described as follows.
A feedforward neural network is a member of the family of functions
f: RD0 →RDL, f(u)=(f
L
◦f
L−1
◦···◦f
1
)(u)
where each layer f is a function of the following form:
l
(cid:16) (cid:17)
f
l
: RDl−1 →RDl, f
l
(u)=φ
l
w(l)·u+b(l)
foralll∈{1,...,L},withso-calledactivationfunctionsφ
l
: RDl →RDl ,
matrices of weights w(l) of format D ×D , and the bias vectors
l l−1
b(l) ∈RDl .
The functions f ,...,f represent the neurons of the l-th layer, and
l1 lDl
the value of each function represents the activation of the neuron.
Wemayimaginethatatrivialzerothlayerf : u7→uisaddedtothenetwork,the
0
input layer. The final layer f represents the output layer. The intermediate
L
layerswith1≤l<Larecalledhiddenlayers.Thenumberoflayersdetermines
the depth of the network, and the number of neurons in each layer determines
its width. If the network has more than one hidden layer, i.e., if L>2 applies,
we may speak of deep learning.
A feedforward neural network can be thought of as an acyclic directed graph.
Thefollowingfigureshowsthenode–linkdiagramofafeedforwardnetworkwith
two hidden layers:


================================================================================
PAGE 244
================================================================================

230 Supervised machine learning
input l = 1 l = 2 output
f
11
x
1
f f
12 21
x y
2
f f
13 22
f
14
1 1 1
Fig. 6.8. Feedforward neural network
Each node corresponds to a single neuron. Every neuron of a given layer is
linked to each neuron of the following layer via the weights. These links are
represented as directed edges and could be called synapses. The additional
neuronslabeled“1” representthebiasvectors.Thenumberofmodelparameters
of a neural network is equal to the number of edges in the associated graph; the
network sketched above has 25 parameters.
In principle, any acyclic graph can be used as the architecture of a neural
network. In a residual neural network, synapses may also skip layers [30].
Onepossiblechoicefortheactivationfunctionisasigmoid function,orFermi
function:
(cid:18) (cid:19)
1 1 t
sig: R→R, sig(t)= = · 1+tanh
1+e−t 2 2
The following figure shows the function graph:
1.0
0.8
0.5
0.2
0.0
-10.0 -5.0 0.0 5.0 10.0
t
)t(gis
Fig. 6.9. Sigmoid function


================================================================================
PAGE 245
================================================================================

6.4. Artificial neural networks 231
The sigmoid function is applied to each component of a network layer:
φ
l
: RDl →RDl, φ
l
(u)=(sig(u
1
),sig(u
2
),...,sig(u
Dl
))
Here is the “biological” interpretation of the sigmoid function: a neuron in the
subsequent layer is activated only when the signal transmitted through the
synapse has reached the “threshold potential” t=0.
Another option is to apply a rectifier function, also called the rectified
linear unit (ReLU):
(
t if t>0
rect : R→R, rect (t)=
α α α·t if t≤0
The parameter α≥0 is chosen to have a much smaller value than one—note
that α = 0 and α = 0.01 are popular values. A rectifier with α > 0 is called
a leaky rectifier [31]. The value for α may also be learned during training,
which is called parametric ReLU (PReLU) [32].
The rectifier function is not differentiable at t=0. Many optimization methods
require calculating the derivative, so we may want to use a smooth approxima-
tion:
splus (t)=αt+(1−α)·ln(1+et)
α
In particular for α=0, this is known as the softplus function.
Finally, the softmax function is used in the output layer for classification
tasks; it is defined as follows:
K
!−1
X
smax: RK →RK, smax(u)= euk ·(eu1,eu2,...,euK)
k=1
The values of the softmax function can be interpreted as a probability mass
distributed over the output neurons, for all k ∈{1,...,K} and u∈RK:
K
X
(smax(u)) >0, (smax(u)) =1
k l
l=1
6.4.1 Regression and classification with neural networks
Themodelparametersofanartificialneuralnetworkaretheentriesoftheweight
matrices w(1),...,w(L) and the components of the bias vectors b(1),...,b(L).
Wedenotetheentriesoftheweightmatrix w(l) andofthebiasvector b(l) inthe
l-th layer, 1≤l≤L, by w(l) and b(l) , respectively, where i∈{1,...,D }
ji j l−1
and j ∈{1,...,D }. For the sake of clarity, in reference to these formulas, we
l
also denote the collection of all of these parameters with the letter θ.
According to the empirical risk minimization paradigm, training the neural
network means minimization of the objective function that is the average loss:


================================================================================
PAGE 246
================================================================================

232 Supervised machine learning
N
1 X
R(θ)= λ(y ,f(x ;θ))
N n n
n=1
where (x ,y ),...,(x ,y ) are the training examples and (y,yˆ) 7→ λ(y,yˆ) is
1 1 N N
the loss function.
Iftheneuralnetworkisusedforregressiontasks,λ (y,yˆ)=(y−yˆ)2orλ (y,yˆ)=
2 1
|y −yˆ| are popular loss functions. The simplest neural network imaginable
consists of exactly one output neuron, has no hidden layers, and the identity
map φ: u 7→ u is used as the activation function. Using quadratic loss, the
objective function for this (very simple) network is the following:
N
1 X
R(w ,...,w )= (y −w −w·x )2
0 D N n 0 n
n=1
N D
!2
1 X X
= y −w − w x
N n 0 d nd
n=1 d=1
Since there is only one layer, we have written the weight matrix w(1) =
(w(1) ,...,w(1) ) as a row vector of weights w =(w ,...,w ), and w ∈R is
1 D 1 D 0
the only entry in the distortion vector b(1). Ignoring the constant factor 1/N ,
this expression is the residual sum of squares, the objective function for linear
regression (see Sect. 6.2.1). Therefore, both methods are equivalent: we have
just shown that linear regression is included in the family of neural networks.
For classification tasks, each neuron of the output layer corresponds to one of
the total K classes so that the width of the output layer is D =K. A softmax
L
function ensures that the activation of an output neuron can be interpreted as
a probability for the respective class membership. A suitable loss function for
classification tasks is cross-entropy:
K
X
λ(y,yˆ)=λ(y ,...,y ,yˆ ,...,yˆ )=− y ln(yˆ )
1 K 1 K k k
k=1
Here, y =1 holds if the training example belongs to the k-th class, otherwise
k
y = 0: this is again the one-hot encoding. All summands, except the one
k
corresponding to the true class membership, are zero. However, we might also
want to train fuzzy labels where class membership is not binary but a matter of
degree: 0≤y ≤1 for all k ∈{1,...,K}. For example, label smoothing [33]
k
is a method that implies working with fuzzy training labels. Label smoothing
can lead to improved generalizability of the trained model [34] and works by
granting every training example at least a small but non-zero probability of
membership for every class:
ε
y =(1−ε)·y +
k,ε k K
where ε>0 is a small smoothing parameter.


================================================================================
PAGE 247
================================================================================

6.4. Artificial neural networks 233
Regardless of whether the training labels are fuzzy/soft or hard, the output of
the neural network is generally not a hard class assignment but is a probability
distributionofclassmembership.Thefinalclassifiercanbeobtainedbyselecting
the class with the highest membership probability.
For binary classification, we do not need an output layer with two neurons,
as we can make due with a single sigmoid-activated neuron that outputs a
positiveclassmembershipprobabilitybetweenzeroandone.Forsuchanetwork,
cross-entropy takes the following form:
λ(y,yˆ)=−ylnyˆ−(1−y)ln(1−yˆ)
Given this setup, let us consider once again a very simple and “shallow” neural
network with no hidden layers. The output of this network, given u∈RD, takes
the following form:
f(u;w ,...,w )=sig(w·u+w )
0 D 0
1
=
1+e−(w·u+w0)
where w =(w ,...,w ) is a row vector of weights and w ∈R is the only entry
1 D 0
in the bias vector.
The empirical risk, given a training dataset x ,...,x ∈RD, is therefore the
1 N
following function in the model parameters:
N
X
N ·R(w ,...,w )= λ(y ,f(x ;w ,...,w ))
0 D n n 0 D
k=1
N
X
= λ(y ,sig(w·x +w ))
n n 0
k=1
N
X
=− y ln(sig(w·x +w ))−
n n 0
k=1
N
X
(1−y )ln(sig(−(w·x +w )))
n n 0
k=1
N
X
=− ln(sig((−1)yn(w·x +w )))
n 0
k=1
N
X
= ln(1+exp((−1)yn(w·x +w )))
n 0
k=1
N D !!
X X
= ln 1+exp (−1)yn · w x
d nd
n=1 d=0
We used the following property of the sigmoid function:


================================================================================
PAGE 248
================================================================================

234 Supervised machine learning
1 e−t 1
1−sig(t)=1− = = =sig(−t)
1+e−t 1+e−t 1+et
A comparison with the log-likelihood function ℓ(·) of logistic regression
(Sect. 6.3.1) implies: ℓ(w ,...,w ) = −NR(w ,...,w ). Thus, maximizing
0 D 0 D
this log-likelihood function corresponds exactly to minimizing the training error
of this simple neural network. Finally, the decision rules are also identical,
because due to sig(t)>1/2⇔t>0, we have this formula:
D
1 X
f(x ;wˆ ,...,wˆ )> ⇔ wˆ x >0
∗ 0 D 2 d ∗d
d=0
It is worth summarizing and highlighting those results.
Linear and logistic regression as special neural networks.
Linear regression is equivalent to a feedforward network with no hidden
layers and a single, trivially activated output neuron using quadratic loss.
Logistic regression (without the kernel trick) is equivalent to a feedforward
network with no hidden layers and with a single sigmoid-activated output
neuron using cross-entropy loss.
Fig. 6.11 shows the results of a classification on two similar synthetic datasets
using a neural network. The architecture used for this task is shown in Fig. 6.8:
two hidden layers with four and two neurons, respectively; sigmoid functions
were used as activation functions. The decision boundary is not a straight line:
byaddinghiddenlayers,thenetworkisabletolearnnonlinearclassifiers—unlike
logistic regression, the result of which is a linear classifier.
Linearandlogisticregressionarepartofthehypothesisspaceofneuralnetworks.
What other models can be represented as a neural network? It turns out that
in some sense, all models can be: any continuous function can be approximated
by a suitable neural network. Without proof, we state the following theorems
that make this statement mathematically precise.
Universalapproximationpropertyofneuralnetworksofarbitrary
width [35, Theorem 3.1]. Let φ: R→R be a continuous function, and
W(φ) be the set of feedforward neural networks with a single hidden
φ-activated layer of potentially unlimited width:
K D !
X X
f: RD →R, f(u)= w(2) ·φ w(1) ·u +b
k kd d k
k=1 d=1
with parameters K ∈N and w(1) ,w(2) ,b ∈R.
k kd k
If φ is not a polynomial, then for any ε>0 and any continuous function
g: K → R defined on a compact set K ⊂ RD (e.g., K = [0,1]D) there
exists a function f ∈W(φ) with the following property:


================================================================================
PAGE 249
================================================================================

6.4. Artificial neural networks 235
sup|f(u)−g(u)|<ε
u∈K
Thus, any continuous function can be uniformly approximated on compact
sets by functions in W(φ). Conversely, if W(φ) possesses this universal
approximation property, then φ cannot be a polynomial.
A similar theorem can be proved for deep networks with bounded width.
Universalapproximationpropertyofneuralnetworksofarbitrary
depth and bounded width [36, Theorem 3.2]. Let φ: R→R be a
continuousfunctionthatiscontinuouslydifferentiableinatleastonepoint,
with non-vanishing derivative.
Furthermore, let D(φ) be the set of all feedforward neural networks
f: RD →R of any depth with φ-activated hidden layers, where no layer
consists of more than D+3 neurons.
If φ: R → R is not a linear function—that is, it is not of the form
φ(u)=m·u+c—then D(φ) has the universal approximation property:
Any continuous function g: RD ⊃ K → R, with K compact, can be
uniformly approximated by functions in D(φ).
6.4.2 Training neural networks by backpropagation of error
In order to minimize the training error using gradient descent methods, and
thus determine the optimal model parameters, with each iteration step, the
gradient of a function of the form
M
1 X
R(θ)= λ(y ,f(x ;θ))
M nk nk
k=1
needs to be calculated. Depending on whether a full-batch gradient descent,
stochastic gradient descent, or mini-batch gradient descent is performed, we
have M =N, M =1, or 1<M <N summands, where N is the total number
of training examples.
Because derivation is a linear operation, we can also write the gradient as the
sum of the gradients of each summand. Hence, in the following formula, we
only consider the contribution of a single training example (x ,y ), so we are
n n
interested in calculating the gradient of the function
R (θ)=λ(y ,f(x ;θ)).
n n n
For clarity, instead of the above expression, we write r(θ)=λ(y,f(x;θ)) in the
following calculations.
We can compute the gradient of r(·) by an efficient algorithm known as the
backpropagation of error, or just backpropagation or backprop for short.


================================================================================
PAGE 250
================================================================================

236 Supervised machine learning
Before describing this algorithm, we first introduce a few abbreviations. We
denote the vector of activations in the l-th layer by a(l), so it holds that
a(l) =(f ◦f ◦···◦f )(x)
l l−1 1
for 1 ≤ l ≤ L, and a(0) = x. Furthermore, for each layer, we introduce the
vector of weighted inputs
z(l) =w(l)·a(l−1)+b(l),
so that a(l) =φ (cid:0) z(l)(cid:1) where φ is the activation function of the l-th layer.
l l
Finally, we will denote the loss function with respect to the training example y
by Λ, i.e.: Λ(·)=λ(y, ·).
Backpropagation computes the gradient of the objective function of
a feedforward neural network by performing the following steps (cf. [37,
Chap. 2]):
1. Input. Activate the input layer a(0) =x, and set the current values of
the model parameters w(l) and b(l) .
ji j
2. Feedforward. For l = 1,...,L, successively compute the weighted
inputs and activations: z(l) =w(l)·a(l−1)+b(l) and a(l) =φ (z(l)).
l
3. Output error. Compute ∆(L) :=(Dφ (z(L)))T ·∇Λ(a(L)).
L
4. Backpropagation of error. For l=L−1,L−2,...,1, successively
compute ∆(l) =(Dφ (z(l)))T ·(w(l+1))T ·∆(l+1).
l
5. Output. Finally, the gradient of the objective function is given by the
following partial derivatives:
∂r ∂r
=∆(l) ·a(l−1) , =∆(l)
∂w(l) j i ∂b(l) j
ji j
for all l∈{1,...,L}, i∈{1,...,D }, and j ∈{1,...,D }.
l−1 l
At the first iteration step of the gradient descent, the model parameters need
to be initialized. In practice, one common method is the following:
• Set every bias b(l) to zero,
j
• for each layer—say, the l-th layer with D input neurons and D output
l−1 l
neurons—initialize the weights w(l) by drawing random, i.i.d. values from
ji
adistribution(forexample,uniformornormal)withzeromeanandvariance
σ2.
l
If σ2 = 2(D + D )−1, this initalization scheme may be called Glorot
l l−1 l
initalization, also known as Xavier initialization [38]. If the variance is
σ2 =2(D )−1, it may be called He initialization [32]. Glorot initialization
l l−1
is recommended when using sigmoidal activations, while He initialization is
geared towards the use of ReLUs.


================================================================================
PAGE 251
================================================================================

6.4. Artificial neural networks 237
The backpropagation algorithm is based, firstly, on the observation that the
change in the loss function with varying weights and bias in the l-th layer can
be expressed by the change in the weighted inputs in that layer alone. This fact
follows from the chain rule for partial derivatives:
∂r = X Dl ∂r · ∂z(l) k
∂w(l) ∂z(l) ∂w(l)
ji k ji
k=1
 
X Dl ∂r ∂ D Xl−1
= ∂z(l) · ∂w(l)  w(l) km a(l−1) m +b(l) k
k ji
k=1 m=1
∂r
= ·a(l−1) ,
∂z(l) i
j
∂r = X Dl ∂r · ∂z(l) k = ∂r
∂b(l) ∂z(l) ∂b(l) ∂z(l)
j k j j
k=1
The activations a(l−1) are calculated during the feedforward step. We still
i
need to compute the partial derivatives ∂r/∂z(l)
j
. We combine them into column
vectors, one for each layer:
(cid:18)
∂r ∂r
(cid:19)T
∆(l) = ,...,
∂z(l) ∂z(l)
1 Dl
We can compute the transpose of those vectors via the chain rule for Jacobians:
(∆(L))T =DΛ(a(L))·Dφ (z(L)),
L
(∆(L−1))T =DΛ(a(L))·Dφ (z(L))·w(L)·Dφ (z(L−1)),
L L−1
.
.
.
(∆(l))T =DΛ(a(L))·Dφ (z(L))·w(L)·Dφ (z(L−1))····
L L−1
·w(l+2)·Dφ (z(l+1))·w(l+1)·Dφ (z(l))
l+1 l
.
.
.
(∆(1))T =DΛ(a(L))·Dφ (z(L))·w(L)·Dφ (z(L−1))····
L L−1
·w(3)·Dφ (z(2))·w(2)·Dφ (z(1))
2 1
Derivatives of inner functions are successively multiplied from the right side
in order to produce the error terms ∆(l): the error is propagated backwards
along the network from the output layer in the direction of the input layer.
Multiplication from the left side is the more common representation, which we
can derive by taking the transpose:


================================================================================
PAGE 252
================================================================================

238 Supervised machine learning
∆(L) =(Dφ (z(L)))T ·∇Λ(a(L)),
L
∆(L−1) =(Dφ (z(L−1)))T ·(w(L))T ·∆(L),
L−1
.
.
.
∆(l) =(Dφ (z(l)))T ·(w(l+1))T ·∆(l+1)
l
.
.
.
∆(1) =(Dφ (z(1)))T ·(w(2))T ·∆(2)
1
6.4.2.1 Dropout
Dropout is a stochastic modification of backpropagation that is an effective
and simple method to avoid overfitting. The idea is to use only part of the
network during training, which is randomly selected with each iteration step
[39].
Given dropout probabilities 0 ≤ q < 1 for each hidden layer l ∈
l
{1,...,L−1}, the propagation algorithm is modified as follows:
1. With each iteration during the feedforward step, disable a random
selection of neurons:
a) For each index d∈{1,...,D }, select ρ(l) ∈{0,1} independently
l d
at random where q is the probability for the outcome ρ(l) =0.
l d
b) Set z(l) =w(l)·a(l−1)+b(l) and (a(l)) =ρ(l) ·(φ (z(l))) for all
d d l d
d∈{1,...,D }.
l
2. Disabled neurons are ignored when calculating backpropagated errors:
only weights w(l) and biases b(l) with ρ(l−1) =ρ(l) =1 or ρ(l) =1
ji j i j j
are updated.
3. After the training is complete, all weights in the l-th layer are scaled
by a factor of 1−q .
l
The dropout probabilities q ,...,q can be interpreted as new hyperparam-
1 L−1
eters of the model. They only affect the training process: when applying the
final, trained model, all neurons remain enabled.
6.4.3 Convolutional neural networks
Convolutional neural networks(CNNs)arespecialartificialneuralnetworks
that are well-suited for the automated classification of digital images. In this
section, we introduce the basic ideas behind their architecture.
A digital image can be represented as a three-dimensional grid of pixels M
with width B, height H, and a depth of T color channels. Each pixel with
spatial position (i,j) is assigned a color value M(i,j,t) in color channel t where


================================================================================
PAGE 253
================================================================================

6.4. Artificial neural networks 239
70AD
LNLP LVBMS RVAAS LDAAS LDBMS
LNIA RNIA
LD2LI
RDFA LDFA
RVA R R E U MR VE LV M AR R U LEMR
LP LD I A R RU
LD1LI
LVAIS
LD L AI B S IR LDBISLVBIS
LAUA
RAUA
RYIA RAWA LYIA RESA LBIA LAWA L L Z G I SA A RHMR RQDS
RD1LI RDARU RPIR
DEMR RDQLO
LDQLO
LDPEC LBRU LVQLO
L1LI LV1LI L2L LV I 2LI
RGAB LGAB
RIR
RBWA
RZI R A GSA
RAIA RCWA R LC B W I A A LESA RISA LISA LAIA LMIA RDBIS RVBIS LHMR
RVIR
LVIR
RVDMS L R A A IR IR L L V D D D M M S S RD R YR D U DMS
L R D V R Y Y L R R V U U D D D R M M D R L R D V M D R MR
L R R D D AI L B S M VY I R R R U
RDM
HI R R RV R A V I Q S LO R L R V V P E P S E R E C C B I V R R R X U A RU
L R LL LL O O R2L R I GI R L R D G BM IR S LNLA L L V R F A F A M M S R R RKVA
RV L B M M I S R R D L A K AS R V N L L A A EDA
R RE M L D E IR A VA
L R P C L L F I Q R D R S GMR
RAD
R A L M L C M IA L I A R RKSA
M L V X A RU RH RM S L L A A GM MV R P RUD L B HSA L L V U A DB L L FD A L A L B D W N A A V R P N R V R Q N P V S P H LJVA L R N F S IR H R L F L V K L H A Q R S V A J V P S A A LF L V J G S A A VA LAHP RH RA V H A P LLD R R L A D V A 1LI
R1LI
LWVP
RNLP
80SA
RD2LIRDPEC
ALA
RPLF
LFIR RJVA RDVA RQP LEDP
REDP
90DV
DIR
60AD
LPVP LDVA RAUL RMLP RVP
RV2LI 10SA
3 1 0 0 A B V V DBAS 10AV 20 1 A 0 V DV 2 4 0 2 0 A A 0 D V S 2 A 0DV 10DD
30DV 10 2 B 3 3 0 0 B 0 B D S V A V
70A 4 V 0 1 D 2 0 V 0 CV DD 40CV
20C 3 V 0 3 5 C 0 0 5 D D 0 V D V CV 40BV
50AV
C 5 4 0 V T B 0B V D V D P
RP
R V WV 5 P P 0AD 70BV L 4 B 6 0D 0 D SA V R 8 A 0 B DV 70S V A 0 A 1S 8 A 0A L 6 V 0BV AV 50 4 S 0 A S R A A 01AAV LB V 3 3 H 0 0 P A B D 4 D 0 A A R D BHP 20B L D DVP RDVP 10A L R L D VB Q C AS R A V V R B P AS C 60 V BD P 50BD AVD 70 R B F D DA 31DV
RCHP
LA B U D L P 11 L S C A HP 21 9 L 0 A M A V D L A P DP 11BV
60DD 8 2 0 1 A D D V
0 1 1 1 B A V V
BVD
11DV
90SA
60AV
60DV
70DV 90AV 80BV 50D 9 D 0BV 01DV
)etidorhpamreh(
snagele
sitidbahroneaC
edotamen eht fo sespanys laruenretni
dna
snorueN
.01.6
.giF


================================================================================
PAGE 254
================================================================================

240 Supervised machine learning
0,5
0,0
-0,5
-0,5 0,0 0,5 1,0
x
1
x
2
1.0
0.5
0.0
-0.5
-1.0
-1.0 -0.5 0.0 0.5 1.0
x
1
x
2
Fig. 6.11. Classification with an artificial neural network


================================================================================
PAGE 255
================================================================================

6.4. Artificial neural networks 241
j ∈ {1,...,B}, i ∈ {1,...,H}, t ∈ {1,...,T}. For example, a high-resolution
color image might have a width of B = 1920 pixels, a height of H = 1080
pixels, and a depth of T = 3 color channels. Usually the format of a digital
images is specified as width-times-height. However, to stay consistent with the
mathematical convention for matrix formats, we will note the number of pixel
rows, i.e., the height, first.
Let us call any abstract numerical grid with three dimensions—regardless of
whether it represents a human-readable image—a feature map, or an activa-
tion map. In a convolutional neural network, the input image is transformed
into new feature maps with each layer. These transformations are implemented
through two key operations, convolution and pooling, which we will describe
in more detail below.
A convolution mask of bandwidth 2F +1, F ∈N is a square feature map of
the format (2F +1)×(2F +1)×T. The typical values for convolution masks
used in practice are F =1 or F =2. For convolution masks, we want to index
the width and height symmetrically around zero: −F,...,−1,0,1,...,F—this
convention makes the definition of the following operation clearer.
Thetwo-dimensional convolution,or2D convolution,ofanimage/ac-
tivation map M of format H ×B×T with a convolution mask κ of the
format (2F +1)×(2F +1)×T yields the following new feature map of
format H ×B×1:
T F F
X X X
(M ⋆κ)(i,j,1)= M(i+f ,j+f ,t)·κ(f ,f ,t)
1 2 1 2
t=1f1=−Ff2=−F
for all j ∈{1,...,B} and i∈{1,...,H}.
Whenever the summation index (i+f ,j +f ) leaves the boundaries of the
1 2
image/activation map M, we assume the color values of M to be zero. In other
words, we think of the exterior of M as empty or black pixels—this is called
padding.
2D convolution is a linear map over the vector space of feature maps of a
fixed format—for any convolution mask κ, arbitrary feature maps M ,M , and
1 2
scalars λ∈R:
(M +M )⋆κ=M ⋆κ+M ⋆κ, (λ·M )⋆κ=λ·(M ⋆κ)
1 2 1 2 1 1
Addition and scalar multiplication are to be understood as pixel-wise.
The above definition of the convolution operation is commonly used in deep
learning literature. However, in the fields of signal and image processing, the
above operation is often referred to as cross-correlation, and the following
operation for images of format H ×B is commonly known as convolution:


================================================================================
PAGE 256
================================================================================

242 Supervised machine learning
F F
X X
(M ∗k)(i,j)= M(i−f ,j−f )·κ(f ,f )
1 2 1 2
f1=−Ff2=−F
Cross-correlation is convolution with a mirrored convolution mask, and vice
versa.Thissubtletyplaysaminorrolewhenimplementingaconvolutionalneural
network, since the entries of the convolution mask are the model parameters
and are learned during training. Nevertheless, the different conventions may
cause confusion when studying the subject.
Fig. 6.12. 2D convolution in image processing
The above illustration shows the results of applying various convolution filters
that are commonly used in image processing. The convolution masks applied to
the original photo [40] (from left to right in the figure) are the following:
   
1 2 1 0 1 0
κ
1
= 0 0 0 , κ
2
=1−41
−1−2−1 0 1 0
   
2 1 0 111
1
κ
3
=1 1 −1, κ
4
=
9
·111
0−1−2 111
The first two convolution masks are the horizontal Sobel operator and the
discrete Laplace operator. Both are used in image processing for edge
detection. These are followed by the emboss filter and the mean filter. The
mean filter calculates the average color/gray value in the neighborhood of each
pixel, which results in a blurring of the image.
For all image filters based on convolution, only the neighborhood of a pixel
determines the value of the filtered image at that location. The result is a
feature map that reflects local image features, such as edges. The basic idea of
a convolutional neural network is to let it learn on its own which filters/features
are best suited for characterizing and classifying image information.
Reducingimageresolutionisanotherimportantoperationwithinaconvolutional
neural network. One option is to introduce a stride s>1 that skips pixels:
(M ⋆ κ)(i,j)
s
F F
X X
= M(1+s·(i−1)+f ,1+s·(j−1)+f )·κ(f ,f )
1 2 1 2
f1=−Ff2=−F


================================================================================
PAGE 257
================================================================================

6.4. Artificial neural networks 243
with j ∈{1,...,⌊B/s⌋}, i∈{1,...,⌊H/s⌋}.
Anotheroptionconsistsofpartioningthefeaturemapintopatchesandselecting
only the largest activation in each patch.
Maximum pooling, or max pooling, an activation map M of format
B×H×T,withevennumbersB andH,consistsofthefollowingoperation:
max-pool(M)(i,j,t)= max {M(2i−1+k,2j−1+l,t)}
k,l∈{0,1}
for all j ∈{1,...,⌊B/2⌋}, i∈{1,...,⌊H/2⌋}, t∈{1,...,T}.
The operations on images/feature maps defined above represent the most
essential components of a convolutional neural network. The architecture of
such a network is an arrangement of the following types of layers:
• A convolution layer convolves the input map M of format H ×B×T
with convolution masks κ ,...,κ of the format (2F +1)×(2F +1)×T,
1 K
and each convolution comes with a global bias b ,...,b ∈R that is to be
1 K
added to every entry of the input map. Then, an activation function φ is
applied (usually pixel-wise). These operations produce K new images or
feature maps of the format H ×B×1:
φ(M ⋆κ +b ),...,φ(M ⋆κ +b )
1 1 K K
These K activation maps are concatenated to yield the output, a feature
map of the format H×B×K. The entries of the convolution mask and the
biases represent the model parameters to be learned.
• Apoolinglayerthatperformsmaximumpoolingwhichreducesthesize/res-
olution of the input.
• Afully-connectedlayerfirstappliesaflatteningoperation:theinputgrid
M is reshaped into a (long) vector flatten(M) of length D =H·B·T. This
vector is processed by an affine transformation, followed by an activation
function—an operation that we already know from ordinary feedforward
networks:
φ(w·flatten(M)+b)
with a matrix of weights w of format K×D and a bias vector b of length K.
Foreachoftheselayers,thefollowingtableliststhenumberofmodelparameters
and the format of the output map, given an input map of format H ×B×T:
layer type nb. model parameters output format
convolution, K masks K·(T ·(2F +1)2+1) H×B×K
max pooling 0 ⌊B/2⌋×⌊H/2⌋×T
fully-connected, width K K·(H·B·T +1) 1×1×K
Table 6.4. Layer types of a convolutional neural network


================================================================================
PAGE 258
================================================================================

244 Supervised machine learning
Afully-connectedlayerappliesanaffinemapthatcan,inprinciple,bearbitrary:
M 7→w·flat(M)+b
A convolution layer also applies an affine map but is only allowed to draw from
the family of convolutions (plus a shift/bias):
M 7→M ⋆κ+b
Therefore, the number of model parameters to be trained in a convolution layer
is usually much smaller than in a fully-connected layer, given the same input.
A typical architecture of a convolutional neural network consists of alternating
the execution of convolutional and pooling layers, the output of which is even-
tually processed by one or more fully-connected layers. Fig. 6.13 illustrates the
VGG-164 architecture [41], which in 2014 achieved an accuracy of 74.4% on the
ImageNet dataset [2, 42]. As of 2022, state-of-the-art architectures achieve an
accuracy of more than 88% on ImageNet [43].
4 VGG-16 stands for Visual Geometric Group of the University of Oxford, 16 layers


================================================================================
PAGE 259
================================================================================

6.4. Artificial neural networks 245
61-GGV
krowten
laruen
lanoitulovnoc
eht
fo
erutcetihcrA
.31.6
.giF


================================================================================
PAGE 260
================================================================================

246 Supervised machine learning
References
[1] ISO Central Secretary. Information technology – Vocabulary. Standard
ISO/IEC 2382:2015. Genf, Schweiz: International Organization for Stan-
dardization, 2015, p. 2121376.
[2] Jia Deng et al. “ImageNet: A large-scale hierarchical image database”.
In: IEEE Conference on Computer Vision and Pattern Recognition. 2009,
pp. 248–255. doi: 10.1109/CVPR.2009.5206848.
[3] Chen Sun et al. “Revisiting unreasonable effectiveness of data in deep
learningera”.In:2017IEEEInternationalConferenceonComputerVision
(ICCV). Venice: IEEE, Oct. 2017. arXiv:1707.02968.
[4] Andriy Burkov. Machine Learning Engineering. True Positive, Sept. 2020.
[5] Martin Popel et al. “Transforming machine translation: a deep learning
system reaches news translation quality comparable to human profes-
sionals”. In: Nature Communications 11.1 (Sept. 2020), p. 4381. doi:
10.1038/s41467-020-18073-9.
[6] David Silver et al. “Mastering the game of Go without human knowledge”.
In: Nature 550.7676 (Oct. 2017), pp. 354–359. doi: 10.1038/nature24270.
[7] Berkeley Earth. Time Series Data – Monthly Global Average Temperature
(Annual Summary). Accessed Feb. 1, 2020. url: http://berkeleyearth.
org/data/.
[8] Pierre Baldi et al. “Assessing the accuracy of prediction algorithms for
classification: an overview”. In: Bioinformatics 16.5 (May 2000), pp. 412–
424. doi: 10.1093/bioinformatics/16.5.412.
[9] W. J. Youden. “Index for rating diagnostic tests”. In: Cancer 3.1 (1950),
pp. 32–35. doi: 10.1002/1097-0142(1950)3:1<32::aid-cncr2820030106>3.
0.co;2-3.
[10] Jonathan Barzilai and Jonathan M. Borwein. “Two-Point Step Size Gradi-
entMethods”.In: IMA Journal of Numerical Analysis 8.1(1988),pp.141–
148. doi: 10.1093/imanum/8.1.141.
[11] Charles George Broyden. “The Convergence of a Class of Double-rank
Minimization Algorithms 1. General Considerations”. In: IMA Journal of
Applied Mathematics 6.1 (1970), pp. 76–90. doi: 10.1093/imamat/6.1.76.
[12] Roger Fletcher. “A new approach to variable metric algorithms”. In: The
Computer Journal 13.3 (Mar. 1970), pp. 317–322. doi: 10.1093/comjnl/
13.3.317.
[13] Donald Goldfarb. “A family of variable-metric methods derived by varia-
tionalmeans”.In:MathematicsofComputation24.109(Jan.1970),pp.23–
23. doi: 10.1090/s0025-5718-1970-0258249-6.
[14] DavidF.Shanno.“Conditioningofquasi-Newtonmethodsforfunctionmin-
imization”. In: Mathematics of Computation 24.111 (Sept. 1970), pp. 647–
647. doi: 10.1090/s0025-5718-1970-0274029-x.
[15] Larry Armijo. “Minimization of functions having Lipschitz continuous
first partial derivatives”. In: Pacific Journal of Mathematics 16.1 (Jan.
1966), pp. 1–3. doi: 10.2140/pjm.1966.16.1.
[16] Roger Fletcher. Practical methods of optimization. 2nd ed. Wiley, 1987.


================================================================================
PAGE 261
================================================================================

References 247
[17] JanR.Magnus.MatrixDifferentialCalculuswithApplicationsinStatistics
and Econometrics. 3rd ed. Wiley, Feb. 2019. doi: 10.1002/9781119541219.
[18] D. Randall Wilson and Tony R. Martinez. “Reduction Techniques for
Instance-Based Learning Algorithms”. In: Machine Learning 38 (2000),
pp. 257–286. doi: 10.1023/a:1007626913721.
[19] Thomas Hofmann, Bernhard Schölkopf, and Alexander J. Smola. “Kernel
methods in machine learning”. In: The Annals of Statistics 36.3 (2008),
pp. 1171–1220. doi: 10.1214/009053607000000677.
[20] MehryarMohri,AfshinRostamizadeh,andAmeetTalwalkar. Foundations
of Machine Learning. 2nd ed. MIT Press, 2018.
√
[21] microhaus. Why is k = N a good solution of the number of neighbors to
consider? Cross Validated. July 2021. url: https://stats.stackexchange.
com/q/535051.
[22] CDC Population Health Surveillance Branch. Behavioral Risk Factor
Surveillance System (BRFSS) Survey Data 2018. Accessed Feb. 1, 2020.
url: https://www.cdc.gov/brfss/.
[23] Sebastian Raschka. Naive Bayes and Text Classification I – Introduction
and Theory. Feb. 2017. arXiv:1410.5329v4.
[24] David H. Hall, Zeynep F. Altun, and Laura A. Herndon. Wormatlas.
Neuronal Wiring. Accessed Dec. 30, 2020. New York, USA. url: https:
//www.wormatlas.org/neuronalwiring.html.
[25] Lav R. Varshney et al. “Structural Properties of the Caenorhabditis
elegans Neuronal Network”. In: PLoS Computational Biology 7.2 (Feb.
2011). Ed. by Olaf Sporns, e1001066. doi: 10.1371/journal.pcbi.1001066.
[26] Gang Yan et al. “Network control principles predict neuron function in
the Caenorhabditis elegans connectome”. In: Nature 550.7677 (Oct. 2017),
pp. 519–523. doi: 10.1038/nature24056.
[27] Frank Rosenblatt. “The perceptron: A probabilistic model for information
storage and organization in the brain.” In: Psychological Review 65.6
(1958), pp. 386–408. doi: 10.1037/h0042519.
[28] Frank Rosenblatt. Principles of Neurodynamics. Perceptrons and the
Theory of Brain Mechanisms. Washington, D.C., USA: Spartan Books,
1962.
[29] Melanie Lefkowitz. “Professor’s perceptron paved the way for AI – 60
years too soon”. In: Cornell Chronicle (Sept. 2019). url: https://news.
cornell.edu/stories/2019/09/professors-perceptron-paved-way-ai-60-
years-too-soon.
[30] Kaiming He et al. “Deep Residual Learning for Image Recognition”. In:
2016 IEEE Conference on Computer Vision and Pattern Recognition
(CVPR). IEEE, June 2016. doi: 10.1109/cvpr.2016.90. arXiv:1512.03385.
[31] Andrew L. Maas, Awni Y. Hannun, and Andrew Y. Ng. “Rectifier nonlin-
earities improve neural network acoustic models”. In: ICML Workshop on
Deep Learning for Audio, Speech and Language Processing. 2013.
[32] Kaiming He et al. Delving Deep into Rectifiers: Surpassing Human-Level
Performance on ImageNet Classification. 2015. doi: 10.48550/ARXIV.
1502.01852.


================================================================================
PAGE 262
================================================================================

248 Supervised machine learning
[33] Christian Szegedy et al. “Rethinking the Inception Architecture for Com-
puterVision”.In:2016IEEEConferenceonComputerVisionandPattern
Recognition (CVPR). IEEE, June 2016. doi: 10.1109/cvpr.2016.308.
arXiv:1512.00567.
[34] Rafael Müller, Simon Kornblith, and Geoffrey E Hinton. “When does
label smoothing help?” In: Advances in Neural Information Processing
Systems. Ed. by H. Wallach et al. Vol. 32. Curran Associates, Inc., 2019,
pp. 4694–4703. arXiv:1906.02629.
[35] Allan Pinkus. “Approximation theory of the MLP model in neural net-
works”. In: Acta Numerica 8 (Jan. 1999), pp. 143–195. doi: 10.1017/
s0962492900002919.
[36] Patrick Kidger and Terry Lyons. “Universal Approximation with Deep
Narrow Networks”. In: 33rd Conference on Learning Theory. Ed. by
Jacob Abernethy and Shivani Agarwal. Vol. 125. Proceedings of Machine
Learning Research. PMLR, July 2020, pp. 2306–2327. arXiv:1905.08539.
[37] Michael A. Nielsen. Neural networks and deep learning. Determination
Press, 2015. url: http://neuralnetworksanddeeplearning.com/.
[38] XavierGlorotandYoshuaBengio.“Understandingthedifficultyoftraining
deep feedforward neural networks”. In: Proceedings of the Thirteenth
International Conference on Artificial Intelligence and Statistics. Vol. 9.
PMLR. 2010, pp. 249–256.
[39] Nitish Srivastava et al. “Dropout: A Simple Way to Prevent Neural
Networks from Overfitting”. In: J. Mach. Learn. Res. 15.1 (Jan. 2014),
pp. 1929–1958.
[40] Allan G. Weber. The USC-SIPI Image Database: version 6. Tech. rep.
Los Angeles, USA: Signal and Image Processing Institute, University of
Southern California, Feb. 2018. url: http://sipi.usc.edu/database.
[41] Karen Simonyan and Andrew Zisserman. “Very Deep Convolutional Net-
worksforLarge-ScaleImageRecognition”.In:3rdInternationalConference
on Learning Representations, San Diego, USA. Ed. by Yoshua Bengio and
Yann LeCun. May 2015. arXiv:1409.1556.
[42] Olga Russakovsky et al. “ImageNet Large Scale Visual Recognition Chal-
lenge”.In:International Journal of Computer Vision (IJCV) 115.3(2015),
pp. 211–252. doi: 10.1007/s11263-015-0816-y. arXiv:1409.0575.
[43] Papers with Code Community. ImageNet Benchmark (Image Classifica-
tion). Ed. by Robert Stojnic et al. Accessed Oct. 10, 2022. url: https:
//paperswithcode.com/sota/image-classification-on-imagenet.


================================================================================
PAGE 263
================================================================================

7
Unsupervised machine learning
Supervisedmachinelearningmethodsderiveadecisionrulef: X →Y bymaking
generalizations from the patterns observed in an annotated dataset (X ×Y)N
where Y =R or Y ={0,1,...,K −1} is the space of target values/labels. In
unsupervised learning, the input data is not annotated: none of the features
of the dataset to be analyzed are distinguished a priori as the target variable or
class label.
There are two major methods used in unsupervised learning:
• Thegoalofadimensionalityreductionistoreducethenumberoffeatures
without significantly changing key characteristics of the data, such as the
distances between data points. Dimensionality reduction can be understood
as an unsupervised analogue to regression.
• Cluster analysis aims to group the dataset into sets of similar data
records/information objects. Cluster analysis is thus similar to the task
of classification—except that the cluster labels are not included with the
training data but are learned by the algorithm from the structure of the
input data alone.
In the first section of this chapter, we deal with the geometric and topological
views on data. This perspective serves as an introductory motivation of dimen-
sionality reduction and for cluster analysis methods, which will be explained in
the following sections.
7.1 Elements of unsupervised learning
Given a sequence or set of data points x ,x ,...,x ∈ RD, we have already
1 2 N
seen that adopting a geometric view is often useful for a better understanding
of the algorithms and methods we employ. To give a few examples: The K-
nearest-neighbor classifier exploits the view of data points as objects spaced
at certain distances. Affine subspaces also play an important role: the result
© Springer-Verlag GmbH Germany, part of Springer Nature 2023 249
M. Plaue, Data Science, https://doi.org/10.1007/978-3-662-67882-4_7


================================================================================
PAGE 264
================================================================================

250 Unsupervised machine learning
of a linear regression is a hyperplane in feature space, and a linear classifier
separates classes by such hyperplanes.
7.1.1 Intrinsic dimensionality of data
Let us look again at scatter plots of strongly correlated features, for example
Fig. 2.3 or Fig. 6.3. In these cases, the data points do not scatter arbitrarily
in all directions in the plane, but instead they are close to a regression line or,
more generally, regression curve. Thus—except for a small amount of random
dispersion—the position of a data point can be described as a point along that
curve. In this way, the dimensionality of the dataset was effectively reduced
from two (the feature space spanned by the dependent and the independent
variable) to one (the position along the regression curve).
The following theorem gives a general indication of whether we may hope to
find a given number of data points near a subspace that has low dimensionality.
Johnson–Lindenstrauss lemma [1]. Let x ,...,x ∈ RD be data
1 N
points and ε∈]0,1[ be a (small) number. Furthermore, let K ∈N be such
that:
(cid:18) ε2 ε3(cid:19)−1
K ≥4· − ·lnN
2 3
Then, there exists a linear map f: RD → RK so that for all m,n ∈
{1,...,N} the following bound holds:
(1−ε)·∥x −x ∥2 ≤∥f(x )−f(x )∥2 ≤(1+ε)·∥x −x ∥2
m n m n m n
For small values of ε, the pairwise distances between data points are nearly
preserved under the map f. A less strict bound for the target dimension, but
perhaps easier to remember, is K ≥20·ε−2·lnN if 0<ε<0.9 (cf. [2, Lemma
15.4]).
We roughly sketch the idea of the proof. First, we randomly choose a K-
dimensional subspace of RD. If proj(·) denotes the orthogonal projection onto
that subspace, it can be shown that the map f(v):= p D/K·proj(v), v ∈RD,
satisfies the desired bound with a probability of at least 1/N . In particular,
the probability is strictly greater than zero—thus, there must exist a random
projection that satisfies the desired bound with certainty.
The estimated target dimension K does not depend on the original dimension-
ality D, and it depends only logarithmically on the number of data points N.
We illustrate this fact with an example: We are given a dataset of N =10,000
digital color photographs with a resolution of 1920×1080 pixels. Given three
color channels, D =1920·1080·3=6,220,800 color values must be stored for
each uncompressed photo: each image can be represented as a vector in a space
with a dimension of about 6 million.


================================================================================
PAGE 265
================================================================================

7.1. Elements of unsupervised learning 251
However, the lemma of Johnson and Lindenstrauss implies that the intrinsic
dimensionality is much lower: there exists a projection f: RD → RK with
K =7895 such that the squared distances between the projected data points
do not differ by more than ε=10% from the squared distances in the original
data. This potential reduction in dimensionality changes very little with the
size of the dataset. For example, even a dataset of N =1,000,000 photographs
has an intrinsic dimensionality of at most K ≈12,000.
Notethatweassumednothingaboutthedistributionoftheoriginaldatapoints:
the contents of the photos could be arbitrary, or consist only of image noise.
Furthermore, the theorem is only considered with the linear transformation
of the data. Therefore, in practice, we can expect the intrinsic dimensionality
of any given data to be significantly smaller than what is suggested by the
Johnson–Lindenstrauss bound.
The construction of a low-dimensional representation of data is the task of
dimensionality reduction algorithms, the result of such a reduction is some-
times referred to as an embedding. Embeddings commonly used in image
analysis [3] or text analysis [4] may have a dimensionality of only a few hundred
components.
7.1.2 Topological characteristics of data
According to the Johnson–Lindenstrauss lemma, data points of dimensionality
D lie near a K-dimensional linear subspace. In practice, it often turns out that
the intrinsic dimensionality K can be assumed to be much smaller than the
extrinsic dimensionality D.
This insight is not limited to linear subspaces: it can be extended to more
generalcurves,surfaces,ortheirhigher-dimensionalanalogues.Forexample,the
following scatter plots show two (synthetic) datasets, both distributed around a
closed curve:
1.0
0.5
0.0
-0.5
-1.0
-1.0 -0.5 0.0 0.5 1.0 -1.0 -0.5 0.0 0.5 1.0
Fig. 7.1. Data points along a curve


================================================================================
PAGE 266
================================================================================

252 Unsupervised machine learning
Geometrically, both curves are quite different: the left one is a circle with
constant radius, the right curve has variable curvature. However, the qualitative
shape is the same: both are continuous, closed curves that we can imagine
could be transformed into each other by continuous deformation. Topology is
the mathematical discipline devoted to the study of qualitative shape, jokingly
called “rubber-sheet geometry.”
Animportanttopologicalpropertyisconnectedness,thepossibilitytodecompose
a set into connected parts.
Let U be a subset of RD. A set V ⊆U is called a path-component of U
if the following holds:
1. For all x,y ∈V, there exists a continuous curve that lies entirely in V
and connects x to y.
2. There is no set W different from V with V ⊂ W ⊆ U that also has
the above property.
It can be proved that instead of arbitrary continuous curves it is sufficient to
consider polygonal chains. The path-components form a partition of U, i.e.,
they are pairwise disjoint and cover U. The sets studied in data analysis usually
have only finitely many path-connected components S ,...,S :
1 K
U =S ∪···∪S , S ∩S =∅
1 K k l
for all k,l∈{1,...,K}.
A finite set of N data points U = {x ,...,x } ⊂ RD has always exactly N
0 1 N
path-components: S ={x }, n∈{1,...,N}. Indeed, any path between two
n n
different data points necessarily leads out of the set. Thus, the notion does
not seem to represent any particular advance in the analysis of the topological
structure of the data. Consider instead the following cover of U by balls of
0
radius ε > 0, centered around each data point: U = B (x )∪···∪B (x )
ε ε 1 ε N
where
B
ε
(x
n
)=
(cid:8) u∈RD(cid:12)
(cid:12)∥u−x
n
∥≤ε
(cid:9)
for all n∈{1,...,N}.
Fig. 7.2 shows an example of such a cover for different values of ε (for D =
2, the covering balls are disks) given a synthetic dataset. The number of
path-components of U decreases with increasing disk radius ε. Each of these
ε
components represents a grouping of data points that are close in feature
space, and which are called clusters. The goal of a cluster analysis is the
identification of such clusters.
Clusters are the simplest, but not the only topological features that can be
identified in data. For example, the largest cover in Fig. 7.2 reveals a ring
structure,ora“hole” inthedata.Therelativelyyoungdisciplineof topological
data analysis is concerned with the identification of such structures and their
higher-dimensional analogues [5, 6, 7, 8].


================================================================================
PAGE 267
================================================================================

7.1. Elements of unsupervised learning 253
K
tnuoc
retsulc
dna
ε
suidar
gniyrav
htiw
sksid
yb
stniop
atad
gnirevoC
.2.7
.giF
5.1 0.1 5.0 0.0 5.0- 0.1- 5.1-
5.1
0.1
5.0
0.0
5.0-
0.1-
5.1-
5.1
0.1
5.0
0.0
5.0-
0.1-
5.1-
5.1
0.1
5.0
0.0
5.0-
0.1-
5.1-
1=
K
,3.0=ε
2=
K
,2.0=ε
41=
K
,1.0=ε


================================================================================
PAGE 268
================================================================================

254 Unsupervised machine learning
7.2 Dimensionality reduction
By dimensionality reduction, or dimension reduction, we mean a reduction
in the number of features (attributes, statistical variables) that describe each
observation (entity, statistical unit). Two approaches can be distinguished:
• Infeatureselection,K <DfeaturesareselectedfromtheDinputfeatures
according to certain criteria.
• In feature extraction, the D input features are, in general, modified: a
suitable transformation converts them into K <D new output features.
In both cases, the output features, although fewer in number, are intended to
reflect essential characteristics of the dataset.
In supervised learning, dimensionality reduction can be a processing step that
precedes the actual task, such as training a classifier. Dimensionality reduction
may be required to optimize efficiency: the fewer features that have to be
processed,thefastertheexecutionofthealgorithm.Anotherimportantfactoris
theobservationthattheuseofalargenumberoffeaturescanleadtooverfitting.
The methods presented in this chapter will, in general, extract features that are
different from the original set of features. We will not elaborate on methods
for feature selection but instead content ourselves with the following remarks.
When selecting features for supervised prediction:
• We can compute association measures like mutual information or Pearson
correlation of the features with the target variable. Those features that show
only a small association with the target variable can be discarded, since we
do not expect them to be good predictors.
• L -regularized methods (like LASSO) tend to produce sparse solutions, i.e.,
1
linear models where some of the coefficients vanish. Those features that are
associated with vanishing coefficients can be discarded since they have no
impact on the prediction.
Typical challenges associated with processing high-dimensional data are known
as the curse of dimensionality. One prototypical method to “break the curse”
is principal component analysis (PCA), which we describe in the following
section.
In the context of data visualization, the goal of a dimension reduction is to be
able to visually highlight essential aspects of the high-dimensional input data.
The t-SNE method presented in Section 7.2.4 is well-suited for this purpose.
7.2.1 Principal component analysis
LetX =(X ,...,X )T bearandomvectorwithcovariancematrixΣ[X].Since
1 D
Σ[X] is a symmetric matrix, there exist an orthogonal matrix V and a diagonal
matrix Λ such that the following holds (see Sect. B.2.4 in the appendix):


================================================================================
PAGE 269
================================================================================

7.2. Dimensionality reduction 255
Σ[X]=V ·Λ·VT
The columns of V are the normalized and pairwise orthogonal eigenvectors
v ,...,v ∈RD ofΣ[X].ThediagonalofΛcontainsthecorrespondingeigenval-
1 D
uesλ ,...,λ .SinceΣ[X]isalsopositivesemidefinite,noneoftheseeigenvalues
1 D
are negative.
If we define the new random vector Z :=VT ·(X−E[X]), we have E[Z]=0,
and moreover:
Σ[Z]=E[Z·ZT]=VTE[(X−E[X])·(X−E[X])T]V =VTΣ[X]V =Λ
The covariance matrix of Z is diagonal: the above transformation turns any ran-
domvectorX intoanewrandomvector Z thathaszeromeananduncorrelated
components.
A corresponding result holds for sequences of data points/feature vectors
x ,...,x ∈ RD. Since the sample covariance matrix S(x) is also symmet-
1 N
ric and positive semidefinite, we can repeat the above arguments and start by
writing down the same representation:
S(x)=V ·Λ·VT
We assume that the corresponding data matrix X is mean-centered, and there-
fore write S(x)= 1XTX for the covariance matrix. The data matrix of the
N
transformed sample z = VTx ,...,z = VTx is given by Z = X ·V, and
1 1 N N
diagonal:
NS(z)=ZTZ =(XV)TXV =VTXTXV =NVTS(x)V =NΛ
Let us compare the data transformation methods that we have learned about
so far:
• Mean-centering shifts the data points so that their centroid coincides with
the origin of feature space.
• Standardization—i.e., computing z-scores, Sect. 5.1—mean-centers the data
and scales them so that the variance of every feature is identical to one.
(The new features may still be correlated.)
• Principal component analysis, as explained above, mean-centers the
data and linearly transforms them so that the features have vanishing
covariance/correlation.
Allofthesetransformationsareaffinemapsinfeaturespace:atranslationofthe
centroidontotheorigin,followedbyalinearmap.Inthecaseofstandardization,
that linear map is a scaling transformation (in general, non-uniform). In the
case of principal component analysis, it is represented by the matrix VT.
Let us assume that the eigenvalues of the sample covariance matrix have been
sorted in descending order: λ ≥ λ ≥ ··· ≥ λ ≥ 0. Then, the sequence of
1 2 D


================================================================================
PAGE 270
================================================================================

256 Unsupervised machine learning
observations Z has the largest variance σ2 =λ , while Z has the smallest
•1 1 1 •D
variance.Thebasicideaofdimensionreductionviaprincipalcomponentanalysis
is to neglect directions of small variance.
Principal component analysis. Let data points x ,...,x ∈RD with
1 N
centroid x¯ be given. A Karhunen–Loève transform with target dimen-
sionality 1≤K ≤D is the affine map
pca : RD →RK, pca (u)=(V )T ·(u−x¯).
K K K
The columns of the D×K matrix V are the first K of the normalized
K
eigenvectorsofthecovariancematrixS(x)thatcorrespondtotheK largest
eigenvalues.
Conventionsfornamingtheobjectsinvolvedvary1;wewillusethefollowing.The
eigenvectors v ,...,v ,...,v of the covariance matrix, sorted in descending
1 K D
orderbythesizeoftheassociatedvariance,arecalledthe principal directions.
The straight line passing through the centroid, spanned by the k-th principal
direction v , has the parameter equation
k
R→RD, λ7→x¯+λ·v
k
and represents a principal axis. Any two different principal axes are per-
pendicular. If we project any vector u∈RD onto the k-th principal axis, the
oriented distance of the projection from the centroid is given by ⟨v ,u−x¯⟩: the
k
k-th principal component, or principal coordinate. The first K principal
components form the Karhunen–Loève transformed vector:
 
⟨v ,u−x¯⟩
1
.
pca : RD →RK, pca : u7→ . . 
K K  
⟨v ,u−x¯⟩
K
In summary, the principal components are the coordinates—with respect to the
basis of principal directions—of the projection onto the K-dimensional affine
subspace spanned by the first K principal axes.
Suppose that the input vector was drawn from a distribution similar to the
distributionofthedatathattheprincipalcomponentanalysiswasperformedon.
Then, the projected vector can be understood as an approximation of the input
vector in the sense that it is very likely that it has a small distance to the input
vector. That is because, along directions perpendicular to the first principal
axes, the variance of the distribution is small. Therefore, it is very likely—we
remind ourselves of Chebyshev’s inequality, Sect. 3.4.3—that the components
in these directions have a small magnitude and can thus be neglected.
1 In particular, the term “principal component” is used very interchangeably for
principal axes, directions or coordinates.


================================================================================
PAGE 271
================================================================================

7.2. Dimensionality reduction 257
Consequently, we can also expect to be able to reconstruct the vector ap-
proximately from its principal components: we have u≈((pca )†◦pca )(u)
K K
with
K
X
(pca )†: RK →RD, (pca )†: y 7→x¯+ y ·v
K K k k
k=1
Example. The MNIST dataset [9] consists of digital images of handwritten
digits with a resolution of 28×28 pixels, see Fig. 8.6.
First, we flatten each image, i.e., we represent it as a vector of gray values
with length D =28·28=784. We can use PCA to reduce the dimensionality
of the dataset to K =2: Fig. 7.5 on top shows the result for a small selection
of digits, each placed at the position of their respective first two principal
coordinates. A certain tendency can be seen with which the same digits are
grouped together: this is a first indication that we can identify a handwritten
digit from just a few principal components.
Fig. 7.5 on the bottom shows the (approximately) inverse transformation:
anylinearcombinationofthefirsttwoprincipaldirectionscanberepresented
as an image. These artificially generated images show some similarity to the
digits zero, one, and nine—but it appears that two principal directions do
not span a region of feature space large enough to cover all the digits.
However, twenty principal components can already be used for the recon-
structionofacceptablequality.Thefirsttwentyeigenvectorsofthecovariance
matrix, brought back to image format, look like this:
Fig. 7.3. “Eigendigits” of the MNIST dataset
These images can be seen as a generating set for the MNIST data, and
each digit can be represented approximately as a linear combination of these
images:
Fig. 7.4. Image reconstruction from principal components


================================================================================
PAGE 272
================================================================================

258 Unsupervised machine learning
The figure above shows an example of each digit (top row) and the recon-
struction from their first twenty principal components.
7.2.2 Autoencoders
Artificial neural networks can also be used for unsupervised learning. Autoen-
coders are based on two essential ideas or assumptions:
• The activations of hidden neurons reflect essential characteristics of the
relationship between input and output data.
• We can apply a neural network to any dataset—even when it is unlabeled—
by assigning a training example to itself as the output. As a consequence,
the network learns an approximation of the identity map RD →RD, u7→u.
An autoencoder is an artificial neural network with at least one hidden
layer, where the input and output layers have the same width:
f: RD →RD, f(u)=(f ◦f ◦···◦f )(u), L≥2
L L−1 1
One of the hidden layers of the autoencoder—say f
m
: RDm−1 → RDm ,
1≤m<L—is singled out as the latent layer, and we denote its width
by K :=D .
m
Givenadatasetx ,...,x ∈RD,theautoencoderistrainedwithidentical
1 N
input and output activations—the empirical risk to be minimized has the
following form:
N
Rˆ[f]= 1 X λ(x ,f(x ))
N n n
n=1
Once the weights and biases have been learned, the maps
code: RD →RK, code(u)=(fˆ ◦fˆ ◦···◦fˆ)(u)
m m−1 1
and
code†: RK →RD, code†(y)=(fˆ ◦fˆ ◦···◦fˆ )(y)
L L−1 m+1
represent the encoding map and decoding map, respectively.
In other words, we represent the data as the activations of the latent layer.
The space of possible activations—i.e., the range (domain) of the encoding
(decoding) map—is also called latent space. The dimensionality of the latent
spaceisgivenbythewidthofthelatentlayer.Forthepurposeofdimensionality
reduction,itis typicallychosento be(significantly)lessthan thedimensionality
of the input data: K ≪D.


================================================================================
PAGE 273
================================================================================

7.2. Dimensionality reduction 259
Example. Fig. 7.6 on top shows a scatter plot of an autoencoder’s encoding
of digits selected from the MNIST dataset; the entire dataset was used for
training. The autoencoder itself is an ordinary feedforward network with five
hidden layers and the following number of neurons in the hidden layers: 32,
64, 2, 64, 32. The middle layer with two neurons represents the latent layer.
Leaky rectifiers were used as activation functions. The training error based
on the quadratic loss was minimized via stochastic gradient descent, using
the open-source software library Keras [10, 11].
Thefigurebelowthescatterplotisarepresentationofthedecoding map.When
we compare this representation with the results of a principal component
analysis (Fig. 7.5 bottom), we can see that the neural network is apparently
much better at compressing the entire feature space to a low-dimensional
representation with a relatively small loss: we can see the neural network
interpolate between a wider variety of digits.
7.2.3 Multidimensional scaling
Suppose we are given data points x ,...,x and a symmetric premetric δ(·, ·)
1 N
that we may apply to those data points to measure their distance/similarity.
These can be points in a high-dimensional Euclidean space or other types of
data, such as lists of binary features that were compared using the Jaccard
distance.Wewanttomapthesedatapointsontoaconfigurationoftargetpoints
y ,...,y ∈RK inaEuclideanspaceofprescribeddimensionK,usuallychosen
1 N
to be comparatively low. This map should have pairwise distances between
points that change as little as possible:
∆ =δ(x ,x )≈∥y −y ∥
mn m n m n
We can find such a configuration by minimizing a suitable choice of objective
function, also called a stress function in this context.
Let ∆ be a distance matrix of format N ×N.
Metric multidimensional scaling is based on minimizing the following
stress function:
N N
R (y ,...,y )= XX (∆ −∥y −y ∥)2
mMDS 1 N kl k l
k=1l=1
Sammon projectionisbasedonminimizingthefollowingstressfunction:
R (y ,...,y )= X N X N (∆ kl −∥y k −y l ∥)2
Samm 1 N ∆
kl
k=1l=1
Here, undefined summands with vanishing denominators are set equal to
zero.


================================================================================
PAGE 274
================================================================================

260 Unsupervised machine learning
Metric multidimensional scaling minimizes a quadratic loss with the goal of
preserving pairwise distances between data points.
TheSammonvariantdiffersfrommetricmultidimensionalscalingbytheaddition
ofweights1/∆kl :datapointslocatedclosetoeachotheraregivenagreaterweight
than those located further apart. That way, local neighborhood relationships
are given more weight to be preserved. This rationale is also behind the t-SNE
method discussed in the next section.
The following normalized stress functions are also commonly found in the
literature, and they deliver the same results as the respective stress functions
listed above:
N N
!−1
N N
S (y ,...,y )= XX (∆ )2 · XX (∆ −∥y −y ∥)2
mMDS 1 N kl kl k l
k=1l=1 k=1l=1
S (y ,...,y )= X N X N ∆
!−1
· X N X N (∆ kl −∥y k −y l ∥)2
Samm 1 N kl ∆
kl
k=1l=1 k=1l=1
Example. Fig. 7.7 shows the result of a Sammon projection applied to a
selection of images from the MNIST handwritten digit dataset. The stress
was minimized using the BFGS algorithm sketched in Sect. 6.1.4.
7.2.4 t-distributed stochastic neighbor embedding (t-SNE)
Like in the last section, suppose we are given data points x ,...,x and a
1 N
symmetric premetric δ(·, ·), which we can use to determine the distances
between data points. Again, we want to map these data points onto a new
set of data points y ,...,y ∈ RK with target dimensionality K. This map
1 N
should preserve distances between neighboring data points: in a suitable sense,
∆ =δ(x ,x )≈∥y −y ∥ shall hold for small ∆ .
mn m n m n mn
The basic idea of stochastic neighbor embedding (SNE) is the following.
First, we imagine a random walk on the set of data points, i.e., a succession of
random steps where each step connects two data points. We want to impose the
following conditions: If the walker is at position x , at the following step, they
m
move to the position x with the transition probability p(n|m). This probability
n
does not depend on the walker’s past trajectory, and it depends only on the
distance ∆ between the two data points. We posit that the smaller the
mn
distance between x and x , the larger the probability of transitioning between
m n
those two points.
For all m∈{1,...,N}, PN p(n|m)=1 holds: this is a family of probability
n=1
mass functions reflecting the local intrinsic geometry. The idea is to produce
a distribution of data points in the target space that is similar to the original
distribution, thus exhibiting a similar local geometry.


================================================================================
PAGE 275
================================================================================

7.2. Dimensionality reduction 261
4
2
0
-2
-4
-2.5 0.0 2.5 5.0 7.5
y
1
y
2
4
2
0
-2
-4
-2.5 0.0 2.5 5.0 7.5
y
1
y
2
Fig. 7.5. Scatter plot of the first two principal coordinates of a selection of MNIST
images (top); reconstruction of linear combinations of the first two principal
directions (bottom)


================================================================================
PAGE 276
================================================================================

262 Unsupervised machine learning
8
6
4
2
0
0.0 2.5 5.0 7.5 10.0
y
1
y
2
6
4
2
0
0.0 2.5 5.0 7.5
y
1
y
2
Fig. 7.6. Result of encoding a selection of MNIST images with an autoencoder (top);
decoding points in latent space (bottom)


================================================================================
PAGE 277
================================================================================

7.2. Dimensionality reduction 263
We write down the following more concrete models, where the bandwidths
σ =(σ ,...,σ ) are parameters yet to be determined:
1 N
p x,σ (n|m)=e−1 2 (∆ σ m m n)2 · −1+ X N e −1 2 (cid:16)∆ σ m m k (cid:17)2
!−1
k=1
and
N N
!−1
1 XX 1
q (m,n)= · −N +
y 1+∥y −y ∥2 1+∥y −y ∥2
m n k l
k=1l=1
if m,n∈{1,...,N} and m̸=n, otherwise p (n|m)=q (m,n)=0.
x,σ y
Thus, for the original distribution, a form of kernel density estimator with a
Gaussian kernel is used, while for the target distribution a Cauchy distribution
serves as the kernel. The originally proposed SNE method uses a Gaussian
kernel to model the target distribution as well [12]. However, using the fat-
tailed Cauchy distribution instead avoids the “crowding problem” that prevents
naturalclustersfrombeingclearlyseparatedamongthemappeddatapoints[13,
Sect.3.2].Forpositivearguments,theCauchydistributionL(u|0,1)∝(1+u2)−1
agrees with the t-distribution with one degree of freedom, hence the name of
the method described below.
Let eH >0 be a fixed parameter, the perplexity. With the above defini-
tions, t-distributed stochastic neighborhood embedding, or t-SNE
for short, is a dimensionality reduction algorithm that consists of the
following steps (cf. [13]):
1. The bandwidths σ ,...,σ are determined such that for all m ∈
1 N
{1,...,N}, the distribution of transition probabilities matches the
prescribed perplexity:
N
X
− p (n|m)·ln(p (n|m))=H
x,σm x
n=1
2. A symmetric distribution is determined as follows:
1
p (n,m)= (p (n|m)+p (m|n))
x 2N x,σm x,σn
3. The target data points are determined by minimizing the following ob-
jective function, the cross-entropy between the distributions p (·, ·)
x
and q (·, ·):
y
N N
XX
R(y ,...,y )=− p (k,l)ln(q (k,l))
1 N x y
k=1l=1
where agree on 0·ln0=0, as usual.


================================================================================
PAGE 278
================================================================================

264 Unsupervised machine learning
The perplexity can be interpreted as the effective number of neighbors of a data
point—a typical range to choose from is given by 5 ≤ eH ≤ 50. The primary
applicationofthet-SNEmethodisdatavisualization:drawingalow-dimensional
scatter plot of high-dimensional data. Thus, K =2 or K =3 usually applies.
The numerical implementation is facilitated by the fact that the gradient of the
above objective function can be calculated explicitly. For all n∈{1,...,N}:
N
∇ R(y ,...,y )=4
Xp
x
(n,k)−q
y
(n,k)
·(y −y )
yn 1 N 1+∥y −y ∥2 n k
n k
k=1
UMAP2 is an algorithm that is similar to t-SNE but has been developed more
recently [14].
Example. Fig. 7.7 (bottom) shows the result of applying t-SNE with a
perplexity of eH =12 to a selection of images from the MNIST dataset.
7.3 Cluster analysis
Suppose that we are given a sequence or set of observations/data points
x ,...,x supplied with some notion of similarity or distance. In its most
1 N
basicform,thegoalofacluster analysisistopartitionthosedataintosubsets
S ,...,S ⊆{x ,...,x }, the clusters, where each observation is contained
1 K 1 N
inasinglecluster.Wemaylabeleachdatapoint,f: {x ,...,x }→{1,...,K},
1 N
in order to indicate cluster membership.
There are variants of clustering algorithms where the stated goal is to assign
each data point to at most one cluster: some data points may be considered
outliers and not assigned to any cluster. DBSCAN [15] and HDBSCAN [16] are
examples3 of such algorithms.
Therearealsofuzzyclusteringalgorithmsthatmayassignasingleobservation
to several clusters [17]. In that case, the assignment comes with a weighting
value that reflects the degree of membership; the clusters are interpreted as
fuzzy sets.
Cluster analysis may or may not learn a decision rule4 that would allow for
determining cluster membership of yet unseen data points, data points which
were not included in the original dataset.
2 UMAP stands for Uniform Manifold Approximation and Projection.
3(H)DBSCAN stands for (Hierarchical) Density-Based Spatial Clustering of Applica-
tions with Noise.
4 If the clustering algorithm does not provide a decision rule out-of-the-box, there is
always the option to learn it from the cluster labels after the fact via a supervised
algorithm.


================================================================================
PAGE 279
================================================================================

7.3. Cluster analysis 265
10
5
0
-5
-10
-10 -5 0 5 10
y
1
y
2
600
300
0
-300
-600
-400 0 400
y
1
y
2
Fig. 7.7. Sammon projection (top) and t-distributed stochastic neighbor embedding
(bottom)


================================================================================
PAGE 280
================================================================================

266 Unsupervised machine learning
Whateverthedetailsonthedefinitionofclustermembershipare,thepartitioning
of the data is not arbitrary, of course. The goal is to group similar observations
together and separate dissimilar observations. As a rule, the data points within
a single cluster should have a small distance, while the distance of data points
that belong to two different clusters should be large.
In the following sections, we describe two commonly used clustering algorithms:
K-means clustering and hierarchical clustering.
7.3.1 K-means algorithm
The K-means algorithm can be used to cluster data points x ,...,x ∈ RD,
1 N
where points are assumed to be similar when they have a small (squared)
Euclidean distance. Let us assume that our data are generated by a member
of the following family of probability density functions, a particular Gaussian
mixture model p : RD →R:
GMM
p (u|µ ,...,µ ,h2)= 1 · 1 X
K
exp
(cid:18)
− ∥u−µ k
∥2(cid:19)
GMM 1 K K (2π)D
2 k=1
2h2
with mean vectors µ ,...,µ ∈RD and a standard deviation h>0 assumed
1 K
to be equal for each subpopulation. Each of the mean vectors determines the
centroid of an isotropic multivariate normal distribution that produces a cluster
of data points. We assume that the subpopulations defined by each Gaussian
distribution in the above sum have only a small overlap. In other words, the
cluster centroids are sufficiently far apart from each other when measured in
multiples of h. With this assumption, we can approximate the total density
function as follows:
1 1 (cid:18) ∥u−µ ∥2(cid:19)
p (u|µ ,...,µ ,h2)≈ · exp − f(u)
GMM 1 K K (2π)D
2
2h2
where µ ∈{µ ,...,µ } is the cluster centroid that has the smallest distance
f(u) 1 k
to u∈RD. We assume that only this cluster provides a significant contribution
to the density at u. The decision rule f: RD →{1,...,K} assigns each point
to its cluster label. With the exception of decision boundaries that have equal
distance to multiple centroids, this decision rule is determined by the cluster
centroids: f(·)=f(·;µ ,...,µ ).
1 K
A partition S ,...,S of a set of data points x ,...,x ∈RD based on such a
1 K 1 N
decision rule can be characterized as follows, for all k ∈{1,...,K}:
S ={x |n∈{1,...,N}, f(x )=k}
k n n
Alternatively, we can write down groups I ,...,I of indices:
1 K
I ={n∈{1,...,N}|f(x )=k}={n∈{1,...,N}|x ∈S }
k n n k


================================================================================
PAGE 281
================================================================================

7.3. Cluster analysis 267
With those simplifying assumptions, the log-likelihood function computed from
plugging the data into the Gaussian mixture model takes the following form:
N
X
ℓ(µ ,...,µ ,h2)= ln(p (x |µ ,...,µ ,h))
1 K GMM n 1 K
n=1
N
1 X
≈− · ∥x −µ ∥2
2h2 n f(xn;µ1,...,µK)
n=1
ND
−N ·ln(K)− ln(2π)
2
Maximizingthisfunctionisequivalenttotheminimizationofthesumofsquared
distances to the respective cluster centroids (the bandwidth h plays no role
anymore):
N K
X X X
R= ∥x −µ ∥2 = ∥x −µ ∥2
n f(xn;µ1,...,µK) n k
n=1 k=1n∈Ik
In simpler words, we minimize the squared distances of the data points to the
centroid of the cluster they belong to.
Each term of the inner sum is nonnegative, and it is minimized by setting each
µ to be the empirical centroid of the k-th cluster. This argument leads to the
k
following criterion.
Let x ,...,x ∈ RD be data points. The K-means algorithm for
1 N
clusteranalysisminimizesthefollowingobjectivefunctionoverthepossible
assignments of cluster labels I ,...,I :
1 K
K
X X 1 X
R(I ,...,I )= ∥x −µ ∥2 with µ = x
1 K n k k |I | n
k
k=1n∈Ik n∈Ik
Lloyd’s algorithm can find a local minimum of the objective function:
initialize cluster centroids µ ,...,µ
1 K
while the value of R changes with each iteration do
for i = 1 to N do
f(x ):= index of nearest centroid
i
end
for j = 1 to K do
µ := centroid of the j-th cluster
j
end
update: R= PN ∥x −µ ∥2
n=1 n f(xn)
end
output:
cluster centroids µ ,...,µ
1 K
cluster memberships f(x ),...,f(x )
1 N


================================================================================
PAGE 282
================================================================================

268 Unsupervised machine learning
The centroids can be initialized, for example, by randomly selecting K of the
data points to be clustered: µ = x ,...,µ = x . Lloyd’s algorithm
1 ι(1) K ι(K)
always finds a local minimum—however, an unfavorable initialization may lead
to a result of low quality that is far away from the global minimum. Therefore,
it is recommended to run the algorithm several times with different initial
centroids and to compare the results, e.g., using the final goodness-of-fit R.
Fig. 7.8 shows the application of the method to a synthetic dataset generated
by a Gaussian mixture model with three centroids. The quality of the result
depends crucially on the hyperparameter K, i.e., the number of clusters that
the algorithm is set out to determine.
K-medoids algorithms are similar to K-means [18]. As the name suggests,
these algorithms replace cluster centroids with their medoids. This replacement
has the advantage that more general distance measures can be used.
7.3.1.1 Kernel K-means algorithm
InderivingtheK-meansalgorithm,wemadesomeratherrestrictiveassumptions:
the clusters have equal size, and the data points in each cluster distribute
isotropically around its centroid. Any two clusters can be linearly separated. If
these assumptions are not justified, the cluster analysis may yield an inferior
result. One such result can be seen in Fig. 7.9 above: the blocks of feature space
produced by K-means partitioning5 can not cover the oddly shaped clusters of
the “smiley.”
The limitations of the ordinary K-means method can be countered by using
the kernel trick that we had already applied to logistic regression in Sect. 6.3.1.
We assume that there exists a feature map Φ: RD →H, where the dimension
of the target space H may be much larger than D or even infinite. The scalar
product ⟨·, ·⟩ in the target space will be induced by a kernel σ: RD×RD →R,
so that for all u,v ∈RD the following holds:
⟨Φ(u),Φ(v)⟩=σ(u,v)
For example, we can use the popular Gaussian kernel once more: σ (u,v) =
h
exp(−1h−2∥u−v∥2).
2
Furthermore, we write for the cluster centroids under the feature map:
1 X
Φ∗µ := Φ(x )
k |I | n
k
n∈Ik
Forthesquareddistanceofatransformeddatapoint u∈RD tothe k-thcluster
centroid, we get:
5 The kind of partition that ordinary K-means is able to produce is called a Voronoi
partition.


================================================================================
PAGE 283
================================================================================

7.3. Cluster analysis 269
r2(u)=∥Φ(u)−Φ∗µ ∥2
k k
=⟨Φ(u),Φ(u)⟩−2⟨Φ(u),Φ∗µ ⟩+⟨Φ∗µ ,Φ∗µ ⟩
k k k
2 X 1 X X
=σ(u,u)− σ(u,x )+ σ(x ,x )
|I | m |I |2 m n
k k
m∈Ik m∈Ikn∈Ik
Let x ,...,x ∈RD be data points. The kernel K-Means algorithm
1 N
consists of minimizing the following objective function over the possible
occupancies of cluster labels I ,...,I :
1 K
K
X X
R(I ,...,I )= r2(x ),
1 K k n
k=1n∈Ik
where r2(x ) is calculated as shown in the derivation above.
k n
The Lloyd algorithm can be adapted to the new paradigm as follows:
initialize cluster labels for x ,...,x
1 N
while the value of R changes with each iteration do
for i = 1 to N do
new cluster label of x := index k with smallest value for r2(x )
i k i
end
update: R= PK P r2(x )
k=1 n∈Ik k n
end
output: cluster labels for x ,...,x
1 N
In Fig. 7.9, the result of a kernel K-means cluster analysis is shown below
(K =4, Gaussian kernel with h=0.5, cluster labels initialized randomly).
7.3.2 Hierarchical cluster analysis
The basic idea behind agglomerative hierarchical cluster analysis is the
following.Westarttheiterationwiththefinestpossiblepartitionofthedataset:
each cluster contains a single data point. Then, with each subsequent step,
the clusters that have minimum distance to each other are merged. The new
partition constructed in this way consists of fewer clusters, so it is coarser. The
procedureterminatesoncethepartitionconsistsofasingleclusterthatcontains
all of the data points.
In this way, we have constructed not one clustering but a whole hierarchy of
partitions of the data that we can chose from.
Let x ,...,x be the data points that we wish to group into clusters.
1 N
Suppose that we are given a distance measure δ(·, ·) to compare those
data points with. In order to determine the distance D(A,B) between two


================================================================================
PAGE 284
================================================================================

270 Unsupervised machine learning
arbitrary clusters of data points A and B, we can choose from one of the
following alternatives:
D (A,B)= min {δ(u,v)},
min
u∈A,v∈B
D (A,B)=⟨δ(u,v)⟩ ,
avg u∈A,v∈B
D (A,B)= max {δ(u,v)}
max
u∈A,v∈B
An agglomerative hierarchical cluster analysis generates a hierarchy
of partitions of the dataset:
n o
initialize t:=0, S(0) := S(0),...,S(0) ={{x },...,{x }}
1 N 1 N
while |S(t)|>1 do
update t←t+1, initialize S(t) :=S(t−1)
# Determine cluster with smallest distance:
for i = 2 to |S(t)| do
for j = 1 to i−1 do
(cid:16) (cid:17)
compute ∆ :=D S(t),S(t)
ij i j
end
end
determine i,j with smallest distance ∆
ij
# Merge clusters with smallest distance:
update S(t) ←S(t)∪S(t), drop S(t)
i i j j
end
output: partitions S(0),S(1), ..., S(T)
Depending on whether D , D , or D is used as the distance measure
min avg max
between clusters, we speak of single-linkage, average-linkage, or complete-
linkage clustering.
A divisive hierarchical cluster analysis continuously refines partitions,
starting from a single cluster that covers the whole dataset. We do not discuss
these methods here, see [19, Chap. 6] instead.
In a hierarchy of clusterings, every level of the hierarchy represents a different
partition. Hierarchies can also be called rooted trees (look back to Sect. 1.2.3).
Everyvertexofthetreerepresentsacluster,startingattheroot,whichrepresents
the largest possible cluster—the cluster which contains all of the data points.
With each level in the direction of the tree’s leaves, the partitions become finer
and finer, containing smaller and smaller clusters.
We can draw a dendrogram to visualize this hierarchy/tree. Fig. 7.10 shows
an example that represents the clustering of forty international cities by geo-
graphical distance using the average-linkage method. The leaves correspond
to the cities to be grouped, and each bifurcation represents the merger of two


================================================================================
PAGE 285
================================================================================

7.3. Cluster analysis 271
clusters of cities. The position of the bifurcation can be used to read off the
value of the cluster distance function D (·, ·) at which the merger occurred.
avg


================================================================================
PAGE 286
================================================================================

272 Unsupervised machine learning
2
1
1
2
0
-1
3
-2
K=3
-3
-2 0 2
x
1
x
2
2
1
1
5
4
2
0
-1
3
-2
K=5
-3
-2 0 2
x
1
x
2
Fig. 7.8. K-means clustering


================================================================================
PAGE 287
================================================================================

7.3. Cluster analysis 273
1.0
1 2
0.5
0.0 4
-0.5
3
-1.0 -0.5 0.0 0.5 1.0
x
1
x
2
1.0
3 1
0.5
2
0.0
-0.5 4
-1.0 -0.5 0.0 0.5 1.0
x
1
x
2
Fig. 7.9. K-means clustering: ordinary (top) and using the kernel trick (bottom)


================================================================================
PAGE 288
================================================================================

274 Unsupervised machine learning
Istanbul
Cairo
Tehran
Moscow
London
Paris
Kinshasa
Lagos
Chengdu
Chongqing
Shenzhen
Guangzhou
Manila
Bangkok
Seoul
Shanghai
Tianjin
Beijing
Nagoya
Osaka
Tokyo
Chennai
Bangalore
Hyderabad
Mumbai
Kolkata
Dhaka
Lahore
Delhi
Karachi
Jakarta
Lima
Bogotá
Rio de Janeiro
São Paulo
Buenos Aires
Los Angeles
Mexico City
Chicago
New York
0 5000 10000
Fig. 7.10. Dendrogram of a hierarchical cluster analysis of international cities


================================================================================
PAGE 289
================================================================================

References 275
References
[1] Sanjoy Dasgupta and Anupam Gupta. “An elementary proof of a theorem
of Johnson and Lindenstrauss”. In: Random Structures & Algorithms 22.1
(2003), pp. 60–65. doi: 10.1002/rsa.10073.
[2] MehryarMohri,AfshinRostamizadeh,andAmeetTalwalkar. Foundations
of Machine Learning. 2nd ed. MIT Press, 2018.
[3] SixueGong,VishnuNareshBoddeti,andAnilK.Jain.“OntheIntrinsicDi-
mensionalityofImageRepresentations”.In:Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition (CVPR). June
2019. arXiv:1803.09672.
[4] Christian S. Perone, Roberto Silveira, and Thomas S. Paula. Evaluation
of sentence embeddings in downstream and linguistic probing tasks. June
2018. arXiv:1806.06259v1.
[5] Gunnar Carlsson. “Topology and data”. In: Bulletin of the American
Mathematical Society 46.2 (Jan. 2009), pp. 255–308. doi: 10.1090/s0273-
0979-09-01249-x.
[6] Gunnar Carlsson. “Topological pattern recognition for point cloud data”.
In: Acta Numerica 23 (May 2014), pp. 289–368. doi: 10.1017/s096249291
4000051.
[7] Gunnar Carlsson and Mikael Vejdemo-Johansson. Topological Data Anal-
ysis with Applications. Cambridge University Press, Nov. 2021. doi: 10.
1017/9781108975704.
[8] Frédéric Chazal and Bertrand Michel. “An Introduction to Topological
Data Analysis: Fundamental and Practical Aspects for Data Scientists”.
In: Frontiers in Artificial Intelligence 4 (Sept. 2021). doi: 10.3389/frai.
2021.667963.
[9] Yann LeCun, Corinna Cortes, and Christopher J. C. Burges. The MNIST
database of handwritten digits. 2010. url: http://yann.lecun.com/exdb/
mnist/.
[10] François Collet et al. Keras. url: https://keras.io.
[11] J.J.AllaireandFrançoisChollet.keras: R Interface to ’Keras’.Rpackage.
2020. url: https://CRAN.R-project.org/package=keras.
[12] Geoffrey E Hinton and Sam Roweis. “Stochastic Neighbor Embedding”.
In: Advances in Neural Information Processing Systems. Ed. by S. Becker,
S. Thrun, and K. Obermayer. Vol. 15. MIT Press, 2002.
[13] Laurens J. P. van der Maaten and Geoffrey E. Hinton. “Visualizing High-
DimensionalDataUsingt-SNE”.In:JournalofMachineLearningResearch
9 (Nov. 2008), pp. 2579–2605.
[14] Leland McInnes, John Healy, and James Melville. UMAP: Uniform Man-
ifold Approximation and Projection for Dimension Reduction. Sept. 2020.
arXiv:1802.03426v3.
[15] Martin Ester et al. “A density-based algorithm for discovering clusters in
large spatial databases with noise”. In: Proceedings of the 2nd ACM In-
ternational Conference on Knowledge Discovery and Data Mining (KDD).
1996, pp. 226–231.


================================================================================
PAGE 290
================================================================================

276 Unsupervised machine learning
[16] Ricardo J. G. B. Campello, Davoud Moulavi, and Joerg Sander. “Density-
Based Clustering Based on Hierarchical Density Estimates”. In: Advances
in Knowledge Discovery and Data Mining. Springer Berlin Heidelberg,
2013, pp. 160–172. doi: 10.1007/978-3-642-37456-2_14.
[17] Enrique H. Ruspini, James C. Bezdek, and James M. Keller. “Fuzzy
Clustering:AHistoricalPerspective”.In:IEEEComputationalIntelligence
Magazine 14.1 (Feb. 2019), pp. 45–55. doi: 10.1109/mci.2018.2881643.
[18] Erich Schubert and Peter J. Rousseeuw. Faster k-Medoids Clustering:
Improving the PAM, CLARA, and CLARANS Algorithms. Oct. 2019.
arXiv:1810.05691v4.
[19] Leonard Kaufman and Peter J. Rousseeuw, eds. Finding Groups in Data:
An Introduction to Cluster Analysis. John Wiley & Sons, Mar. 1990. doi:
10.1002/9780470316801.


================================================================================
PAGE 291
================================================================================

8
Applications of machine learning
Methodsofdatascienceandstatisticsingeneral,andmachinelearningmethods
in particular, are widely used in science and engineering. Here are just a few
examples:
• Medical image processing and analysis [1]—for example, for diagnosing
diseases such as COVID-19 based on thoracic computed tomography images
[2, 3],
• drug discovery [4], protein structure prediction [5],
• processing of astronomical data [6], such as for the morphological classifica-
tion of galaxies [7, 8] or the discovery of exoplanets [9, 10],
• gesture and speech recognition for human–machine communication [11, 12],
• autonomous vehicle control [13],
• credit fraud detection and prevention [14].
At the time of writing this text in early 2023, state-of-the-art generative
artificial intelligence that can produce various types of content such as
images [15, 16, 17], text [18, 19, 20, 21, 22], and music [23, 24] had been
receiving considerable media attention [25, 26, 27, 28].
Withtheproliferationofincreasinglypowerfultechniquesbasedonever-growing
datasets, legal and ethical issues arise in data protection and privacy [29]
and the socially and environmentally responsible use of artificial intelligence
[30, 31, 32, 33, 34, 35].
In this chapter, we demonstrate how the techniques introduced in Chap-
ters 6 and 7 are already powerful enough to solve various hard problems in
computing.
© Springer-Verlag GmbH Germany, part of Springer Nature 2023 277
M. Plaue, Data Science, https://doi.org/10.1007/978-3-662-67882-4_8


================================================================================
PAGE 292
================================================================================

278 Applications of machine learning
8.1 Supervised learning in practice
In the following sections, we demonstrate the application of procedures for the
automated categorization of data: first, the classification of digital images, and
second, text documents.
8.1.1 MNIST: handwritten text recognition
The MNIST dataset [36, 37] consists of 70,000 digital grayscale images1 with a
resolution of 28×28 pixels. Each of the images shows a handwritten digit, see
Fig. 8.6 above. Each image is labeled with the digit shown in the image. The
problem to solve: implement an algorithm that automatically recognizes the
digit that the image depicts. A rule-based solution seems impractical or at least
very costly, so we would want to apply machine learning.
For the purpose of exposition, we keep things simple and solve the following
binary classification problem instead: recognize the digit one as distinct from all
other digits. First, we transform each image by lining up the gray values of the
pixels to form a single array. This transformation is also called flattening and
resultsinacollectionoffeaturevectorsinRD thatcontaintheD =28·28=784
gray values of each image.
We then split the dataset into a training dataset of 60,000 images and a
test dataset of 10,000 images. The training dataset can be used to train the
algorithmspresentedintheprevioussections.Weevaluatethetrainedclassifiers
by applying them to the images in the test dataset and compute measures for
the goodness of fit.
The following table shows a comparison of logistic regression, quadratic discrim-
inant analysis, the 1-nearest neighbor classifier, and a feedforward network:
precision recall F -score
1
logistic regression 93.1% 97.1% 95.1%
QDA 89.6% 95.9% 92.6%
1-NN 96.7% 99.5% 98.1%
feedforward network 98.7% 99.0% 98.9%
random (baseline) 11.4% 50.0% 18.5%
Table 8.1. Performance of different classifiers applied to the MNIST dataset
Overall, all methods perform relatively well on this dataset. The last line shows
the measures that could be expected from an algorithm that were to decide
whether the image depicts the digit one or not on a coin toss, i.e., with a
probability of 50% each.
To perform the quadratic discriminant analysis, the covariance matrices Σ and
0
Σ and the centroids µ and µ were obtained from the training data with class
1 0 1
1 MNIST stands for Modified National Institute of Standards and Technology.


================================================================================
PAGE 293
================================================================================

8.1. Supervised learning in practice 279
membership y =0 and y =1, respectively. These parameters determine the
n n
likelihood to find a feature vector given that the image shows the digit one or
does not show the digit one, assuming a multivariate normal distribution:
1
p(x|y =k)=N(x|µ k ,Σ k )= p ·e−1 2 (x−µk)T·(Σk)−1·(x−µk)
(2π)D·det(Σ )
k
with k ∈{0,1}. However, since the Σ are singular—i.e., have vanishing deter-
k
minant and cannot be inverted—we use regularized covariance matrices
instead: Σ =Σ +diag(ε,ε,...,ε) with a small smoothing parameter ε>0.
k,ε k
The optimal hyperparameter K =1 for the K-nearest neighbor classification
can be obtained by cross-validation. The following plot shows the range and
arithmeticmeanoftheF scoreoverK onthebasisofasix-foldcross-validation:
1
100
99
98
97
96
95
1 3 5 7 9 15 21
K
F
1
Fig. 8.1. Cross-validation of a K-nearest neighbor model
The classifier learned by the neural network shows the best goodness-of-fit
in terms of the F score. Nevertheless, the method misclassified the following
1
images as the digit one:
Fig. 8.2. MNIST: false positives for identifying the digit one
Conversely, the following handwritten variants of the number one were not
recognized as such:


================================================================================
PAGE 294
================================================================================

280 Applications of machine learning
Fig. 8.3. MNIST: false negatives for identifying the digit one
The neural network used for the above classification consists of three hidden
layers with 128, 64, and 32 neurons. For the hidden layers, a leaky rectifier
has been used as the activation function. The output layer consists of only one
neuron activated by a sigmoid function, and cross-entropy was chosen as the
lossfunction.Thetrainingerrorbasedonthislossfunctionwasminimizedusing
a gradient descent at a batch size of twenty training examples each.
8.1.2 CIFAR-10: object recognition
The CIFAR-10 dataset [38] consists of 60,000 digital RGB color images2 with a
resolution of 32×32 pixels. With three color channels, this corresponds to an
extrinsic dimensionality of the input data of D =32·32·3=3072. Each image
features an object of one of the following ten classes and have been labeled as
such—see Fig. 8.6 below: airplane, automobile, bird, cat, deer, dog, frog, horse,
ship, and truck.
The test dataset contains 10,000 of these images. We want to train a classifier
that is able to automatically identify images of cats. The following table shows
a performance comparison of the same methods that we applied to MNIST in
the previous section:
precision recall F score
1
logistic regression 22% 27% 24%
QDA 16% 29% 21%
1-NN 29% 24% 26%
feedforward network 41% 9% 15%
random (baseline) 10% 50% 17%
Table 8.2. Performance of different classifiers applied to the CIFAR-10 dataset
The results are not good—they can be compared to random guessing!
However, using a deep Convolutional Neural Network, we can train a classifier
that has an F score of 60%, a precision of 70%, and a recall of 53%. Part of the
1
program code in R (cf. [39]) is shown in Fig. 8.7; the program libraries Keras
[40, 41] and TensorFlow were used for the implementation [42, 43]. The training
can be performed on standard, consumer-level hardware. The average loss was
2 CIFAR-10 stands for Canadian Institute for Advanced Research, 10 object classes.


================================================================================
PAGE 295
================================================================================

8.1. Supervised learning in practice 281
minimized using Adam3 [44], an efficient numerical optimization algorithm. A
dropout probability of q =0.5 was applied to the final hidden, fully-connected
layer.
Anadditionalcomponentoftheappliedarchitectureiscalledbatch normaliza-
tion[45].Inthisprocedure,theactivationsarestandardizedwitheachiteration
across the mini-batch, i.e., mean-centered, and brought to a variance of one.
This can lead to improved numerical stability.
The following test examples were incorrectly classified by the CNN as images of
a cat—the majority are photos of dogs:
Fig. 8.4. CIFAR-10: false positives for identifying a cat
Conversely, the following photos of a cat were not recognized as such:
Fig. 8.5. CIFAR-10: false negatives for identifying a cat
Explainable AI (xAI) is a research field that is concerned with the task of
applying complex models and algorithms like deep learning while ensuring that
humans understand how those systems arrive at a certain result or prediction.
Iftheoutputneuronisreplacedbyalayeroftensoftmax-activatedneurons,the
architecture can also be used to tackle the complete problem of assigning the
photos to any of the ten object classes. The accuracy of that classifier applied
to the CIFAR-10 test dataset is 80%, and data augmentation may boost it to
90% [39].
Current state-of-the-art algorithms achieve an accuracy of more than 99% [46].
For comparison, humans are able to correctly label about 94% of CIFAR-10
images [47].
3 Adam stands for Adaptive Moment Estimation.


================================================================================
PAGE 296
================================================================================

282 Applications of machine learning
Fig. 8.6. MNISTdatasetforhandwrittendigitrecognition(top)andCIFAR-10dataset
for object recognition (bottom; original images are in color)


================================================================================
PAGE 297
================================================================================

8.1. Supervised learning in practice 283
model <- keras_model_sequential() %>%
layer_conv_2d(filters = 32, kernel_size = c(3,3)
, input_shape = c(32, 32, 3), padding = 'same') %>%
layer_activation_leaky_relu() %>%
layer_batch_normalization(axis = -1) %>%
layer_conv_2d(filters = 32, kernel_size = c(3,3)
, padding = 'same') %>%
layer_activation_leaky_relu() %>%
layer_batch_normalization(axis = -1) %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
layer_conv_2d(filters = 64, kernel_size = c(3,3)
, padding = 'same') %>%
layer_activation_leaky_relu() %>%
layer_batch_normalization(axis = -1) %>%
layer_conv_2d(filters = 64, kernel_size = c(3,3)
, padding = 'same') %>%
layer_activation_leaky_relu() %>%
layer_batch_normalization(axis = -1) %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
layer_conv_2d(filters = 128, kernel_size = c(3,3)
, padding = 'same') %>%
layer_activation_leaky_relu() %>%
layer_batch_normalization(axis = -1) %>%
layer_conv_2d(filters = 128, kernel_size = c(3,3)
, padding = 'same') %>%
layer_activation_leaky_relu() %>%
layer_batch_normalization(axis = -1) %>%
layer_max_pooling_2d(pool_size = c(2,2)) %>%
layer_flatten() %>%
layer_dense(units = 512) %>%
layer_activation_leaky_relu() %>%
layer_batch_normalization(axis = -1) %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 1, activation = "sigmoid");
model %>% compile(
optimizer = 'adam',
loss = 'binary_crossentropy', metrics = 'accuracy'.
);
set.seed(1234)
history <- model %>%
fit(
x = X_train, y = Y_train, epochs = 20, batch_size = 20,
validation_data = unname(list(x = X_val, y = Y_val))
);
Fig. 8.7. Example code for defining and training a convolutional neural network


================================================================================
PAGE 298
================================================================================

284 Applications of machine learning
8.1.3 Large Movie Review Dataset: sentiment analysis
In the broadest sense, sentiment analysis is the systematic identification,
extraction,andmeasurementofinformationcharacterizedbyasubjectivefeeling.
For example, a biometric image or video capture system could be trained to
recognize what state of mind a person is in: are they happy, sad, angry, etc.?
In a narrower sense, sentiment analysis is a task of natural language processing
(NLP) and consists of analyzing text data with respect to content such as
expressionsofemotionoropinion.Oneparticularsuchanalysisistheevaluation
of the polarity of a text, or part of it: does the author express a positive or
negative opinion, do they speak positively or negatively about a topic?
A simple way to determine polarity is to use a dictionary of terms that have
positive/negativeconnotations,orusuallyexpressapositive/negativesentiment.
The text under study would then be matched with the dictionary. For example,
the sentence “I love this wonderful movie” contains the words “love” and “won-
derful,” suggesting positive sentiment. Conversely, if a text contains negatively
connotated words like “hate” or “disgusting,” the system might classify it as
expressing a negative sentiment. The dictionary may also include emoticons like
:-) or :-(.
Lexicoder 2015 [48, 49] and VADER4 [50] are examples of dictionaries for
sentiment analysis. Another option is to use supervised learning, as we will
demonstrate below.
We use the dataset Large Movie Review Dataset v1.0 [51, 52]. A version
simplified in format is available on the data science platform Kaggle [53]. The
dataset contains a total of 50,000 English-language reviews of feature films and
televisionserieswrittenbyusersoftheInternetMovieDatabase5.Dependingon
whether the user liked the movie or trashed the movie, the reviews are labeled
as positive or negative.
Here are two example texts from the dataset that clearly express the author’s
sentiment towards the reviewed movie:
polarity review
positive If you like original gut wrenching laughter you will like this movie. If
you are young or old then you will love this movie, hell even my mom
liked it. Great Camp!!!
negative Hated it with all my being. Worst movie ever. Mentally scarred. Help
me. It was that bad. TRUST ME!!!
Table 8.3. Positive/negative movie reviews
We want to use a naive Bayes classifier to automatically label a movie review as
either positive or negative. First, we use single words as tokens, case-insensitive.
4 VADER stands for Valence Aware Dictionary and sEntiment Reasoner.
5 https://www.imdb.com/


================================================================================
PAGE 299
================================================================================

8.1. Supervised learning in practice 285
Although we apply some fairly advanced theory, we should remind ourselves
that the underlying rationale is quite intuitive: We perform a word frequency
analysisandcounthowoftencertainwordsappearinpositive/negativereviews.
For example, the following words appear almost exclusively in positive reviews:
token flawless superbly perfection wonderfully must-see
likelihood (pos.) 90% 89% 89% 88% 88%
Table 8.4. Words that indicate a positive movie review
On the other hand, an occurrence of the following tokens6 indicates a negative
review:
token stinker mst3k waste unwatchable 0 unfunny
likelihood (neg.) 96% 96% 94% 93% 92% 92%
Table 8.5. Words that indicate a negative movie review
The words thus identified are then used as features to classify any movie review
as either positive or negative. That is, even if the algorithm has not seen a
particularreviewyet:theoccurrenceoftheterm“stinker” willindicateanegative
opinion for almost any review.
The naive Bayes classifier was trained using 40,000 reviews. A total of D =
149,653wordscanbeextractedfromthosetexts.Laplacesmoothingwasapplied
toregularizethefrequenciesofwordoccurrence.Appliedtothetestdatasetofthe
remaining 10,000 reviews, machine learning provides a significant improvement
over the rule-based methods:
precision recall F score
1
Lexicoder 2015 70.9% 74.6% 72.7%
VADER 65.0% 79.0% 71.3%
multinomial 87.2% 81.1% 84.1%
Bernoulli 88.6% 81.1% 84.7%
random (baseline) 50.0% 50.0% 50.0%
Table 8.6. Performance of different methods for sentiment analysis
A further improvement can be achieved by using not only words but also
N-grams as features. An N-gram is a contiguous sequence of N tokens. For
example, the sentence “I love this wonderful movie” consists of the following
N-grams, N ≤4:
6 Mystery Science Theater 3000, or MST3K, is a television show that spoofs select
B movies.


================================================================================
PAGE 300
================================================================================

286 Applications of machine learning
N N-grams
1 i, love, this, wonderful, movie
2 i love, love this, this wonderful, wonderful movie
3 i love this, love this wonderful, this wonderful movie
4 i love this wonderful, love this wonderful movie
Table 8.7. Examples of N-grams
Both monograms (N =1) and bigrams (N =2) were used as features to arrive
at the following performance:
precision recall F score
1
multinomial, N-grams 88.7% 87.1% 87.9%
Bernoulli, N-grams 87.0% 89.5% 88.2%
Table 8.8. Performance of naive Bayes classifiers based on N-grams
Since the use of N-grams increases the number of features significantly, feature
selection was performed before training: First, N-grams occurring in fewer than
ten reviews were removed. Additionally, 10% of the N-grams with smallest
mutual information with the distribution of positive/negative sentiment were
removed.Asaresultofthisprocedure,atotalofD =137,806N-gramsremained
for the final analysis.
Here are two examples of misclassified reviews, where key aspects have been
highlighted manually:
ground truth prediction review
positive negative InBlackMask,JetLiplaysabio-engineeredsuper-killer
turned pacifist, who has to fight against other super-
killers. Bad plot, bad sfx (60 million dollar budget),
but the fighting scenes were excellent! Jet Li is
the greatest martial-arts star alive!
negative positive ThefirstpartofGreasewithJohnTravoltaandOlivia
NewtonJohnisoneofthebestmovieforteens,This
one is a very bad copy. The change is only in the
sex. In the first one the good one was Sandy, here it’s
Michael. I prefer to watch the first Grease.
Table 8.9. Misclassified movie reviews
The first example is a more balanced review that also lists negative aspects of
the film. In the second misclassification, the positive opinion refers to an earlier
film in the series—but the actual subject of the review was evaluated negatively.
Thus, it could have been advantageous to perform the sentiment analysis not at
the document level but at the aspect level [54].


================================================================================
PAGE 301
================================================================================

8.2. Unsupervised learning in practice 287
8.2 Unsupervised learning in practice
For the applications in the following sections, we use data from IMDb, the
Internet Movie Database [55], as we did in the previous chapter. The dataset7
contains a total of 85,855 movies, with attributes such as the title, an En-
glish language description, average user rating, number of ratings, genre, etc.
The movies have 297,705 people associated with them who worked on their
production: actors and actresses, directors, cinematographers, etc.
8.2.1 Text mining: topic modelling
First,wewouldliketoexaminethefilms’descriptions.Werestricttheanalysisto
two genres and a certain time period: 3141 family films and 2835 science fiction
films from the years 1980–2020. We want to get a quick overview of typical
themes that inform the plots of those films. To avoid reading and manually
summarizing all of the 6000 plot descriptions, we use methods of automated
text analysis instead, which is also called text mining.
In order to make the unstructured text data accessible to such an analysis,
we must preprocess it first. Similar to the sentiment analysis of movie reviews
(Sect. 8.1.3), we tokenize the text. In this case, the tokens are not only a means
for the algorithm to compute the final result. As we will see later, they are also
presented to the analyst as items in a topic map. Therefore, we have to be a
bit more careful with the feature selection and only extract tokens that have a
certain relevance for the content of the text. For example, certain words should
be excluded from the analysis that occur very frequently in almost any text
corpus, such as the articles “the,” “a,” or frequently occurring prepositions such
as “with” or “from.” These stopwords are removed during the preprocessing of
the data.
Furthermore, we will use only noun phrases: these can be single nouns like
“astronaut” but also groups of words like “virtual reality” or “time machine.”
Noun phrase extraction can be performed with software libraries for natural
language processing like quanteda [57] or spaCy [58, 59] Finally, we will only
consider phrases composed of no more than two words.
A total of 105,292 noun phrases were extracted from the corpus. These are of
variable relevance to the content. The following table shows a small selection
of “genre-typical” phrases and their frequency of occurrence in the respective
genres in percent. Any proportions missing from 100% are covered by the
remaining genres. For example, 73% of all films that contain the phrase “outer
space” in the description are science fiction films. We want to focus on such
genre-typical phrases and calculate the mutual information of each phrase with
the distribution of genres to inform feature selection.
7 As of 2023, the cited dataset is not available at Kaggle anymore. The same author
has since then published a similar dataset [56] that can be used instead.


================================================================================
PAGE 302
================================================================================

288 Applications of machine learning
genre
crime family horror romance sci-fi western
phrase
undercover cop 65 0 4 0 2 0
fairy tale 2 39 6 16 0 2
occult 7 2 80 5 2 0
young lovers 8 0 8 43 5 0
outer space 2 13 22 4 73 0
cavalry 1 4 0 18 0 70
Table 8.10. Noun phrases typically associated with certain film genres
First, from the 10,522 phrases that occur in descriptions of family films, we
removethosethatoccureitherinlessthantendescriptionsormoreoftenthanin
25% ofthe descriptions. The rationalebehind thisapproach: ifa phrase appears
in only a few texts, it is not descriptive for the whole corpus or significant parts
ofthecorpus.Ifthephraseappearstoooften,itisnotwell-suitedasafeatureto
distinguish between different sub-types of family films. This procedure reduces
the number of tokens to 674. Finally, from these remaining nominal phrases,
the top 60 are selected according to their mutual information score.
The features that we want to use to characterize the science fiction films are
selected using the same method. Finally, we apply the t-SNE algorithm to the
similarity matrix between the phrases, which is calculated using the overlap
coefficient: if two phrases tend to appear in the same films, that score is going
to be high. This results in two topic maps, shown in Fig. 8.8. Moreover, the
size of the phrases was scaled with the frequency of their occurrence.
8.2.2 Network analysis: community structure
In addition to the description for each film, the IMDb dataset also contains a
list of actors and actresses who worked on each film. From these data, we can
construct a collaboration network: If two actors/actresses appear together
in at least one movie, we determine that they are connected in that sense.
Mathematically,suchanetworkisanundirectedgraph:eachnoderepresentsan
actororactress,andeachcollaborationanedge.Thus,wecanalsodrawanode–
link diagram for such a graph: see Fig. 8.9 for an example of a collaboration
network of actors and actresses that played in at least one movie directed by
Martin Scorsese. With a few exceptions, all names have been pseudonymized to
ensure information privacy.
The position of the nodes in the diagram were determined using the t-SNE
method, and the visualization was generated using R libraries for network
analysis[60,61,62].Examplesofsoftwareentirelydedicatedtonetworkanalysis
and visualization include Gephi [63] and Cytoscape [64].
Althoughthechartshowsonlyaverysmallsectionofthecollaborationnetwork,
it may already be quite confusing due to clutter. Especially in the vicinity of


================================================================================
PAGE 303
================================================================================

8.2. Unsupervised learning in practice 289
strongly networked actors/actresses (so-called hubs), it is not easy to visually
trace collaborations.
One way to reduce complexity is to detect clusters in the network, the com-
munities: Fig. 8.10 shows the dendrogram of a hierarchical cluster analysis
using the average-linkage method, based on min–max scaled Jaccard similarity,
computed from the number of films in which both performers appeared in.


================================================================================
PAGE 304
================================================================================

290 Applications of machine learning
two kids
twins
mouse
imagination coach
basketball
two boys soccer imaginary
league bullies
baseball junior
fairy tale
piratefavorite feel monkey
companion toy books
dogs odds dragon danis g h olden lessons emma
courage
surprise grandpa
elephantzoo
stepmother strict new frie l n it d tl s e bro su th p e er r hero animal
snow pet
gift fair dysfunction li a t l tle girl santa clcaluasus wizard
season christmas eve
horses
holidays angel green
little sister puppy
orphanage
bird
single msowtheedren
federation
nuclear war
mutants
chemical
laboratory mutant
landing
transport rampage waste entity
galaxy deep space android toxic ufo
research facility
astronauts
robots machines
flesh serum
space station small group
extinction apocalyptic
mars dystopian
meteor
frozen astronautdna time travel
near futuredinosaurs science fiction
epide d m oc i t c ors network lethal planet eaortnhly hoopueter space video game
virtual reality
cyborg human race
wastelanhodlocaust
extraterrestrial
beings
apocalypse
alien invasion
clone satellite
spacecraft
crash lands
artificial intelligence
distant future
time machine
Fig. 8.8. Topic maps for family films and science fiction films (1980-2020)


================================================================================
PAGE 305
================================================================================

8.2. Unsupervised learning in practice 291
areviR
assylA
edaaS-la
deezaM
attoiL
yaR
retsoF
eidoJ
ytreffaL
werdnA
rewerB
leahciM
relkcaC
rehpotsirhC
nosrekcE
ehC
aloidrauG
nitsuguA
laucsaP-zehcnaS
xelA
grubniklaF
ecnerwaL
siweL
etteiluJ
aereP
ynattirB
kloP
nyraT
eeL
araG
relliM
neelhtaK
enrohT
samohT
eL
ulnaH
nadroJ
annaiT
lligcM
ekuL
remitroM
ylimE
amtsoP
auhsoJ
eellA-le
adiaaR
einodeB
assenaV
ollitsaC
edaC
eibboR
tograM
naH
kebiB
giwtraH
eiraM
neyugN
gnohP
zednanreF
assyllA
gnulccM
nhoJ
amaJ-la
a'fiR
yhguagcM
annaiK
imihaR-la
ahsooM
siweL-yaD
leinaD
revirD
madA
trawetS
retnuH
namahaR-la
hsee'aY
imezaK-le
arimaahT
)dezimynoduesp
yllaitrap(
sessertca/srotca
fo
krowten
noitaroballoC
.9.8
.giF


================================================================================
PAGE 306
================================================================================

292 Applications of machine learning
Kianna Mcgaughy
Allyssa Fernandez
Taryn Polk
Cade Castillo
Raaida el-Allee
Joshua Postma
Margot Robbie
Phong Nguyen
Vanessa Bedonie
Hanlu Le
Bibek Han
Rif'a al-Jama
Marie Hartwig
Emily Mortimer
Luke Mcgill
Gara Lee
Ya'eesh al-Rahaman
Daniel Day-Lewis
Hunter Stewart
Kathleen Miller
Juliette Lewis
Lawrence Falkinburg
Tianna Jordan
Thomas Thorne
Che Eckerson
Michael Brewer
Jodie Foster
Brittany Perea
Augustin Guardiola
Alex Sanchez-Pascual
Mazeed al-Saade
Andrew Lafferty
Alyssa Rivera
Christopher Cackler
Ray Liotta
Adam Driver
Moosha al-Rahimi
Thaamira el-Kazemi
John Mcclung
0.00 0.25 0.50 0.75 1.00
Fig. 8.10. Hierarchical cluster analysis of a collaboration network of actors/actresses
(partially pseudonymized)


================================================================================
PAGE 307
================================================================================

References 293
References
[1] S. Kevin Zhou, Hayit Greenspan, and Dinggang Shen, eds. Deep Learning
for Medical Image Analysis. Academic Press, Jan. 2017.
[2] Edward H. Lee et al. “Deep COVID DeteCT: an international experience
onCOVID-19lungdetectionandprognosisusingchestCT”.In:npjDigital
Medicine 4.1 (Jan. 2021). doi: 10.1038/s41746-020-00369-1.
[3] Nikolas Lessmann et al. “Automated Assessment of COVID-19 Reporting
and Data System and Chest CT Severity Scores in Patients Suspected of
Having COVID-19 Using Artificial Intelligence”. In: Radiology 298.1 (Jan.
2021), E18–E28. doi: 10.1148/radiol.2020202439.
[4] Austin Robert Clyde. “Artificial Intelligence and High-Performance Com-
puting for Accelerating Structure-Based Drug Discovery”. PhD thesis.
University of Chicago, Dec. 2022.
[5] Ewen Callaway. “What’s next for AlphaFold and the AI protein-folding
revolution”. In: Nature 604.7905 (Apr. 2022), pp. 234–238. doi: 10.1038/
d41586-022-00997-5.
[6] Željko Ivezić et al. Statistics, Data Mining, and Machine Learning in
Astronomy. Revised Edition. Princeton University Press, Dec. 2019.
[7] Sander Dieleman, Kyle W. Willett, and Joni Dambre. “Rotation-invariant
convolutional neural networks for galaxy morphology prediction”. In:
Monthly Notices of the Royal Astronomical Society 450.2 (Apr. 2015),
pp. 1441–1459. doi: 10.1093/mnras/stv632. arXiv:1503.07077.
[8] Helena Domínguez Sánchez et al. “Improving galaxy morphologies for
SDSSwithDeepLearning”.In:Monthly Notices of the Royal Astronomical
Society 476.3 (Feb. 2018), pp. 3661–3676. doi: 10.1093/mnras/sty338.
arXiv:1711.05744.
[9] Carlos Alberto Gomez Gonzalez, Olivier Absil, and Marc van Droogen-
broeck. “Supervised detection of exoplanets in high-contrast imaging
sequences”. In: Astronomy & Astrophysics 613 (May 2018), A71. doi:
10.1051/0004-6361/201731961. arXiv:1712.02841.
[10] Faustine Cantalloube et al. “Exoplanet imaging data challenge: bench-
markingthevariousimageprocessingmethodsforexoplanetdetection”.In:
Adaptive Optics Systems VII. Ed. by Dirk Schmidt, Laura Schreiber, and
Elise Vernet. Vol. 11448. International Society for Optics and Photonics.
SPIE, Dec. 2020, pp. 1027–1062. doi: 10.1117/12.2574803.
[11] Fan Zhang et al. MediaPipe Hands: On-device Real-time Hand Tracking.
June 2020. arXiv:2006.10214v1.
[12] Dong Yu and Li Deng. Automatic Speech Recognition. Springer, London,
2015. doi: 10.1007/978-1-4471-5779-3.
[13] Sampo Kuutti et al. “A Survey of Deep Learning Applications to Au-
tonomous Vehicle Control”. In: IEEE Transactions on Intelligent Trans-
portation Systems (2020), pp. 1–22. doi: 10.1109/tits.2019.2962338.
arXiv:1912.10773.


================================================================================
PAGE 308
================================================================================

294 Applications of machine learning
[14] Fabrizio Carcillo et al. “Combining unsupervised and supervised learning
in credit card fraud detection”. In: Information Sciences (May 2019). doi:
10.1016/j.ins.2019.05.042.
[15] Aditya Ramesh et al. Zero-Shot Text-to-Image Generation. 2021. doi:
10.48550/ARXIV.2102.12092.
[16] Aditya Ramesh et al. Hierarchical Text-Conditional Image Generation
with CLIP Latents. 2022. doi: 10.48550/ARXIV.2204.06125.
[17] Robin Rombach et al. High-Resolution Image Synthesis with Latent Dif-
fusion Models. 2021. doi: 10.48550/ARXIV.2112.10752.
[18] Tom B. Brown et al. Language Models are Few-Shot Learners. May 2020.
doi: 10.48550/ARXIV.2005.14165.
[19] Leo Gao, John Schulman, and Jacob Hilton. Scaling Laws for Reward
Model Overoptimization. Sept. 2020. doi: 10.48550/ARXIV.2210.10760.
[20] Nisan Stiennon et al. “Learning to summarize with human feedback”.
In: Advances in Neural Information Processing Systems. Ed. by H.
Larochelle et al. Vol. 33. Curran Associates, Inc., 2020, pp. 3008–3021.
arXiv:2009.01325.
[21] Aarohi Srivastava et al. Beyond the Imitation Game: Quantifying and
extrapolating the capabilities of language models.June2022.doi:10.48550/
ARXIV.2206.04615.
[22] Renqian Luo et al. “BioGPT: generative pre-trained transformer for
biomedical text generation and mining”. In: Briefings in Bioinformatics
23.6 (Sept. 2022). doi: 10.1093/bib/bbac409. arXiv:2210.10341.
[23] Prafulla Dhariwal et al. Jukebox: A Generative Model for Music. Apr.
2020. doi: 10.48550/ARXIV.2005.00341.
[24] Andrea Agostinelli et al. MusicLM: Generating Music From Text. Jan.
2023. arXiv:2301.11325.
[25] Cade Metz. “Meet DALL-E, the A.I. That Draws Anything at Your
Command”. In: The New York Times (Aug. 2022). url: https://www.
nytimes.com/2022/04/06/technology/openai-images-dall-e.html.
[26] Kevin Roose. “The Brilliance and Weirdness of ChatGPT”. In: The New
York Times (Dec. 2022). url: https://www.nytimes.com/2022/12/05/
technology/chatgpt-ai-twitter.html.
[27] Ajay Agrawal, Joshua Gans, and Avi Goldfarb. “ChatGPT and How
AI Disrupts Industries”. In: Harvard Business Review (Dec. 2022). url:
https://hbr.org/2022/12/chatgpt-and-how-ai-disrupts-industries.
[28] Ted Chiang. “ChatGPT Is a Blurry JPEG of the Web”. In: The New
Yorker (Feb. 2023). url: https://www.newyorker.com/tech/annals-of-
technology/chatgpt-is-a-blurry-jpeg-of-the-web.
[29] Elif Kiesow Cortez, ed. Data Protection Around the World. T.M.C. Asser
Press, 2021. doi: 10.1007/978-94-6265-407-5.
[30] Matthias Plaue. “Rise of the Mindless Machines”. In: towards data science
(Nov. 2018). url: https://towardsdatascience.com/rise-of-the-mindless-
machines-c0e578061e65.


================================================================================
PAGE 309
================================================================================

References 295
[31] Anna Jobin, Marcello Ienca, and Effy Vayena. “The global landscape of
AI ethics guidelines”. In: Nature Machine Intelligence 1.9 (Sept. 2019),
pp. 389–399. doi: 10.1038/s42256-019-0088-2. arXiv:1906.11668.
[32] Miles Brundage et al. Toward Trustworthy AI Development: Mechanisms
for Supporting Verifiable Claims. Apr. 2020. doi: 10.48550/ARXIV.2004.
07213.
[33] Markus D. Dubber, Frank Pasquale, and Sunit Das, eds. The Oxford
Handbook of Ethics of AI. Oxford University Press, July 2020. doi: 10.
1093/oxfordhb/9780190067397.001.0001.
[34] Emily M. Bender et al. “On the Dangers of Stochastic Parrots”. In:
Proceedings of the 2021 ACM Conference on Fairness, Accountability, and
Transparency. ACM, Mar. 2021. doi: 10.1145/3442188.3445922.
[35] Philipp Hacker, Andreas Engel, and Marco Mauer. Regulating ChatGPT
and other Large Generative AI Models. Feb. 2023. doi: 10.48550/ARXIV.
2302.02337.
[36] Yann LeCun, Corinna Cortes, and Christopher J. C. Burges. The MNIST
database of handwritten digits. 2010. url: http://yann.lecun.com/exdb/
mnist/.
[37] Jiang Junfeng. readmnist: Read MNIST Dataset. R package. 2018. url:
https://CRAN.R-project.org/package=readmnist.
[38] Alex Krizhevsky. Learning Multiple Layers of Features from Tiny Images.
Tech. rep. 2009.
[39] Moritz Hambach. Image Augmentation in Keras (CIFAR-10). Jan. 2018.
url: https://github.com/moritzhambach/Image-Augmentation-in-Keras-
CIFAR-10-.
[40] François Collet et al. Keras. url: https://keras.io.
[41] J.J.AllaireandFrançoisChollet.keras: R Interface to ’Keras’.Rpackage.
2020. url: https://CRAN.R-project.org/package=keras.
[42] Martín Abadi et al. TensorFlow: Large-Scale Machine Learning on Het-
erogeneous Systems. url: https://www.tensorflow.org/.
[43] J. J. Allaire and Yuan Tang. tensorflow: R Interface to ’TensorFlow’. R
package. 2020. url: https://CRAN.R-project.org/package=tensorflow.
[44] Diederik P. Kingma and Jimmy Ba. “Adam: A Method for Stochastic
Optimization”. In: 3rd International Conference on Learning Represen-
tations, San Diego, USA. Ed. by Yoshua Bengio and Yann LeCun. May
2015. arXiv:1412.6980.
[45] Sergey Ioffe and Christian Szegedy. “Batch Normalization: Accelerating
Deep Network Training by Reducing Internal Covariate Shift”. In: 32nd
International Conference on Machine Learning, Lille, France. Ed. by
Francis Bach and David Blei. Vol. 37. Proceedings of Machine Learning
Research. PMLR, July 2015, pp. 448–456. arXiv:1502.03167.
[46] Papers with Code Community. CIFAR-10 Benchmark (Image Classi-
fication). Ed. by Robert Stojnic et al. Accessed Nov. 20, 2022. url:
https://paperswithcode.com/sota/image-classification-on-cifar-10.


================================================================================
PAGE 310
================================================================================

296 Applications of machine learning
[47] Andrej Karpathy. Lessons learned from manually classifying CIFAR-10.
Apr. 2011. url: http://karpathy.github.io/2011/04/27/manually-
classifying-cifar10/.
[48] Lori Young and Stuart Soroka. Lexicoder Sentiment Dictionary. 2012.
[49] Lori Young and Stuart Soroka. “Affective News: The Automated Coding
of Sentiment in Political Texts”. In: Political Communication 29.2 (2012),
pp. 205–231. doi: 10.1080/10584609.2012.671234.
[50] C. Hutto and Eric Gilbert. “VADER: A Parsimonious Rule-Based Model
for Sentiment Analysis of Social Media Text”. In: Proceedings of the
International AAAI Conference on Web and Social Media 8.1 (May 2014),
pp. 216–225. doi: 10.1609/icwsm.v8i1.14550.
[51] Andrew L. Maas et al. “Learning Word Vectors for Sentiment Analysis”.
In:49th Annual Meeting of the Association for Computational Linguistics:
Human Language Technologies, Portland, Oregon, USA. Association for
Computational Linguistics, June 2011, pp. 142–150.
[52] Andrew L. Maas. Large Movie Review Dataset v1.0. Accessed Nov. 15,
2020. url: http://ai.stanford.edu/~amaas/data/sentiment/.
[53] N.Lakshmipathi.IMDb dataset of 50k movie reviews. Large Movie Review
Dataset. Accessed Nov. 15, 2020. url: https://www.kaggle.com/lakshmi2
5npathi/imdb-dataset-of-50k-movie-reviews.
[54] Ambreen Nazir et al. “Issues and Challenges of Aspect-based Sentiment
Analysis: A Comprehensive Survey”. In: IEEE Transactions on Affective
Computing (2020). doi: 10.1109/taffc.2020.2970399.
[55] Stefano Leone. IMDb movies extensive dataset. 81k+ movies and 175k+
cast members scraped from IMDb.
[56] StefanoLeone.FilmTVmoviesdataset.40k+moviesscrapedfromFilmTV.
Accessed Jan. 22, 2023. url: https://www.kaggle.com/datasets/stefanole
one992/filmtv-movies-dataset.
[57] Kenneth Benoit et al. “quanteda: An R package for the quantitative
analysis of textual data”. In: Journal of Open Source Software 3.30 (2018),
p. 774. doi: 10.21105/joss.00774. url: https://quanteda.io.
[58] Matthew Honnibal and Ines Montani. spaCy. Industrial-Strength Natural
Language Processing. Accessed Dec. 9, 2020. url: https://spacy.io/.
[59] KennethBenoitandAkitakaMatsuo.spacyr: Wrapper to the ’spaCy’ NLP
Library. R package. 2020. url: https://CRAN.R-project.org/package=
spacyr.
[60] Barret Schloerke et al. GGally: Extension to ’ggplot2’. R package. 2020.
url: https://CRAN.R-project.org/package=GGally.
[61] Carter T. Butts. network: Classes for Relational Data. R package. The
Statnet Project (http://www.statnet.org). 2020. url: https://CRAN.R-
project.org/package=network.
[62] Carter T. Butts. “network: a Package for Managing Relational Data in
R”. In: Journal of Statistical Software 24.2 (2008). url: https://www.
jstatsoft.org/v24/i02/paper.


================================================================================
PAGE 311
================================================================================

References 297
[63] Mathieu Bastian, Sebastien Heymann, and Mathieu Jacomy. Gephi: An
Open Source Software for Exploring and Manipulating Networks. 2009.
url: https://gephi.org/.
[64] Paul Shannon et al. “Cytoscape: A Software Environment for Integrated
Models of Biomolecular Interaction Networks”. In: Genome Research
13.11 (Nov. 2003), pp. 2498–2504. doi: 10.1101/gr.1239303. url: https:
//cytoscape.org/.


================================================================================
PAGE 312
================================================================================

Appendix


================================================================================
PAGE 313
================================================================================




================================================================================
PAGE 314
================================================================================

A
Exercises with answers
A.1 Exercises
Exercise 1. Entity–relationship model. Draw an entity–relationship dia-
graminChennotationthatmodelsthedomainofamoviedatasetthatcontains
the following information about each film:
• title, year, and genre of the film,
• names of the actors and actresses cast in the film,
• names of the directors of the film,
• names and addresses of production companies involved.
The model includes the following entity types: person, company, film.
Exercise 2. Data quality assessment. The data table below lists organiza-
tions and their attributes:
• id: primary key; unique identifier for the organization
• name: name of the organization
• cc: country of origin/location of headquarters of the organization; two letter
country codes according to ISO 3166-1 alpha-2 standard1
• city: name of the city that the organization’s headquarters are located in
• hospital: binary Boolean variable, TRUE if the organization is a hospital
or other medical facility
Checkforinvalid,missing,orotherwisecorruptedornotoptimallycleaneddata.
Identify as many data defects and data quality issues as possible.
1 https://www.iso.org/iso-3166-country-codes.html
© Springer-Verlag GmbH Germany, part of Springer Nature 2023 301
M. Plaue, Data Science, https://doi.org/10.1007/978-3-662-67882-4


================================================================================
PAGE 315
================================================================================

302 Exercises with answers
id name cc city hospital
5 Apple Inc. US TRUE
1 Samsung Electronics Co., Ltd. KR ⟨NA⟩ TRUE
10 Boston Children’s Hospital US Boston FALSE
7 Mayo Clinic US Rochester FALSE
8 Uber Technologies US ⟨NA⟩ TRUE
6 Tesla ZZ Austin TRUE
9 Oxford Univeristy UK Oxford TRUE
10 Oxford University GB Oxford TRUE
4 Seoul National Univeristy KR NULL TRUE
2 Broadcom Limited US San Jose TRUE
3 Stanford Univeristy US TRUE
Table A.1. Dirty organization data
Exercise 3. Exploratory data analysis. The UC Irvine Machine Learning
RepositoryprovidestheresultsofasurveyoffacultymembersfromtwoSpanish
universities on teaching uses of Wikipedia [1, 2]:
https://doi.org/10.24432/C50031
Download the data and process them with a tool for data analysis and visual-
ization of your choosing, e.g., RStudio [3] or Colab [4].
1. Provide an overview of the respondents’ demographics that includes age,
years of experience, domain/field of expertise, and job position.
2. TheanswerstothesurveyquestionsaregivenonaLikert scalethatranges
fromone(stronglydisagree/never)tofive(stronglyagree/veryoften).Which
ofthequestionsdoamajorityofsurveyparticipantsselectextremeresponses
for?
3. Membersfromwhichdomainsarethemost/leastlikelytoconsultWikipedia
for issues related to their field of expertise? Compare with the practice of
citing Wikipedia in academic papers.
Use charts to visualize your findings.
Hint: As of April 2023, the codebook supplied by the UCI website is incomplete
and does not explain the meaning of the variable assignment DOMAIN = 6.
Comparison with the original publication [2], however, shows that this value
almost certainly corresponds to “Social Sciences.”
Exercise 4. Base rate fallacy. In February 2023, a member of the UK
parliament posted on Twitter [5]: “devastating stats from New Zealand, how


================================================================================
PAGE 316
================================================================================

A.1. Exercises 303
can anyone deny the [COVID] vaccine harms now,” referencing the following
statistics [6]:
900
600
300
0
0-59 60-69 70-79 80-89 90+
age group
shtaed
not fully vaccinated
fully vaccinated
received booster
Fig. A.1. COVID-19 deaths by vaccination status
Wecancomputethepercentagesbyvaccinationstatusfromthosedata.Depend-
ing on age group, among all fatalities, between 69% and 89% died of COVID
even though they had been fully vaccinated against the disease:
100%
89%
69%
50%
0%
0-59 60-69 70-79 80-89 90+
age group
shtaed
not fully vaccinated fully vaccinated received booster
Fig. A.2. Vaccination status of people that died of COVID-19
DothosedataactuallysupportthehypothesisthatCOVIDvaccinesaregenerally
harmful? If not, provide an (educational) explanation for the presumably high
proportion of vaccinated individuals among the fatalities.


================================================================================
PAGE 317
================================================================================

304 Exercises with answers
Hint: As of February 2023, at least 80% of New Zealand’s population has been
fully vaccinated/boosted against COVID-19 [7]. In the age groups 80+, at least
95% of the population are fully vaccinated/boosted [8].
Exercise 5. Birthday problem. Assume that when selecting a person from
the population at random, they have one of 365 possible birthdays with equal
probability. Among N randomly selected people, what is the probability that
at least two of them share a birthday? For which values of N is the probability
that two people share a birthday at least 50%, 95%, 100%?
Exercise6.Exponentialdistribution. Considerthefollowingparameterized
family of exponential probability density functions:
(
λ·e−λu if u>0
Exp(u|λ)=
0 if u≤0
with parameter λ>0.
SupposethatX isarandomvariablethatisexponentiallydistributed.Compute
the mean, the median, and the variance of X (as a function of the parameter
λ).
Given numeric data x ,...,x , derive the formula to determine the parameter
1 N
λ, based on the maximum likelihood method.
Exercise 7. Box–Muller transform. Let V and W be independent con-
tinuous random variables that are both uniformly distributed on the interval
[0,1].
Define the following random variables:
√
X = −2lnV ·cos(2πW),
√
Y = −2lnV ·sin(2πW)
Prove that X and Y are independent and standard normally distributed. You
may use the following formula for the transformation of joint probability densi-
ties:
p (r,θ)=p (φ(r,θ))·|Dφ(r,θ)|
φ−1(X,Y) X,Y
whereφ: U →R2 withU ⊆R2 iscontinuouslydifferentiableandinjective(with
the possible exception of isolated points).
Hint: As the naming of the arguments already suggests, the polar coordinate
map
(cid:18) (cid:19)
r·cos(θ)
φ: [0,∞[×[0,2π[→R2, (r,θ)7→
r·sin(θ)
is of particular interest here.


================================================================================
PAGE 318
================================================================================

A.1. Exercises 305
Exercise 8. Simpson’s paradox. At a university’s six largest departments,
p =30% of N =1835 female applicants are admitted, compared to p =45%
x x y
of N = 2691 male applicants. Use the one-sided Z-test to show that the
y
difference in admission rate is statistically significant at a 99% confidence level,
which would support the hypothesis that female applicants are more likely to
be rejected.
These are the numbers broken down by university department:
dept. N p N p
x x y y
A 108 82% 825 62%
B 25 68% 560 63%
C 593 34% 325 37%
D 375 35% 417 33%
E 393 24% 191 28%
F 341 7% 373 6%
all 1835 30% 2691 45%
Table A.2. University admission rates by department and gender
Show that an analysis of the data for each department does not support the
hypothesis that female applicants are more likely to be rejected. Try to find an
explanation for this paradoxical result.
Hint: Foreachdepartment,computetheadmissionrate p,irrespectiveofgender.
Which departments are the easiest to be admitted to, and persons of which
gender typically apply for them?
Exercise 9. Expected root mean squared error of random guessing.
Suppose that we are given a test dataset for a regression task where the target
variable takes values y ,...,y between zero and one. A machine guesses every
1 M
outcome by randomly choosing a number from the unit interval with uniform
probability, yielding the predictions yˆ ,...,yˆ . Prove the following inequality:
1 M
E

 M 1 X M (Y m −Yˆ m )2
!1
2

<0.58
m=1
where Y ,...,Y and Yˆ ,...,Yˆ are i.i.d. random variables that produce the
1 M 1 M
target values and predictions, respectively.
Hint: Since the random variable Y takes values within the unit interval, E[(1−
Y)·Y]≥0.
Exercise 10. Data transformations. Consider the tasks of training a
K-nearest neighbor classifier (using Euclidean distance), applying a linear
regression, applying a logistic regression, and performing a K-means cluster
analysis.


================================================================================
PAGE 319
================================================================================

306 Exercises with answers
Determine for each task whether mean-centering or standardizing the features
beforehand would have an impact on the results, assuming that the mean and
standard deviation is estimated once and the same transformation applied to
all datasets involved. What about performing a full Karhunen–Loève transform
that preserves the dimensionality of the dataset? What about arbitrary affine
transformations that are invertible?
Hints: Which of those transformations preserve distances between data points?
How does the objective function change?
Exercise 11. Parkinson’s disease detection. For this exercise and the
following exercises, use of the Python libraries pandas [9, 10] and scikit-learn
[11] is recommended.
SpeechdisorderscanbeanearlysignofmotorimpairmentinParkinson’sdisease
[12]. The Oxford Parkinson’s Disease Detection Dataset [13, 14] can be used
to demonstrate that biomedical voice measurements are indicative of whether
the patient suffers from Parkinson’s. The dataset is available at the UC Irvine
Machine Learning Repository:
https://doi.org/10.24432/C59C74
Write a computer program that will:
• load the dataset; clean/normalize the data if necessary,
• standardize the features (i.e., compute the z-scores),
• split the data into training and testing data,
• train an L -regularized logistic regression classifier to predict whether the
2
voice recording comes from a patient who suffers from Parkinson’s disease,
with the regularization parameter determined from cross-validation aimed
at optimizing the F score,
1
• trainaK-nearestneighborclassifierforthesamepurposewithK determined
from cross-validation,
• train a neural network with a single hidden layer, the width of which is
determined from cross-validation,
• test all three classifiers and print the optimal hyperparameter, precision,
recall, F score, and accuracy.
1
Compare the performance of the classifiers with class majority assignment as
the baseline, i.e., with the performance of a machine that would assign every
data record the class that appears most frequently in the dataset.
Exercise 12. Customer segmentation. The UC Irvine Machine Learning
Repositoryincludesadataset[15]oftheannualspendingofclientsofawholesale
distributor on diverse product categories:


================================================================================
PAGE 320
================================================================================

A.1. Exercises 307
https://doi.org/10.24432/C5030X
Write a computer program that will:
• load the dataset and drop the Region column,
• filter the data records for clients that are restaurants, hotels, and cafés (i.e.,
drop clients from retail),
• normalize the data by computing the proportionate spending per product
category (i.e., each row in the data table sums to one),
• standardize the data,
• use K-means to cluster the distributor’s customers based on those data into
K =4 groups,
• print the cluster centroids.
Offer a shortdescriptionof each group of clients based on their annual spending
across product categories.
Exercise 13. Concrete compressive strength prediction. The following
dataset [16, 17] is available at the UC Irvine Machine Learning Repository
which can be used to demonstrate how the compressive strength of concrete
can be predicted from the composition and age of the material:
https://doi.org/10.24432/C5PK67
We can apply a Yeo–Johnson transform to each feature in a way that the
distribution of the variable more closely resembles a normal distribution. Write
a computer program that will:
• load the dataset and perform the necessary preprocessing,
• performaridgeregressionandtrainaneuralnetwork,withhyperparameters
tuned by cross-validation,
• using the raw data and the Yeo–Johnson transformed data,
• test all four regression algorithms and print the optimal hyperparameter,
coefficient of determination r2, and the root mean squared error.
Compare the performance of the regression models with the performance of a
machine that would assign every data record the mean of the target variable.


================================================================================
PAGE 321
================================================================================

308 Exercises with answers
A.2 Answers
Answer 1. Entity–relationship model.
directs
title
M N
name person acts in film genre
M N
year
N
name company produces
M
address
Fig. A.3. Entity–relationship diagram of movie productions
Answer 2. Data quality assessment.
• typographic errors: almost all instances of “University” are misspelled as
“Univeristy”
• duplicates, incomplete disambiguation: the organization Oxford University
is represented by two data records
• id: Boston Children’s Hospital and Oxford University both reference the
same primary key
• name:incomplete/inconsistentharmonization:somecompanynamesinclude
the organization type (“Inc.”, “Ltd.”), some do not; types are abbreviated
but not always (“Broadcom Limited”)
• cc: “UK” is not a valid country code; “ZZ” may indicate missing data
• city:missingdata(5outof11datarecords);inconsistentformatformissing
data: NULL, ⟨NA⟩, empty string
• hospital: all the Boolean values have been flipped
Answer 3. Exploratory data analysis.
1. 46% of the respondents have a PhD, and 42% are female. The distribution
of age and years of experience can be visualized with histograms; bar charts
can be used to chart the distribution of domain and position: see Fig. A.6.


================================================================================
PAGE 322
================================================================================

A.2. Answers 309
For each respondent, if more than one job position was stated, the higher
position was selected.
2. More than 50% strongly agree with at least one of the following statements:
• PEU1: “Wikipedia is user-friendly”
• SA3: “It is important that students become familiar with online collabo-
rative environments”
Less than 50% engage in more than one of the following activities:
• Use2: using Wikipedia as a platform to develop educational activities
with students
• Exp4: contributing to Wikipedia
Charts for illustration are shown in Fig. A.7.
3. For each domain, we can summarize the responses to the question Exp1: “I
consult Wikipedia for issues related to my field of expertise.” The following
stacked bar chart shows that in Engineering & Architecture, at least 50% of
faculty members use Wikipedia often or very often. On the other hand, the
majority of faculty members from Law & Politics rarely or never consult
Wikipedia to inform on issues related to their field.
(very) often sometimes rarely, never
Eng. & Archit.
Sciences
Arts & Human.
Social Sci.
Health Sci.
Law & Politics
0% 25% 50% 75% 100%
Fig. A.4. Frequency of faculty members consulting Wikipedia by field of expertise
As the following figure shows, a similar association can be observed for
the practice of citing Wikipedia—which, however, appears to be much less
common across all fields. This suggests that Wikipedia is being used by
academic authors as a starting point for research more often than what
could be inferred from citation counts.


================================================================================
PAGE 323
================================================================================

310 Exercises with answers
(very) often sometimes rarely, never
Eng. & Archit.
Sciences
Arts & Human.
Social Sci.
Health Sci.
Law & Politics
0% 25% 50% 75% 100%
Fig. A.5. Frequency of faculty members citing Wikipedia in academic papers
Answer 4. Base rate fallacy. Cf. [18, 19]. It is true that if COVID vaccines
were to provide full protection from the disease, then no vaccinated individuals
would get infected or sick. Consequently, we would find no such individuals
among the fatalities of the disease.
However, in reality, vaccines do not provide full protection; they are not 100%
effective [20, 21]. Consequently, a high base vaccination rate in the general
population implies high vaccination rates among COVID fatalities as well. In
order to understand and internalize this fact, it may be instructive to consider
the following hypotheticals:
• If COVID vaccines had no effect on mortality at all, we would find that the
proportion of vaccinated individuals among those dying from the disease is
equal to the proportion among the general population, i.e., 95% for higher
age groups and 80% for individuals of lower age.
• If every individual among the population was vaccinated, we would find
a vaccination rate of 100% among fatalities, no matter how effective the
vaccine.
Theactualdatashowthattheproportionofvaccinatedindividualsamongthose
dying from COVID-19 is considerably lower than the proportion of vaccinated
people among the general population. Thus, the data do not support the
hypothesis that COVID vaccines are generally harmful.
Note that adverse, possibly severe reactions after vaccination do happen. How-
ever, they are rare [22].
Answer 5. Birthday problem. Cf. [23, Sect. 4.7]. First, let us consider a
situation when N >365, i.e., there are more people than possible birthdays. In


================================================================================
PAGE 324
================================================================================

A.2. Answers 311
yevrus
EH4ikiw
eht
fo
scihpargomeD
.6.A
.giF
etaicossA
.icS
laicoS
rosseforP
.namuH
&
strA
tnatsissA
.tihcrA
&
.gnE
rerutceL
scitiloP
&
waL
rotcurtsnI
.icS
htlaeH
rehto
secneicS
%05
%04
%03
%02
%01
%0
%05
%04
%03
%02
%01
%0
60.0
40.0
40.0
30.0 20.0
20.0
10.0
00.0
00.0
05
04
03
02
01
0
07
06
05
04
03
02
ecneirepxe
fo
sraey
sraey
ni
ega


================================================================================
PAGE 325
================================================================================

312 Exercises with answers
rrraaaiiillliiimmmaaafff
eeemmmoooccceeebbb
ssstttnnneeeddduuutttsss
tttaaahhhttt
tttnnnaaatttrrrooopppmmmiii
sssiii
tttIII«««
»»»yyyllldddnnneeeiiirrrfff---rrreeesssuuu
sssiii
aaaiiidddeeepppiiikkkiiiWWW«««
»»»ssstttnnneeemmmnnnooorrriiivvvnnneee
eeevvviiitttaaarrrooobbbaaalllllloooccc
eeennniiilllnnnooo
hhhtttiiiwww
rewsna
on/rehto
rewsna
on/rehto
%41
%31
%15
%45
eerga
ylgnorts
%13
eerga
ylgnorts
%63
eerga
eerga
aaaiiidddeeepppiiikkkiiiWWW
ooottt
eeetttuuubbbiiirrrtttnnnoooccc
III«««
pppooollleeevvveeeddd
ooottt
mmmrrroooffftttaaalllppp
aaa sssaaa
aaaiiidddeeepppiiikkkiiiWWW
eeesssuuu
III«««
»»»))).........tttnnneeemmmeeevvvooorrrpppmmmiii
ssseeelllccciiitttrrraaa
,,,sssnnnoooiiisssiiivvveeerrr
,,,sssnnnoooiiitttiiidddeee(((
»»»ssstttnnneeeddduuutttsss
hhhtttiiiwww
ssseeeiiitttiiivvviiitttcccaaa
lllaaannnoooiiitttaaacccuuudddeee
rewsna
on/rehto
rewsna
on/rehto
%71
%62
%91
ylerar
reven
%25
%46
reven
%32
ylerar
yevrus
EH4ikiw
eht
ot
srewsna
detceleS
.7.A
.giF


================================================================================
PAGE 326
================================================================================

A.2. Answers 313
thatcase,theremustbeatleasttwopersonswhoshareabirthdaybecausethere
is no way to distribute the birthdays among the people without2 repetition.
Now, say that we have selected one person, and afterwards we then select
another. The two persons have different birthdays if the second person doesn’t
happen to have the same birthday as the first. This event has the probability
364/365=1− 1 . A third person has one of the remaining 363 birthdays with
365
probability 363/365=1− 2 . And so on and so forth. Independent probabilities
365
multiply, so if N ≤365, then the probability that all of the N people have a
different birthday is given by the following product:
(cid:18) 1 (cid:19) (cid:18) 2 (cid:19) (cid:18) N −1 (cid:19) N Y −1 (cid:16) n (cid:17)
1− · 1− ··· 1− = 1−
365 365 365 365
n=1
The probability p that at least two people share the same birthday is given by
N
one minus this number because that is the complementary event. The following
figure is a plot of that probability as a function of N:
1.00
0.95
0.75
0.50
0.25
0 20 40 60 80
N
p
N
Fig. A.8. Probability that two people share a birthday
As noted before, p = 100% if N ≥ 366. Furthermore, p ≥ 50% if N ≥ 23
N N
and p ≥95% if N ≥47. Thus, in a room with more than 50 people, it is very
N
likely that at least two of them share a birthday.
Answer 6. Exponential distribution. The cumulative distribution function
of an exponentially distributed random variable X is given as follows, with
u>0:
2 This is an application of the so-called pigeonhole principle.


================================================================================
PAGE 327
================================================================================

314 Exercises with answers
Z u Z u
F (u)= Exp(ξ|λ)dξ = λe−λξdξ
X
−∞ 0
= −e−λξ(cid:12) (cid:12) u =1−e−λu
ξ=0
The median of X is the number m[X] where F
X
(m[X])=1/2 , that is:
1 ln(2)
1−e−λ·m[X] = ⇔m[X]=
2 λ
The mean is given by the following integral which can be solved by integration
by parts:
Z u Z ∞
E[X]= ξ·λe−λξdξ = λξe−λξ(cid:12) (cid:12) ∞ + e−λξdξ
ξ=0
0 0
=0−0+ −1 e−λξ (cid:12) (cid:12) (cid:12) ∞ = 1
λ (cid:12) λ
ξ=0
Similarly:
Z u Z ∞
E[X2]= ξ2·λe−λξdξ = λξ2e−λξ(cid:12) (cid:12) ∞ +2 ξe−λξdξ
ξ=0
0 0
2
=
λ2
Thus, the variance of X is given by:
2
(cid:18)
1
(cid:19)2
1
σ2[X]=E[X2]−(E[X])2 = − =
λ2 λ λ2
Given observations of positive numeric values x ,...,x , the log-likelihood
1 N
function for the exponential distribution is the following:
N N
X X
ℓ(λ)= ln(λe−λxn)=Nln(λ)−λ x
n
n=1 n=1
We can compute its first and second derivative:
N
dℓ N X
(λ)= − x ,
dλ λ n
n=1
d2ℓ N
(λ)=− <0
dλ2 λ2
The second derivative is negative everywhere, so the log-likelihood is maximized
at the zero of the first derivative:
N
!−1
λˆ =N · X x =(x¯ )−1
n arithm
n=1


================================================================================
PAGE 328
================================================================================

A.2. Answers 315
Answer 7. Box–Muller transform. Cf. [24]. We define the following new
random variables which represent the random vector (X,Y)T in polar coordi-
nates:
√
R= −2lnV, Θ =2πW
The joint probability distribution functions are related as follows:
1
p (r·cosθ,r·sinθ)= ·p (r,θ)
X,Y r R,Θ
where the factor “1/r ” is produced by the Jacobian determinant.
Since V and W are independent, R and Θ are independent as well:
p (r,θ)=p (r)·p (θ)
R,Θ R Θ
Clearly, Θ provides a uniformly distributed polar angle. Thus, on the interval
of interest, the density is constant: p (θ)= 1 . As for the radial variable, we
Θ 2π
notice that
√
f(v)= −2lnv ⇒f−1(r)=e−r 2 2
and apply the usual transformation formula:
(cid:12) (cid:12)
p R (r)=p f(V) (r)=p V (f−1(r))· (cid:12) (cid:12) (cid:12)d d r f−1(r) (cid:12) (cid:12) (cid:12) =r·e−r 2 2
Plugging these results into the formula for the joint probability density yields
the following result:
1
p (r·cosθ,r·sinθ)= ·p (r)·p (θ)
X,Y r R Θ
=e−r 2 2 · 1
2π
Expressing this result in Cartesian coordinates (x,y) with r2 =x2+y2 shows
that it is the product of two standard normal distributions:
p X,Y
(x,y)=e−x2+
2
y2
· 2
1
π
= √ 1 e−x 2 2 · √ 1 e−y 2 2
2π 2π
Answer 8. Simpson’s paradox. Cf. [25, 26] and [27, Chap. 2, Sect. 4]. The
dataareBernoullidistributedwithanestimatedprobabilityofsuccess/admission
p and p for female and male applicants, respectively. We can calculate the
x y
variance from those probabilities: s2(x) = p (1−p ) and s2(y) = p (1−p ).
x x y y
Thus, the test score for the one-sided Z-test computes to:


================================================================================
PAGE 329
================================================================================

316 Exercises with answers
s
p (1−p ) p (1−p )
z∗(0.99)· x x + y y =
N N
x y
r
0.3·(1−0.3) 0.45·(1−0.45)
2.33· + =3.3%
1835 2691
This Z-test gives a smaller value than the observed difference of 15%. Thus, at
a confidence level of 99%, the data are not consistent with the null hypothesis
“female applicants are at least as likely to be admitted as male applicants.”
For each department, we can compute the two-sided test score (z(0.99)=2.58)
and compare that score with the absolute value of the observed difference in
admission rate, |p −p |. From the available data, we can also compute the rate
y x
of admission for each department, irrespective of gender:
N ·p +N ·p
p= x x y y
N +N
x y
The results are summarized in a table:
dept. p N N p −p z
x y y x
A 64% 108 825 -20% 10%
B 63% 25 560 -5% 25%
C 35% 593 325 +3% 9%
D 34% 375 417 -2% 9%
E 25% 393 191 +4% 10%
F 6% 341 373 -1% 5%
all 39% 1835 2691 +15% 4%
Table A.3. Analysis of university admission rates
OnlydepartmentAexhibitsasignificantdifferenceinadmissionrates.Contrary
to the comparison across all departments, it is in favor of female applicants.
Departments A and B are the departments where applicants are the most likely
to succeed in being admitted, by a large margin. 51% of male applicants choose
these departments to apply for but only 7% of all female applicants do so.
Therefore, the data are consistent with the hypothesis that female applicants
are more likely to apply for more competitive studies, which implies that they
are more likely to be rejected.
Answer 9. Expected root mean squared error of random guessing.
For convenience, we write Y =Y and Yˆ =Yˆ .
m m
The predictions are chosen from a continuous uniform distribution on the unit
interval, and we know the mean and the variance of this distribution:
1 1
E[Yˆ]= , σ2[Yˆ]=
2 12


================================================================================
PAGE 330
================================================================================

A.2. Answers 317
Those values imply E[Yˆ2]=(E[Yˆ])2+σ2[Yˆ]=1/3 . Furthermore:
E[(Y −Yˆ)2]=E[Y2]−2E[Y]·E[Yˆ]+E[Yˆ2]
1 1
=E[Y2]−E[Y]+ =−E[Y ·(1−Y)]+
3 3
1
≤
3
We can apply Jensen’s inequality (the square root is a concave function) and
the fact that the random variables are i.i.d.:
E   M 1 X M (Y m −Yˆ m )2 !1 2  ≤ E " N 1 X M (Y m −Yˆ m )2 #!1 2
m=1 m=1
q r 1
= E[(Y −Yˆ)2]≤ <0.58
3
Answer 10. Data transformations. An invertible affine transformation
appliedtoeverydatapointhasnoimpactontheresultsofeitherlinearregression
or logistic regression.
The argument in more detail: the linear term in either objective function that
depends on the model parameters w ,...,w can be written as PD x w
0 D d=0 d d
where x=(x ,...,x )T is one of the data points augmented by a one in the
0 D
zeroth component. Suppose that we transform the data point(s): z =A·x with
A being an invertible matrix of format (D+1)×(D+1). A short calculation
shows that applying the transformation to the data is the same operation as
applying its transpose to the model parameters:
D D D ! D D !
X X X X X
z w = A x w = x A w
d d dk k d d kd k
d=0 d=0 k=0 d=0 k=0
In terms of the objective function R(parameters;data), we may therefore write:
R(w;z)=R(w;A·x)=R(AT·w;x).Applyingthechainruleyieldsthefollowing
result:
gradR(w;z)=AT ·gradR(AT ·w;x)
Thus, vˆ is a critical point of the objective function with respect to the trans-
formeddataifandonlyifwˆ =AT·vˆisacriticalpointwithrespecttotheoriginal
data. Both situations are equivalent because they yield the same predictions for
the target/latent variable when applied to test data x or z , respectively:
∗ ∗
f(x ;wˆ)=wˆT ·x = (cid:0) AT ·vˆ (cid:1)T ·A−1·z
∗ ∗ ∗
=vˆT ·A·A−1·z =vˆT ·z
∗ ∗
=f(z ;vˆ)
∗


================================================================================
PAGE 331
================================================================================

318 Exercises with answers
Mean-centering preserves pairwise distances between data points. Applied to
the already mean-centered data, the full Karhunen–Loève transform is an
orthogonal map, and therefore it preserves distances as well. This means that
neither mean-centering nor the full Karhunen–Loève transform have an impact
on determining the nearest neighbors of data points. They also don’t change
the value of the objective function for K-means cluster analysis.
Computing the standard scores, on the other hand, implies dividing by the
variance which is a scaling operation that is, in general, non-uniform. Non-
uniform scaling does not preserve distances. Thus, if the distance measure is
not transformed as well, standardizing the data has an impact3 on determining
the K nearest neighbors, or clusters with the K-means algorithm.
Answer11.Parkinson’sdiseasedetection. Thisandthefollowingsolutions
have been written in Python. The code can be executed, for example, in Colab
[4].
First, we can download the data directly from the UC Irvine Machine Learning
Repository:
import pandas as pd
url = "https://archive.ics.uci.edu/ml/
machine-learning-databases/parkinsons/parkinsons.data"
,→
df = pd.read_csv(url)
df.set_index("name", inplace = True, drop = True)
Next, we apply some prepocessing to the data:
# drop rows with missing values (if present)
df.dropna(inplace = True)
# set proper data types
df = df.astype(float)
# set named labels
labels = ['healthy', 'PD']
df["status"] = df["status"].replace({0: labels[0], 1:␣
labels[1]})
,→
The following code will randomly select 60% of the data (117 records) to be
used for training. The remaining data records (78) are held back for testing:
3 In practice, this effect of standardization is often welcomed, as standardization
eliminates the need for a choice of units and leads to an equal contribution from
each feature.


================================================================================
PAGE 332
================================================================================

A.2. Answers 319
from sklearn.model_selection import train_test_split
X = df.drop(["status"], axis = 1)
y = df["status"]
X_train, X_test, y_train, y_test = train_test_split(X, y,␣
test_size = 0.4, random_state = 42)
,→
With a few lines of code, we can standardize the data. Since the algorithm
should not be informed by the test data in any way during the training step,
we estimate the mean and standard deviation from the training data only:
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
Z_train = scaler.fit_transform(X_train)
Z_test = scaler.transform(X_test)
Wecansummarizethemodelsfortheexperimentstoberuninasingledictionary.
For each model, we define a range of hyperparameters to be explored via grid
search.ThedistancemeasurefortheK-nearestneighborclassifierisnotspecified
in the exercise; we can decide to use the Euclidean metric. The hidden layer of
the neural network is activated with a rectified linear unit:
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import f1_score, make_scorer,␣
classification_report
,→
experiments = [
{"name": "logistic regression w/ L2",
"model": LogisticRegression(penalty = "l2",␣
random_state = 42, solver = "lbfgs", max_iter = 1000),
,→
"param_grid": {"C": np.arange(0.05, 1.5, 0.05)}},
{"name": "KNN",
"model": KNeighborsClassifier(metric = "euclidean"),
"param_grid": {"n_neighbors": np.arange(1, 20)}},
{"name": "neural network",
"model": MLPClassifier(solver = "lbfgs", alpha = 0.
0, random_state = 42, max_iter = 1000, activation = "relu"),
,→
"param_grid": {"hidden_layer_sizes": np.arange(5,␣
20)}}
,→
]


================================================================================
PAGE 333
================================================================================

320 Exercises with answers
Finally, for every model, we train and determine the hyperparameters via 5-
fold cross-validation, and afterwards we then print a classification report that
includes the measures for goodness of fit asked for by the exercise:
scorer = make_scorer(f1_score, pos_label = "PD")
result = pd.DataFrame(columns = ["name", "accuracy",␣
"precision", "recall", "f1 score"])
,→
for exp in experiments:
# train and validate the model
model = GridSearchCV(exp["model"], exp["param_grid"], cv =␣
5, scoring = scorer)
,→
model.fit(Z_train, y_train)
# test the model
y_pred = model.predict(Z_test)
print(exp["name"], "-- opt. hyperparam.:", model.
best_params_)
,→
print("\n", classification_report(y_test, y_pred,␣
target_names = model.classes_), "\n")
,→
The optimal regularization parameter for the logistic regression is given by
β =1.43; the optimal number of neighbors for KNN is given by K =1; and the
optimal width of the hidden layer of the neural network was determined to be
D =9.
1
75% of the data records in the test dataset describe audio recordings of patients
suffering from Parkinson’s disease. Therefore, any machine learning algorithm
we train should achieve an accuracy of at least 75% in order to beat majority
classassignment.Wecansummarizetheinformationfromthereportsasfollows:
precision recall F -score accuracy
1
logistic regression (L ) 89% 95% 92% 87%
2
KNN 98% 97% 97% 96%
neural network 93% 95% 94% 91%
majority vote (baseline) 74% 100% 85% 74%
Table A.4. Performance of classifiers applied to the Oxford Parkinson’s Disease
Detection Dataset
Answer 12. Customer segmentation. We download the data from the
UC Irvine Machine Learning Repository and then apply the necessary steps of
normalization and standardization:
import pandas as pd


================================================================================
PAGE 334
================================================================================

A.2. Answers 321
url = "https://archive.ics.uci.edu/ml/
machine-learning-databases/00292/
,→
Wholesale%20customers%20data.csv"
,→
X = pd.read_csv(url)
# Channel 1: hotel/restaurant/cafe
# Channel 2: retail
X.drop(X[X["Channel"] == 2].index, inplace = True)
X.drop(columns = ["Region", "Channel"], inplace = True)
# store proportions of spendings instead
X = X.div(X.sum(axis = 1), axis = 0)
# standardize data
Z = (X - X.mean()) / X.std()
We run the K-means algorithm on the prepared data:
from sklearn.cluster import KMeans
K = 4
kmeans = KMeans(n_clusters = K, random_state=42, n_init␣
="auto")
,→
kmeans.fit(Z)
labels = pd.DataFrame({"cluster": kmeans.predict(Z)}, index =␣
X.index)
,→
Z = Z.join(labels)
Finally, we summarize the cluster centroids into one table:
Z.groupby("cluster").mean().round(2)
The above command produces the following output when printed:
Fresh Milk Grocery Frozen Detergents_Paper Delicassen
cluster
0 -1.31 0.94 1.63 -0.67 1.73 -0.40
1 0.85 -0.49 -0.45 -0.43 -0.33 -0.34
2 -0.30 -0.34 -0.34 1.43 -0.25 -0.18
3 -0.93 1.13 0.44 -0.30 -0.10 1.58
Table A.5. Cluster centroids of customer segments produced by K-means
Compared with customers from other groups, those in group #1 spend mostly
onfreshproducts,whereasthoseingroup#2preferfrozenproducts.Customers
from the remaining groups spend above average on milk and grocery products.


================================================================================
PAGE 335
================================================================================

322 Exercises with answers
However, customer group #0 spends significantly more on detergents/paper
products, whereas #3 predominantly buys delicatessen products.
Answer 13. Concrete compressive strength prediction. The loading
and preprocessing of the data are similar to what is required for the exercise on
Parkinson’s detection. For the solution of this exercise, we select 70% of the
data (721 records) for training and 309 data records for testing.
Afterwards,weapplytheYeo–Johnsontransform.Tomakesurethatallvariables
operate on the same scale, we standardize both raw data and transformed data.
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import PowerTransformer
linscaler = StandardScaler()
Z_train = linscaler.fit_transform(X_train)
Z_test = linscaler.transform(X_test)
powerscaler = PowerTransformer(method = "yeo-johnson",␣
standardize = True)
,→
W_train = powerscaler.fit_transform(X_train)
W_test = powerscaler.transform(X_test)
The code for training and testing is also very similar; we use 8-fold cross
validation to tune the hyperparameters:
import numpy as np
from sklearn.linear_model import Ridge
from sklearn.neural_network import MLPRegressor
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import r2_score, mean_squared_error
experiments = [
{"name": "ridge regression",
"model": Ridge(max_iter = 1000, solver = "svd",␣
random_state = 42),
,→
"param_grid": {"alpha": np.arange(0.0, 5.0, 0.01)},
"powertrans": False},
{"name": "Yeo-Johnson + ridge regression",
"model": Ridge(max_iter = 1000, solver = "svd",␣
random_state = 42),
,→
"param_grid": {"alpha": np.arange(0.0, 5.0, 0.01)},
"powertrans": True},
{"name": "neural network",
"model": MLPRegressor(solver = "lbfgs", alpha = 0.0,␣
random_state = 42, max_iter = 2000, activation = "relu"),
,→


================================================================================
PAGE 336
================================================================================

A.2. Answers 323
"param_grid": {"hidden_layer_sizes": np.arange(3, 7)},
"powertrans": False},
{"name": "Yeo-Johnson + neural network",
"model": MLPRegressor(solver = "lbfgs", alpha = 0.0,␣
random_state = 42, max_iter = 2000, activation = "relu"),
,→
"param_grid": {"hidden_layer_sizes": np.arange(3, 7)},
"powertrans": True}
]
for exp in experiments:
# train and validate the model
model = GridSearchCV(exp["model"], exp["param_grid"], cv =␣
8, scoring = "r2")
,→
if exp["powertrans"]:
model.fit(W_train, y_train)
y_pred = model.predict(W_test)
else:
model.fit(Z_train, y_train)
y_pred = model.predict(Z_test)
# test the model
print(exp["name"], "-- opt. hyperparam.:", model.
best_params_)
,→
print("\nR^2 score:", round(r2_score(y_test, y_pred), 3))
print("RMSE:", round(mean_squared_error(y_test, y_pred,␣
squared = False), 3), "\n")
,→
Theoptimalregularizationparameterfortheridgeregressionisgivenbyβ =2.17
when using the raw data and β = 3.67 based on the transformed data. The
optimal number of neurons in the hidden layer of the neural network is given
by D =3 on the raw data and D =6 on the transformed data.
1 1
The mean squared error for the predictor that assigns every outcome the mean
of the target variable is equal to the variance of the target variable, which
implies that the coefficient of determination vanishes. The standard deviation
of the compressive strength values (estimated from the test data) is given by
16.5MPa.
r2 RMSE
ridge regression 60% 10.5MPa
Yeo–Johnson + ridge regression 80% 7.4MPa
neural network 82% 7.1MPa
Yeo–Johnson + neural network 86% 6.3MPa
mean (baseline) 0% 16.5MPa
Table A.6. Performance of regression models applied to the Concrete Compressive
Strength Dataset


================================================================================
PAGE 337
================================================================================

324 Exercises with answers
References
[1] Eduard Aibar et al. wiki4HE. UCI Machine Learning Repository. 2015.
doi: 10.24432/C50031.
[2] Antoni Meseguer-Artola et al. “Factors that influence the teaching use
of Wikipedia in higher education”. In: Journal of the Association for
Information Science and Technology 67.5 (Feb. 2015), pp. 1224–1232. doi:
10.1002/asi.23488.
[3] RStudioTeam.RStudio:IntegratedDevelopmentEnvironmentforR.Posit,
PBC. Boston, MA, 2022. url: http://www.rstudio.com/.
[4] Google Research. Colaboratory. Frequently Asked Questions. Accessed
April 1, 2023. url: https://research.google.com/colaboratory/faq.html.
[5] Andrew Bridgen [@ABridgen]. Devastating stats from New Zealand, how
can anyone deny the vaccine harms now? UK stats May to Dec 2022
should be released tomorrow. Twitter. Feb. 20, 2023. url: https://twitter.
com/ABridgen/status/1627687430835916802.
[6] Statistics New Zealand. COVID-19 data portal. Accessed Feb. 22, 2023.
url: https://www.stats.govt.nz/experimental/covid-19-data-portal/.
[7] Edouard Mathieu et al. “A global database of COVID-19 vaccinations”.
In: Nature Human Behaviour 5.7 (May 2021), pp. 947–953. doi: 10.1038/
s41562-021-01122-8.
[8] New Zealand Ministry of Health. COVID-19: Vaccine data. Accessed
Feb. 22, 2023. url: https://www.health.govt.nz/covid-19-novel-
coronavirus/covid-19-data-and-statistics/covid-19-vaccine-data.
[9] The pandas development team. pandas-dev/pandas: Pandas 1.4.4. Aug.
2022. doi: 10.5281/zenodo.3509134.
[10] Wes McKinney. “Data Structures for Statistical Computing in Python”.
In: Proceedings of the 9th Python in Science Conference. Ed. by Stéfan
vanderWaltandJarrodMillman.2010,pp.56–61. doi:10.25080/Majora-
92bf1922-00a.
[11] F.Pedregosaetal.“Scikit-learn:MachineLearninginPython”.In:Journal
of Machine Learning Research 12 (2011), pp. 2825–2830.
[12] Andrew Ma, Kenneth K Lau, and Dominic Thyagarajan. “Voice changes
in Parkinson’s disease: What are they telling us?” In: Journal of Clinical
Neuroscience 72 (Feb. 2020), pp. 1–7. doi: 10.1016/j.jocn.2019.12.029.
[13] Max A. Little. Oxford Parkinson’s Disease Detection Dataset. UCI Ma-
chine Learning Repository. 2008. doi: 10.24432/C59C74.
[14] MaxA.Littleetal.“SuitabilityofDysphoniaMeasurementsforTelemoni-
toringofParkinson’sDisease”.In:IEEE Transactions on Biomedical Engi-
neering 56.4 (Apr. 2009), pp. 1015–1022. doi: 10.1109/tbme.2008.2005954.
[15] MargaridaCardoso.WholesaleCustomersDataset.UCIMachineLearning
Repository. 2014. doi: 10.24432/C5030X.
[16] I-Cheng Yeh. Concrete Compressive Strength. UCI Machine Learning
Repository. 2007. doi: 10.24432/C5PK67.


================================================================================
PAGE 338
================================================================================

References 325
[17] I.-C. Yeh. “Modeling of strength of high-performance concrete using
artificial neural networks”. In: Cement and Concrete Research 28.12 (Dec.
1998), pp. 1797–1808. doi: 10.1016/s0008-8846(98)00165-3.
[18] Martin Bauer [@martinmbauer]. This is a @ABridgen, a member of
parliament in the UK with a science degree, unable to grasp the concept
of a base rate. He is making a very strong case for more mandatory
math education here. Twitter. Feb. 21, 2023. url: https://twitter.com/
martinmbauer/status/1627820248144441346.
[19] UlrichHoffrageetal.“CommunicatingStatisticalInformation”.In:Science
290.5500 (Dec. 2000), pp. 2261–2262. doi: 10.1126/science.290.5500.2261.
[20] DanielR.Feikinetal.“DurationofeffectivenessofvaccinesagainstSARS-
CoV-2 infection and COVID-19 disease: results of a systematic review
and meta-regression”. In: The Lancet 399.10328 (Mar. 2022), pp. 924–944.
doi: 10.1016/s0140-6736(22)00152-0.
[21] JonathanJ.Lauetal.“Real-worldCOVID-19vaccineeffectivenessagainst
the Omicron BA.2 variant in a SARS-CoV-2 infection-naive population”.
In: Nature Medicine 29.2 (Jan. 2023), pp. 348–357. doi: 10.1038/s41591-
023-02219-5.
[22] U.S.NationalCenterforImmunizationandRespiratoryDiseases(NCIRD),
DivisionofViralDiseases.Selected Adverse Events Reported after COVID-
19 Vaccination. Accessed Feb. 23, 2023. url: https://www.cdc.gov/
coronavirus/2019-ncov/vaccines/safety/adverse-events.html.
[23] I. J. Good. Probability and the Weighing of Evidence. Charles Griffin,
1950.
[24] George E. P. Box and Mervin E. Muller. “A Note on the Generation of
Random Normal Deviates”. In: The Annals of Mathematical Statistics
29.2 (June 1958), pp. 610–611. doi: 10.1214/aoms/1177706645.
[25] Colin R. Blyth. “On Simpson’s Paradox and the Sure-Thing Principle”.
In: Journal of the American Statistical Association 67.338 (June 1972),
pp. 364–366. doi: 10.1080/01621459.1972.10482387.
[26] P. J. Bickel, E. A. Hammel, and J. W. O’Connell. “Sex Bias in Gradu-
ate Admissions: Data from Berkeley”. In: Science 187.4175 (Feb. 1975),
pp. 398–404. doi: 10.1126/science.187.4175.398.
[27] David Freedman, Robert Pisani, and Roger Purves. Statistics. 4th ed. W.
W. Norton & Company, Feb. 2007.


================================================================================
PAGE 339
================================================================================

B
Mathematical preliminaries
This appendix provides a quick reference for the mathematical concepts from
linear algebra and multivariate calculus that were used in this book. It is not
intended to serve as a textbook (see, for example, [1, 2, 3, 4, 5]), nor does it
replace a proper course on the subject matter. Basic arithmetic and univariate
calculus are assumed to be familiar subjects to the reader.
B.1 Basic concepts
B.1.1 Numbers and sets
Real numbers can be used to quantify the result of a measurement or compu-
tation to arbitrary precision. A real number may be positive, zero, or negative.
√
Examples of real numbers are: 0.35, −1, 2, π =3.14159....
2
Real numbers can be ordered: either two real numbers are equal or one of them
is smaller than the other. We write x<y if the number x is smaller than y, for
example: 1.1<1.2. We write x≤y to mean “x is less than or equal to y.”
The absolute value |x| of a real number x is its nonnegative value without
regardtoitssign,forexample: |−2|=2,or|2|=2.Thefloor functionrounds
a real number down to the closest integer, while the ceiling function rounds
up: ⌊2.3⌋=2, ⌈2.3⌉=3.
A natural number is a nonnegative integer. Natural numbers can be used for
counting or enumerating objects.
A set M is a “gathering together of definite, distinct objects of our intuition or
of our thought (which are called the ‘elements’ of M) into a whole” (translated1
from [6]). An example of a set that contains three natural numbers is the
1 Unter einer ,Menge’ verstehen wir jede Zusammenfassung M von bestimmten
wohlunterschiedenen Objecten unsrer Anschauung oder unseres Denkens (welche
die ,Elemente’ von M genannt werden) zu einem Ganzen.
© Springer-Verlag GmbH Germany, part of Springer Nature 2023 327
M. Plaue, Data Science, https://doi.org/10.1007/978-3-662-67882-4


================================================================================
PAGE 340
================================================================================

328 Mathematical preliminaries
following: M ={2,3,5}. The order of elements plays no role in the definition of
a set: {2,3,5}={5,3,2}.
We write |M| for the number of elements contained in M. However, a set may
also contain an infinite number of elements. The set of all natural numbers is
an example of such a set: N={0,1,2,3,4,...}. The set of all real numbers is
another example, denoted by R.
A set M is called of countably infinite size if there exists a one-to-one
correspondencebetweenelementsofNandelementsofM.Suchacorrespondence
is also called a bijective map, see further below. In other words, although M
has an infinite number of elements, we may enumerate all of them without
repetition. The set of integers is an example of a countably infinite set: Z =
{0,−1,1,−2,2,...}.
Sets can be declared via properties of their elements. The set of prime numbers,
for example, can be written as:
P ={n|n is a natural number that has exactly two distinct divisors}
GivenasetM,ifxisanelementofM,wewritex∈M asashorthandnotation,
and x̸∈M otherwise. The set with no elements is called the empty set and is
denoted by ∅.
Basic operations on sets are the intersection, union, and difference of two
sets M and N:
M ∩N ={x|x∈M and x∈N},
M ∪N ={x|x∈M or x∈N},
M \N ={x|x∈M and not x∈N}
Note that, in mathematics, the words “and,” “or,” and “not” have well-defined
meanings as part of a propositional expression that might not always coincide
witheverydayusage.Inparticular,“or” is not exclusive:anelementthatbelongs
to both sets is also an element of their union.
These operations can be illustrated with the following diagrams:
M N
M N M N
M \N
M ∩N M ∪N
Fig. B.1. Set operations
Two sets M and N are called disjoint if they have no element in common:
M ∩N =∅.


================================================================================
PAGE 341
================================================================================

B.1. Basic concepts 329
If every element of M is also an element of N, we call M a subset of N. We
write M ⊆N as the shorthand notation. Any set is also a subset of itself—if
we want to exclude that situation, we write M ⊂N and call M a proper subset
of N.
Important subsets of the set of real numbers are the intervals, i.e., all numbers
that lie between two given numbers a and b:
]a,b[={x|x∈R, x>a, x<b}
Theaboveformularepresentsthedefinitionofanopen interval—iftheendpoints
are included, it is a closed interval:
[a,b]={x|x∈R, x≥a, x≤b}
Furthermore, we refer to half-open intervals that exclude only one of the end-
points, and unbounded intervals like the following:
[a,∞[={x|x∈R, x≥a}
B.1.2 Maps and functions
Let X and Y be sets. A map f from X to Y assigns each element x of X to
exactly one element y of Y. The set X is called the domain of f, and Y the
codomain. Given a map f and some fixed element in its domain x, we write
f(x) to denote the unique element that x is assigned to. We write the following
as a shorthand for those statements:
f: X →Y, x7→f(x)
We may also write f(·) instead of f to make it clear that the object in question
is a map that takes an argument to produce a result.
A map can also be called a function, a term that is often used when the map
produces real numbers. An example of a function is
√ √
·: [0,∞[→R, x7→ x
which maps every nonnegative real number onto its square root. The term
transformation is generally reserved for maps where domain and codomain
coincide.
The image of some subset of the domain, U ⊆ X, under f is the following
subset of the codomain:
f(U)={y|y ∈Y and there exists some x∈U with y =f(x)}
The image of the whole domain under f—i.e., f(X)—is also simply called the
image of f, or the range of f. The preimage of some subset of the codomain,
V ⊆Y, is defined as follows:


================================================================================
PAGE 342
================================================================================

330 Mathematical preliminaries
f−1(V)={x|x∈X and there exists some y ∈V with y =f(x)}
By the definition of a map, we must always have f−1(Y)=X, because every
element of the domain needs to be assigned a value from the codomain. A map
does not necessarily map onto its whole codomain, though. For example, the
range of the exponential function
exp: R→R, x7→ex,
where e=2.71828... is Euler’s number, is given by the set of all positive real
numbers.
We say that a map f: X →Y is surjective if Y =f(X). It is called injective
ifu̸=v impliesf(u)̸=f(v)forallu,v ∈X.Amapisbijectiveifandonlyifit
is both surjective and injective. A simple but important example for a bijective
map is the identity map on some set X, which assigns every element to itself:
id : X →X, x7→x
X
Given two maps f: X →Y and g: W →Z with f(Y)⊆W, we may define the
composition of those maps as follows:
g◦f: X →Z, x7→g(f(x))
Given some map f: X → Y, a map g: Y → X is called an inverse of f if
g◦f =id and f ◦g =id hold. It turns out that, if an inverse exists, it must
X Y
be unique, and we may denote it by f−1. Furthermore, a map has an inverse if
and only if it is bijective.
If we restrict the codomain of the exponential function to the positive numbers,
it has an inverse that is given by the natural logarithm:
ln: ]0,∞[→R, x7→ln(x)=log (x)
e
The following figure shows the graphs of those functions.
ex
2
ln(x)
1
x
−2 −1 1 2
−1
−2
Fig. B.2. Graphs of exponential and logarithmic functions


================================================================================
PAGE 343
================================================================================

B.1. Basic concepts 331
We will make extensive use of both the exponential function and logarithms
throughout this book. Therefore, we should recall some basic properties:
ex·ey =ex+y, (ex)y =ex·y, ln(ex)=x
for any x,y ∈R, and
ln(x)+ln(y)=ln(x·y), y·ln(x)=ln(xy), eln(x) =x
for any x,y ∈R with x,y >0.
B.1.3 Families, sequences and tuples
A sequence s is an ordered, not necessarily finite list of not necessarily distinct
objects. The famous Fibonacci sequence in which each number is the sum of
the two preceding ones may serve as an example:
s=(s ,s ,...)=(0,1,1,2,3,5,8,13,21,34,55,...)
1 2
A tuple t is a finite sequence, for example t = (2,5,2). For sequences and
tuples, the order of elements matters: (2,5,2)̸=(2,2,5). A tuple with exactly
two elements may be called an (ordered) pair.
The Cartesian product of a collection M ,...,M of sets is the set of all
1 D
tuples with D elements that we may build from elements of those sets:
M ×···×M ={(x ,...,x )|x ∈M ,...,x ∈M }
1 D 1 D 1 1 D D
We can also define Cartesian powers. For example, the set of all tuples of real
numbers of length D may be written as follows:
R×···×R=RD ={(x ,...,x )|x ∈R,...,x ∈R}
1 D 1 D
| {z }
Dtimes
We may identify nested tuples with simple tuples by appropriate omitting of
parentheses, for example:
(x,(y,z))∼ =((x,y),z)∼ =(x,y,z)
By a similar abuse of notation, we may also identify a singleton with the unique
element that it contains: (x)∼ =x.
Finally,an(indexed) family isamapA: I →X wherewecallI theindex set,
and that we rather write as (A ) , or just (A ) for short, instead of i7→A(i).
i i∈I i
For example, an infinite sequence s can be seen as a family that is indexed
by the set of natural numbers: (s n ) n∈N —or (s n ) n∈{1,2,...} if we prefer to start
counting from one.
For an indexed family of sets—i.e., A is a set for every i∈I—we may define
i
the intersection/union of all of the sets in the family:


================================================================================
PAGE 344
================================================================================

332 Mathematical preliminaries
\
A ={x|for every i∈I, x∈A }
i i
i∈I
[
A ={x|there exists some i∈I with x∈A }
i i
i∈I
B.1.4 Minimum/maximum and infimum/supremum
SupposethatM isasetofrealnumbers.The minimumofM isthesmallestof
the numbers contained in M, and we denote this number by minM. Similarly,
the maximum is denoted by maxM. For example, min{2,3,5} = 2 and
max{2,3,5}=5. Similarly, we can determine the smallest and largest elements
in a sequence of real numbers (x ), written as min {x } and max {x }.
n n n n n
The minimum or maximum may not exist. For example, the open interval ]2,5[
has neither minimum nor maximum.
We define a lower bound of M to be any a∈R such that a≤x for all x∈M.
The infimum of M is a greatest lower bound, i.e., a lower bound b∈R such
that a≤b for any lower bound a of M. It turns out that if an infimum exists, it
is uniquely determined. If the set has a minimum, it coincides with the infimum.
The supremum is defined as the least upper bound. For example: inf]2,5[=2
and sup]2,5[=5.
We can apply those definitions to the range of a function f: X → R. In this
case, we write inf
ξ∈X
{f(ξ)} and sup
ξ∈X
{f(ξ)}. For example, inf ξ∈R{eξ} = 0.
The supremum of the exponential function does not exist, but it is custom to
write sup {eξ}=∞ if the function has no upper bound.
ξ∈R
B.2 Linear algebra
B.2.1 Vectors and points
The set of all tuples of real numbers with D elements is denoted by RD.
An element x of RD may be written as x = (x ,...,x ), where each x ,
1 D d
d∈{1,...,D} denotes a real number.
An element of RD can be interpreted as both a vector or a point. When we
say “vector,” we mean the object to represent a direction and a scale. Vectors
may change direction and scale via the operations of vector addition and scalar
multiplication, as explained below. On the other hand, a “point” denotes a
specific location in D-dimensional space.
For D =2, we may illustrate vectors and points in the coordinate plane—here
is a selection of three points and their position vectors drawn as arrows that
connect them with the origin:


================================================================================
PAGE 345
================================================================================

B.2. Linear algebra 333
x
2
(1.5,3)
(−1.8,2) 2
(3,1)
x
1
−2 2
−1
Fig. B.3. Points and vectors
We define the dot product between two vectors x and y with the same number
of entries as follows:
D
X
x•y =x ·y +x ·y +···+x ·y = x ·y
1 1 2 2 D D d d
d=1
Here, we have also introduced summation notation “P.” Products can be
denoted with “Q” instead. Two vectors v,w of real numbers are orthogonal if
and only if v•w =0.
The Euclidean distance between points is the following nonnegative number,
which is the length of the line segment that connects those points:
v
u D
uX
δ(x,y)=t (x −y )2
d d
d=1
The Euclidean norm, length, or magnitude of a vector is closely related:
v
u D
uX
∥x∥=t (x )2
d
d=1
Any vector v that is not the zero vector (i.e., at least one entry of v is not
zero) can be normalized (i.e., scaled to unit length) by dividing by its norm:
v 7→v/∥v∥ .
B.2.2 Matrices
A column vector is a vector that we arrange vertically, for example:
 
0.3
x=−0.5
1.1


================================================================================
PAGE 346
================================================================================

334 Mathematical preliminaries
A row vector is arranged horizontally. More generally, a matrix A is a
rectangular arrangement. The following is an example of a matrix with three
rows and two columns, or 3×2-matrix for short:
 
0.3 −0.1
A=−0.5 2.2 
1.1 −2.2
A matrix can be transposed by exchanging rows with columns:
(cid:18) (cid:19)
0.3 −0.5 1.1
AT =
−0.1 2.2 −2.2
If A = AT holds for a matrix A, that matrix is called symmetric. It must
necessarily be square, i.e., have as many columns as it has rows.
A computer program may store vectors and matrices as arrays. Vectors or
matrices of the same format can be added by adding them entry by entry. For
example:
(cid:18) (cid:19) (cid:18) (cid:19) (cid:18) (cid:19) (cid:18) (cid:19)
0.3 0.3 0.3+0.3 0.6
+ = =
−0.5 0.5 −0.5+0.5 0.0
Similarly, we may multiply a matrix/vector by a single real number—in this
context called a scalar—by multiplying each entry of the matrix/vector with
that number.
Wemayalsocomputetheproductoftwovectorsormatrices AandB.However,
regular matrix multiplication is not multiplication entry by entry. Rather,
the product A·B is computed according to the following rule: the entry located
in the m-th row and the n-th column of A·B is given by the dot product of
the m-th row of A with the n-th column of B. For example:
     
0.3 −0.1 (cid:18) (cid:19) 0.3·0.6+(−0.1)·0.0 0.18
0.6
−0.5 2.2 · =(−0.5)·0.6+2.2·0.0=−0.30
0.0
1.1 −2.2 1.1·0.6+(−2.2)·0.0 0.66
In order for this product to be defined, the number of columns of A must be
equal to the number of rows of B. Matrix multiplication relates to transposition
via the following rule: (A·B)T =BT ·AT.
The determinant of a square matrix of format 2×2 may be computed as
follows:
(cid:18) (cid:19)
a b
det =a·d−b·c
c d
This number is the signed area of the parallelogram spanned by the column
vectors. It turns out to be equal to the signed area spanned by the row vectors,
as illustrated in the following figure:


================================================================================
PAGE 347
================================================================================

B.2. Linear algebra 335
x
2
(a+c,b+d)
(a,b)
|a·d−b·c|
(c,d)
x
1
Fig. B.4. Area of a parallelogram; determinant of a matrix
The determinant of a 3×3-matrix is the signed volume of the parallelepiped
spannedbythecolumn/rowvectors.Moregenerally,thedeterminantofasquare
matrixofformatD×DisdeterminedbythesignedvolumeoftheD-dimensional
parallelotope that is spanned by the column/row vectors.
B.2.3 Subspaces and linear maps
Linear combinations of vectors v ,...,v are terms of the form λ v +···+
1 K 1 1
λ v with scalars λ ,...,λ .
K K 1 K
A finite set or tuple of vectors is called linearly independent if none of the
vectors can be written as a linear combination of the others.
Given vectors v ,...,v , we can study the subspace that they span:
1 K
( X K (cid:12) (cid:12) )
span(v ,...,v )= λ v (cid:12)λ ,...,λ ∈R
1 K k k(cid:12) 1 K
(cid:12)
k=0
The dimension of a subspace is the minimum number of linearly independent
vectors needed to span that space.
For example, let us consider the subspace in three-dimensional space that is
spanned by the following column vectors:
     
0 1 2
v
1
=1, v
2
=0, v
3
=1
0 0 0
We notice that v = v +2·v , so those vectors are linearly dependent. The
3 1 2
linearly independent vectors v and v suffice to span the subspace, which is a
1 2
two-dimensional plane. More generally, subspaces of D-dimensional space that
have dimension D−1 are called hyperplanes.


================================================================================
PAGE 348
================================================================================

336 Mathematical preliminaries
Suppose that A is a square matrix of format D×D. For any column vector x of
lengthD,thematrixmultiplicationA·xproducesanewcolumnvectoroflength
D. We may thus interpret the assignment x7→A·x as a map f : RD →RD.
A
A map of this form is linear—that is, it commutes with vector addition and
scalar multiplication:
A·x+A·y =A·(x+y) and A·(λ·x)=λ·(A·x)
for any x,y ∈RD and λ∈R.
The image of a linear map is a subspace, its dimension is called the rank of
that linear map/the matrix A.
If a linear map has an inverse, that inverse can also be written as a matrix
multiplication. The corresponding matrix is the inverse of A, denoted by A−1.
An inverse of A exists if and only if the determinant of A does not vanish. The
transpose of an invertible matrix is invertible, and (cid:0) AT(cid:1)−1 = (cid:0) A−1(cid:1)T holds.
AnorthogonalmatrixV isamatrixthatwecansimplyinvertbytransposition,
i.e., it is invertible and V−1 = VT holds. An orthogonal matrix may also be
characterized by the fact that its columns are pairwise orthogonal and have
unit length. Orthogonal maps represent rotations, reflections, and compositions
thereof. As such, they preserve Euclidean distance: δ(V ·x,V ·y)=δ(x,y) for
all vectors x,y.
B.2.4 Eigenvectors and eigenvalues
Let A be some square matrix, representing a linear map. Assume that v is
a vector that is not the zero vector and that there is some λ ∈ R such that
A·v =λ·v. In that case, v is called an eigenvector of A to eigenvalue λ.
In general, the linear map may change the direction of its input, so that the
outputA·xisnot amultipleofx.TheeigenvectorsofAdenotethosedirections
where it is.
For example, the following matrix reflects every vector with respect to the
x -axis:
2
(cid:18) (cid:19)
−1 0
R=
0 1
As can be easily checked, v = (1,0)T is an eigenvector of R with eigenvalue
1
λ =−1, and v =(0,1)T is an eigenvector with eigenvalue λ =1:
1 2 2
R·v =−v , R·v =v
1 1 2 2
Thesedirectionscorrespondtotheaxisofreflectionandthedirectionorthogonal
to that axis:


================================================================================
PAGE 349
================================================================================

B.3. Multivariate calculus 337
x
2
v 2 R·v 2
R·v v
1 1
x
1
x R·x
Fig. B.5. Reflection in the plane
For diagonal matrices like R, i.e., when all entries outside the main diagonal
are zero, determining the eigenvalues is easy: they are the entries which are
exactly on the diagonal.
Suppose that A is a square matrix. We may say that A:
• is positive definite if all of its eigenvalues are positive,
• is positive semidefinite if all of its eigenvalues are nonnegative,
• is indefinite if it has both positive and negative eigenvalues.
Negative (semi-)definite matrices satisfy analogous conditions.
Oneveryusefulfactthathasmanyapplicationsisthefollowing(see,forexample,
[3, Sect. 6.4] or [5, Sect. 1.14]): If S is a symmetric matrix of format D×D,
there exists an orthogonal matrix V and a diagonal matrix Λ such that the
following holds:
S =V ·Λ·VT
Furthermore, the diagonal entries λ ,...,λ of Λ are the eigenvalues, while the
1 D
columns v ,...,v of V are the corresponding normalized eigenvectors of S.
1 D
B.3 Multivariate calculus
B.3.1 Limits
In this section, by “sequence” we mean an infinite sequence with values in RD
for some fixed D ≥ 1. Such a sequence can be written as a list of numbers
(D =1) or vectors (D >1) that does not end: (ξ )=(ξ ,ξ ,...) with every ξ
n 1 2 n
being an element of RD.
Given some sequence (ξ ) with values in RD, an accumulation point of that
n
sequence is any ξ ∈RD, so that no matter how small we choose some positive
∞


================================================================================
PAGE 350
================================================================================

338 Mathematical preliminaries
distance ε>0 there are an infinite number of elements in the sequence within
that distance from ξ . If the sequence has exactly one accumulation point ξ ,
∞ ∞
we say that it converges to ξ and write the following formula:
∞
ξ = lim ξ
∞ n
n→∞
Forexample,thesequenceofnumbers ξ =(−1)n hasexactlytwoaccumulation
n
points:−1and1.Thesequenceξ =nhasnoaccumulationpoint.Thesequence
n
ξ = 1 converges to the value zero: lim 1 =0.
n n n→∞ n
The sequence of points in R2 given by the formula ξ = (1,1− 1) starts at
n n n
ξ =(1,0) and converges to the point ξ =(0,1):
1 ∞
x
2
ξ
∞
1
ξ
1 x
1
1
Fig. B.6. Convergent sequence in the plane
B.3.2 Continuous functions
Let f be some vector-valued function with domain X ⊆RD:
 
f (x ,...,x )
1 1 D
.
f: X →RK, (x 1 ,...,x D )7→  . .  
f (x ,...,x )
K 1 D
The number D denotes the dimension of the domain, and K is the dimension of
the codomain. The graph of f is the set of points (x,f(x))∈RD×RK, where
x varies over the domain.
Now, suppose that K =1, i.e., the codomain is the real number line. In other
words, f is a scalar-valued function that just returns a single value. If the
domain has low dimensionality, we may illustrate the function by drawing its
graph:
• Univariate functions. The simplest case is D = 1, which includes the
elementaryfunctionsstudiedinbasicunivariatecalculus,likelogarithms,ex-
ponentialfunctions,trigonometricfunctions(likesineorcosine),polynomials,
etc. These functions can be graphed in the usual way in the 2-dimensional
coordinate plane.


================================================================================
PAGE 351
================================================================================

B.3. Multivariate calculus 339
• Bivariate functions, surfaces. For D =2, we can also draw the graph
of f but in 3-dimensional space. If the function is sufficiently regular (i.e.,
continuous, differentiable—as explained in the following), that graph is now
a surface. See Fig. B.9 for an example.
If the function is vector-valued (K > 1), we may still be able to interpret it
geometrically and draw a visual representation.
• Curves.ForD =1andK =2,theimage off (ifsufficientlyregular)traces
a curve in the plane. For D =1 and K =3, the function traces a curve in
3-dimensional space.
• Vector fields. For D = 2 and K = 2, we may interpret the function as
a vector field in the plane: every point in the domain is assigned a vector.
We may draw that vector as an arrow (possibly rescaled in length to avoid
clutter) for a suitable selection of points, e.g., on a regular grid.
1
0.5
0
−0.5
−1
−1 −0.5 0 0.5 1
u
v
Fig. B.7. Plot of the vector field (u,v)7→(−v,u)
The functions, graphs, curves, and vector fields that we study and like to model
dataandobservationswithshouldbesufficiently regular.Forexample,wewould
frequentlyimposetheconditionthatthefunctiondoesnotexhibitlargechanges
in value given small changes in its argument.
In order to formalize that idea, let us assume that we are given some function
f: X →RK with X ⊆RD, and fix some point ξ ∈RD. Suppose that there
∞
exists at least one sequence (ξ ) that takes values in X and converges to ξ ,
n ∞
and that for all those sequences the corresponding (f(ξ )) converge to the same
n
value y . Then, the following limit is well-defined:
∞
y = lim f(ξ)
∞
ξ→ξ∞


================================================================================
PAGE 352
================================================================================

340 Mathematical preliminaries
Now, fix a point x∈X. We say that the function f is continuous at x if:
f(x)= limf(ξ)
ξ→x
Moreinformally,wecanimaginewalkingaroundthedomaintowardssomevalue
x, taking the steps ξ ,ξ ,... along the way. We may say that f is continuous
1 2
at x if the corresponding function values f(ξ ),f(ξ ),... always approach f(x)
1 2
just the same.
It turns out that a function is continuous if and only if every one of its scalar
componentfunctionsf ,...,f iscontinuous.Sums,products,andcompositions
1 K
of continuous scalar functions are continuous. Multivariate monomials—i.e.,
(x
1
)i1···(x
D
)iD with i
1
,...,i
D
∈N—are continuous functions. Thus, an exam-
ple of a continuous function would be the following:
 u2+v2
f: R2 →R3, (u,v)7→u+5·v
u·v
B.3.3 Differentiable functions
The derivative of a differentiable univariate function f is the slope of the
tangent line to the graph. It is defined as the limit of the difference quotient
α−1·(f(x+α)−f(x)) as α approaches zero.
We want to generalize this concept to the multivariate case where f: X →RK
with X ⊆RD. Let x∈X be a point within the function’s domain, and h∈RD
with ∥h∥=1 be a unit column vector that we imagine to point away from x.
Suppose that we may choose α > 0 so that the line segment that connects
x−αh and x+αh is entirely contained in the domain X, and secondly so that
the following limit exists:
f(x+α·h)−f(x)
D f(x)= lim
h α→0 α
In that case, the above vector is the derivative of f in the direction of
h at x. If all directional derivatives exist and are continuous, the function is
called continuously differentiable at x. The derivatives in the direction of
the coordinate axes e ,...,e are called the partial derivatives of f and are
1 D
also denoted as follows:
∂f
∂ f(x)= (x)=D f(x)
d ∂x ed
d
Furthermore, it turns out that if the function is continuously differentiable, we
can write every directional derivative as D f(x) = Df(x)·h where Df(x) is
h
the Jacobian matrix that contains all of the partial derivatives:


================================================================================
PAGE 353
================================================================================

B.3. Multivariate calculus 341
 
∂ f (x) ∂ f (x) ... ∂ f (x)
1 1 2 1 D 1
∂
1
f
2
(x) ∂
2
f
2
(x) ... ∂
D
f
2
(x)
Df(x)=(∂ f(x),∂ f(x),...,∂ f(x))= . . 
1 2 D  . . . . 
 
∂ f (x)∂ f (x)...∂ f (x)
1 K 2 K D K
We may also denote the Jacobian as a total derivative, d f(x).
dx
Given known derivatives of univariate elementary functions, partial derivatives
are fairly easy to compute by keeping all but one variable fixed, treating the
others as constants. For example:
 u2+v2 
2u 2v

f(u,v)=u+5·v⇒Df(u,v)=1 5
u·v v u
The chain rule in multivariate calculus is given by the following formula:
D(g◦f)(x)=Dg(f(x))·Df(x)
In the following discussion, we will assume that f is continuously differentiable
and scalar-valued, i.e., f: X →R with X ⊆RD. The gradient of f is given by
the transposed Jacobian, which is the column vector that contains all partial
derivatives:
 ∂f (x)
∂x1.
gradf(x)=∇f(x)=(Df(x))T = . . 
 
∂f (x)
∂xD
A level set of f is the preimage of some fixed constant value c∈R, i.e., the
set f−1({c}). The gradient of a scalar function at some point is either zero, or
perpendicular to the level set at that point. If it is nonzero, the gradient points
in the direction in which the values of the function exhibit the largest increase,
and its magnitude is equal to the rate of that increase. For D =2, a level set
is either empty, a single point, or a curve that is called a contour line: see
Fig. B.9.
Let us further assume that f is twice continuously differentiable, i.e., the vector
field gradf: X →RD is continuously differentiable. In that case, we may write
down the Hessian matrix (also referred to as just Hessian) of second partial
derivatives:
 
∂ ∂ f(x) ∂ ∂ f(x) ... ∂ ∂ f(x)
1 1 2 1 D 1
∂
1
∂
2
f(x) ∂
2
∂
2
f(x) ... ∂
D
∂
2
f(x)
Hessf(x)=Dgradf(x)= . . 
 . . . . 
 
∂ ∂ f(x)∂ ∂ f(x)...∂ ∂ f(x)
1 D 2 D D D
Under the conditions given here, it turns out that the Hessian must be a sym-
metric matrix: it holds that ∂ ∂ f(x)=∂ ∂ f(x) for all m,n∈{1,...,D}.
m n n m


================================================================================
PAGE 354
================================================================================

342 Mathematical preliminaries
We may use the gradient and the Hessian to locate minimum and maximum
points of f. A local minimum point of f is any point x ∈ X such that
min
there exists some ε>0 so that for any point x∈X within distance ε of x it
min
holds that f(x)≥f(x ). A local maximum is defined analogously.
min
A boundary point of X is a point so that at any positive distance from that
point we can find points in X as well as points not in X. It turns out that every
local minimum or maximum point that is not a boundary point of X must be a
stationary point, i.e., the gradient vanishes at that point. Suppose that x is
c
a stationary point of f: gradf(x )=0. Then, the following holds:
c
• x is a local maximum of f if Hessf(x ) is negative definite,
c c
• x is a local minimum of f if Hessf(x ) is positive definite,
c c
• x isneitheralocalminimumnoramaximumof f ifHessf(x )isindefinite.
c c
Forexample,thegradientofthefunctionf: R2 →Rwithf(u,v)=u·e−(u2+v2)
is the following vector field:
gradf(u,v)=e−(u2+v2)·
(cid:18) 1−2u2(cid:19)
−2uv
The gradient vanishes at the points (−1/ √ 2,0) and (1/ √ 2,0). Calculating second
derivatives and plugging those stationary points into the Hessian matrix yields
the following results:
Hessf(∓1/ √ 2,0)= √ 2e−1 2 · (cid:18) ±2 0 (cid:19)
0 ±1
These are diagonal matrices, so we may read off their eigenvalues from the
diagonal: the Hessian at (−1/ √ 2,0) is a positive definite matrix, at (1/ √ 2,0) it is
negative definite. Thus, the function has a local minimum at (−1/ √ 2,0) and a
local maximum at (1/ √ 2,0).
We conclude this section with a list of some derivatives known from basic
calculus that are used in this book (r ∈R is an arbitrary constant):
f(x) xr ex ln(x) sin(x) cos(x) arcsin(x) arctan(x)
√
f′(x) r·xr−1 ex 1/x cos(x) −sin(x) 1/ 1−x2 1/1+x2
Table B.1. Derivatives of elementary functions
B.3.4 Integrals
In basic univariate calculus, we may compute the signed area under the graph
of a continuous function f: [a,b]→R via an integral. The fundamental theorem
of calculus implies that we may compute the integral as follows:
Z b
f(ξ)dξ =F(b)−F(a)
a


================================================================================
PAGE 355
================================================================================

B.3. Multivariate calculus 343
where F: [a,b]→R is an antiderivative of f. That is, F is continuous, and the
derivative of F exists on the open interval and is equal to f.
Suppose now that we are given instead a bivariate, continuous function f: X →
R with X ⊆R2, and that we may write X as a normal domain of integration:
X ={(u,v)∈R2|a≤u≤b, α(u)≤v ≤β(u)}
whereα: [a,b]→Randβ: [a,b]→Rarecontinuousfunctionswithα(u)≤β(u)
for all u∈[a,b].
v
β(u)
X
α(u)
u
a b
Fig. B.8. Normal domain of integration
We want to compute the signed volume under the graph of f. It turns out that
this volume is given by the following iterated integral:
!
Z b Z β(u)
f(ξ)dξ = f(u,v)dv du
x
a α(u)
X
If the domain of integration is a rectangle, X = [a,b]×[c,d], the order of
integration can be exchanged—this is known as Fubini’s theorem:
! !
Z b Z d Z d Z b
f(ξ)dξ = f(u,v)dv du= f(u,v)du dv
x
a c c a
X
Integration by substitution in univariate calculus is given by the following
formula:
Z φ(b) Z b
f(η)dη = f(φ(ξ))·φ′(ξ)dξ
φ(a) a
where φ: [a,b]→R is continuously differentiable with range inside the domain
of f.


================================================================================
PAGE 356
================================================================================

344 Mathematical preliminaries
The corresponding formula in bivariate calculus is the following:
f(η)dη = f(φ(ξ))·|det(Dφ(ξ))| dξ
x x
φ(X) X
where φ: X →R2 is continuously differentiable and injective.
We will apply the above formula to compute the Gaussian integral that plays
a prominent role in probability theory and statistics:
Z ∞
G=
e−ξ2
dξ
−∞
First of all, we note that the square of our goal integral G is a double integral2
over the plane:
Z ∞ (cid:18)Z ∞ (cid:19)
e−(u2+v2)dudv
=
e−u2 e−v2
dv du
x
R2 −∞ −∞
Z ∞ (cid:18)Z ∞ (cid:19)
=
e−u2
·
e−v2
dv du
−∞ −∞
(cid:18)Z ∞ (cid:19) (cid:18)Z ∞ (cid:19)
=
e−u2
du ·
e−v2
dv
−∞ −∞
=G2
As an integral over a positive function, G is a positive number, so the square
root of the double integral is equal to G.
We compute this double integral via the following change of variables3 (intro-
ducing polar coordinates):
(cid:18) (cid:19)
r·cos(θ)
φ: [0,∞[×[0,2π[→R2, (r,θ)7→
r·sin(θ)
The Jacobian matrix is given as follows:
(cid:18) (cid:19)
cos(θ)−r·sin(θ)
Dφ(r,θ)=
sin(θ) r·cos(θ)
The Jacobian determinant:
det(Dφ(r,θ))=r·(cos(θ))2−(−r·(sin(θ))2)=r
where we have used the trigonometric identity (cos(θ))2+(sin(θ))2 =1.
2 This is an improper integral, and mathematical rigour would call for discussing
definition and existence of limits. However, we will omit these details.
3 Thattransformationisnotinjectiveattheorigin,butsinglepointsmaybeexcluded
without changing the value of the integral.


================================================================================
PAGE 357
================================================================================

B.3. Multivariate calculus 345
Thus, via the substitution z(r)=r2 in the end:
Z 2π(cid:18)Z ∞ (cid:19)
e−(u2+v2)dudv
=
e−r2
rdr dφ
x
R2 0 0
Z ∞
=2π·
e−r2
rdr
0
1Z ∞
=2π· e−zdz
2
0
=π
Therefore, the final result for the Gaussian integral is given as follows:
Z ∞ √
e−ξ2
dξ = π
−∞


================================================================================
PAGE 358
================================================================================

346 Mathematical preliminaries
0.5
v
2
−2
u
2
−2
−0.5
1
0
−1
−1 0 1
u
v
Fig. B.9. Graph of the bivariate function
(u,v)7→u·e−(u2+v2)
(top), contour lines
and gradient (bottom)


================================================================================
PAGE 359
================================================================================

References 347
References
[1] Michael Spivak. Calculus on Manifolds. A Modern Approach to Classical
Theorems of Advanced Calculus. Philadelphia, PA: Westview Press, Jan.
1971.
[2] Michael Spivak. Calculus. 3rd ed. Cambridge, England: Cambridge Uni-
versity Press, June 2006.
[3] Gilbert Strang. Introduction to Linear Algebra. 5th ed. Wellesley, MA:
Wellesley-Cambridge Press, Aug. 2016.
[4] Gilbert Strang. Calculus. 3rd ed. Wellesley, MA: Wellesley-Cambridge
Press, Sept. 2017.
[5] JanR.Magnus.MatrixDifferentialCalculuswithApplicationsinStatistics
and Econometrics. 3rd ed. Wiley, Feb. 2019. doi: 10.1002/9781119541219.
[6] Georg Cantor. “Beiträge zur Begründung der transfiniten Mengenlehre”.
In: Mathematische Annalen 46.4 (Nov. 1895), pp. 481–512. doi: 10.1007/
bf02124929.


================================================================================
PAGE 360
================================================================================

Supplementary literature
The mathematical prerequisites necessary for understanding this book are
taughtinacademiccoursesonlinearalgebraand(multivariate)calculus. Matrix
Differential Calculus with Applications in Statistics and Econometrics by Jan R.
Magnus is a self-contained text that covers all that groundwork [1]. The books
by Strang [2, 3] and Spivak [4, 5] come recommended. The mathematically
inclined reader might enjoy Foundations of Modern Analysis [6] by Dieudonné,
andadvancedbooksonlinearalgebrahavebeenwrittenbyKostrikinandManin
[7] and Halmos [8].
For further reading, I would like to refer to the following texts.
Data organization. The Data Management Body of Knowledge [9] by the
international Data Management Association provides a comprehensive overview
that extends far beyond the scope of this book. Entity–relationship modeling
is covered by Bernhard Thalheim [10], whereas graph-based data models in
general—and the graph database neo4j in particular—are the subject of a book
by Ian Robinson et al. [11]. For those who would like to study the mathematical
theory of graphs in more detail, the classic book by Harary is recommended
[12].
Probability theory and statistics. With Probability: Theory and Examples,
Rick Durrett provides a mathematically well-founded overview of probability
theory, covering important topics like central limit theorems [13]. Also recom-
mended to mathematically inclined readers is the classic text by Fisz [14] and
thesomewhatmorerecentvolumebyCasellaandBerger[15].RomanVershynin,
in his book High-Dimensional Probability, highlights the essential mathematical
concepts and results that are the basis for the analysis of high-dimensional data
[16]. Gunnar Carlsson and Mikael Vejdemo-Johansson have recently published
a book on topological data analysis [17]. Finally, the Encyclopedia of Distances
is entirely devoted to the topic of distance measures [18].
Machine learning. Recommended classics on machine learning and pattern
recognition are Pattern Classification, by Duda, Hart, and Stork [19], and
© Springer-Verlag GmbH Germany, part of Springer Nature 2023 349
M. Plaue, Data Science, https://doi.org/10.1007/978-3-662-67882-4


================================================================================
PAGE 361
================================================================================

350 Supplementary literature
The Elements of Statistical Learning, by Hastie, Tibshirani, and Friedman [20],
together with its companion book that aims at making the methods accessible
to a wider audience [21]. Theodoridis and Koutroumbas also share a wealth of
knowledge [22]. The volume by Ian Goodfellow et al. contains a comprehensive
accountofartificialneuralnetworks[23].FrançoisChollet,initiatoroftheKeras
deeplearningprogramlibrary,istheauthorofpracticalbooksonthesubject[24,
25]. A compact and clear presentation of the core aspects of statistical learning
theory is provided in a review article by Ulrike von Luxburg and Bernhard
Schölkopf [26]. A recommended book on the subject is the text by Mehryar
Mohri et al. [27].
Other topics. The book by Tufte may serve as a classic reference on data
visualization[28],andStorytellingwithData byKnaflic[29]comesrecommended.
AstandardworkondigitalimageprocessingisthetextbookbyBerndJähne[30].
Jacob Eisenstein offers a modern introduction to natural language processing
[31]. Those who wish to know more about sentiment analysis can consult the
book by one of the field’s top experts, Bing Liu [32]. Perhaps the leading
introductory textbook in the scientific study of networks is the book by Mark
Newman [33].
Furthermore, Foundations of Data Science by Avrim Blum, John Hopcroft, and
Ravindran Kannan should not go unmentioned, which provides insight into a
wide variety of topics [34].
Finally, I’d like to call attention to Grant Sanderson’s YouTube channel
3Blue1Brown, which—among other interesting mathematical topics—features
entertaining and insightful introductions to neural networks [35] and Bayes’
theorem [36].


================================================================================
PAGE 362
================================================================================

References 351
References
[1] JanR.Magnus.MatrixDifferentialCalculuswithApplicationsinStatistics
and Econometrics. 3rd ed. Wiley, Feb. 2019. doi: 10.1002/9781119541219.
[2] Gilbert Strang. Introduction to Linear Algebra. 5th ed. Wellesley, MA:
Wellesley-Cambridge Press, Aug. 2016.
[3] Gilbert Strang. Calculus. 3rd ed. Wellesley, MA: Wellesley-Cambridge
Press, Sept. 2017.
[4] Michael Spivak. Calculus. 3rd ed. Cambridge, England: Cambridge Uni-
versity Press, June 2006.
[5] Michael Spivak. Calculus on Manifolds. A Modern Approach to Classical
Theorems of Advanced Calculus. Philadelphia, PA: Westview Press, Jan.
1971.
[6] Jean Dieudonné. Foundations of Modern Analysis. Academic Press, 1960.
[7] Alexei I. Kostrikin and Yuri I. Manin. Linear Algebra and Geometry.
Gordon and Breach Science Publishers, 1997.
[8] Paul R. Halmos. Finite-Dimensional Vector Spaces. Springer New York,
1974. doi: 10.1007/978-1-4612-6387-6.
[9] DAMA International. DAMA-DMBOK: Data Management Body of
Knowledge. Bradley Beach, NJ: Technics Publications, July 2021.
[10] Bernhard Thalheim. Entity–Relationship Modeling. Springer Berlin Hei-
delberg, 2000. doi: 10.1007/978-3-662-04058-4.
[11] Ian Robinson, Jim Webber, and Emil Eifrem. Graph Databases. 2nd ed.
Sebastopol, USA: O’Reilly, 2015.
[12] Frank Harary. Graph Theory. Reading, USA: Addison Wesley, 1969.
[13] Rick Durrett. Probability: Theory and Examples. 5th ed. Cambridge Uni-
versity Press, May 2019.
[14] Marek Fisz. Probability Theory and Mathematical Statistics. 3rd ed. John
Wiley & Sons, Dec. 1963.
[15] George Casella and Roger L. Berger. Statistical Inference. Pacific Grove,
USA: Duxbury Thomson Learning, 2001.
[16] Roman Vershynin. High-Dimensional Probability: An Introduction with
Applications in Data Science. Cambridge University Press, Sept. 2018.
doi: 10.1017/9781108231596.
[17] Gunnar Carlsson and Mikael Vejdemo-Johansson. Topological Data Anal-
ysis with Applications. Cambridge University Press, Nov. 2021. doi: 10.
1017/9781108975704.
[18] Michel Marie Deza and Elena Deza. Encyclopedia of Distances. Springer,
Berlin, Heidelberg, 2009. doi: 10.1007/978-3-642-00234-2.
[19] Richard O. Duda, Peter E. Hart, and David G. Stork. Pattern Classifica-
tion. 2nd ed. Wiley, 2000.
[20] Trevor Hastie, Robert Tibshirani, and Jerome Friedman. The Elements
of Statistical Learning: Data Mining, Inference, and Prediction. 2nd ed.
Springer, New York, 2009. doi: 10.1007/978-0-387-84858-7.
[21] Gareth James et al. An Introduction to Statistical Learning. With appli-
cations in R. 2nd ed. Springer Texts in Statistics. Springer, July 2021.


================================================================================
PAGE 363
================================================================================

352 Supplementary literature
[22] Sergios Theodoridis and Konstantinos Koutroumbas. Pattern Recognition.
4th ed. Academic Press, 2008.
[23] Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Deep Learning.
MIT Press, Nov. 2016. url: http://www.deeplearningbook.org/.
[24] Francois Chollet. Deep Learning with Python. 2nd ed. Manning Publica-
tions, Dec. 2021.
[25] Francois Chollet. Deep Learning with R. 2nd ed. Manning Publications,
July 2022.
[26] UlrikevonLuxburgandBernhardSchölkopf.“StatisticalLearningTheory:
Models, Concepts, and Results”. In: Handbook of the History of Logic.
Vol. 10. Amsterdam, Niederlande: Elsevier North Holland, May 2011,
pp. 651–706. doi: 10.1016/b978-0-444-52936-7.50016-1. arXiv:0810.4752.
[27] MehryarMohri,AfshinRostamizadeh,andAmeetTalwalkar. Foundations
of Machine Learning. 2nd ed. MIT Press, 2018.
[28] EdwardR.Tufte.The Visual Display of Quantitative Information.2nded.
Cheshire, CT: Graphics Press, Jan. 2001.
[29] Cole Nussbaumer Knaflic. Storytelling with Data. A Data Visualization
Guide for Business Professionals. Nashville, TN: John Wiley & Sons, Oct.
2015.
[30] Bernd Jähne. Digital Image Processing. 6th ed. Springer, 2005. doi: 10.
1007/3-540-27563-0.
[31] JacobEisenstein.IntroductiontoNaturalLanguageProcessing.MITPress,
2019.
[32] Bing Liu. Sentiment Analysis. 2nd ed. Studies in Natural Language
Processing. Cambridge University Press, Oct. 2020.
[33] Mark Newman. Networks. 2nd ed. Oxford University Press, July 2018.
[34] Avrim Blum, John Hopcroft, and Ravi Kannan. Foundations of Data
Science. Cambridge University Press, Jan. 2020. doi: 10.1017/978110875
5528.
[35] Grant Sanderson. 3Blue1Brown, Season 3: Neural networks. Aug. 2018.
url: https://youtube.com/playlist?list=PLZHQObOWTQDNU6R1_
67000Dx_ZCJB-3pi.
[36] Grant Sanderson. 3Blue1Brown: Bayes theorem, the geometry of changing
beliefs. Dec. 2019. url: https://youtu.be/HZGCoVF3YvM.


================================================================================
PAGE 364
================================================================================

Index
2D convolution................241 naive........................226
Bayes classifier...........217, 224
A Bayes error....................195
accuracy......................199
Bayes’ theorem.................76
activation function............229
bell curve.............97, 117, 149
Adam.........................281
Berkeley Earth..153, 155, 209, 215
additive smoothing............228
Bernoulli distribution..........113
aggregation.....................16
Bernoulli trial.................113
AI.............................187
Bessel correction...........51, 125
algorithm.....................185
BFGS method.................204
ALLBUS survey..43, 60, 131, 133,
bias...........................194
140, 145, 156
response.....................39
Anscombe’s quartet............ 58
bias–variance decomposition...194
approximation error...........195
bias–variance tradeoff.........194
Armijo rule....................205
big data........................11
artificial intelligence...........187
bin width.......................38
explainable..................281
binomial coefficient............114
generative...................277
birthday problem..............304
attribute.......................12
body mass index............37, 40
autoencoder...................258
Box–Cox transform............144
Box–Muller transform.........304
B
backpropagation...............235 Bravais–Pearson correlation
backtracking line search.......205 coefficient............55, 155
bag-of-words model............226 Broca index....................40
bar chart.......................38 bubble sort....................185
grouped......................42 business intelligence............. 1
stacked.......................42
Barzilai–Borwein method......203 C
base rate fallacy...............303 CDC survey.35, 38, 40, 51, 54, 56,
batch normalization...........281 122, 130, 136, 142, 148, 150,
Bayes classification 225
© Springer-Verlag GmbH Germany, part of Springer Nature 2023 353
M. Plaue, Data Science, https://doi.org/10.1007/978-3-662-67882-4


================================================================================
PAGE 365
================================================================================

354 Index
centroid..................154, 171 sample.......................55
Chebyshev’s inequality........102 covariance error ellipse........174
Chen notation..................13 covariance matrix.............175
chi-squared distribution.......107 regularized..................279
with one degree of freedom...88 sample......................173
choropleth map.................43 credibility interval.............148
CIFAR-10.....................280 critical value
circle chart.....................41 t-test.......................135
classification...................187 Z-test.......................133
binary......................188 Cromwell’s rule.................79
classifier.......................188 cross-correlation...............241
linear.......................189 cross-entropy.............232, 263
cluster analysis...........252, 264 cross-validation...........197, 279
agglomerative hierarchical...269 cumulative distribution function80
average-linkage..............270 empirical....................137
complete-linkage............270 joint.........................88
divisive hierarchical.........270 curse of dimensionality........254
fuzzy........................264
single-linkage...............270 D
CNN..........................243 data.............................1
codebook.......................22 high-dimensional............186
coefficient of determination153, 198 data analysis....................2
Cohen’s d.....................136 exploratory...................37
cohort..........................37 topological..................252
collaboration network.........288 data augmentation.........26, 281
community detection..........289 data deduplication..............27
complete case analysis..........25 data documentation.........12, 22
confidence band...............154 data engineering................12
confidence level................131 data generating process........111
confusion matrix..............199 data imputation................24
contingency table...............59 data integration................11
continuous mapping theorem..126 data item.......................14
convergence in distribution....126 data matrix...................162
convolution mean-centered..............162
of functions.................104 standardized...........162, 306
of images....................241 data mining.....................3
correlation.....................99 data model
correlation coefficient conceptual................11, 12
Kendall’s.....................58 graph-based..................18
Matthews’..................200 hierarchical..................20
Pearson’s....................55 logical....................11, 14
Spearman’s..................58 physical......................12
correlation matrix relational.....................14
sample......................173 data point......................37
cost matrix....................190 data preprocessing..............23
covariance......................99 data profiling...................22


================================================================================
PAGE 366
================================================================================

Index 355
data protection............22, 277 Poisson.....................114
data provenance................23 posterior....................146
data quality...............22, 301 prior........................146
data record.....................14 uniform......................69
data science.....................1 disturbance...................152
data source.....................11 domain.........................36
data standardization............24 doughnut chart.................41
data tuple......................14 dropout.......................238
data validation.................23
data versioning.................22 E
data visualization................2 edge detection.................242
database........................11 edit distance...................28
database management system...12 efficiency......................197
dataset.........................14 embedding....................251
training.....................186 emboss filter..................242
decision boundary...142, 158, 189 empirical risk minimzation.....191
decision rule...................188 entity.......................12, 36
Bayesian....................224 entity resolution................27
generalizable................191 entity type.....................12
deep learning..................229 entity–relationship diagram.....13
dendrogram...................270 entity–relationship model..12, 301
design matrix.................163 epoch.........................204
differential entropy.............98 error term.....................152
dimensionality.................162 estimate
intrinsic.....................251 interval.....................130
dimensionality reduction.......251 kernel density...............149
Dirac measure..................70 maximum a posteriori.......147
distance maximum likelihood.........140
Chebyshev..................164 estimation error...............195
Damerau–Levenshtein........28 estimator
Euclidean...................164 asymptotically unbiased.....125
Hamming...................166 consistent..............122, 124
Jaccard.....................168 unbiased....................121
Levenshtein..................28 event...........................69
Manhattan..................164 atomic.......................69
maximum...................164 complementary...............71
Minkowski..................165 elementary...................69
distance matrix...............169 event model
distribution Bernoulli....................228
binomial....................114 multinomial.................227
Cauchy–Lorentz.............117 events
exponential.................304 independent..................73
geometric...................114 evidence........................76
logistic......................157 expectation vector.............175
multinomial.................179 expected value..................93
Pareto......................118 empirical....................123


================================================================================
PAGE 367
================================================================================

356 Index
of a random vector/matrix..175 acyclic.......................19
experiment.....................68 directed......................17
undirected...................17
F grid search....................197
F -score.......................200
1
factorial..................107, 114 H
feature............12, 36, 152, 186 He initialization...............236
feature engineering............186 heatmap........................43
feature extraction.............254 heteroskedasticity.............212
feature selection...............254 hierarchical cluster analysis....269
feature space...................36 histogram..................38, 137
feature vector..............37, 161 holdout validation.............197
feedforward network...........229 homoskedasticity..............214
Fellegi–Sunter model............31 hub...........................289
Fermi function................230 hyperparameter tuning........197
flattening......................278 hyperparameters.....146, 188, 197
Fréchet mean..................173 hypothesis......................76
frequency alternative..................131
absolute......................53 null.........................131
joint.........................59 hypothesis in machine learning 188
marginal.....................59 hypothesis space..............188
relative.......................53
word........................285 I
frequency distribution..........35 image processing..............242
multimodal...............43, 52 ImageNet.....................244
skewed.......................47 IMDb....................284, 287
symmetric....................47 indicator function.............102
unimodal.....................43 information object..............12
frequency table.................35 information retrieval...........201
fuzzy search....................28 instance........................36
instance-based learning...219, 221
G interquartile range..............51
gamma function...............107 Iris flower dataset52, 165, 166, 172,
Gaussian integral...........85, 99 174
Gaussian mixture model.......266 irreducible error...............194
Gaussian process..............213
Gaussian process regression....214
J
Geary’s theorem...............134 Jaccard index...................61
generalization error............192 Jensen’s inequality..............97
Glivenko–Cantelli theorem.....137 Johnson–Lindenstrauss lemma.250
Glorot initialization...........236 join............................16
gradient descent...............202
full-batch...................204 K
mini-batch..................204 Kaggle........................284
simple......................203 Karhunen–Loève transform256, 306
stochastic...................204 Keras.........................281
graph kernel density estimation......149


================================================================================
PAGE 368
================================================================================

Index 357
kernel K-means algorithm.....269 L ..........................190
p
kernel smoothing..............150 quadratic...................190
kernel trick....................218 zero–one....................190
keyword extraction.............75
K-means algorithm............267 M
K-medoids algorithm..........268 machine learning..............186
K-nearest neighbors classification machine learning engineering..186
221 marginal density
Kolmogorov axioms.............69 of a multivariate normal
distribution..............178
L matrix
label......................186, 187 distance.....................169
label smoothing...............232 positive semidefinite.........175
Laplace operator..............242 similarity...................169
Laplace smoothing............228 Matthews’ correlation coefficient
Laplace’s rule..................69 200
LASSO........................208 max pooling...................243
latent space...................258 maximum a posteriori estimator147
law of large numbers maximum cardinality...........13
Bernoulli’s..................122 maximum likelihood estimator.140
Chebyshev’s.................124 maximum norm...............164
laws of large numbers.........118 maximum-a-posteriori estimator225
layer mean
convolution.................243 arithmetic....................46
fully-connected..............243 empirical.....................46
pooling.....................243 Fréchet.....................173
LDA..........................224 geometric....................49
learning harmonic.....................49
unsupervised................249 population...................47
learning rate..................203 mean absolute deviation........52
least squares method..........153 mean absolute error...........198
Lebesgue decomposition........80 mean filter....................242
Lidstone smoothing...........228 mean squared error.......153, 198
likelihood.......................76 mean substitution..............25
likelihood function............139 mean vector...................175
Likert scale....................302 empirical....................171
Lindeberg–Lévy central limit mean-centering......162, 172, 306
theorem..................126 measurement.................1, 36
line chart.......................37 measures
line graph......................37 of association................55
linear discriminant analysis....224 of central tendency...........43
linear separability.............218 of dispersion.................51
Lloyd’s algorithm..............267 of variation...................51
logit function..................227 median.........................93
log-likelihood function.........139 empirical.....................46
loss function...................190 geometric...................172


================================================================================
PAGE 369
================================================================================

358 Index
population...................47 P
sample.......................46 padding.......................241
medoid....................31, 173 paired data.....................55
metadata.......................12 Pareto distribution............140
metric.........................168 path-component...............252
discrete......................28 PCA..........................174
mini-batch....................204 Pearson correlation............155
min–max scaling..............163 percentile rank.................57
MNIST.........261, 262, 265, 278 perplexity.....................263
mode...........................43 pie chart........................41
model matrix..................163 PMI............................74
model parameters.............188 p-norm........................164
model selection................194 polarity.......................284
Moore–Penrose inverse........210 Popoviciu’s inequality..........98
multidimensional scaling.......259 population......................37
multigraph.....................17 posterior...................76, 146
mutual information precision......................199
pointwise.....................74 prediction band...............154
sample.......................59 prediction interval.............131
premetric.....................168
prevalence......................77
N
primary key....................14
name harmonization............31
principal axis..................256
natural language processing75, 284
principal component...........256
neural network................229
principal component analysis..255,
convolutional................243
256
feedforward.................229
principal coordinate...........256
residual.....................230
principal direction.............256
N-grams......................285
principle of indifference....69, 113
node–link diagram.........17, 288
principle of maximum entropy.117
norm
prior.......................76, 146
Euclidean...................164
empirical....................225
Minkowski..................164
improper....................146
normal distribution...97, 115, 141
noninformative..............147
multivariate.................176
probability
standard................84, 116
Bayesian.....................68
null hypothesis................111
conditional...................73
empirical.....................67
O frequentist...................68
object..........................36 posterior.....................76
object identification............27 prior.........................76
objective function........153, 202 probability density function.....83
observation.................36, 79 conditional...................90
outliers...............47, 117, 156 empirical....................139
overfitting.....................195 fat-tailed....................117
overlap coefficient.............167 joint....................89, 176


================================================================================
PAGE 370
================================================================================

Index 359
marginal.....................89 record linkage..................27
mixed joint...................89 rectified linear unit............231
multivariate.................176 rectifier
probability mass function.......82 leaky........................231
conditional...................90 regression.....................187
joint.........................88 kernel logistic...............219
multivariate.................179 linear..................151, 208
probability measure............69 logistic.................157, 216
probability of error............130 ridge........................208
projection......................15 regression function............188
property graph.................18 regression line.................152
psephology..........41, 61, 67, 75 regressor matrix...............163
Python.....................4, 306 regular expressions.............24
regularization.................195
Q elastic net...................196
QDA..........................224
L ..........................196
quadratic discriminant analysis224 p
relation.........................14
quanteda......................287
relational algebra...............15
quantile........................93
relationship type...............13
sample.......................48
ReLU.........................231
quantile function...............93
residual.......................153
quartile........................49
residual sum of squares...153, 210
quasi-Newton condition.......205
risk
empirical....................190
R
expected....................192
R...........................4, 283
robustness.................47, 156
random matrix................174
root mean square...............49
random search.................197
root mean squared error..153, 198
random variable............67, 79
absolutely continuous........80
continuous...................80 S
discrete......................80 Sammon projection............259
latent.......................157 sample.........................35
transformed..................85 sample space...................68
random variables scatterplot.....................39
i.i.d.........................123 selection........................16
independent and identically sensitivity.................76, 199
distributed...............123 sentiment analysis.............284
mutually independent........91 at aspect level..............286
uncorrelated.................99 set
random vector............162, 174 fuzzy........................264
random walk..................260 measurable...................69
range of a statistical variable...51 Shannon entropy...............98
rank of an observation..........57 empirical.....................53
raw data........................3 Shannon index.................53
realization..................67, 79 joint.........................59
recall..........................199 sigmoid function..............230


================================================================================
PAGE 371
================================================================================

360 Index
significance level...............130 Theil–Sen regression...........156
similarity time series.................37, 153
cosine.......................165 tokenization...................226
Jaccard.....................167 topic map................287, 288
Jaro..........................30 training dataset...............196
Jaro–Winkler................30 training error..................190
Szymkiewicz–Simpson.......167 tree............................20
Tanimoto...................166 trial............................68
similarity matrix..............169 t-SNE.........................263
Simpson’s paradox............305 type compatibility..............15
Slutsky’s theorem.............130
Sobel operator................242
U
softmax function..............231
UMAP........................264
softplus function...............231
uniform distribution............54
sonification......................2
continuous..................115
spaCy.........................287
discrete.....................112
spam filter............78, 190, 201
universal approximation property
specificity..................76, 199
235
SQL............................16
St. Petersburg paradox.........94
standard deviation.............96 V
validation dataset.............197
sample.......................51
variable
standard score.................162
statistical model...............112 binary........................37
statistical unit..................36 bivariate.....................37
statistics categorical...................36
Bayesian....................146 dependent..................152
descriptive...................35 dichotomous.................37
inferential...................111 explanatory.................152
steepest descent...............202 independent.................152
stochastics......................67 multivariate..................37
stopwords.....................287 nominal......................36
stress function.................259 numeric......................36
Student’s t-distribution........108 ordinal.......................36
Student’s t-test................132 qualitative...................36
subpopulation..................37 quantitative..................36
supervised learning............188 random......................79
support.........................81 response....................152
synapse.......................230 statistical.................12, 36
univariate....................37
T variance...................96, 194
t-distribution..................108 pooled......................137
TensorFlow....................281 sample.......................51
test dataset...................197 unbiased................51, 125
test error......................192 vector norm...................164
text mining...................287 vocabulary....................226


================================================================================
PAGE 372
================================================================================

Index 361
W Youden’s index................200
Weiszfeld’s algorithm..........172
X
Z
Xavier initialization...........236
z-score........................162
XML...........................21
Z-test
Y one-sample..................132
Yeo–Johnson transform........144 two-sample..................133

